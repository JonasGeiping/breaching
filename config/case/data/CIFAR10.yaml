
name: CIFAR10
path: "~/data"
size: 50_000
classes: 10
shape:
  - 3
  - 32
  - 32

normalize: True
mean:
  - 0.4914672374725342
  - 0.4822617471218109
  - 0.4467701315879822
std:
  - 0.24703224003314972
  - 0.24348513782024384
  - 0.26158785820007324

# Data-specific implementation constants:
batch_size: 128 # this is the maximum batchsize that fits onto the GPU for gradient accumulation

augmentations_train:
  RandomCrop:
    - 32
    - 4
  RandomHorizontalFlip: 0.5
augmentations_val:

caching: # dataset is alreay cached in RAM
# Database Setup # use the cmd-line to activate the LMDB module with data.db=LMDB
defaults:
  - db: none
