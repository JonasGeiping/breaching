{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# TAG: Gradient Attack on Transformer-based Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook shows an example for a **short sentence gradient inversion** as described in \"TAG: Gradient Attack on Transformer-based Language Models\". The setting is a BERT-base model and the federated learning algorithm is **fedSGD**.\n",
    "\n",
    "Paper URL: https://aclanthology.org/2021.findings-emnlp.305/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107d723",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "Although distributed learning has increasingly gained attention in terms of effectively utilizing local devices for data privacy enhancement, recent studies show that publicly shared gradients in the training process can reveal the private training data (gradient leakage) to a third-party. We have, however, no systematic understanding of the gradient leakage mechanism on the Transformer based language models. In this paper, as the first attempt, we formulate the gradient attack problem on the Transformer-based language models and propose a gradient attack algorithm, TAG, to reconstruct the local training data. Experimental results on Transformer, TinyBERT4, TinyBERT6 BERT_BASE, and BERT_LARGE using GLUE benchmark show that compared with DLG, TAG works well on more weight distributions in reconstructing training data and achieves 1.5x recover rate and 2.5x ROUGE-2 over prior methods without the need of ground truth label. TAG can obtain up to 90% data by attacking gradients in CoLA dataset. In addition, TAG is stronger than previous approaches on larger models, smaller dictionary size, and smaller input length. We hope the proposed TAG will shed some light on the privacy leakage problem in Transformer-based NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcd6cb",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import breaching\n",
    "except ModuleNotFoundError:\n",
    "    # You only really need this safety net if you want to run these notebooks directly in the examples directory\n",
    "    # Don't worry about this if you installed the package or moved the notebook to the main directory.\n",
    "    import os; os.chdir(\"..\")\n",
    "    import breaching\n",
    "    \n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Redirects logs directly into the jupyter notebook\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will load the full configuration object. This includes the configuration for the use case and threat model as `cfg.case` and the hyperparameters and implementation of the attack as `cfg.attack`. All parameters can be modified below, or overriden with `overrides=` as if they were cmd-line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case bert_training with server type honest_but_curious.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cuda'), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = breaching.get_config(overrides=[\"case=9_bert_training\", \"case/data=cola\", \"case.data.task=classification\",\n",
    "                                      \"attack=tag\"])\n",
    "          \n",
    "device = torch.device(f'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations for the attack, or the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 1 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [16] # This is the sequence length\n",
    "\n",
    "cfg.case.model=\"bert-sanity-check\"\n",
    "\n",
    "cfg.attack.optim.max_iterations = 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2272f",
   "metadata": {},
   "source": [
    "The following lines generate \"server, \"user\" and \"attacker\" objects and print an overview of their configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/jonas/data/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Model architecture bert-sanity-check loaded with 109,483,778 parameters and 1,024 buffers.\n",
      "Overall this is a data ratio of 6842736:1 for target shape [1, 16] given that num_queries=1.\n",
      "User (of type UserSingleStep) with settings:\n",
      "    Number of data points: 1\n",
      "\n",
      "    Threat model:\n",
      "    User provides labels: False\n",
      "    User provides buffers: False\n",
      "    User provides number of data points: True\n",
      "\n",
      "    Data:\n",
      "    Dataset: cola\n",
      "    user: 1\n",
      "    \n",
      "        \n",
      "Server (of type HonestServer) with settings:\n",
      "    Threat model: Honest-but-curious\n",
      "    Number of planned queries: 1\n",
      "    Has external/public data: False\n",
      "\n",
      "    Model:\n",
      "        model specification: bert-sanity-check\n",
      "        model state: default\n",
      "        public buffers: True\n",
      "\n",
      "    Secrets: {}\n",
      "    \n",
      "Attacker (of type OptimizationJointAttacker) with settings:\n",
      "    Hyperparameter Template: tag\n",
      "\n",
      "    Objective: Tag loss with scale=1.0, weight scheme linear, L1 scale 0.1 and task reg=0.0\n",
      "    Regularizers: \n",
      "    Augmentations: \n",
      "\n",
      "    Optimization Setup:\n",
      "        optimizer: bert-adam\n",
      "        signed: None\n",
      "        step_size: 0.05\n",
      "        boxed: False\n",
      "        max_iterations: 12000\n",
      "        step_size_decay: linear\n",
      "        langevin_noise: 0.0\n",
      "        warmup: 50\n",
      "        grad_clip: 1.0\n",
      "        callback: 100\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "This exchange is a simulation of a single query in a federated learning protocol. The server sends out a `server_payload` and the user computes an update based on their private local data. This user update is `shared_data` and contains, for example, the parameter gradient of the model in the simplest case. `true_user_data` is also returned by `.compute_local_updates`, but of course not forwarded to the server or attacker and only used for (our) analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n"
     ]
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49c68628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] one more pseudo generalization and i'm giving up. [SEP] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82360c14",
   "metadata": {},
   "source": [
    "Now we launch the attack, reconstructing user data based on only the `server_payload` and the `shared_data`. \n",
    "\n",
    "You can interrupt the computation early to see a partial solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9a32fd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| It: 1 | Rec. loss: 95.2092 |  Task loss: 0.6980 | T: 0.23s |  Label Entropy: 0.9979.\n",
      "| It: 101 | Rec. loss: 27.7278 |  Task loss: 0.8908 | T: 18.31s |  Label Entropy: 0.2830.\n",
      "| It: 201 | Rec. loss: 22.1621 |  Task loss: 0.8842 | T: 19.68s |  Label Entropy: 0.1864.\n",
      "| It: 301 | Rec. loss: 19.5941 |  Task loss: 0.8836 | T: 20.15s |  Label Entropy: 0.1639.\n",
      "| It: 401 | Rec. loss: 19.5519 |  Task loss: 0.8839 | T: 11.45s |  Label Entropy: 0.1755.\n",
      "| It: 501 | Rec. loss: 19.2239 |  Task loss: 0.8855 | T: 11.45s |  Label Entropy: 0.1721.\n",
      "| It: 601 | Rec. loss: 18.9395 |  Task loss: 0.8847 | T: 11.34s |  Label Entropy: 0.1671.\n",
      "| It: 701 | Rec. loss: 19.3074 |  Task loss: 0.8886 | T: 11.62s |  Label Entropy: 0.1712.\n",
      "| It: 801 | Rec. loss: 18.7212 |  Task loss: 0.8857 | T: 11.54s |  Label Entropy: 0.1664.\n",
      "| It: 901 | Rec. loss: 17.2360 |  Task loss: 0.8819 | T: 11.69s |  Label Entropy: 0.1611.\n",
      "| It: 1001 | Rec. loss: 17.2748 |  Task loss: 0.8853 | T: 11.68s |  Label Entropy: 0.1539.\n",
      "| It: 1101 | Rec. loss: 16.7582 |  Task loss: 0.8860 | T: 11.45s |  Label Entropy: 0.1546.\n",
      "| It: 1201 | Rec. loss: 18.0701 |  Task loss: 0.8863 | T: 11.58s |  Label Entropy: 0.1625.\n",
      "| It: 1301 | Rec. loss: 17.3243 |  Task loss: 0.8859 | T: 11.63s |  Label Entropy: 0.1560.\n",
      "| It: 1401 | Rec. loss: 16.8047 |  Task loss: 0.8859 | T: 11.56s |  Label Entropy: 0.1535.\n",
      "| It: 1501 | Rec. loss: 17.1779 |  Task loss: 0.8845 | T: 11.59s |  Label Entropy: 0.1549.\n",
      "| It: 1601 | Rec. loss: 16.4652 |  Task loss: 0.8851 | T: 11.66s |  Label Entropy: 0.1578.\n",
      "| It: 1701 | Rec. loss: 17.3905 |  Task loss: 0.8869 | T: 11.49s |  Label Entropy: 0.1642.\n",
      "| It: 1801 | Rec. loss: 16.9784 |  Task loss: 0.8853 | T: 11.71s |  Label Entropy: 0.1582.\n",
      "| It: 1901 | Rec. loss: 16.9737 |  Task loss: 0.8844 | T: 11.61s |  Label Entropy: 0.1582.\n",
      "| It: 2001 | Rec. loss: 16.7117 |  Task loss: 0.8857 | T: 11.52s |  Label Entropy: 0.1598.\n",
      "| It: 2101 | Rec. loss: 16.1823 |  Task loss: 0.8861 | T: 10.72s |  Label Entropy: 0.1578.\n",
      "| It: 2201 | Rec. loss: 16.8830 |  Task loss: 0.8860 | T: 10.69s |  Label Entropy: 0.1536.\n",
      "| It: 2301 | Rec. loss: 16.5070 |  Task loss: 0.8863 | T: 10.63s |  Label Entropy: 0.1532.\n",
      "| It: 2401 | Rec. loss: 16.6580 |  Task loss: 0.8859 | T: 10.63s |  Label Entropy: 0.1562.\n",
      "| It: 2501 | Rec. loss: 16.7837 |  Task loss: 0.8867 | T: 10.65s |  Label Entropy: 0.1599.\n",
      "| It: 2601 | Rec. loss: 16.5390 |  Task loss: 0.8864 | T: 10.63s |  Label Entropy: 0.1579.\n",
      "| It: 2701 | Rec. loss: 16.3920 |  Task loss: 0.8864 | T: 10.66s |  Label Entropy: 0.1580.\n",
      "| It: 2801 | Rec. loss: 16.3390 |  Task loss: 0.8849 | T: 10.68s |  Label Entropy: 0.1601.\n",
      "| It: 2901 | Rec. loss: 16.4046 |  Task loss: 0.8857 | T: 10.58s |  Label Entropy: 0.1569.\n",
      "| It: 3001 | Rec. loss: 17.8143 |  Task loss: 0.8853 | T: 10.63s |  Label Entropy: 0.1651.\n",
      "| It: 3101 | Rec. loss: 16.7907 |  Task loss: 0.8859 | T: 10.68s |  Label Entropy: 0.1584.\n",
      "| It: 3201 | Rec. loss: 16.3853 |  Task loss: 0.8867 | T: 10.57s |  Label Entropy: 0.1553.\n",
      "| It: 3301 | Rec. loss: 17.2706 |  Task loss: 0.8877 | T: 10.65s |  Label Entropy: 0.1547.\n",
      "| It: 3401 | Rec. loss: 16.3386 |  Task loss: 0.8854 | T: 10.51s |  Label Entropy: 0.1557.\n",
      "| It: 3501 | Rec. loss: 16.9840 |  Task loss: 0.8866 | T: 10.58s |  Label Entropy: 0.1565.\n",
      "| It: 3601 | Rec. loss: 16.7067 |  Task loss: 0.8870 | T: 10.54s |  Label Entropy: 0.1540.\n",
      "| It: 3701 | Rec. loss: 16.6322 |  Task loss: 0.8861 | T: 10.65s |  Label Entropy: 0.1530.\n",
      "| It: 3801 | Rec. loss: 16.6901 |  Task loss: 0.8857 | T: 10.65s |  Label Entropy: 0.1600.\n",
      "| It: 3901 | Rec. loss: 16.5911 |  Task loss: 0.8863 | T: 10.66s |  Label Entropy: 0.1598.\n",
      "| It: 4001 | Rec. loss: 16.0989 |  Task loss: 0.8857 | T: 10.52s |  Label Entropy: 0.1584.\n",
      "| It: 4101 | Rec. loss: 16.5069 |  Task loss: 0.8865 | T: 10.46s |  Label Entropy: 0.1566.\n",
      "| It: 4201 | Rec. loss: 16.1793 |  Task loss: 0.8861 | T: 10.82s |  Label Entropy: 0.1598.\n",
      "| It: 4301 | Rec. loss: 16.4369 |  Task loss: 0.8860 | T: 10.68s |  Label Entropy: 0.1593.\n",
      "| It: 4401 | Rec. loss: 16.2338 |  Task loss: 0.8849 | T: 10.51s |  Label Entropy: 0.1590.\n",
      "| It: 4501 | Rec. loss: 16.8211 |  Task loss: 0.8859 | T: 10.52s |  Label Entropy: 0.1626.\n",
      "| It: 4601 | Rec. loss: 17.0281 |  Task loss: 0.8862 | T: 10.72s |  Label Entropy: 0.1553.\n",
      "| It: 4701 | Rec. loss: 16.6189 |  Task loss: 0.8851 | T: 11.56s |  Label Entropy: 0.1650.\n",
      "| It: 4801 | Rec. loss: 16.3285 |  Task loss: 0.8869 | T: 14.91s |  Label Entropy: 0.1547.\n",
      "| It: 4901 | Rec. loss: 16.7281 |  Task loss: 0.8862 | T: 13.61s |  Label Entropy: 0.1569.\n",
      "| It: 5001 | Rec. loss: 16.3081 |  Task loss: 0.8867 | T: 10.71s |  Label Entropy: 0.1567.\n",
      "| It: 5101 | Rec. loss: 16.1548 |  Task loss: 0.8870 | T: 10.77s |  Label Entropy: 0.1523.\n",
      "| It: 5201 | Rec. loss: 16.7203 |  Task loss: 0.8867 | T: 10.79s |  Label Entropy: 0.1622.\n",
      "| It: 5301 | Rec. loss: 16.4006 |  Task loss: 0.8876 | T: 10.17s |  Label Entropy: 0.1519.\n",
      "| It: 5401 | Rec. loss: 16.4131 |  Task loss: 0.8858 | T: 10.36s |  Label Entropy: 0.1517.\n",
      "| It: 5501 | Rec. loss: 16.2888 |  Task loss: 0.8850 | T: 10.36s |  Label Entropy: 0.1538.\n",
      "| It: 5601 | Rec. loss: 16.3196 |  Task loss: 0.8867 | T: 10.29s |  Label Entropy: 0.1516.\n",
      "| It: 5701 | Rec. loss: 16.3061 |  Task loss: 0.8855 | T: 10.38s |  Label Entropy: 0.1567.\n",
      "| It: 5801 | Rec. loss: 15.8724 |  Task loss: 0.8867 | T: 10.16s |  Label Entropy: 0.1573.\n",
      "| It: 5901 | Rec. loss: 16.0357 |  Task loss: 0.8864 | T: 10.33s |  Label Entropy: 0.1553.\n",
      "| It: 6001 | Rec. loss: 16.2178 |  Task loss: 0.8857 | T: 10.35s |  Label Entropy: 0.1546.\n",
      "| It: 6101 | Rec. loss: 16.8327 |  Task loss: 0.8874 | T: 10.40s |  Label Entropy: 0.1540.\n",
      "| It: 6201 | Rec. loss: 16.5671 |  Task loss: 0.8862 | T: 10.27s |  Label Entropy: 0.1532.\n",
      "| It: 6301 | Rec. loss: 16.4892 |  Task loss: 0.8870 | T: 10.27s |  Label Entropy: 0.1531.\n",
      "| It: 6401 | Rec. loss: 16.0749 |  Task loss: 0.8864 | T: 10.31s |  Label Entropy: 0.1564.\n",
      "| It: 6501 | Rec. loss: 16.0160 |  Task loss: 0.8862 | T: 10.25s |  Label Entropy: 0.1502.\n",
      "| It: 6601 | Rec. loss: 16.2750 |  Task loss: 0.8864 | T: 10.13s |  Label Entropy: 0.1534.\n",
      "| It: 6701 | Rec. loss: 16.1333 |  Task loss: 0.8857 | T: 10.36s |  Label Entropy: 0.1493.\n",
      "| It: 6801 | Rec. loss: 16.5715 |  Task loss: 0.8872 | T: 10.24s |  Label Entropy: 0.1515.\n",
      "| It: 6901 | Rec. loss: 16.8285 |  Task loss: 0.8870 | T: 10.39s |  Label Entropy: 0.1529.\n",
      "| It: 7001 | Rec. loss: 16.5481 |  Task loss: 0.8869 | T: 10.41s |  Label Entropy: 0.1562.\n",
      "| It: 7101 | Rec. loss: 16.3497 |  Task loss: 0.8863 | T: 10.28s |  Label Entropy: 0.1535.\n",
      "| It: 7201 | Rec. loss: 16.6588 |  Task loss: 0.8862 | T: 10.21s |  Label Entropy: 0.1521.\n",
      "| It: 7301 | Rec. loss: 16.1432 |  Task loss: 0.8867 | T: 10.38s |  Label Entropy: 0.1541.\n",
      "| It: 7401 | Rec. loss: 16.2942 |  Task loss: 0.8864 | T: 10.25s |  Label Entropy: 0.1560.\n",
      "| It: 7501 | Rec. loss: 16.3747 |  Task loss: 0.8852 | T: 10.21s |  Label Entropy: 0.1561.\n",
      "| It: 7601 | Rec. loss: 16.1089 |  Task loss: 0.8864 | T: 10.23s |  Label Entropy: 0.1536.\n",
      "| It: 7701 | Rec. loss: 16.3736 |  Task loss: 0.8867 | T: 10.21s |  Label Entropy: 0.1547.\n",
      "| It: 7801 | Rec. loss: 15.9616 |  Task loss: 0.8849 | T: 10.44s |  Label Entropy: 0.1562.\n",
      "| It: 7901 | Rec. loss: 16.3183 |  Task loss: 0.8868 | T: 10.33s |  Label Entropy: 0.1544.\n",
      "| It: 8001 | Rec. loss: 16.4047 |  Task loss: 0.8846 | T: 10.33s |  Label Entropy: 0.1558.\n",
      "| It: 8101 | Rec. loss: 16.3606 |  Task loss: 0.8861 | T: 10.28s |  Label Entropy: 0.1586.\n",
      "| It: 8201 | Rec. loss: 16.6056 |  Task loss: 0.8873 | T: 10.34s |  Label Entropy: 0.1525.\n",
      "| It: 8301 | Rec. loss: 16.6241 |  Task loss: 0.8876 | T: 10.24s |  Label Entropy: 0.1524.\n",
      "| It: 8401 | Rec. loss: 16.1776 |  Task loss: 0.8866 | T: 10.26s |  Label Entropy: 0.1557.\n",
      "| It: 8501 | Rec. loss: 16.5447 |  Task loss: 0.8847 | T: 10.28s |  Label Entropy: 0.1572.\n",
      "| It: 8601 | Rec. loss: 16.4667 |  Task loss: 0.8871 | T: 10.31s |  Label Entropy: 0.1531.\n",
      "| It: 8701 | Rec. loss: 16.3368 |  Task loss: 0.8859 | T: 10.09s |  Label Entropy: 0.1563.\n",
      "| It: 8801 | Rec. loss: 16.2480 |  Task loss: 0.8851 | T: 10.18s |  Label Entropy: 0.1567.\n",
      "| It: 8901 | Rec. loss: 16.4400 |  Task loss: 0.8870 | T: 10.29s |  Label Entropy: 0.1538.\n",
      "| It: 9001 | Rec. loss: 16.5085 |  Task loss: 0.8866 | T: 10.46s |  Label Entropy: 0.1533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| It: 9101 | Rec. loss: 16.1902 |  Task loss: 0.8859 | T: 10.41s |  Label Entropy: 0.1519.\n",
      "| It: 9201 | Rec. loss: 16.5991 |  Task loss: 0.8865 | T: 10.19s |  Label Entropy: 0.1531.\n",
      "| It: 9301 | Rec. loss: 16.2550 |  Task loss: 0.8864 | T: 10.30s |  Label Entropy: 0.1545.\n",
      "| It: 9401 | Rec. loss: 16.0714 |  Task loss: 0.8860 | T: 10.29s |  Label Entropy: 0.1539.\n",
      "| It: 9501 | Rec. loss: 16.2131 |  Task loss: 0.8857 | T: 10.04s |  Label Entropy: 0.1543.\n",
      "| It: 9601 | Rec. loss: 16.4635 |  Task loss: 0.8862 | T: 10.13s |  Label Entropy: 0.1534.\n",
      "| It: 9701 | Rec. loss: 16.4038 |  Task loss: 0.8867 | T: 10.28s |  Label Entropy: 0.1535.\n",
      "| It: 9801 | Rec. loss: 16.4264 |  Task loss: 0.8866 | T: 10.45s |  Label Entropy: 0.1531.\n",
      "| It: 9901 | Rec. loss: 16.7151 |  Task loss: 0.8868 | T: 10.24s |  Label Entropy: 0.1528.\n",
      "| It: 10001 | Rec. loss: 16.4080 |  Task loss: 0.8857 | T: 10.25s |  Label Entropy: 0.1544.\n",
      "| It: 10101 | Rec. loss: 15.9016 |  Task loss: 0.8857 | T: 10.21s |  Label Entropy: 0.1519.\n",
      "| It: 10201 | Rec. loss: 16.4512 |  Task loss: 0.8869 | T: 10.45s |  Label Entropy: 0.1539.\n",
      "| It: 10301 | Rec. loss: 16.2757 |  Task loss: 0.8864 | T: 10.20s |  Label Entropy: 0.1530.\n",
      "| It: 10401 | Rec. loss: 16.2227 |  Task loss: 0.8868 | T: 10.30s |  Label Entropy: 0.1537.\n",
      "| It: 10501 | Rec. loss: 16.6848 |  Task loss: 0.8866 | T: 10.38s |  Label Entropy: 0.1535.\n",
      "| It: 10601 | Rec. loss: 16.3668 |  Task loss: 0.8858 | T: 10.16s |  Label Entropy: 0.1520.\n",
      "| It: 10701 | Rec. loss: 16.5100 |  Task loss: 0.8863 | T: 10.43s |  Label Entropy: 0.1544.\n",
      "| It: 10801 | Rec. loss: 16.3280 |  Task loss: 0.8865 | T: 10.29s |  Label Entropy: 0.1522.\n",
      "| It: 10901 | Rec. loss: 16.7263 |  Task loss: 0.8863 | T: 10.27s |  Label Entropy: 0.1537.\n",
      "| It: 11001 | Rec. loss: 16.1895 |  Task loss: 0.8850 | T: 10.42s |  Label Entropy: 0.1555.\n",
      "| It: 11101 | Rec. loss: 16.3616 |  Task loss: 0.8859 | T: 10.29s |  Label Entropy: 0.1525.\n",
      "| It: 11201 | Rec. loss: 16.0530 |  Task loss: 0.8851 | T: 10.08s |  Label Entropy: 0.1547.\n",
      "| It: 11301 | Rec. loss: 16.3619 |  Task loss: 0.8867 | T: 10.12s |  Label Entropy: 0.1525.\n",
      "| It: 11401 | Rec. loss: 15.9193 |  Task loss: 0.8859 | T: 10.07s |  Label Entropy: 0.1535.\n",
      "| It: 11501 | Rec. loss: 16.1763 |  Task loss: 0.8861 | T: 10.22s |  Label Entropy: 0.1536.\n",
      "| It: 11601 | Rec. loss: 15.9472 |  Task loss: 0.8864 | T: 10.41s |  Label Entropy: 0.1546.\n",
      "| It: 11701 | Rec. loss: 15.7883 |  Task loss: 0.8860 | T: 10.32s |  Label Entropy: 0.1542.\n",
      "| It: 11801 | Rec. loss: 15.9950 |  Task loss: 0.8863 | T: 10.26s |  Label Entropy: 0.1534.\n",
      "| It: 11901 | Rec. loss: 15.8202 |  Task loss: 0.8861 | T: 10.21s |  Label Entropy: 0.1551.\n",
      "| It: 12000 | Rec. loss: 15.8673 |  Task loss: 0.8863 | T: 10.33s |  Label Entropy: 0.1539.\n",
      "Optimal candidate solution with rec. loss 216.4682 selected.\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], {}, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4943f",
   "metadata": {},
   "source": [
    "Next we'll evaluate metrics, comparing the `reconstructed_user_data` to the `true_user_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31f2685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0625 | S-BLEU: 0.15 | FMSE: 5.8470e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.77| ROUGE2: 0.25 | ROUGE-L: 0.46| Token Acc: 75.00% | Label Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, order_batch=True, compute_full_iip=False, \n",
    "                                    cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200797e",
   "metadata": {},
   "source": [
    "And finally, we also print the reconstructed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] generalization and [SEP] pseudo i giving up [CLS] 20 one. é™½ more [SEP]\n"
     ]
    }
   ],
   "source": [
    "user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb085f",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* Sentence classification is a better scenario for TAG than e.g. next-token prediction. This is because the attack has to recover the label in addition to the input sentence. For COLA, this is just a binary choice, but for a next-token prediction, the \"label\" space is the entire vocabulary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
