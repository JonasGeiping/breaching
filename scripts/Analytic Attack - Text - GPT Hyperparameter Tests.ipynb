{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Breaching privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook does the same job as the cmd-line tool `simulate_breach.py`, but also directly visualizes the user data and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import breaching\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "breaching.utils.huggingface_offline_mode(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will print out all configuration options. \n",
    "There are a lot of possible configurations, but there is usually no need to worry about most of these. Below, a few options are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070d66",
   "metadata": {},
   "source": [
    "Choose `case/data=` `shakespeare`, `wikitext`over `stackoverflow` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case single_imagenet with server type malicious_transformer_parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cpu'), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with hydra.initialize(config_path=\"config\"):\n",
    "    cfg = hydra.compose(config_name='cfg', overrides=[\"case/data=wikitext\", \"case/server=malicious-transformer\",\n",
    "                                                      \"case.model=gpt2\",\n",
    "                                                      \"attack=decepticon\"])\n",
    "    print(f'Investigating use case {cfg.case.name} with server type {cfg.case.server.name}.')\n",
    "          \n",
    "# device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=torch.float)\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 8 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [512] # This is the sequence length\n",
    "\n",
    "cfg.case.model = \"gpt2S\" #+ \"gpt2\" #\"transformer3\"\n",
    "cfg.case.server.provide_public_buffers = True\n",
    "\n",
    "cfg.case.server.has_external_data = True\n",
    "cfg.case.data.tokenizer = \"gpt2\"\n",
    "\n",
    "cfg.attack.token_strategy=\"embedding-norm\"\n",
    "cfg.case.server.param_modification.v_length = 32\n",
    "\n",
    "cfg.case.server.param_modification.eps = 1e-8\n",
    "cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "cfg.case.server.param_modification.softmax_skew = 100000000\n",
    "cfg.case.server.param_modification.sequence_token_weight = 1\n",
    "\n",
    "cfg.case.server.param_modification.measurement_scale = 1\n",
    "\n",
    "cfg.case.server.pretrained = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30235b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Model architecture gpt2S loaded with 124,439,808 parameters and 12,582,924 buffers.\n",
      "Overall this is a data ratio of   30381:1 for target shape [8, 512] given that num_queries=1.\n",
      "User (of type UserSingleStep) with settings:\n",
      "    Number of data points: 8\n",
      "\n",
      "    Threat model:\n",
      "    User provides labels: False\n",
      "    User provides buffers: False\n",
      "    User provides number of data points: True\n",
      "\n",
      "    Data:\n",
      "    Dataset: wikitext\n",
      "    user: 1\n",
      "    \n",
      "        \n",
      "Server (of type MaliciousTransformerServer) with settings:\n",
      "    Threat model: Malicious (Parameters)\n",
      "    Number of planned queries: 1\n",
      "    Has external/public data: True\n",
      "\n",
      "    Model:\n",
      "        model specification: gpt2S\n",
      "        model state: default\n",
      "        public buffers: True\n",
      "\n",
      "    Secrets: {}\n",
      "    \n",
      "Attacker (of type DecepticonAttacker).\n"
     ]
    }
   ],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "True user data is returned only for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2a2e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.06816399842500687, feature std is 0.707169234752655.\n",
      "Computing user update in model mode: eval.\n"
     ]
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c6ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2867bcc",
   "metadata": {},
   "source": [
    "# Reconstruct user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2264e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attacker.cfg.sentence_algorithm=\"k-means\"\n",
    "# attacker.embedding_token_weight = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c4ffdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3868 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 489, 484, 423, 512, 487, 482, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8611 | S-BLEU: 0.69 | FMSE: 3.9889e-03 | \n",
      " G-BLEU: 0.67 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.39% | Label Acc: 95.39%\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)\n",
    "\n",
    "# user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a51583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dynamic-threshold with 0\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8652 | S-BLEU: 0.70 | FMSE: 3.7850e-03 | \n",
      " G-BLEU: 0.66 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.14% | Label Acc: 95.14%\n",
      "Evaluating dynamic-threshold with 0.0001\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8652 | S-BLEU: 0.70 | FMSE: 3.7850e-03 | \n",
      " G-BLEU: 0.66 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.14% | Label Acc: 95.14%\n",
      "Evaluating dynamic-threshold with 0.001\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8652 | S-BLEU: 0.70 | FMSE: 3.7850e-03 | \n",
      " G-BLEU: 0.66 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.14% | Label Acc: 95.14%\n",
      "Evaluating dynamic-threshold with 0.01\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8652 | S-BLEU: 0.70 | FMSE: 3.7850e-03 | \n",
      " G-BLEU: 0.66 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.14% | Label Acc: 95.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dynamic-threshold with 0.1\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8652 | S-BLEU: 0.70 | FMSE: 3.7850e-03 | \n",
      " G-BLEU: 0.66 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.14% | Label Acc: 95.14%\n",
      "Evaluating dynamic-threshold with 0.2\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8652 | S-BLEU: 0.70 | FMSE: 3.7850e-03 | \n",
      " G-BLEU: 0.66 | ROUGE1: 0.86| ROUGE2: 0.71 | ROUGE-L: 0.84| Token Acc: 95.14% | Label Acc: 95.14%\n",
      "Evaluating dynamic-threshold with 0.5\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Replaced token 32 with corr 0.10004569590091705 with new token with corr 0.27175667881965637\n",
      "Replaced token 58 with corr 0.12161212414503098 with new token with corr 0.3063763380050659\n",
      "Replaced token 96 with corr 0.09464694559574127 with new token with corr 0.2000071108341217\n",
      "Replaced token 100 with corr 0.11622016131877899 with new token with corr 0.2580813467502594\n",
      "Replaced token 123 with corr 0.10482989251613617 with new token with corr 0.221369206905365\n",
      "Replaced token 166 with corr 0.08978059887886047 with new token with corr 0.3762853443622589\n",
      "Replaced token 188 with corr 0.09136594831943512 with new token with corr 0.23894765973091125\n",
      "Replaced token 191 with corr 0.1137547567486763 with new token with corr 0.26309698820114136\n",
      "Replaced token 205 with corr 0.0792447179555893 with new token with corr 0.2740797698497772\n",
      "Replaced token 257 with corr 0.09256129711866379 with new token with corr 0.24084514379501343\n",
      "Replaced token 265 with corr 0.09990415722131729 with new token with corr 0.26489901542663574\n",
      "Replaced token 266 with corr 0.09759923070669174 with new token with corr 0.2242376208305359\n",
      "Replaced token 326 with corr 0.07846662402153015 with new token with corr 0.15889431536197662\n",
      "Replaced token 357 with corr 0.11765756458044052 with new token with corr 0.25508594512939453\n",
      "Replaced token 363 with corr 0.11083157360553741 with new token with corr 0.22495022416114807\n",
      "Replaced token 422 with corr 0.09864215552806854 with new token with corr 0.2360743284225464\n",
      "Replaced token 458 with corr 0.11354941129684448 with new token with corr 0.3059351146221161\n",
      "Replaced token 487 with corr 0.11485637724399567 with new token with corr 0.25687742233276367\n",
      "Replaced token 488 with corr 0.10698159784078598 with new token with corr 0.22048774361610413\n",
      "Replaced token 490 with corr 0.09709368646144867 with new token with corr 0.31151992082595825\n",
      "Replaced token 511 with corr 0.07224166393280029 with new token with corr 0.14823205769062042\n",
      "Replaced token 525 with corr 0.11561029404401779 with new token with corr 0.25178301334381104\n",
      "Replaced token 592 with corr 0.09372688829898834 with new token with corr 0.31124797463417053\n",
      "Replaced token 599 with corr 0.09186166524887085 with new token with corr 0.20139718055725098\n",
      "Replaced token 615 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 618 with corr 0.11568886786699295 with new token with corr 0.23867349326610565\n",
      "Replaced token 640 with corr 0.12705056369304657 with new token with corr 0.29355359077453613\n",
      "Replaced token 654 with corr 0.08123092353343964 with new token with corr 0.17212828993797302\n",
      "Replaced token 661 with corr 0.07817701250314713 with new token with corr 0.29225459694862366\n",
      "Replaced token 713 with corr 0.0795915424823761 with new token with corr 0.19586622714996338\n",
      "Replaced token 715 with corr 0.09467495232820511 with new token with corr 0.20234717428684235\n",
      "Replaced token 725 with corr 0.08259778469800949 with new token with corr 0.22294455766677856\n",
      "Replaced token 731 with corr 0.10537471622228622 with new token with corr 0.22179755568504333\n",
      "Replaced token 771 with corr 0.09703671932220459 with new token with corr 0.302799254655838\n",
      "Replaced token 777 with corr 0.09922241419553757 with new token with corr 0.2945486605167389\n",
      "Replaced token 791 with corr 0.07144638150930405 with new token with corr 0.17704078555107117\n",
      "Replaced token 798 with corr 0.09041425585746765 with new token with corr 0.20528154075145721\n",
      "Replaced token 839 with corr 0.09296030551195145 with new token with corr 0.246667742729187\n",
      "Replaced token 870 with corr 0.07660464197397232 with new token with corr 0.31718987226486206\n",
      "Replaced token 957 with corr 0.09542372822761536 with new token with corr 0.23909063637256622\n",
      "Replaced token 1050 with corr 0.10594883561134338 with new token with corr 0.24959640204906464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1057 with corr 0.08473658561706543 with new token with corr 0.22825545072555542\n",
      "Replaced token 1074 with corr 0.08387237042188644 with new token with corr 0.1788710653781891\n",
      "Replaced token 1089 with corr 0.09365814179182053 with new token with corr 0.23969314992427826\n",
      "Replaced token 1093 with corr 0.0979638621211052 with new token with corr 0.25052905082702637\n",
      "Replaced token 1098 with corr 0.07346440106630325 with new token with corr 0.14864100515842438\n",
      "Replaced token 1153 with corr 0.10632549226284027 with new token with corr 0.2262493073940277\n",
      "Replaced token 1171 with corr 0.09213504195213318 with new token with corr 0.23409555852413177\n",
      "Replaced token 1240 with corr 0.1078638881444931 with new token with corr 0.255260169506073\n",
      "Replaced token 1261 with corr 0.1271013468503952 with new token with corr 0.2786852717399597\n",
      "Replaced token 1263 with corr 0.11042303591966629 with new token with corr 0.23266048729419708\n",
      "Replaced token 1264 with corr 0.12782299518585205 with new token with corr 0.2583874464035034\n",
      "Replaced token 1284 with corr 0.08835963159799576 with new token with corr 0.19375872611999512\n",
      "Replaced token 1349 with corr 0.08382277935743332 with new token with corr 0.23777472972869873\n",
      "Replaced token 1351 with corr 0.07137275487184525 with new token with corr 0.246667742729187\n",
      "Replaced token 1362 with corr 0.09793490171432495 with new token with corr 0.2076321393251419\n",
      "Replaced token 1363 with corr 0.07055403292179108 with new token with corr 0.20594865083694458\n",
      "Replaced token 1368 with corr 0.09996118396520615 with new token with corr 0.2627990245819092\n",
      "Replaced token 1373 with corr 0.09707263112068176 with new token with corr 0.22873805463314056\n",
      "Replaced token 1394 with corr 0.12385053932666779 with new token with corr 0.2960706353187561\n",
      "Replaced token 1411 with corr 0.09213609993457794 with new token with corr 0.2126815766096115\n",
      "Replaced token 1418 with corr 0.08426766842603683 with new token with corr 0.1918579488992691\n",
      "Replaced token 1422 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 1489 with corr 0.1247924417257309 with new token with corr 0.33324137330055237\n",
      "Replaced token 1674 with corr 0.10315745323896408 with new token with corr 0.2663765847682953\n",
      "Replaced token 1724 with corr 0.09965529292821884 with new token with corr 0.23894765973091125\n",
      "Replaced token 1725 with corr 0.11401858180761337 with new token with corr 0.23250730335712433\n",
      "Replaced token 1749 with corr 0.09431915730237961 with new token with corr 0.26409608125686646\n",
      "Replaced token 1765 with corr 0.113925039768219 with new token with corr 0.23003029823303223\n",
      "Replaced token 1798 with corr 0.12051334232091904 with new token with corr 0.2571505308151245\n",
      "Replaced token 1815 with corr 0.09153895825147629 with new token with corr 0.2720903754234314\n",
      "Replaced token 1828 with corr 0.1047699898481369 with new token with corr 0.24702207744121552\n",
      "Replaced token 1898 with corr 0.08746799826622009 with new token with corr 0.18822109699249268\n",
      "Replaced token 1911 with corr 0.10159188508987427 with new token with corr 0.2432563453912735\n",
      "Replaced token 1914 with corr 0.10121522843837738 with new token with corr 0.28528982400894165\n",
      "Replaced token 1994 with corr 0.07788437604904175 with new token with corr 0.15879173576831818\n",
      "Replaced token 2008 with corr 0.12380942702293396 with new token with corr 0.2583029270172119\n",
      "Replaced token 2013 with corr 0.0755612924695015 with new token with corr 0.24288199841976166\n",
      "Replaced token 2025 with corr 0.10530538856983185 with new token with corr 0.2723276913166046\n",
      "Replaced token 2047 with corr 0.07412855327129364 with new token with corr 0.14971689879894257\n",
      "Replaced token 2085 with corr 0.11269345879554749 with new token with corr 0.32850000262260437\n",
      "Replaced token 2132 with corr 0.08016213029623032 with new token with corr 0.1699904054403305\n",
      "Replaced token 2175 with corr 0.07608034461736679 with new token with corr 0.15946857631206512\n",
      "Replaced token 2212 with corr 0.078856460750103 with new token with corr 0.17004385590553284\n",
      "Replaced token 2276 with corr 0.10801269114017487 with new token with corr 0.21808457374572754\n",
      "Replaced token 2385 with corr 0.09798111021518707 with new token with corr 0.3236064016819\n",
      "Replaced token 2413 with corr 0.08556809276342392 with new token with corr 0.34158772230148315\n",
      "Replaced token 2428 with corr 0.07455836236476898 with new token with corr 0.2022038847208023\n",
      "Replaced token 2446 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 2454 with corr 0.10390853136777878 with new token with corr 0.2800275385379791\n",
      "Replaced token 2475 with corr 0.08915002644062042 with new token with corr 0.18457834422588348\n",
      "Replaced token 2497 with corr 0.10846427083015442 with new token with corr 0.2654228210449219\n",
      "Replaced token 2498 with corr 0.11025235056877136 with new token with corr 0.2499328851699829\n",
      "Replaced token 2526 with corr 0.08897241204977036 with new token with corr 0.2087474912405014\n",
      "Replaced token 2559 with corr 0.0657072365283966 with new token with corr 0.14971689879894257\n",
      "Replaced token 2585 with corr 0.10871854424476624 with new token with corr 0.21969276666641235\n",
      "Replaced token 2647 with corr 0.08146478235721588 with new token with corr 0.20139718055725098\n",
      "Replaced token 2648 with corr 0.08135887235403061 with new token with corr 0.2486138641834259\n",
      "Replaced token 2712 with corr 0.07433526962995529 with new token with corr 0.24520720541477203\n",
      "Replaced token 2787 with corr 0.09799249470233917 with new token with corr 0.21334560215473175\n",
      "Replaced token 2795 with corr 0.09221586585044861 with new token with corr 0.28454074263572693\n",
      "Replaced token 2802 with corr 0.10049636662006378 with new token with corr 0.27976542711257935\n",
      "Replaced token 2828 with corr 0.08878589421510696 with new token with corr 0.29726266860961914\n",
      "Replaced token 2882 with corr 0.08526802062988281 with new token with corr 0.21527671813964844\n",
      "Replaced token 2883 with corr 0.10055611282587051 with new token with corr 0.23668323457241058\n",
      "Replaced token 2914 with corr 0.08962295949459076 with new token with corr 0.2755124270915985\n",
      "Replaced token 2926 with corr 0.0813339427113533 with new token with corr 0.1766229122877121\n",
      "Replaced token 2931 with corr 0.10793379694223404 with new token with corr 0.3027452528476715\n",
      "Replaced token 2943 with corr 0.12474377453327179 with new token with corr 0.2676112949848175\n",
      "Replaced token 3027 with corr 0.11195295304059982 with new token with corr 0.2836076021194458\n",
      "Replaced token 3030 with corr 0.09112260490655899 with new token with corr 0.21726897358894348\n",
      "Replaced token 3094 with corr 0.10854519158601761 with new token with corr 0.30788329243659973\n",
      "Replaced token 3109 with corr 0.10213868319988251 with new token with corr 0.25648751854896545\n",
      "Replaced token 3128 with corr 0.08161012083292007 with new token with corr 0.2301304042339325\n",
      "Replaced token 3143 with corr 0.08852166682481766 with new token with corr 0.19981727004051208\n",
      "Replaced token 3166 with corr 0.09498576074838638 with new token with corr 0.24592570960521698\n",
      "Replaced token 3175 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 3211 with corr 0.1092938631772995 with new token with corr 0.22648459672927856\n",
      "Replaced token 3221 with corr 0.07762452960014343 with new token with corr 0.2182246446609497\n",
      "Replaced token 3223 with corr 0.09327423572540283 with new token with corr 0.2611684203147888\n",
      "Replaced token 3308 with corr 0.10283837467432022 with new token with corr 0.23205004632472992\n",
      "Replaced token 3335 with corr 0.08474868535995483 with new token with corr 0.260865181684494\n",
      "Replaced token 3340 with corr 0.08995696157217026 with new token with corr 0.29117822647094727\n",
      "Replaced token 3344 with corr 0.07471393793821335 with new token with corr 0.20954430103302002\n",
      "Replaced token 3402 with corr 0.09207748621702194 with new token with corr 0.20862500369548798\n",
      "Replaced token 3413 with corr 0.07762213796377182 with new token with corr 0.1717095524072647\n",
      "Replaced token 3415 with corr 0.11113911122083664 with new token with corr 0.23568634688854218\n",
      "Replaced token 3451 with corr 0.09928575158119202 with new token with corr 0.2579036355018616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3480 with corr 0.11261890828609467 with new token with corr 0.23385603725910187\n",
      "Replaced token 3486 with corr 0.094296395778656 with new token with corr 0.26696982979774475\n",
      "Replaced token 3504 with corr 0.10243967920541763 with new token with corr 0.21259687840938568\n",
      "Replaced token 3508 with corr 0.11241219192743301 with new token with corr 0.3117140233516693\n",
      "Replaced token 3522 with corr 0.11608175188302994 with new token with corr 0.2361796647310257\n",
      "Replaced token 3540 with corr 0.0735185369849205 with new token with corr 0.18384917080402374\n",
      "Replaced token 3547 with corr 0.12320207059383392 with new token with corr 0.2969287633895874\n",
      "Replaced token 3565 with corr 0.07344812899827957 with new token with corr 0.14897918701171875\n",
      "Replaced token 3573 with corr 0.0852590948343277 with new token with corr 0.22231847047805786\n",
      "Replaced token 3583 with corr 0.07468339055776596 with new token with corr 0.15685757994651794\n",
      "Replaced token 3611 with corr 0.1045120358467102 with new token with corr 0.2583322823047638\n",
      "Replaced token 3623 with corr 0.09608295559883118 with new token with corr 0.20783036947250366\n",
      "Replaced token 3631 with corr 0.07907850295305252 with new token with corr 0.1806187927722931\n",
      "Replaced token 3638 with corr 0.07013028860092163 with new token with corr 0.1800089031457901\n",
      "Replaced token 3667 with corr 0.10379547625780106 with new token with corr 0.2801976799964905\n",
      "Replaced token 3669 with corr 0.07176963239908218 with new token with corr 0.2982428967952728\n",
      "Replaced token 3670 with corr 0.06947410106658936 with new token with corr 0.32409781217575073\n",
      "Replaced token 3674 with corr 0.1082954853773117 with new token with corr 0.34233036637306213\n",
      "Replaced token 3679 with corr 0.08759612590074539 with new token with corr 0.23954784870147705\n",
      "Replaced token 3713 with corr 0.0684177502989769 with new token with corr 0.2262493073940277\n",
      "Replaced token 3736 with corr 0.09470909088850021 with new token with corr 0.21329985558986664\n",
      "Replaced token 3744 with corr 0.0792054533958435 with new token with corr 0.2511129677295685\n",
      "Replaced token 3785 with corr 0.08235035091638565 with new token with corr 0.19586622714996338\n",
      "Replaced token 3794 with corr 0.0956580862402916 with new token with corr 0.2699718177318573\n",
      "Replaced token 3843 with corr 0.09166190773248672 with new token with corr 0.2591124176979065\n",
      "Replaced token 3849 with corr 0.10936854779720306 with new token with corr 0.26489901542663574\n",
      "Replaced token 3851 with corr 0.10035465657711029 with new token with corr 0.22951041162014008\n",
      "Replaced token 3871 with corr 0.11843269318342209 with new token with corr 0.2503451406955719\n",
      "Replaced token 3872 with corr 0.11060427874326706 with new token with corr 0.2391880452632904\n",
      "Replaced token 3885 with corr 0.0908476859331131 with new token with corr 0.2347525656223297\n",
      "Replaced token 3928 with corr 0.09814780950546265 with new token with corr 0.2512640953063965\n",
      "Replaced token 3933 with corr 0.10581307113170624 with new token with corr 0.2439889907836914\n",
      "Replaced token 3948 with corr 0.10665471851825714 with new token with corr 0.25099965929985046\n",
      "Replaced token 3960 with corr 0.08955783396959305 with new token with corr 0.23699374496936798\n",
      "Replaced token 3979 with corr 0.09531667828559875 with new token with corr 0.2902751863002777\n",
      "Replaced token 4007 with corr 0.10252664983272552 with new token with corr 0.25471606850624084\n",
      "Replaced token 4022 with corr 0.10040204226970673 with new token with corr 0.21668174862861633\n",
      "Replaced token 4023 with corr 0.0731392577290535 with new token with corr 0.1712467074394226\n",
      "Replaced token 4095 with corr 0.0721680223941803 with new token with corr 0.14965713024139404\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.8918 | S-BLEU: 0.75 | FMSE: 3.1694e-03 | \n",
      " G-BLEU: 0.71 | ROUGE1: 0.88| ROUGE2: 0.76 | ROUGE-L: 0.87| Token Acc: 94.56% | Label Acc: 94.56%\n",
      "Evaluating dynamic-threshold with 0.75\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Replaced token 32 with corr 0.10004569590091705 with new token with corr 0.27175667881965637\n",
      "Replaced token 58 with corr 0.12161212414503098 with new token with corr 0.3063763380050659\n",
      "Replaced token 96 with corr 0.09464694559574127 with new token with corr 0.2000071108341217\n",
      "Replaced token 100 with corr 0.11622016131877899 with new token with corr 0.2580813467502594\n",
      "Replaced token 123 with corr 0.10482989251613617 with new token with corr 0.221369206905365\n",
      "Replaced token 142 with corr 0.1426793485879898 with new token with corr 0.24854715168476105\n",
      "Replaced token 147 with corr 0.09084136039018631 with new token with corr 0.13877294957637787\n",
      "Replaced token 148 with corr 0.11775460094213486 with new token with corr 0.1684461236000061\n",
      "Replaced token 156 with corr 0.0995953381061554 with new token with corr 0.19734443724155426\n",
      "Replaced token 166 with corr 0.08978059887886047 with new token with corr 0.3762853443622589\n",
      "Replaced token 172 with corr 0.09863615036010742 with new token with corr 0.1725509762763977\n",
      "Replaced token 188 with corr 0.09136594831943512 with new token with corr 0.23894765973091125\n",
      "Replaced token 191 with corr 0.1137547567486763 with new token with corr 0.26309698820114136\n",
      "Replaced token 202 with corr 0.1084042489528656 with new token with corr 0.15070481598377228\n",
      "Replaced token 205 with corr 0.0792447179555893 with new token with corr 0.2740797698497772\n",
      "Replaced token 257 with corr 0.09256129711866379 with new token with corr 0.24084514379501343\n",
      "Replaced token 265 with corr 0.09990415722131729 with new token with corr 0.26489901542663574\n",
      "Replaced token 266 with corr 0.09759923070669174 with new token with corr 0.2242376208305359\n",
      "Replaced token 326 with corr 0.07846662402153015 with new token with corr 0.15889431536197662\n",
      "Replaced token 357 with corr 0.11765756458044052 with new token with corr 0.25508594512939453\n",
      "Replaced token 363 with corr 0.11083157360553741 with new token with corr 0.22495022416114807\n",
      "Replaced token 389 with corr 0.12040932476520538 with new token with corr 0.2243054360151291\n",
      "Replaced token 422 with corr 0.09864215552806854 with new token with corr 0.2360743284225464\n",
      "Replaced token 440 with corr 0.09062034636735916 with new token with corr 0.15890830755233765\n",
      "Replaced token 458 with corr 0.11354941129684448 with new token with corr 0.3059351146221161\n",
      "Replaced token 487 with corr 0.11485637724399567 with new token with corr 0.25687742233276367\n",
      "Replaced token 488 with corr 0.10698159784078598 with new token with corr 0.22048774361610413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 490 with corr 0.09709368646144867 with new token with corr 0.31151992082595825\n",
      "Replaced token 511 with corr 0.07224166393280029 with new token with corr 0.14823205769062042\n",
      "Replaced token 525 with corr 0.11561029404401779 with new token with corr 0.25178301334381104\n",
      "Replaced token 538 with corr 0.09454026818275452 with new token with corr 0.15348148345947266\n",
      "Replaced token 566 with corr 0.11152159422636032 with new token with corr 0.22072097659111023\n",
      "Replaced token 572 with corr 0.10247683525085449 with new token with corr 0.1441391110420227\n",
      "Replaced token 592 with corr 0.09372688829898834 with new token with corr 0.31124797463417053\n",
      "Replaced token 599 with corr 0.09186166524887085 with new token with corr 0.20139718055725098\n",
      "Replaced token 615 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 618 with corr 0.11568886786699295 with new token with corr 0.23867349326610565\n",
      "Replaced token 640 with corr 0.12705056369304657 with new token with corr 0.29355359077453613\n",
      "Replaced token 654 with corr 0.08123092353343964 with new token with corr 0.17212828993797302\n",
      "Replaced token 660 with corr 0.10303323715925217 with new token with corr 0.14963647723197937\n",
      "Replaced token 661 with corr 0.07817701250314713 with new token with corr 0.29225459694862366\n",
      "Replaced token 708 with corr 0.08453399688005447 with new token with corr 0.15257667005062103\n",
      "Replaced token 713 with corr 0.0795915424823761 with new token with corr 0.19586622714996338\n",
      "Replaced token 715 with corr 0.09467495232820511 with new token with corr 0.20234717428684235\n",
      "Replaced token 720 with corr 0.0878865048289299 with new token with corr 0.1572844237089157\n",
      "Replaced token 725 with corr 0.08259778469800949 with new token with corr 0.22294455766677856\n",
      "Replaced token 731 with corr 0.10537471622228622 with new token with corr 0.22179755568504333\n",
      "Replaced token 758 with corr 0.10030191391706467 with new token with corr 0.15615716576576233\n",
      "Replaced token 769 with corr 0.08440469950437546 with new token with corr 0.14953385293483734\n",
      "Replaced token 771 with corr 0.09703671932220459 with new token with corr 0.302799254655838\n",
      "Replaced token 773 with corr 0.09112171828746796 with new token with corr 0.16130287945270538\n",
      "Replaced token 777 with corr 0.09922241419553757 with new token with corr 0.2945486605167389\n",
      "Replaced token 791 with corr 0.07144638150930405 with new token with corr 0.17704078555107117\n",
      "Replaced token 792 with corr 0.09265730530023575 with new token with corr 0.14915414154529572\n",
      "Replaced token 798 with corr 0.09041425585746765 with new token with corr 0.20528154075145721\n",
      "Replaced token 800 with corr 0.09082973748445511 with new token with corr 0.14501212537288666\n",
      "Replaced token 839 with corr 0.09296030551195145 with new token with corr 0.246667742729187\n",
      "Replaced token 848 with corr 0.10579328238964081 with new token with corr 0.14981573820114136\n",
      "Replaced token 867 with corr 0.09563031792640686 with new token with corr 0.16406835615634918\n",
      "Replaced token 870 with corr 0.07660464197397232 with new token with corr 0.31718987226486206\n",
      "Replaced token 919 with corr 0.09916584193706512 with new token with corr 0.18581438064575195\n",
      "Replaced token 957 with corr 0.09542372822761536 with new token with corr 0.23909063637256622\n",
      "Replaced token 973 with corr 0.12015997618436813 with new token with corr 0.18991312384605408\n",
      "Replaced token 989 with corr 0.09649454057216644 with new token with corr 0.13950996100902557\n",
      "Replaced token 1023 with corr 0.07638375461101532 with new token with corr 0.15259888768196106\n",
      "Replaced token 1031 with corr 0.10887496918439865 with new token with corr 0.21241869032382965\n",
      "Replaced token 1050 with corr 0.10594883561134338 with new token with corr 0.24959640204906464\n",
      "Replaced token 1057 with corr 0.08473658561706543 with new token with corr 0.22825545072555542\n",
      "Replaced token 1074 with corr 0.08387237042188644 with new token with corr 0.1788710653781891\n",
      "Replaced token 1089 with corr 0.09365814179182053 with new token with corr 0.23969314992427826\n",
      "Replaced token 1093 with corr 0.0979638621211052 with new token with corr 0.25052905082702637\n",
      "Replaced token 1095 with corr 0.12025484442710876 with new token with corr 0.16140015423297882\n",
      "Replaced token 1098 with corr 0.07346440106630325 with new token with corr 0.14864100515842438\n",
      "Replaced token 1110 with corr 0.10249369591474533 with new token with corr 0.17979593575000763\n",
      "Replaced token 1131 with corr 0.08043554425239563 with new token with corr 0.1565866470336914\n",
      "Replaced token 1152 with corr 0.1226913258433342 with new token with corr 0.2075427621603012\n",
      "Replaced token 1153 with corr 0.10632549226284027 with new token with corr 0.2262493073940277\n",
      "Replaced token 1162 with corr 0.11809735745191574 with new token with corr 0.22573135793209076\n",
      "Replaced token 1171 with corr 0.09213504195213318 with new token with corr 0.23409555852413177\n",
      "Replaced token 1172 with corr 0.11133114993572235 with new token with corr 0.21641553938388824\n",
      "Replaced token 1200 with corr 0.1666034758090973 with new token with corr 0.2607845067977905\n",
      "Replaced token 1202 with corr 0.12341270595788956 with new token with corr 0.22799696028232574\n",
      "Replaced token 1213 with corr 0.12440091371536255 with new token with corr 0.23250730335712433\n",
      "Replaced token 1240 with corr 0.1078638881444931 with new token with corr 0.255260169506073\n",
      "Replaced token 1256 with corr 0.11450932174921036 with new token with corr 0.1628721058368683\n",
      "Replaced token 1261 with corr 0.1271013468503952 with new token with corr 0.2786852717399597\n",
      "Replaced token 1263 with corr 0.11042303591966629 with new token with corr 0.23266048729419708\n",
      "Replaced token 1264 with corr 0.12782299518585205 with new token with corr 0.2583874464035034\n",
      "Replaced token 1265 with corr 0.09573346376419067 with new token with corr 0.1466173231601715\n",
      "Replaced token 1284 with corr 0.08835963159799576 with new token with corr 0.19375872611999512\n",
      "Replaced token 1294 with corr 0.11533965170383453 with new token with corr 0.1674846112728119\n",
      "Replaced token 1349 with corr 0.08382277935743332 with new token with corr 0.23777472972869873\n",
      "Replaced token 1351 with corr 0.07137275487184525 with new token with corr 0.246667742729187\n",
      "Replaced token 1357 with corr 0.10285451263189316 with new token with corr 0.1462312936782837\n",
      "Replaced token 1362 with corr 0.09793490171432495 with new token with corr 0.2076321393251419\n",
      "Replaced token 1363 with corr 0.07055403292179108 with new token with corr 0.20594865083694458\n",
      "Replaced token 1368 with corr 0.09996118396520615 with new token with corr 0.2627990245819092\n",
      "Replaced token 1373 with corr 0.09707263112068176 with new token with corr 0.22873805463314056\n",
      "Replaced token 1394 with corr 0.12385053932666779 with new token with corr 0.2960706353187561\n",
      "Replaced token 1411 with corr 0.09213609993457794 with new token with corr 0.2126815766096115\n",
      "Replaced token 1418 with corr 0.08426766842603683 with new token with corr 0.1918579488992691\n",
      "Replaced token 1422 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 1450 with corr 0.098807692527771 with new token with corr 0.15420272946357727\n",
      "Replaced token 1487 with corr 0.09526169300079346 with new token with corr 0.15965573489665985\n",
      "Replaced token 1489 with corr 0.1247924417257309 with new token with corr 0.33324137330055237\n",
      "Replaced token 1492 with corr 0.09415073692798615 with new token with corr 0.16341851651668549\n",
      "Replaced token 1493 with corr 0.12412174046039581 with new token with corr 0.22170911729335785\n",
      "Replaced token 1514 with corr 0.12196523696184158 with new token with corr 0.23732560873031616\n",
      "Replaced token 1572 with corr 0.1058175265789032 with new token with corr 0.2089463174343109\n",
      "Replaced token 1573 with corr 0.13325977325439453 with new token with corr 0.17801524698734283\n",
      "Replaced token 1630 with corr 0.14292779564857483 with new token with corr 0.21474862098693848\n",
      "Replaced token 1674 with corr 0.10315745323896408 with new token with corr 0.2663765847682953\n",
      "Replaced token 1678 with corr 0.12826283276081085 with new token with corr 0.24345025420188904\n",
      "Replaced token 1721 with corr 0.12230458110570908 with new token with corr 0.1910378485918045\n",
      "Replaced token 1724 with corr 0.09965529292821884 with new token with corr 0.23894765973091125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1725 with corr 0.11401858180761337 with new token with corr 0.23250730335712433\n",
      "Replaced token 1749 with corr 0.09431915730237961 with new token with corr 0.26409608125686646\n",
      "Replaced token 1765 with corr 0.113925039768219 with new token with corr 0.23003029823303223\n",
      "Replaced token 1772 with corr 0.12538324296474457 with new token with corr 0.17466109991073608\n",
      "Replaced token 1796 with corr 0.10505230724811554 with new token with corr 0.19375872611999512\n",
      "Replaced token 1797 with corr 0.1041848435997963 with new token with corr 0.20226873457431793\n",
      "Replaced token 1798 with corr 0.12051334232091904 with new token with corr 0.2571505308151245\n",
      "Replaced token 1815 with corr 0.09153895825147629 with new token with corr 0.2720903754234314\n",
      "Replaced token 1828 with corr 0.1047699898481369 with new token with corr 0.24702207744121552\n",
      "Replaced token 1851 with corr 0.14143934845924377 with new token with corr 0.21197469532489777\n",
      "Replaced token 1869 with corr 0.09271486848592758 with new token with corr 0.14925695955753326\n",
      "Replaced token 1886 with corr 0.09809347987174988 with new token with corr 0.15751954913139343\n",
      "Replaced token 1898 with corr 0.08746799826622009 with new token with corr 0.18822109699249268\n",
      "Replaced token 1911 with corr 0.10159188508987427 with new token with corr 0.2432563453912735\n",
      "Replaced token 1914 with corr 0.10121522843837738 with new token with corr 0.28528982400894165\n",
      "Replaced token 1919 with corr 0.1328171342611313 with new token with corr 0.2570674419403076\n",
      "Replaced token 1925 with corr 0.14087232947349548 with new token with corr 0.24447175860404968\n",
      "Replaced token 1937 with corr 0.10361011326313019 with new token with corr 0.19467350840568542\n",
      "Replaced token 1939 with corr 0.11677804589271545 with new token with corr 0.15687577426433563\n",
      "Replaced token 1950 with corr 0.10692845284938812 with new token with corr 0.1659749299287796\n",
      "Replaced token 1967 with corr 0.0919974073767662 with new token with corr 0.15440888702869415\n",
      "Replaced token 1994 with corr 0.07788437604904175 with new token with corr 0.15879173576831818\n",
      "Replaced token 2008 with corr 0.12380942702293396 with new token with corr 0.2583029270172119\n",
      "Replaced token 2013 with corr 0.0755612924695015 with new token with corr 0.24288199841976166\n",
      "Replaced token 2014 with corr 0.10457774251699448 with new token with corr 0.20454064011573792\n",
      "Replaced token 2025 with corr 0.10530538856983185 with new token with corr 0.2723276913166046\n",
      "Replaced token 2032 with corr 0.11544646322727203 with new token with corr 0.15804436802864075\n",
      "Replaced token 2035 with corr 0.11083207279443741 with new token with corr 0.1620553880929947\n",
      "Replaced token 2047 with corr 0.07412855327129364 with new token with corr 0.14971689879894257\n",
      "Replaced token 2053 with corr 0.09284576773643494 with new token with corr 0.15759992599487305\n",
      "Replaced token 2071 with corr 0.08480403572320938 with new token with corr 0.14924263954162598\n",
      "Replaced token 2085 with corr 0.11269345879554749 with new token with corr 0.32850000262260437\n",
      "Replaced token 2087 with corr 0.11677654832601547 with new token with corr 0.18592093884944916\n",
      "Replaced token 2088 with corr 0.09122069180011749 with new token with corr 0.15591472387313843\n",
      "Replaced token 2095 with corr 0.09982489794492722 with new token with corr 0.15364058315753937\n",
      "Replaced token 2107 with corr 0.11210350692272186 with new token with corr 0.16555650532245636\n",
      "Replaced token 2113 with corr 0.0988474115729332 with new token with corr 0.14790397882461548\n",
      "Replaced token 2119 with corr 0.11014771461486816 with new token with corr 0.19981727004051208\n",
      "Replaced token 2132 with corr 0.08016213029623032 with new token with corr 0.1699904054403305\n",
      "Replaced token 2156 with corr 0.09423402696847916 with new token with corr 0.14619101583957672\n",
      "Replaced token 2167 with corr 0.11323433369398117 with new token with corr 0.15724734961986542\n",
      "Replaced token 2175 with corr 0.07608034461736679 with new token with corr 0.15946857631206512\n",
      "Replaced token 2179 with corr 0.11742740124464035 with new token with corr 0.15789982676506042\n",
      "Replaced token 2181 with corr 0.11763665080070496 with new token with corr 0.16208957135677338\n",
      "Replaced token 2194 with corr 0.09419893473386765 with new token with corr 0.16334612667560577\n",
      "Replaced token 2203 with corr 0.12454036623239517 with new token with corr 0.2125348001718521\n",
      "Replaced token 2206 with corr 0.10140426456928253 with new token with corr 0.14577537775039673\n",
      "Replaced token 2212 with corr 0.078856460750103 with new token with corr 0.17004385590553284\n",
      "Replaced token 2234 with corr 0.086077481508255 with new token with corr 0.15172408521175385\n",
      "Replaced token 2254 with corr 0.08562545478343964 with new token with corr 0.13981670141220093\n",
      "Replaced token 2262 with corr 0.15538953244686127 with new token with corr 0.24535267055034637\n",
      "Replaced token 2276 with corr 0.10801269114017487 with new token with corr 0.21808457374572754\n",
      "Replaced token 2291 with corr 0.08843442052602768 with new token with corr 0.16082386672496796\n",
      "Replaced token 2297 with corr 0.10756257176399231 with new token with corr 0.15493832528591156\n",
      "Replaced token 2301 with corr 0.08621449023485184 with new token with corr 0.1564738005399704\n",
      "Replaced token 2327 with corr 0.08854228258132935 with new token with corr 0.15950819849967957\n",
      "Replaced token 2332 with corr 0.08288747072219849 with new token with corr 0.15377984941005707\n",
      "Replaced token 2340 with corr 0.11191259324550629 with new token with corr 0.1576612889766693\n",
      "Replaced token 2344 with corr 0.09841009229421616 with new token with corr 0.1914386749267578\n",
      "Replaced token 2358 with corr 0.13088653981685638 with new token with corr 0.2129574716091156\n",
      "Replaced token 2365 with corr 0.10503681749105453 with new token with corr 0.1948922723531723\n",
      "Replaced token 2368 with corr 0.09226346760988235 with new token with corr 0.16253669559955597\n",
      "Replaced token 2379 with corr 0.08703435212373734 with new token with corr 0.15441136062145233\n",
      "Replaced token 2385 with corr 0.09798111021518707 with new token with corr 0.3236064016819\n",
      "Replaced token 2386 with corr 0.10839793086051941 with new token with corr 0.17683298885822296\n",
      "Replaced token 2393 with corr 0.1123812273144722 with new token with corr 0.16104480624198914\n",
      "Replaced token 2396 with corr 0.10801953077316284 with new token with corr 0.1671046018600464\n",
      "Replaced token 2413 with corr 0.08556809276342392 with new token with corr 0.34158772230148315\n",
      "Replaced token 2428 with corr 0.07455836236476898 with new token with corr 0.2022038847208023\n",
      "Replaced token 2434 with corr 0.12066151201725006 with new token with corr 0.17029590904712677\n",
      "Replaced token 2446 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 2453 with corr 0.10589312762022018 with new token with corr 0.16211055219173431\n",
      "Replaced token 2454 with corr 0.10390853136777878 with new token with corr 0.2800275385379791\n",
      "Replaced token 2475 with corr 0.08915002644062042 with new token with corr 0.18457834422588348\n",
      "Replaced token 2480 with corr 0.09509865939617157 with new token with corr 0.16629163920879364\n",
      "Replaced token 2488 with corr 0.12982840836048126 with new token with corr 0.20136673748493195\n",
      "Replaced token 2491 with corr 0.11028311401605606 with new token with corr 0.1553986519575119\n",
      "Replaced token 2497 with corr 0.10846427083015442 with new token with corr 0.2654228210449219\n",
      "Replaced token 2498 with corr 0.11025235056877136 with new token with corr 0.2499328851699829\n",
      "Replaced token 2503 with corr 0.10148318111896515 with new token with corr 0.14484058320522308\n",
      "Replaced token 2509 with corr 0.13025347888469696 with new token with corr 0.2553485333919525\n",
      "Replaced token 2522 with corr 0.0978996679186821 with new token with corr 0.1519155353307724\n",
      "Replaced token 2526 with corr 0.08897241204977036 with new token with corr 0.2087474912405014\n",
      "Replaced token 2527 with corr 0.09985345602035522 with new token with corr 0.15002985298633575\n",
      "Replaced token 2539 with corr 0.10612896829843521 with new token with corr 0.14835987985134125\n",
      "Replaced token 2559 with corr 0.0657072365283966 with new token with corr 0.14971689879894257\n",
      "Replaced token 2585 with corr 0.10871854424476624 with new token with corr 0.21969276666641235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2604 with corr 0.1071554645895958 with new token with corr 0.1581401377916336\n",
      "Replaced token 2647 with corr 0.08146478235721588 with new token with corr 0.20139718055725098\n",
      "Replaced token 2648 with corr 0.08135887235403061 with new token with corr 0.2486138641834259\n",
      "Replaced token 2695 with corr 0.08733444660902023 with new token with corr 0.16646850109100342\n",
      "Replaced token 2712 with corr 0.07433526962995529 with new token with corr 0.24520720541477203\n",
      "Replaced token 2787 with corr 0.09799249470233917 with new token with corr 0.21334560215473175\n",
      "Replaced token 2795 with corr 0.09221586585044861 with new token with corr 0.28454074263572693\n",
      "Replaced token 2802 with corr 0.10049636662006378 with new token with corr 0.27976542711257935\n",
      "Replaced token 2805 with corr 0.12199008464813232 with new token with corr 0.237598717212677\n",
      "Replaced token 2828 with corr 0.08878589421510696 with new token with corr 0.29726266860961914\n",
      "Replaced token 2855 with corr 0.10787904262542725 with new token with corr 0.15284587442874908\n",
      "Replaced token 2856 with corr 0.08848107606172562 with new token with corr 0.17137888073921204\n",
      "Replaced token 2860 with corr 0.12482638657093048 with new token with corr 0.17887961864471436\n",
      "Replaced token 2870 with corr 0.09994734823703766 with new token with corr 0.16403447091579437\n",
      "Replaced token 2882 with corr 0.08526802062988281 with new token with corr 0.21527671813964844\n",
      "Replaced token 2883 with corr 0.10055611282587051 with new token with corr 0.23668323457241058\n",
      "Replaced token 2901 with corr 0.10089803487062454 with new token with corr 0.1897086352109909\n",
      "Replaced token 2911 with corr 0.1145368367433548 with new token with corr 0.22872769832611084\n",
      "Replaced token 2914 with corr 0.08962295949459076 with new token with corr 0.2755124270915985\n",
      "Replaced token 2926 with corr 0.0813339427113533 with new token with corr 0.1766229122877121\n",
      "Replaced token 2931 with corr 0.10793379694223404 with new token with corr 0.3027452528476715\n",
      "Replaced token 2943 with corr 0.12474377453327179 with new token with corr 0.2676112949848175\n",
      "Replaced token 2962 with corr 0.08167469501495361 with new token with corr 0.15196111798286438\n",
      "Replaced token 2976 with corr 0.10337535291910172 with new token with corr 0.1584203541278839\n",
      "Replaced token 2977 with corr 0.11099407821893692 with new token with corr 0.14886930584907532\n",
      "Replaced token 3023 with corr 0.10768715292215347 with new token with corr 0.14940567314624786\n",
      "Replaced token 3027 with corr 0.11195295304059982 with new token with corr 0.2836076021194458\n",
      "Replaced token 3030 with corr 0.09112260490655899 with new token with corr 0.21726897358894348\n",
      "Replaced token 3031 with corr 0.1106770858168602 with new token with corr 0.1531311273574829\n",
      "Replaced token 3054 with corr 0.1288672685623169 with new token with corr 0.23834443092346191\n",
      "Replaced token 3094 with corr 0.10854519158601761 with new token with corr 0.30788329243659973\n",
      "Replaced token 3109 with corr 0.10213868319988251 with new token with corr 0.25648751854896545\n",
      "Replaced token 3127 with corr 0.0960758626461029 with new token with corr 0.15783217549324036\n",
      "Replaced token 3128 with corr 0.08161012083292007 with new token with corr 0.2301304042339325\n",
      "Replaced token 3143 with corr 0.08852166682481766 with new token with corr 0.19981727004051208\n",
      "Replaced token 3166 with corr 0.09498576074838638 with new token with corr 0.24592570960521698\n",
      "Replaced token 3175 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 3204 with corr 0.1083015725016594 with new token with corr 0.20106463134288788\n",
      "Replaced token 3211 with corr 0.1092938631772995 with new token with corr 0.22648459672927856\n",
      "Replaced token 3213 with corr 0.09117642790079117 with new token with corr 0.16049659252166748\n",
      "Replaced token 3221 with corr 0.07762452960014343 with new token with corr 0.2182246446609497\n",
      "Replaced token 3223 with corr 0.09327423572540283 with new token with corr 0.2611684203147888\n",
      "Replaced token 3224 with corr 0.11905615776777267 with new token with corr 0.16442018747329712\n",
      "Replaced token 3308 with corr 0.10283837467432022 with new token with corr 0.23205004632472992\n",
      "Replaced token 3329 with corr 0.1003747284412384 with new token with corr 0.14953385293483734\n",
      "Replaced token 3335 with corr 0.08474868535995483 with new token with corr 0.260865181684494\n",
      "Replaced token 3340 with corr 0.08995696157217026 with new token with corr 0.29117822647094727\n",
      "Replaced token 3344 with corr 0.07471393793821335 with new token with corr 0.20954430103302002\n",
      "Replaced token 3370 with corr 0.10360986739397049 with new token with corr 0.14797066152095795\n",
      "Replaced token 3402 with corr 0.09207748621702194 with new token with corr 0.20862500369548798\n",
      "Replaced token 3413 with corr 0.07762213796377182 with new token with corr 0.1717095524072647\n",
      "Replaced token 3415 with corr 0.11113911122083664 with new token with corr 0.23568634688854218\n",
      "Replaced token 3451 with corr 0.09928575158119202 with new token with corr 0.2579036355018616\n",
      "Replaced token 3479 with corr 0.09774256497621536 with new token with corr 0.18581438064575195\n",
      "Replaced token 3480 with corr 0.11261890828609467 with new token with corr 0.23385603725910187\n",
      "Replaced token 3486 with corr 0.094296395778656 with new token with corr 0.26696982979774475\n",
      "Replaced token 3504 with corr 0.10243967920541763 with new token with corr 0.21259687840938568\n",
      "Replaced token 3508 with corr 0.11241219192743301 with new token with corr 0.3117140233516693\n",
      "Replaced token 3522 with corr 0.11608175188302994 with new token with corr 0.2361796647310257\n",
      "Replaced token 3537 with corr 0.1282229721546173 with new token with corr 0.25225773453712463\n",
      "Replaced token 3540 with corr 0.0735185369849205 with new token with corr 0.18384917080402374\n",
      "Replaced token 3547 with corr 0.12320207059383392 with new token with corr 0.2969287633895874\n",
      "Replaced token 3554 with corr 0.11856120079755783 with new token with corr 0.20777767896652222\n",
      "Replaced token 3565 with corr 0.07344812899827957 with new token with corr 0.14897918701171875\n",
      "Replaced token 3573 with corr 0.0852590948343277 with new token with corr 0.22231847047805786\n",
      "Replaced token 3583 with corr 0.07468339055776596 with new token with corr 0.15685757994651794\n",
      "Replaced token 3605 with corr 0.15743738412857056 with new token with corr 0.24347980320453644\n",
      "Replaced token 3611 with corr 0.1045120358467102 with new token with corr 0.2583322823047638\n",
      "Replaced token 3617 with corr 0.11635561287403107 with new token with corr 0.21962647140026093\n",
      "Replaced token 3622 with corr 0.11626020818948746 with new token with corr 0.15774716436862946\n",
      "Replaced token 3623 with corr 0.09608295559883118 with new token with corr 0.20783036947250366\n",
      "Replaced token 3631 with corr 0.07907850295305252 with new token with corr 0.1806187927722931\n",
      "Replaced token 3638 with corr 0.07013028860092163 with new token with corr 0.1800089031457901\n",
      "Replaced token 3667 with corr 0.10379547625780106 with new token with corr 0.2801976799964905\n",
      "Replaced token 3669 with corr 0.07176963239908218 with new token with corr 0.2982428967952728\n",
      "Replaced token 3670 with corr 0.06947410106658936 with new token with corr 0.32409781217575073\n",
      "Replaced token 3673 with corr 0.11199440062046051 with new token with corr 0.21503151953220367\n",
      "Replaced token 3674 with corr 0.1082954853773117 with new token with corr 0.34233036637306213\n",
      "Replaced token 3679 with corr 0.08759612590074539 with new token with corr 0.23954784870147705\n",
      "Replaced token 3701 with corr 0.13045057654380798 with new token with corr 0.25759297609329224\n",
      "Replaced token 3708 with corr 0.13221634924411774 with new token with corr 0.26396578550338745\n",
      "Replaced token 3713 with corr 0.0684177502989769 with new token with corr 0.2262493073940277\n",
      "Replaced token 3727 with corr 0.12891528010368347 with new token with corr 0.24917134642601013\n",
      "Replaced token 3735 with corr 0.11797637492418289 with new token with corr 0.2217080146074295\n",
      "Replaced token 3736 with corr 0.09470909088850021 with new token with corr 0.21329985558986664\n",
      "Replaced token 3737 with corr 0.1390988528728485 with new token with corr 0.2615695893764496\n",
      "Replaced token 3744 with corr 0.0792054533958435 with new token with corr 0.2511129677295685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3751 with corr 0.08053730428218842 with new token with corr 0.14904911816120148\n",
      "Replaced token 3760 with corr 0.12319856882095337 with new token with corr 0.16508053243160248\n",
      "Replaced token 3785 with corr 0.08235035091638565 with new token with corr 0.19586622714996338\n",
      "Replaced token 3794 with corr 0.0956580862402916 with new token with corr 0.2699718177318573\n",
      "Replaced token 3806 with corr 0.10203952342271805 with new token with corr 0.1528431475162506\n",
      "Replaced token 3818 with corr 0.1288331151008606 with new token with corr 0.23295429348945618\n",
      "Replaced token 3841 with corr 0.09109344333410263 with new token with corr 0.1467636376619339\n",
      "Replaced token 3843 with corr 0.09166190773248672 with new token with corr 0.2591124176979065\n",
      "Replaced token 3849 with corr 0.10936854779720306 with new token with corr 0.26489901542663574\n",
      "Replaced token 3851 with corr 0.10035465657711029 with new token with corr 0.22951041162014008\n",
      "Replaced token 3871 with corr 0.11843269318342209 with new token with corr 0.2503451406955719\n",
      "Replaced token 3872 with corr 0.11060427874326706 with new token with corr 0.2391880452632904\n",
      "Replaced token 3875 with corr 0.09328150004148483 with new token with corr 0.15586718916893005\n",
      "Replaced token 3885 with corr 0.0908476859331131 with new token with corr 0.2347525656223297\n",
      "Replaced token 3914 with corr 0.08463185280561447 with new token with corr 0.15947912633419037\n",
      "Replaced token 3923 with corr 0.09905815124511719 with new token with corr 0.14535480737686157\n",
      "Replaced token 3926 with corr 0.12426407635211945 with new token with corr 0.23572112619876862\n",
      "Replaced token 3928 with corr 0.09814780950546265 with new token with corr 0.2512640953063965\n",
      "Replaced token 3933 with corr 0.10581307113170624 with new token with corr 0.2439889907836914\n",
      "Replaced token 3946 with corr 0.11236857622861862 with new token with corr 0.18822109699249268\n",
      "Replaced token 3948 with corr 0.10665471851825714 with new token with corr 0.25099965929985046\n",
      "Replaced token 3957 with corr 0.11053760349750519 with new token with corr 0.1511632204055786\n",
      "Replaced token 3960 with corr 0.08955783396959305 with new token with corr 0.23699374496936798\n",
      "Replaced token 3977 with corr 0.1248236894607544 with new token with corr 0.22677119076251984\n",
      "Replaced token 3979 with corr 0.09531667828559875 with new token with corr 0.2902751863002777\n",
      "Replaced token 3987 with corr 0.09578265994787216 with new token with corr 0.18374766409397125\n",
      "Replaced token 4007 with corr 0.10252664983272552 with new token with corr 0.25471606850624084\n",
      "Replaced token 4022 with corr 0.10040204226970673 with new token with corr 0.21668174862861633\n",
      "Replaced token 4023 with corr 0.0731392577290535 with new token with corr 0.1712467074394226\n",
      "Replaced token 4032 with corr 0.10857785493135452 with new token with corr 0.20799802243709564\n",
      "Replaced token 4041 with corr 0.10823719203472137 with new token with corr 0.2075950801372528\n",
      "Replaced token 4081 with corr 0.09662853181362152 with new token with corr 0.19235314428806305\n",
      "Replaced token 4095 with corr 0.0721680223941803 with new token with corr 0.14965713024139404\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.9045 | S-BLEU: 0.78 | FMSE: 2.7421e-03 | \n",
      " G-BLEU: 0.74 | ROUGE1: 0.89| ROUGE2: 0.78 | ROUGE-L: 0.88| Token Acc: 93.31% | Label Acc: 93.31%\n",
      "Evaluating dynamic-threshold with 0.95\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Replaced token 32 with corr 0.10004569590091705 with new token with corr 0.27175667881965637\n",
      "Replaced token 58 with corr 0.12161212414503098 with new token with corr 0.3063763380050659\n",
      "Replaced token 61 with corr 0.13545501232147217 with new token with corr 0.15473876893520355\n",
      "Replaced token 96 with corr 0.09464694559574127 with new token with corr 0.2000071108341217\n",
      "Replaced token 100 with corr 0.11622016131877899 with new token with corr 0.2580813467502594\n",
      "Replaced token 123 with corr 0.10482989251613617 with new token with corr 0.221369206905365\n",
      "Replaced token 142 with corr 0.1426793485879898 with new token with corr 0.24854715168476105\n",
      "Replaced token 144 with corr 0.137878879904747 with new token with corr 0.15511299669742584\n",
      "Replaced token 147 with corr 0.09084136039018631 with new token with corr 0.13877294957637787\n",
      "Replaced token 148 with corr 0.11775460094213486 with new token with corr 0.1684461236000061\n",
      "Replaced token 152 with corr 0.14698071777820587 with new token with corr 0.17307201027870178\n",
      "Replaced token 156 with corr 0.0995953381061554 with new token with corr 0.19734443724155426\n",
      "Replaced token 166 with corr 0.08978059887886047 with new token with corr 0.3762853443622589\n",
      "Replaced token 172 with corr 0.09863615036010742 with new token with corr 0.1725509762763977\n",
      "Replaced token 188 with corr 0.09136594831943512 with new token with corr 0.23894765973091125\n",
      "Replaced token 191 with corr 0.1137547567486763 with new token with corr 0.26309698820114136\n",
      "Replaced token 202 with corr 0.1084042489528656 with new token with corr 0.15070481598377228\n",
      "Replaced token 205 with corr 0.0792447179555893 with new token with corr 0.2740797698497772\n",
      "Replaced token 257 with corr 0.09256129711866379 with new token with corr 0.24084514379501343\n",
      "Replaced token 259 with corr 0.14304155111312866 with new token with corr 0.16333922743797302\n",
      "Replaced token 265 with corr 0.09990415722131729 with new token with corr 0.26489901542663574\n",
      "Replaced token 266 with corr 0.09759923070669174 with new token with corr 0.2242376208305359\n",
      "Replaced token 312 with corr 0.13131514191627502 with new token with corr 0.15758179128170013\n",
      "Replaced token 326 with corr 0.07846662402153015 with new token with corr 0.15889431536197662\n",
      "Replaced token 357 with corr 0.11765756458044052 with new token with corr 0.25508594512939453\n",
      "Replaced token 363 with corr 0.11083157360553741 with new token with corr 0.22495022416114807\n",
      "Replaced token 389 with corr 0.12040932476520538 with new token with corr 0.2243054360151291\n",
      "Replaced token 422 with corr 0.09864215552806854 with new token with corr 0.2360743284225464\n",
      "Replaced token 440 with corr 0.09062034636735916 with new token with corr 0.15890830755233765\n",
      "Replaced token 458 with corr 0.11354941129684448 with new token with corr 0.3059351146221161\n",
      "Replaced token 487 with corr 0.11485637724399567 with new token with corr 0.25687742233276367\n",
      "Replaced token 488 with corr 0.10698159784078598 with new token with corr 0.22048774361610413\n",
      "Replaced token 490 with corr 0.09709368646144867 with new token with corr 0.31151992082595825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 511 with corr 0.07224166393280029 with new token with corr 0.14823205769062042\n",
      "Replaced token 525 with corr 0.11561029404401779 with new token with corr 0.25178301334381104\n",
      "Replaced token 538 with corr 0.09454026818275452 with new token with corr 0.15348148345947266\n",
      "Replaced token 566 with corr 0.11152159422636032 with new token with corr 0.22072097659111023\n",
      "Replaced token 572 with corr 0.10247683525085449 with new token with corr 0.1441391110420227\n",
      "Replaced token 592 with corr 0.09372688829898834 with new token with corr 0.31124797463417053\n",
      "Replaced token 599 with corr 0.09186166524887085 with new token with corr 0.20139718055725098\n",
      "Replaced token 615 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 618 with corr 0.11568886786699295 with new token with corr 0.23867349326610565\n",
      "Replaced token 640 with corr 0.12705056369304657 with new token with corr 0.29355359077453613\n",
      "Replaced token 641 with corr 0.12931184470653534 with new token with corr 0.1511695832014084\n",
      "Replaced token 647 with corr 0.13254739344120026 with new token with corr 0.14750154316425323\n",
      "Replaced token 654 with corr 0.08123092353343964 with new token with corr 0.17212828993797302\n",
      "Replaced token 660 with corr 0.10303323715925217 with new token with corr 0.14963647723197937\n",
      "Replaced token 661 with corr 0.07817701250314713 with new token with corr 0.29225459694862366\n",
      "Replaced token 681 with corr 0.11854878813028336 with new token with corr 0.14750728011131287\n",
      "Replaced token 708 with corr 0.08453399688005447 with new token with corr 0.15257667005062103\n",
      "Replaced token 713 with corr 0.0795915424823761 with new token with corr 0.19586622714996338\n",
      "Replaced token 715 with corr 0.09467495232820511 with new token with corr 0.20234717428684235\n",
      "Replaced token 720 with corr 0.0878865048289299 with new token with corr 0.1572844237089157\n",
      "Replaced token 725 with corr 0.08259778469800949 with new token with corr 0.22294455766677856\n",
      "Replaced token 731 with corr 0.10537471622228622 with new token with corr 0.22179755568504333\n",
      "Replaced token 736 with corr 0.12210801243782043 with new token with corr 0.14934375882148743\n",
      "Replaced token 758 with corr 0.10030191391706467 with new token with corr 0.15615716576576233\n",
      "Replaced token 769 with corr 0.08440469950437546 with new token with corr 0.14953385293483734\n",
      "Replaced token 771 with corr 0.09703671932220459 with new token with corr 0.302799254655838\n",
      "Replaced token 773 with corr 0.09112171828746796 with new token with corr 0.16130287945270538\n",
      "Replaced token 777 with corr 0.09922241419553757 with new token with corr 0.2945486605167389\n",
      "Replaced token 791 with corr 0.07144638150930405 with new token with corr 0.17704078555107117\n",
      "Replaced token 792 with corr 0.09265730530023575 with new token with corr 0.14915414154529572\n",
      "Replaced token 798 with corr 0.09041425585746765 with new token with corr 0.20528154075145721\n",
      "Replaced token 800 with corr 0.09082973748445511 with new token with corr 0.14501212537288666\n",
      "Replaced token 839 with corr 0.09296030551195145 with new token with corr 0.246667742729187\n",
      "Replaced token 848 with corr 0.10579328238964081 with new token with corr 0.14981573820114136\n",
      "Replaced token 867 with corr 0.09563031792640686 with new token with corr 0.16406835615634918\n",
      "Replaced token 870 with corr 0.07660464197397232 with new token with corr 0.31718987226486206\n",
      "Replaced token 899 with corr 0.11751987785100937 with new token with corr 0.14607861638069153\n",
      "Replaced token 910 with corr 0.13502371311187744 with new token with corr 0.153864324092865\n",
      "Replaced token 919 with corr 0.09916584193706512 with new token with corr 0.18581438064575195\n",
      "Replaced token 923 with corr 0.14851413667201996 with new token with corr 0.16132427752017975\n",
      "Replaced token 957 with corr 0.09542372822761536 with new token with corr 0.23909063637256622\n",
      "Replaced token 973 with corr 0.12015997618436813 with new token with corr 0.18991312384605408\n",
      "Replaced token 989 with corr 0.09649454057216644 with new token with corr 0.13950996100902557\n",
      "Replaced token 1023 with corr 0.07638375461101532 with new token with corr 0.15259888768196106\n",
      "Replaced token 1031 with corr 0.10887496918439865 with new token with corr 0.21241869032382965\n",
      "Replaced token 1050 with corr 0.10594883561134338 with new token with corr 0.24959640204906464\n",
      "Replaced token 1057 with corr 0.08473658561706543 with new token with corr 0.22825545072555542\n",
      "Replaced token 1074 with corr 0.08387237042188644 with new token with corr 0.1788710653781891\n",
      "Replaced token 1082 with corr 0.13931381702423096 with new token with corr 0.14919304847717285\n",
      "Replaced token 1089 with corr 0.09365814179182053 with new token with corr 0.23969314992427826\n",
      "Replaced token 1093 with corr 0.0979638621211052 with new token with corr 0.25052905082702637\n",
      "Replaced token 1095 with corr 0.12025484442710876 with new token with corr 0.16140015423297882\n",
      "Replaced token 1098 with corr 0.07346440106630325 with new token with corr 0.14864100515842438\n",
      "Replaced token 1110 with corr 0.10249369591474533 with new token with corr 0.17979593575000763\n",
      "Replaced token 1131 with corr 0.08043554425239563 with new token with corr 0.1565866470336914\n",
      "Replaced token 1152 with corr 0.1226913258433342 with new token with corr 0.2075427621603012\n",
      "Replaced token 1153 with corr 0.10632549226284027 with new token with corr 0.2262493073940277\n",
      "Replaced token 1160 with corr 0.12260282039642334 with new token with corr 0.14229854941368103\n",
      "Replaced token 1162 with corr 0.11809735745191574 with new token with corr 0.22573135793209076\n",
      "Replaced token 1171 with corr 0.09213504195213318 with new token with corr 0.23409555852413177\n",
      "Replaced token 1172 with corr 0.11133114993572235 with new token with corr 0.21641553938388824\n",
      "Replaced token 1200 with corr 0.1666034758090973 with new token with corr 0.2607845067977905\n",
      "Replaced token 1202 with corr 0.12341270595788956 with new token with corr 0.22799696028232574\n",
      "Replaced token 1213 with corr 0.12440091371536255 with new token with corr 0.23250730335712433\n",
      "Replaced token 1224 with corr 0.1334320306777954 with new token with corr 0.15117771923542023\n",
      "Replaced token 1240 with corr 0.1078638881444931 with new token with corr 0.255260169506073\n",
      "Replaced token 1256 with corr 0.11450932174921036 with new token with corr 0.1628721058368683\n",
      "Replaced token 1261 with corr 0.1271013468503952 with new token with corr 0.2786852717399597\n",
      "Replaced token 1263 with corr 0.11042303591966629 with new token with corr 0.23266048729419708\n",
      "Replaced token 1264 with corr 0.12782299518585205 with new token with corr 0.2583874464035034\n",
      "Replaced token 1265 with corr 0.09573346376419067 with new token with corr 0.1466173231601715\n",
      "Replaced token 1284 with corr 0.08835963159799576 with new token with corr 0.19375872611999512\n",
      "Replaced token 1294 with corr 0.11533965170383453 with new token with corr 0.1674846112728119\n",
      "Replaced token 1349 with corr 0.08382277935743332 with new token with corr 0.23777472972869873\n",
      "Replaced token 1351 with corr 0.07137275487184525 with new token with corr 0.246667742729187\n",
      "Replaced token 1352 with corr 0.11622028797864914 with new token with corr 0.1512851119041443\n",
      "Replaced token 1357 with corr 0.10285451263189316 with new token with corr 0.1462312936782837\n",
      "Replaced token 1362 with corr 0.09793490171432495 with new token with corr 0.2076321393251419\n",
      "Replaced token 1363 with corr 0.07055403292179108 with new token with corr 0.20594865083694458\n",
      "Replaced token 1368 with corr 0.09996118396520615 with new token with corr 0.2627990245819092\n",
      "Replaced token 1373 with corr 0.09707263112068176 with new token with corr 0.22873805463314056\n",
      "Replaced token 1394 with corr 0.12385053932666779 with new token with corr 0.2960706353187561\n",
      "Replaced token 1411 with corr 0.09213609993457794 with new token with corr 0.2126815766096115\n",
      "Replaced token 1418 with corr 0.08426766842603683 with new token with corr 0.1918579488992691\n",
      "Replaced token 1422 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 1450 with corr 0.098807692527771 with new token with corr 0.15420272946357727\n",
      "Replaced token 1487 with corr 0.09526169300079346 with new token with corr 0.15965573489665985\n",
      "Replaced token 1489 with corr 0.1247924417257309 with new token with corr 0.33324137330055237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1492 with corr 0.09415073692798615 with new token with corr 0.16341851651668549\n",
      "Replaced token 1493 with corr 0.12412174046039581 with new token with corr 0.22170911729335785\n",
      "Replaced token 1499 with corr 0.11585573852062225 with new token with corr 0.15386910736560822\n",
      "Replaced token 1514 with corr 0.12196523696184158 with new token with corr 0.23732560873031616\n",
      "Replaced token 1535 with corr 0.12499857693910599 with new token with corr 0.1514664590358734\n",
      "Replaced token 1572 with corr 0.1058175265789032 with new token with corr 0.2089463174343109\n",
      "Replaced token 1573 with corr 0.13325977325439453 with new token with corr 0.17801524698734283\n",
      "Replaced token 1574 with corr 0.15179938077926636 with new token with corr 0.1811733841896057\n",
      "Replaced token 1617 with corr 0.12679360806941986 with new token with corr 0.1484745293855667\n",
      "Replaced token 1630 with corr 0.14292779564857483 with new token with corr 0.21474862098693848\n",
      "Replaced token 1645 with corr 0.14035627245903015 with new token with corr 0.14863604307174683\n",
      "Replaced token 1668 with corr 0.11640621721744537 with new token with corr 0.13924497365951538\n",
      "Replaced token 1674 with corr 0.10315745323896408 with new token with corr 0.2663765847682953\n",
      "Replaced token 1678 with corr 0.12826283276081085 with new token with corr 0.24345025420188904\n",
      "Replaced token 1683 with corr 0.11616560071706772 with new token with corr 0.1530694216489792\n",
      "Replaced token 1721 with corr 0.12230458110570908 with new token with corr 0.1910378485918045\n",
      "Replaced token 1724 with corr 0.09965529292821884 with new token with corr 0.23894765973091125\n",
      "Replaced token 1725 with corr 0.11401858180761337 with new token with corr 0.23250730335712433\n",
      "Replaced token 1749 with corr 0.09431915730237961 with new token with corr 0.26409608125686646\n",
      "Replaced token 1765 with corr 0.113925039768219 with new token with corr 0.23003029823303223\n",
      "Replaced token 1772 with corr 0.12538324296474457 with new token with corr 0.17466109991073608\n",
      "Replaced token 1796 with corr 0.10505230724811554 with new token with corr 0.19375872611999512\n",
      "Replaced token 1797 with corr 0.1041848435997963 with new token with corr 0.20226873457431793\n",
      "Replaced token 1798 with corr 0.12051334232091904 with new token with corr 0.2571505308151245\n",
      "Replaced token 1815 with corr 0.09153895825147629 with new token with corr 0.2720903754234314\n",
      "Replaced token 1828 with corr 0.1047699898481369 with new token with corr 0.24702207744121552\n",
      "Replaced token 1851 with corr 0.14143934845924377 with new token with corr 0.21197469532489777\n",
      "Replaced token 1869 with corr 0.09271486848592758 with new token with corr 0.14925695955753326\n",
      "Replaced token 1886 with corr 0.09809347987174988 with new token with corr 0.15751954913139343\n",
      "Replaced token 1898 with corr 0.08746799826622009 with new token with corr 0.18822109699249268\n",
      "Replaced token 1911 with corr 0.10159188508987427 with new token with corr 0.2432563453912735\n",
      "Replaced token 1914 with corr 0.10121522843837738 with new token with corr 0.28528982400894165\n",
      "Replaced token 1919 with corr 0.1328171342611313 with new token with corr 0.2570674419403076\n",
      "Replaced token 1925 with corr 0.14087232947349548 with new token with corr 0.24447175860404968\n",
      "Replaced token 1937 with corr 0.10361011326313019 with new token with corr 0.19467350840568542\n",
      "Replaced token 1939 with corr 0.11677804589271545 with new token with corr 0.15687577426433563\n",
      "Replaced token 1950 with corr 0.10692845284938812 with new token with corr 0.1659749299287796\n",
      "Replaced token 1967 with corr 0.0919974073767662 with new token with corr 0.15440888702869415\n",
      "Replaced token 1994 with corr 0.07788437604904175 with new token with corr 0.15879173576831818\n",
      "Replaced token 2008 with corr 0.12380942702293396 with new token with corr 0.2583029270172119\n",
      "Replaced token 2013 with corr 0.0755612924695015 with new token with corr 0.24288199841976166\n",
      "Replaced token 2014 with corr 0.10457774251699448 with new token with corr 0.20454064011573792\n",
      "Replaced token 2025 with corr 0.10530538856983185 with new token with corr 0.2723276913166046\n",
      "Replaced token 2032 with corr 0.11544646322727203 with new token with corr 0.15804436802864075\n",
      "Replaced token 2035 with corr 0.11083207279443741 with new token with corr 0.1620553880929947\n",
      "Replaced token 2047 with corr 0.07412855327129364 with new token with corr 0.14971689879894257\n",
      "Replaced token 2053 with corr 0.09284576773643494 with new token with corr 0.15759992599487305\n",
      "Replaced token 2071 with corr 0.08480403572320938 with new token with corr 0.14924263954162598\n",
      "Replaced token 2085 with corr 0.11269345879554749 with new token with corr 0.32850000262260437\n",
      "Replaced token 2087 with corr 0.11677654832601547 with new token with corr 0.18592093884944916\n",
      "Replaced token 2088 with corr 0.09122069180011749 with new token with corr 0.15591472387313843\n",
      "Replaced token 2095 with corr 0.09982489794492722 with new token with corr 0.15364058315753937\n",
      "Replaced token 2102 with corr 0.1170656755566597 with new token with corr 0.15395185351371765\n",
      "Replaced token 2107 with corr 0.11210350692272186 with new token with corr 0.16555650532245636\n",
      "Replaced token 2113 with corr 0.0988474115729332 with new token with corr 0.14790397882461548\n",
      "Replaced token 2119 with corr 0.11014771461486816 with new token with corr 0.19981727004051208\n",
      "Replaced token 2132 with corr 0.08016213029623032 with new token with corr 0.1699904054403305\n",
      "Replaced token 2156 with corr 0.09423402696847916 with new token with corr 0.14619101583957672\n",
      "Replaced token 2164 with corr 0.1118878722190857 with new token with corr 0.14630191028118134\n",
      "Replaced token 2167 with corr 0.11323433369398117 with new token with corr 0.15724734961986542\n",
      "Replaced token 2175 with corr 0.07608034461736679 with new token with corr 0.15946857631206512\n",
      "Replaced token 2179 with corr 0.11742740124464035 with new token with corr 0.15789982676506042\n",
      "Replaced token 2181 with corr 0.11763665080070496 with new token with corr 0.16208957135677338\n",
      "Replaced token 2194 with corr 0.09419893473386765 with new token with corr 0.16334612667560577\n",
      "Replaced token 2203 with corr 0.12454036623239517 with new token with corr 0.2125348001718521\n",
      "Replaced token 2206 with corr 0.10140426456928253 with new token with corr 0.14577537775039673\n",
      "Replaced token 2212 with corr 0.078856460750103 with new token with corr 0.17004385590553284\n",
      "Replaced token 2234 with corr 0.086077481508255 with new token with corr 0.15172408521175385\n",
      "Replaced token 2254 with corr 0.08562545478343964 with new token with corr 0.13981670141220093\n",
      "Replaced token 2262 with corr 0.15538953244686127 with new token with corr 0.24535267055034637\n",
      "Replaced token 2276 with corr 0.10801269114017487 with new token with corr 0.21808457374572754\n",
      "Replaced token 2280 with corr 0.13827355206012726 with new token with corr 0.16273275017738342\n",
      "Replaced token 2291 with corr 0.08843442052602768 with new token with corr 0.16082386672496796\n",
      "Replaced token 2297 with corr 0.10756257176399231 with new token with corr 0.15493832528591156\n",
      "Replaced token 2301 with corr 0.08621449023485184 with new token with corr 0.1564738005399704\n",
      "Replaced token 2305 with corr 0.14443953335285187 with new token with corr 0.16530855000019073\n",
      "Replaced token 2319 with corr 0.13409604132175446 with new token with corr 0.16834183037281036\n",
      "Replaced token 2327 with corr 0.08854228258132935 with new token with corr 0.15950819849967957\n",
      "Replaced token 2332 with corr 0.08288747072219849 with new token with corr 0.15377984941005707\n",
      "Replaced token 2340 with corr 0.11191259324550629 with new token with corr 0.1576612889766693\n",
      "Replaced token 2344 with corr 0.09841009229421616 with new token with corr 0.1914386749267578\n",
      "Replaced token 2358 with corr 0.13088653981685638 with new token with corr 0.2129574716091156\n",
      "Replaced token 2364 with corr 0.11286571621894836 with new token with corr 0.14623808860778809\n",
      "Replaced token 2365 with corr 0.10503681749105453 with new token with corr 0.1948922723531723\n",
      "Replaced token 2368 with corr 0.09226346760988235 with new token with corr 0.16253669559955597\n",
      "Replaced token 2379 with corr 0.08703435212373734 with new token with corr 0.15441136062145233\n",
      "Replaced token 2384 with corr 0.12280003726482391 with new token with corr 0.14209158718585968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2385 with corr 0.09798111021518707 with new token with corr 0.3236064016819\n",
      "Replaced token 2386 with corr 0.10839793086051941 with new token with corr 0.17683298885822296\n",
      "Replaced token 2393 with corr 0.1123812273144722 with new token with corr 0.16104480624198914\n",
      "Replaced token 2396 with corr 0.10801953077316284 with new token with corr 0.1671046018600464\n",
      "Replaced token 2408 with corr 0.11459790915250778 with new token with corr 0.14243915677070618\n",
      "Replaced token 2413 with corr 0.08556809276342392 with new token with corr 0.34158772230148315\n",
      "Replaced token 2428 with corr 0.07455836236476898 with new token with corr 0.2022038847208023\n",
      "Replaced token 2434 with corr 0.12066151201725006 with new token with corr 0.17029590904712677\n",
      "Replaced token 2446 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 2449 with corr 0.1201745867729187 with new token with corr 0.15526935458183289\n",
      "Replaced token 2453 with corr 0.10589312762022018 with new token with corr 0.16211055219173431\n",
      "Replaced token 2454 with corr 0.10390853136777878 with new token with corr 0.2800275385379791\n",
      "Replaced token 2475 with corr 0.08915002644062042 with new token with corr 0.18457834422588348\n",
      "Replaced token 2480 with corr 0.09509865939617157 with new token with corr 0.16629163920879364\n",
      "Replaced token 2488 with corr 0.12982840836048126 with new token with corr 0.20136673748493195\n",
      "Replaced token 2491 with corr 0.11028311401605606 with new token with corr 0.1553986519575119\n",
      "Replaced token 2497 with corr 0.10846427083015442 with new token with corr 0.2654228210449219\n",
      "Replaced token 2498 with corr 0.11025235056877136 with new token with corr 0.2499328851699829\n",
      "Replaced token 2503 with corr 0.10148318111896515 with new token with corr 0.14484058320522308\n",
      "Replaced token 2509 with corr 0.13025347888469696 with new token with corr 0.2553485333919525\n",
      "Replaced token 2522 with corr 0.0978996679186821 with new token with corr 0.1519155353307724\n",
      "Replaced token 2526 with corr 0.08897241204977036 with new token with corr 0.2087474912405014\n",
      "Replaced token 2527 with corr 0.09985345602035522 with new token with corr 0.15002985298633575\n",
      "Replaced token 2539 with corr 0.10612896829843521 with new token with corr 0.14835987985134125\n",
      "Replaced token 2551 with corr 0.132096529006958 with new token with corr 0.15377266705036163\n",
      "Replaced token 2553 with corr 0.11932205408811569 with new token with corr 0.1439962536096573\n",
      "Replaced token 2559 with corr 0.0657072365283966 with new token with corr 0.14971689879894257\n",
      "Replaced token 2585 with corr 0.10871854424476624 with new token with corr 0.21969276666641235\n",
      "Replaced token 2604 with corr 0.1071554645895958 with new token with corr 0.1581401377916336\n",
      "Replaced token 2647 with corr 0.08146478235721588 with new token with corr 0.20139718055725098\n",
      "Replaced token 2648 with corr 0.08135887235403061 with new token with corr 0.2486138641834259\n",
      "Replaced token 2669 with corr 0.11446455866098404 with new token with corr 0.14383286237716675\n",
      "Replaced token 2695 with corr 0.08733444660902023 with new token with corr 0.16646850109100342\n",
      "Replaced token 2712 with corr 0.07433526962995529 with new token with corr 0.24520720541477203\n",
      "Replaced token 2720 with corr 0.10904086381196976 with new token with corr 0.14048784971237183\n",
      "Replaced token 2725 with corr 0.1429840624332428 with new token with corr 0.16428475081920624\n",
      "Replaced token 2787 with corr 0.09799249470233917 with new token with corr 0.21334560215473175\n",
      "Replaced token 2795 with corr 0.09221586585044861 with new token with corr 0.28454074263572693\n",
      "Replaced token 2802 with corr 0.10049636662006378 with new token with corr 0.27976542711257935\n",
      "Replaced token 2805 with corr 0.12199008464813232 with new token with corr 0.237598717212677\n",
      "Replaced token 2828 with corr 0.08878589421510696 with new token with corr 0.29726266860961914\n",
      "Replaced token 2855 with corr 0.10787904262542725 with new token with corr 0.15284587442874908\n",
      "Replaced token 2856 with corr 0.08848107606172562 with new token with corr 0.17137888073921204\n",
      "Replaced token 2860 with corr 0.12482638657093048 with new token with corr 0.17887961864471436\n",
      "Replaced token 2868 with corr 0.131745383143425 with new token with corr 0.15329201519489288\n",
      "Replaced token 2870 with corr 0.09994734823703766 with new token with corr 0.16403447091579437\n",
      "Replaced token 2882 with corr 0.08526802062988281 with new token with corr 0.21527671813964844\n",
      "Replaced token 2883 with corr 0.10055611282587051 with new token with corr 0.23668323457241058\n",
      "Replaced token 2901 with corr 0.10089803487062454 with new token with corr 0.1897086352109909\n",
      "Replaced token 2911 with corr 0.1145368367433548 with new token with corr 0.22872769832611084\n",
      "Replaced token 2914 with corr 0.08962295949459076 with new token with corr 0.2755124270915985\n",
      "Replaced token 2926 with corr 0.0813339427113533 with new token with corr 0.1766229122877121\n",
      "Replaced token 2931 with corr 0.10793379694223404 with new token with corr 0.3027452528476715\n",
      "Replaced token 2932 with corr 0.12502598762512207 with new token with corr 0.1574915200471878\n",
      "Replaced token 2942 with corr 0.1250670999288559 with new token with corr 0.1625632345676422\n",
      "Replaced token 2943 with corr 0.12474377453327179 with new token with corr 0.2676112949848175\n",
      "Replaced token 2962 with corr 0.08167469501495361 with new token with corr 0.15196111798286438\n",
      "Replaced token 2976 with corr 0.10337535291910172 with new token with corr 0.1584203541278839\n",
      "Replaced token 2977 with corr 0.11099407821893692 with new token with corr 0.14886930584907532\n",
      "Replaced token 3010 with corr 0.11868207156658173 with new token with corr 0.14755398035049438\n",
      "Replaced token 3023 with corr 0.10768715292215347 with new token with corr 0.14940567314624786\n",
      "Replaced token 3027 with corr 0.11195295304059982 with new token with corr 0.2836076021194458\n",
      "Replaced token 3030 with corr 0.09112260490655899 with new token with corr 0.21726897358894348\n",
      "Replaced token 3031 with corr 0.1106770858168602 with new token with corr 0.1531311273574829\n",
      "Replaced token 3054 with corr 0.1288672685623169 with new token with corr 0.23834443092346191\n",
      "Replaced token 3094 with corr 0.10854519158601761 with new token with corr 0.30788329243659973\n",
      "Replaced token 3109 with corr 0.10213868319988251 with new token with corr 0.25648751854896545\n",
      "Replaced token 3127 with corr 0.0960758626461029 with new token with corr 0.15783217549324036\n",
      "Replaced token 3128 with corr 0.08161012083292007 with new token with corr 0.2301304042339325\n",
      "Replaced token 3143 with corr 0.08852166682481766 with new token with corr 0.19981727004051208\n",
      "Replaced token 3166 with corr 0.09498576074838638 with new token with corr 0.24592570960521698\n",
      "Replaced token 3175 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 3204 with corr 0.1083015725016594 with new token with corr 0.20106463134288788\n",
      "Replaced token 3211 with corr 0.1092938631772995 with new token with corr 0.22648459672927856\n",
      "Replaced token 3213 with corr 0.09117642790079117 with new token with corr 0.16049659252166748\n",
      "Replaced token 3221 with corr 0.07762452960014343 with new token with corr 0.2182246446609497\n",
      "Replaced token 3223 with corr 0.09327423572540283 with new token with corr 0.2611684203147888\n",
      "Replaced token 3224 with corr 0.11905615776777267 with new token with corr 0.16442018747329712\n",
      "Replaced token 3230 with corr 0.11070850491523743 with new token with corr 0.14476200938224792\n",
      "Replaced token 3308 with corr 0.10283837467432022 with new token with corr 0.23205004632472992\n",
      "Replaced token 3329 with corr 0.1003747284412384 with new token with corr 0.14953385293483734\n",
      "Replaced token 3335 with corr 0.08474868535995483 with new token with corr 0.260865181684494\n",
      "Replaced token 3340 with corr 0.08995696157217026 with new token with corr 0.29117822647094727\n",
      "Replaced token 3343 with corr 0.105535127222538 with new token with corr 0.14037670195102692\n",
      "Replaced token 3344 with corr 0.07471393793821335 with new token with corr 0.20954430103302002\n",
      "Replaced token 3364 with corr 0.1469879299402237 with new token with corr 0.1714986264705658\n",
      "Replaced token 3370 with corr 0.10360986739397049 with new token with corr 0.14797066152095795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3402 with corr 0.09207748621702194 with new token with corr 0.20862500369548798\n",
      "Replaced token 3413 with corr 0.07762213796377182 with new token with corr 0.1717095524072647\n",
      "Replaced token 3415 with corr 0.11113911122083664 with new token with corr 0.23568634688854218\n",
      "Replaced token 3451 with corr 0.09928575158119202 with new token with corr 0.2579036355018616\n",
      "Replaced token 3471 with corr 0.11550285667181015 with new token with corr 0.14842289686203003\n",
      "Replaced token 3479 with corr 0.09774256497621536 with new token with corr 0.18581438064575195\n",
      "Replaced token 3480 with corr 0.11261890828609467 with new token with corr 0.23385603725910187\n",
      "Replaced token 3486 with corr 0.094296395778656 with new token with corr 0.26696982979774475\n",
      "Replaced token 3504 with corr 0.10243967920541763 with new token with corr 0.21259687840938568\n",
      "Replaced token 3508 with corr 0.11241219192743301 with new token with corr 0.3117140233516693\n",
      "Replaced token 3522 with corr 0.11608175188302994 with new token with corr 0.2361796647310257\n",
      "Replaced token 3537 with corr 0.1282229721546173 with new token with corr 0.25225773453712463\n",
      "Replaced token 3540 with corr 0.0735185369849205 with new token with corr 0.18384917080402374\n",
      "Replaced token 3547 with corr 0.12320207059383392 with new token with corr 0.2969287633895874\n",
      "Replaced token 3554 with corr 0.11856120079755783 with new token with corr 0.20777767896652222\n",
      "Replaced token 3565 with corr 0.07344812899827957 with new token with corr 0.14897918701171875\n",
      "Replaced token 3573 with corr 0.0852590948343277 with new token with corr 0.22231847047805786\n",
      "Replaced token 3583 with corr 0.07468339055776596 with new token with corr 0.15685757994651794\n",
      "Replaced token 3593 with corr 0.12260448932647705 with new token with corr 0.15267544984817505\n",
      "Replaced token 3605 with corr 0.15743738412857056 with new token with corr 0.24347980320453644\n",
      "Replaced token 3611 with corr 0.1045120358467102 with new token with corr 0.2583322823047638\n",
      "Replaced token 3617 with corr 0.11635561287403107 with new token with corr 0.21962647140026093\n",
      "Replaced token 3622 with corr 0.11626020818948746 with new token with corr 0.15774716436862946\n",
      "Replaced token 3623 with corr 0.09608295559883118 with new token with corr 0.20783036947250366\n",
      "Replaced token 3631 with corr 0.07907850295305252 with new token with corr 0.1806187927722931\n",
      "Replaced token 3638 with corr 0.07013028860092163 with new token with corr 0.1800089031457901\n",
      "Replaced token 3667 with corr 0.10379547625780106 with new token with corr 0.2801976799964905\n",
      "Replaced token 3669 with corr 0.07176963239908218 with new token with corr 0.2982428967952728\n",
      "Replaced token 3670 with corr 0.06947410106658936 with new token with corr 0.32409781217575073\n",
      "Replaced token 3673 with corr 0.11199440062046051 with new token with corr 0.21503151953220367\n",
      "Replaced token 3674 with corr 0.1082954853773117 with new token with corr 0.34233036637306213\n",
      "Replaced token 3679 with corr 0.08759612590074539 with new token with corr 0.23954784870147705\n",
      "Replaced token 3701 with corr 0.13045057654380798 with new token with corr 0.25759297609329224\n",
      "Replaced token 3708 with corr 0.13221634924411774 with new token with corr 0.26396578550338745\n",
      "Replaced token 3713 with corr 0.0684177502989769 with new token with corr 0.2262493073940277\n",
      "Replaced token 3727 with corr 0.12891528010368347 with new token with corr 0.24917134642601013\n",
      "Replaced token 3735 with corr 0.11797637492418289 with new token with corr 0.2217080146074295\n",
      "Replaced token 3736 with corr 0.09470909088850021 with new token with corr 0.21329985558986664\n",
      "Replaced token 3737 with corr 0.1390988528728485 with new token with corr 0.2615695893764496\n",
      "Replaced token 3744 with corr 0.0792054533958435 with new token with corr 0.2511129677295685\n",
      "Replaced token 3751 with corr 0.08053730428218842 with new token with corr 0.14904911816120148\n",
      "Replaced token 3760 with corr 0.12319856882095337 with new token with corr 0.16508053243160248\n",
      "Replaced token 3785 with corr 0.08235035091638565 with new token with corr 0.19586622714996338\n",
      "Replaced token 3794 with corr 0.0956580862402916 with new token with corr 0.2699718177318573\n",
      "Replaced token 3806 with corr 0.10203952342271805 with new token with corr 0.1528431475162506\n",
      "Replaced token 3818 with corr 0.1288331151008606 with new token with corr 0.23295429348945618\n",
      "Replaced token 3841 with corr 0.09109344333410263 with new token with corr 0.1467636376619339\n",
      "Replaced token 3843 with corr 0.09166190773248672 with new token with corr 0.2591124176979065\n",
      "Replaced token 3849 with corr 0.10936854779720306 with new token with corr 0.26489901542663574\n",
      "Replaced token 3851 with corr 0.10035465657711029 with new token with corr 0.22951041162014008\n",
      "Replaced token 3871 with corr 0.11843269318342209 with new token with corr 0.2503451406955719\n",
      "Replaced token 3872 with corr 0.11060427874326706 with new token with corr 0.2391880452632904\n",
      "Replaced token 3875 with corr 0.09328150004148483 with new token with corr 0.15586718916893005\n",
      "Replaced token 3885 with corr 0.0908476859331131 with new token with corr 0.2347525656223297\n",
      "Replaced token 3914 with corr 0.08463185280561447 with new token with corr 0.15947912633419037\n",
      "Replaced token 3923 with corr 0.09905815124511719 with new token with corr 0.14535480737686157\n",
      "Replaced token 3926 with corr 0.12426407635211945 with new token with corr 0.23572112619876862\n",
      "Replaced token 3928 with corr 0.09814780950546265 with new token with corr 0.2512640953063965\n",
      "Replaced token 3933 with corr 0.10581307113170624 with new token with corr 0.2439889907836914\n",
      "Replaced token 3946 with corr 0.11236857622861862 with new token with corr 0.18822109699249268\n",
      "Replaced token 3948 with corr 0.10665471851825714 with new token with corr 0.25099965929985046\n",
      "Replaced token 3957 with corr 0.11053760349750519 with new token with corr 0.1511632204055786\n",
      "Replaced token 3960 with corr 0.08955783396959305 with new token with corr 0.23699374496936798\n",
      "Replaced token 3977 with corr 0.1248236894607544 with new token with corr 0.22677119076251984\n",
      "Replaced token 3979 with corr 0.09531667828559875 with new token with corr 0.2902751863002777\n",
      "Replaced token 3987 with corr 0.09578265994787216 with new token with corr 0.18374766409397125\n",
      "Replaced token 3991 with corr 0.15551899373531342 with new token with corr 0.1657889187335968\n",
      "Replaced token 4007 with corr 0.10252664983272552 with new token with corr 0.25471606850624084\n",
      "Replaced token 4022 with corr 0.10040204226970673 with new token with corr 0.21668174862861633\n",
      "Replaced token 4023 with corr 0.0731392577290535 with new token with corr 0.1712467074394226\n",
      "Replaced token 4024 with corr 0.11364530771970749 with new token with corr 0.14999864995479584\n",
      "Replaced token 4032 with corr 0.10857785493135452 with new token with corr 0.20799802243709564\n",
      "Replaced token 4041 with corr 0.10823719203472137 with new token with corr 0.2075950801372528\n",
      "Replaced token 4081 with corr 0.09662853181362152 with new token with corr 0.19235314428806305\n",
      "Replaced token 4095 with corr 0.0721680223941803 with new token with corr 0.14965713024139404\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.9023 | S-BLEU: 0.77 | FMSE: 2.7059e-03 | \n",
      " G-BLEU: 0.73 | ROUGE1: 0.89| ROUGE2: 0.77 | ROUGE-L: 0.88| Token Acc: 92.68% | Label Acc: 92.68%\n",
      "Evaluating dynamic-threshold with 1.0\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Replaced token 1 with corr 0.2674526274204254 with new token with corr 0.2674526572227478\n",
      "Replaced token 9 with corr 0.36500394344329834 with new token with corr 0.3650040030479431\n",
      "Replaced token 10 with corr 0.286239355802536 with new token with corr 0.2862393856048584\n",
      "Replaced token 11 with corr 0.2655238211154938 with new token with corr 0.26552385091781616\n",
      "Replaced token 22 with corr 0.3186632990837097 with new token with corr 0.3186633288860321\n",
      "Replaced token 27 with corr 0.292405903339386 with new token with corr 0.2924059331417084\n",
      "Replaced token 28 with corr 0.35538339614868164 with new token with corr 0.35538342595100403\n",
      "Replaced token 32 with corr 0.10004569590091705 with new token with corr 0.27175667881965637\n",
      "Replaced token 37 with corr 0.34061217308044434 with new token with corr 0.3406122028827667\n",
      "Replaced token 38 with corr 0.29537785053253174 with new token with corr 0.2953778803348541\n",
      "Replaced token 39 with corr 0.3105590343475342 with new token with corr 0.31055909395217896\n",
      "Replaced token 43 with corr 0.324539452791214 with new token with corr 0.3245394825935364\n",
      "Replaced token 44 with corr 0.3220812976360321 with new token with corr 0.3220813274383545\n",
      "Replaced token 58 with corr 0.12161212414503098 with new token with corr 0.3063763380050659\n",
      "Replaced token 61 with corr 0.13545501232147217 with new token with corr 0.15473876893520355\n",
      "Replaced token 66 with corr 0.36722037196159363 with new token with corr 0.367220401763916\n",
      "Replaced token 72 with corr 0.229422926902771 with new token with corr 0.2294229418039322\n",
      "Replaced token 73 with corr 0.2785085141658783 with new token with corr 0.2785085439682007\n",
      "Replaced token 74 with corr 0.31562429666519165 with new token with corr 0.31562432646751404\n",
      "Replaced token 78 with corr 0.4015227258205414 with new token with corr 0.40152275562286377\n",
      "Replaced token 84 with corr 0.31879496574401855 with new token with corr 0.31879499554634094\n",
      "Replaced token 89 with corr 0.2501673996448517 with new token with corr 0.2501674294471741\n",
      "Replaced token 96 with corr 0.09464694559574127 with new token with corr 0.2000071108341217\n",
      "Replaced token 97 with corr 0.3042442500591278 with new token with corr 0.3042442798614502\n",
      "Replaced token 98 with corr 0.3305807411670685 with new token with corr 0.33058077096939087\n",
      "Replaced token 100 with corr 0.11622016131877899 with new token with corr 0.2580813467502594\n",
      "Replaced token 104 with corr 0.3251657485961914 with new token with corr 0.3251657783985138\n",
      "Replaced token 107 with corr 0.3126908242702484 with new token with corr 0.3126908540725708\n",
      "Replaced token 109 with corr 0.282394140958786 with new token with corr 0.2823942005634308\n",
      "Replaced token 113 with corr 0.2692374885082245 with new token with corr 0.2692375183105469\n",
      "Replaced token 116 with corr 0.34479859471321106 with new token with corr 0.34479862451553345\n",
      "Replaced token 119 with corr 0.30347496271133423 with new token with corr 0.3034749925136566\n",
      "Replaced token 120 with corr 0.37612834572792053 with new token with corr 0.3761284053325653\n",
      "Replaced token 121 with corr 0.31555798649787903 with new token with corr 0.3155580163002014\n",
      "Replaced token 123 with corr 0.10482989251613617 with new token with corr 0.221369206905365\n",
      "Replaced token 125 with corr 0.25944194197654724 with new token with corr 0.25944197177886963\n",
      "Replaced token 136 with corr 0.24297067523002625 with new token with corr 0.24297070503234863\n",
      "Replaced token 141 with corr 0.23994313180446625 with new token with corr 0.23994316160678864\n",
      "Replaced token 142 with corr 0.1426793485879898 with new token with corr 0.24854715168476105\n",
      "Replaced token 144 with corr 0.137878879904747 with new token with corr 0.15511299669742584\n",
      "Replaced token 147 with corr 0.09084136039018631 with new token with corr 0.13877294957637787\n",
      "Replaced token 148 with corr 0.11775460094213486 with new token with corr 0.1684461236000061\n",
      "Replaced token 149 with corr 0.39941444993019104 with new token with corr 0.3994144797325134\n",
      "Replaced token 151 with corr 0.2441306710243225 with new token with corr 0.2441307008266449\n",
      "Replaced token 152 with corr 0.14698071777820587 with new token with corr 0.17307201027870178\n",
      "Replaced token 154 with corr 0.3848671317100525 with new token with corr 0.3848671615123749\n",
      "Replaced token 156 with corr 0.0995953381061554 with new token with corr 0.19734443724155426\n",
      "Replaced token 157 with corr 0.2830312252044678 with new token with corr 0.28303125500679016\n",
      "Replaced token 158 with corr 0.3177517056465149 with new token with corr 0.3177517354488373\n",
      "Replaced token 160 with corr 0.3071191906929016 with new token with corr 0.307119220495224\n",
      "Replaced token 162 with corr 0.36477038264274597 with new token with corr 0.36477041244506836\n",
      "Replaced token 164 with corr 0.2999100685119629 with new token with corr 0.2999100983142853\n",
      "Replaced token 166 with corr 0.08978059887886047 with new token with corr 0.3762853443622589\n",
      "Replaced token 167 with corr 0.29930686950683594 with new token with corr 0.2993068993091583\n",
      "Replaced token 172 with corr 0.09863615036010742 with new token with corr 0.1725509762763977\n",
      "Replaced token 174 with corr 0.2621551752090454 with new token with corr 0.2621552050113678\n",
      "Replaced token 178 with corr 0.3616720736026764 with new token with corr 0.3616721034049988\n",
      "Replaced token 188 with corr 0.09136594831943512 with new token with corr 0.23894765973091125\n",
      "Replaced token 189 with corr 0.2469366490840912 with new token with corr 0.24693666398525238\n",
      "Replaced token 191 with corr 0.1137547567486763 with new token with corr 0.26309698820114136\n",
      "Replaced token 194 with corr 0.39924705028533936 with new token with corr 0.39924710988998413\n",
      "Replaced token 202 with corr 0.1084042489528656 with new token with corr 0.15070481598377228\n",
      "Replaced token 203 with corr 0.24837519228458405 with new token with corr 0.24837520718574524\n",
      "Replaced token 205 with corr 0.0792447179555893 with new token with corr 0.2740797698497772\n",
      "Replaced token 210 with corr 0.2699717879295349 with new token with corr 0.2699718177318573\n",
      "Replaced token 211 with corr 0.23796449601650238 with new token with corr 0.23796451091766357\n",
      "Replaced token 214 with corr 0.288124680519104 with new token with corr 0.2881247103214264\n",
      "Replaced token 217 with corr 0.3141634464263916 with new token with corr 0.314163476228714\n",
      "Replaced token 219 with corr 0.28749868273735046 with new token with corr 0.28749871253967285\n",
      "Replaced token 221 with corr 0.2901389002799988 with new token with corr 0.29013893008232117\n",
      "Replaced token 229 with corr 0.22757217288017273 with new token with corr 0.22757218778133392\n",
      "Replaced token 238 with corr 0.29347941279411316 with new token with corr 0.29347947239875793\n",
      "Replaced token 242 with corr 0.3106670677661896 with new token with corr 0.31066709756851196\n",
      "Replaced token 246 with corr 0.3033102750778198 with new token with corr 0.3033103048801422\n",
      "Replaced token 257 with corr 0.09256129711866379 with new token with corr 0.24084514379501343\n",
      "Replaced token 259 with corr 0.14304155111312866 with new token with corr 0.16333922743797302\n",
      "Replaced token 265 with corr 0.09990415722131729 with new token with corr 0.26489901542663574\n",
      "Replaced token 266 with corr 0.09759923070669174 with new token with corr 0.2242376208305359\n",
      "Replaced token 275 with corr 0.3172079622745514 with new token with corr 0.3172079920768738\n",
      "Replaced token 286 with corr 0.2796718180179596 with new token with corr 0.279671847820282\n",
      "Replaced token 296 with corr 0.27066338062286377 with new token with corr 0.27066341042518616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 299 with corr 0.38134777545928955 with new token with corr 0.38134780526161194\n",
      "Replaced token 300 with corr 0.353583425283432 with new token with corr 0.3535834848880768\n",
      "Replaced token 310 with corr 0.30350470542907715 with new token with corr 0.30350473523139954\n",
      "Replaced token 311 with corr 0.27485641837120056 with new token with corr 0.27485644817352295\n",
      "Replaced token 312 with corr 0.13131514191627502 with new token with corr 0.15758179128170013\n",
      "Replaced token 313 with corr 0.31624624133110046 with new token with corr 0.31624630093574524\n",
      "Replaced token 316 with corr 0.2159544676542282 with new token with corr 0.2159544825553894\n",
      "Replaced token 325 with corr 0.23777471482753754 with new token with corr 0.23777472972869873\n",
      "Replaced token 326 with corr 0.07846662402153015 with new token with corr 0.15889431536197662\n",
      "Replaced token 329 with corr 0.3311023712158203 with new token with corr 0.3311024010181427\n",
      "Replaced token 330 with corr 0.3004607558250427 with new token with corr 0.3004607856273651\n",
      "Replaced token 331 with corr 0.3168715238571167 with new token with corr 0.3168715536594391\n",
      "Replaced token 333 with corr 0.3072673976421356 with new token with corr 0.307267427444458\n",
      "Replaced token 343 with corr 0.3554314970970154 with new token with corr 0.35543152689933777\n",
      "Replaced token 348 with corr 0.2082279622554779 with new token with corr 0.2082279771566391\n",
      "Replaced token 354 with corr 0.29080504179000854 with new token with corr 0.29080507159233093\n",
      "Replaced token 356 with corr 0.3253614902496338 with new token with corr 0.3253615200519562\n",
      "Replaced token 357 with corr 0.11765756458044052 with new token with corr 0.25508594512939453\n",
      "Replaced token 359 with corr 0.3224485516548157 with new token with corr 0.32244858145713806\n",
      "Replaced token 363 with corr 0.11083157360553741 with new token with corr 0.22495022416114807\n",
      "Replaced token 366 with corr 0.22810214757919312 with new token with corr 0.2281021624803543\n",
      "Replaced token 367 with corr 0.340427428483963 with new token with corr 0.3404274582862854\n",
      "Replaced token 372 with corr 0.3201034665107727 with new token with corr 0.3201034963130951\n",
      "Replaced token 373 with corr 0.27527710795402527 with new token with corr 0.27527713775634766\n",
      "Replaced token 389 with corr 0.12040932476520538 with new token with corr 0.2243054360151291\n",
      "Replaced token 398 with corr 0.334679514169693 with new token with corr 0.3346795439720154\n",
      "Replaced token 420 with corr 0.34427961707115173 with new token with corr 0.3442796468734741\n",
      "Replaced token 422 with corr 0.09864215552806854 with new token with corr 0.2360743284225464\n",
      "Replaced token 426 with corr 0.29870057106018066 with new token with corr 0.29870060086250305\n",
      "Replaced token 433 with corr 0.2367805391550064 with new token with corr 0.2367805540561676\n",
      "Replaced token 440 with corr 0.09062034636735916 with new token with corr 0.15890830755233765\n",
      "Replaced token 444 with corr 0.32975518703460693 with new token with corr 0.3297552168369293\n",
      "Replaced token 455 with corr 0.3189704120159149 with new token with corr 0.3189704418182373\n",
      "Replaced token 458 with corr 0.11354941129684448 with new token with corr 0.3059351146221161\n",
      "Replaced token 459 with corr 0.3077709674835205 with new token with corr 0.3077709972858429\n",
      "Replaced token 461 with corr 0.3277008831501007 with new token with corr 0.3277009129524231\n",
      "Replaced token 463 with corr 0.21326711773872375 with new token with corr 0.21326713263988495\n",
      "Replaced token 474 with corr 0.206318661570549 with new token with corr 0.2063186764717102\n",
      "Replaced token 475 with corr 0.3191225528717041 with new token with corr 0.3191225826740265\n",
      "Replaced token 477 with corr 0.3617229759693146 with new token with corr 0.36172300577163696\n",
      "Replaced token 479 with corr 0.2684403359889984 with new token with corr 0.2684403657913208\n",
      "Replaced token 480 with corr 0.2607404589653015 with new token with corr 0.2607404887676239\n",
      "Replaced token 481 with corr 0.31306692957878113 with new token with corr 0.3130669593811035\n",
      "Replaced token 487 with corr 0.11485637724399567 with new token with corr 0.25687742233276367\n",
      "Replaced token 488 with corr 0.10698159784078598 with new token with corr 0.22048774361610413\n",
      "Replaced token 489 with corr 0.3282724618911743 with new token with corr 0.3282724916934967\n",
      "Replaced token 490 with corr 0.09709368646144867 with new token with corr 0.31151992082595825\n",
      "Replaced token 493 with corr 0.29209059476852417 with new token with corr 0.29209062457084656\n",
      "Replaced token 500 with corr 0.33748859167099 with new token with corr 0.3374886214733124\n",
      "Replaced token 503 with corr 0.2655034065246582 with new token with corr 0.2655034363269806\n",
      "Replaced token 505 with corr 0.2721036672592163 with new token with corr 0.2721036970615387\n",
      "Replaced token 506 with corr 0.33680981397628784 with new token with corr 0.33680984377861023\n",
      "Replaced token 509 with corr 0.2868875563144684 with new token with corr 0.28688758611679077\n",
      "Replaced token 511 with corr 0.07224166393280029 with new token with corr 0.14823205769062042\n",
      "Replaced token 515 with corr 0.40664196014404297 with new token with corr 0.40664198994636536\n",
      "Replaced token 518 with corr 0.28230020403862 with new token with corr 0.2823002338409424\n",
      "Replaced token 520 with corr 0.3080454170703888 with new token with corr 0.3080454468727112\n",
      "Replaced token 523 with corr 0.26085394620895386 with new token with corr 0.26085397601127625\n",
      "Replaced token 525 with corr 0.11561029404401779 with new token with corr 0.25178301334381104\n",
      "Replaced token 526 with corr 0.2930709719657898 with new token with corr 0.2930710017681122\n",
      "Replaced token 527 with corr 0.18727780878543854 with new token with corr 0.18727783858776093\n",
      "Replaced token 530 with corr 0.3450479507446289 with new token with corr 0.3450479805469513\n",
      "Replaced token 538 with corr 0.09454026818275452 with new token with corr 0.15348148345947266\n",
      "Replaced token 543 with corr 0.2899876534938812 with new token with corr 0.2899876832962036\n",
      "Replaced token 555 with corr 0.3017609417438507 with new token with corr 0.3017609715461731\n",
      "Replaced token 559 with corr 0.33055275678634644 with new token with corr 0.3305527865886688\n",
      "Replaced token 560 with corr 0.27857011556625366 with new token with corr 0.27857014536857605\n",
      "Replaced token 561 with corr 0.301175057888031 with new token with corr 0.3011750876903534\n",
      "Replaced token 564 with corr 0.4156951606273651 with new token with corr 0.4156951904296875\n",
      "Replaced token 566 with corr 0.11152159422636032 with new token with corr 0.22072097659111023\n",
      "Replaced token 569 with corr 0.33718082308769226 with new token with corr 0.33718085289001465\n",
      "Replaced token 572 with corr 0.10247683525085449 with new token with corr 0.1441391110420227\n",
      "Replaced token 577 with corr 0.2080012708902359 with new token with corr 0.2080012857913971\n",
      "Replaced token 584 with corr 0.24447892606258392 with new token with corr 0.2444789558649063\n",
      "Replaced token 590 with corr 0.3106013238430023 with new token with corr 0.3106013536453247\n",
      "Replaced token 592 with corr 0.09372688829898834 with new token with corr 0.31124797463417053\n",
      "Replaced token 595 with corr 0.32686612010002136 with new token with corr 0.32686614990234375\n",
      "Replaced token 596 with corr 0.2592151463031769 with new token with corr 0.25921517610549927\n",
      "Replaced token 599 with corr 0.09186166524887085 with new token with corr 0.20139718055725098\n",
      "Replaced token 602 with corr 0.36022284626960754 with new token with corr 0.36022287607192993\n",
      "Replaced token 604 with corr 0.30694955587387085 with new token with corr 0.30694958567619324\n",
      "Replaced token 605 with corr 0.24073874950408936 with new token with corr 0.24073877930641174\n",
      "Replaced token 606 with corr 0.2574733793735504 with new token with corr 0.2574734091758728\n",
      "Replaced token 607 with corr 0.23287850618362427 with new token with corr 0.23287852108478546\n",
      "Replaced token 609 with corr 0.30764633417129517 with new token with corr 0.30764636397361755\n",
      "Replaced token 615 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 618 with corr 0.11568886786699295 with new token with corr 0.23867349326610565\n",
      "Replaced token 619 with corr 0.3717444837093353 with new token with corr 0.3717445135116577\n",
      "Replaced token 623 with corr 0.3479503095149994 with new token with corr 0.3479503393173218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 625 with corr 0.19889305531978607 with new token with corr 0.19889307022094727\n",
      "Replaced token 626 with corr 0.3236023187637329 with new token with corr 0.3236023485660553\n",
      "Replaced token 627 with corr 0.36129704117774963 with new token with corr 0.361297070980072\n",
      "Replaced token 629 with corr 0.29186922311782837 with new token with corr 0.29186925292015076\n",
      "Replaced token 634 with corr 0.2606591582298279 with new token with corr 0.26065918803215027\n",
      "Replaced token 640 with corr 0.12705056369304657 with new token with corr 0.29355359077453613\n",
      "Replaced token 641 with corr 0.12931184470653534 with new token with corr 0.1511695832014084\n",
      "Replaced token 645 with corr 0.3391302525997162 with new token with corr 0.3391302824020386\n",
      "Replaced token 647 with corr 0.13254739344120026 with new token with corr 0.14750154316425323\n",
      "Replaced token 648 with corr 0.2886868417263031 with new token with corr 0.2886868715286255\n",
      "Replaced token 653 with corr 0.4569304287433624 with new token with corr 0.4569304883480072\n",
      "Replaced token 654 with corr 0.08123092353343964 with new token with corr 0.17212828993797302\n",
      "Replaced token 656 with corr 0.3781803250312805 with new token with corr 0.3781803548336029\n",
      "Replaced token 658 with corr 0.24509631097316742 with new token with corr 0.2450963258743286\n",
      "Replaced token 659 with corr 0.2485974133014679 with new token with corr 0.2485974282026291\n",
      "Replaced token 660 with corr 0.10303323715925217 with new token with corr 0.14963647723197937\n",
      "Replaced token 661 with corr 0.07817701250314713 with new token with corr 0.29225459694862366\n",
      "Replaced token 662 with corr 0.3874678909778595 with new token with corr 0.3874679207801819\n",
      "Replaced token 664 with corr 0.20357927680015564 with new token with corr 0.20357929170131683\n",
      "Replaced token 669 with corr 0.3240914046764374 with new token with corr 0.32409143447875977\n",
      "Replaced token 671 with corr 0.26975303888320923 with new token with corr 0.2697530686855316\n",
      "Replaced token 673 with corr 0.24275338649749756 with new token with corr 0.24275340139865875\n",
      "Replaced token 681 with corr 0.11854878813028336 with new token with corr 0.14750728011131287\n",
      "Replaced token 683 with corr 0.27670595049858093 with new token with corr 0.2767059803009033\n",
      "Replaced token 687 with corr 0.23770661652088165 with new token with corr 0.23770663142204285\n",
      "Replaced token 693 with corr 0.1978810727596283 with new token with corr 0.1978810876607895\n",
      "Replaced token 700 with corr 0.2634603679180145 with new token with corr 0.2634603977203369\n",
      "Replaced token 703 with corr 0.3226839601993561 with new token with corr 0.32268399000167847\n",
      "Replaced token 708 with corr 0.08453399688005447 with new token with corr 0.15257667005062103\n",
      "Replaced token 712 with corr 0.2430734932422638 with new token with corr 0.24307352304458618\n",
      "Replaced token 713 with corr 0.0795915424823761 with new token with corr 0.19586622714996338\n",
      "Replaced token 715 with corr 0.09467495232820511 with new token with corr 0.20234717428684235\n",
      "Replaced token 720 with corr 0.0878865048289299 with new token with corr 0.1572844237089157\n",
      "Replaced token 721 with corr 0.2916219234466553 with new token with corr 0.29162195324897766\n",
      "Replaced token 722 with corr 0.3082667887210846 with new token with corr 0.308266818523407\n",
      "Replaced token 725 with corr 0.08259778469800949 with new token with corr 0.22294455766677856\n",
      "Replaced token 728 with corr 0.25273120403289795 with new token with corr 0.25273123383522034\n",
      "Replaced token 731 with corr 0.10537471622228622 with new token with corr 0.22179755568504333\n",
      "Replaced token 734 with corr 0.2786327600479126 with new token with corr 0.278632789850235\n",
      "Replaced token 736 with corr 0.12210801243782043 with new token with corr 0.14934375882148743\n",
      "Replaced token 739 with corr 0.2991703748703003 with new token with corr 0.2991704046726227\n",
      "Replaced token 745 with corr 0.3002951741218567 with new token with corr 0.3002952039241791\n",
      "Replaced token 749 with corr 0.25569775700569153 with new token with corr 0.2556977868080139\n",
      "Replaced token 750 with corr 0.3377458453178406 with new token with corr 0.33774587512016296\n",
      "Replaced token 757 with corr 0.3403818607330322 with new token with corr 0.3403818905353546\n",
      "Replaced token 758 with corr 0.10030191391706467 with new token with corr 0.15615716576576233\n",
      "Replaced token 759 with corr 0.23386308550834656 with new token with corr 0.23386310040950775\n",
      "Replaced token 760 with corr 0.2735257148742676 with new token with corr 0.27352574467658997\n",
      "Replaced token 761 with corr 0.3417925238609314 with new token with corr 0.3417925536632538\n",
      "Replaced token 764 with corr 0.28125885128974915 with new token with corr 0.28125888109207153\n",
      "Replaced token 769 with corr 0.08440469950437546 with new token with corr 0.14953385293483734\n",
      "Replaced token 771 with corr 0.09703671932220459 with new token with corr 0.302799254655838\n",
      "Replaced token 773 with corr 0.09112171828746796 with new token with corr 0.16130287945270538\n",
      "Replaced token 777 with corr 0.09922241419553757 with new token with corr 0.2945486605167389\n",
      "Replaced token 778 with corr 0.2619212865829468 with new token with corr 0.26192131638526917\n",
      "Replaced token 780 with corr 0.2911781966686249 with new token with corr 0.29117822647094727\n",
      "Replaced token 782 with corr 0.25986579060554504 with new token with corr 0.25986582040786743\n",
      "Replaced token 787 with corr 0.2871410548686981 with new token with corr 0.2871410846710205\n",
      "Replaced token 788 with corr 0.2768309414386749 with new token with corr 0.2768309712409973\n",
      "Replaced token 791 with corr 0.07144638150930405 with new token with corr 0.17704078555107117\n",
      "Replaced token 792 with corr 0.09265730530023575 with new token with corr 0.14915414154529572\n",
      "Replaced token 796 with corr 0.20148316025733948 with new token with corr 0.20148317515850067\n",
      "Replaced token 798 with corr 0.09041425585746765 with new token with corr 0.20528154075145721\n",
      "Replaced token 800 with corr 0.09082973748445511 with new token with corr 0.14501212537288666\n",
      "Replaced token 803 with corr 0.3585287630558014 with new token with corr 0.3585287928581238\n",
      "Replaced token 814 with corr 0.30981433391571045 with new token with corr 0.30981436371803284\n",
      "Replaced token 820 with corr 0.2654397189617157 with new token with corr 0.2654397487640381\n",
      "Replaced token 823 with corr 0.3070230185985565 with new token with corr 0.3070230484008789\n",
      "Replaced token 828 with corr 0.2910290062427521 with new token with corr 0.29102903604507446\n",
      "Replaced token 830 with corr 0.31941744685173035 with new token with corr 0.31941747665405273\n",
      "Replaced token 834 with corr 0.2564462721347809 with new token with corr 0.25644630193710327\n",
      "Replaced token 836 with corr 0.3589988648891449 with new token with corr 0.3589989244937897\n",
      "Replaced token 839 with corr 0.09296030551195145 with new token with corr 0.246667742729187\n",
      "Replaced token 841 with corr 0.373872846364975 with new token with corr 0.37387287616729736\n",
      "Replaced token 848 with corr 0.10579328238964081 with new token with corr 0.14981573820114136\n",
      "Replaced token 850 with corr 0.1880614161491394 with new token with corr 0.1880614459514618\n",
      "Replaced token 852 with corr 0.26242202520370483 with new token with corr 0.2624220550060272\n",
      "Replaced token 859 with corr 0.30124905705451965 with new token with corr 0.30124908685684204\n",
      "Replaced token 864 with corr 0.30253711342811584 with new token with corr 0.30253714323043823\n",
      "Replaced token 866 with corr 0.3465314507484436 with new token with corr 0.346531480550766\n",
      "Replaced token 867 with corr 0.09563031792640686 with new token with corr 0.16406835615634918\n",
      "Replaced token 870 with corr 0.07660464197397232 with new token with corr 0.31718987226486206\n",
      "Replaced token 872 with corr 0.36593061685562134 with new token with corr 0.3659306466579437\n",
      "Replaced token 873 with corr 0.27538594603538513 with new token with corr 0.2753859758377075\n",
      "Replaced token 875 with corr 0.28178805112838745 with new token with corr 0.28178808093070984\n",
      "Replaced token 876 with corr 0.23467157781124115 with new token with corr 0.23467159271240234\n",
      "Replaced token 877 with corr 0.33842238783836365 with new token with corr 0.33842241764068604\n",
      "Replaced token 879 with corr 0.3605293929576874 with new token with corr 0.36052942276000977\n",
      "Replaced token 880 with corr 0.2800469696521759 with new token with corr 0.2800470292568207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 890 with corr 0.2894229292869568 with new token with corr 0.2894229590892792\n",
      "Replaced token 899 with corr 0.11751987785100937 with new token with corr 0.14607861638069153\n",
      "Replaced token 902 with corr 0.29908818006515503 with new token with corr 0.2990882098674774\n",
      "Replaced token 903 with corr 0.3296390175819397 with new token with corr 0.3296390473842621\n",
      "Replaced token 904 with corr 0.2844149172306061 with new token with corr 0.28441494703292847\n",
      "Replaced token 906 with corr 0.30530211329460144 with new token with corr 0.30530214309692383\n",
      "Replaced token 910 with corr 0.13502371311187744 with new token with corr 0.153864324092865\n",
      "Replaced token 916 with corr 0.2838912606239319 with new token with corr 0.2838912904262543\n",
      "Replaced token 919 with corr 0.09916584193706512 with new token with corr 0.18581438064575195\n",
      "Replaced token 920 with corr 0.226896733045578 with new token with corr 0.2268967479467392\n",
      "Replaced token 923 with corr 0.14851413667201996 with new token with corr 0.16132427752017975\n",
      "Replaced token 924 with corr 0.31286388635635376 with new token with corr 0.31286391615867615\n",
      "Replaced token 925 with corr 0.2318374663591385 with new token with corr 0.23183748126029968\n",
      "Replaced token 934 with corr 0.2613554298877716 with new token with corr 0.261355459690094\n",
      "Replaced token 941 with corr 0.34538066387176514 with new token with corr 0.3453806936740875\n",
      "Replaced token 944 with corr 0.33165442943573 with new token with corr 0.33165445923805237\n",
      "Replaced token 946 with corr 0.29203668236732483 with new token with corr 0.2920367121696472\n",
      "Replaced token 950 with corr 0.23268327116966248 with new token with corr 0.23268328607082367\n",
      "Replaced token 952 with corr 0.3226957321166992 with new token with corr 0.3226957619190216\n",
      "Replaced token 953 with corr 0.3911118805408478 with new token with corr 0.39111191034317017\n",
      "Replaced token 957 with corr 0.09542372822761536 with new token with corr 0.23909063637256622\n",
      "Replaced token 960 with corr 0.29104161262512207 with new token with corr 0.29104164242744446\n",
      "Replaced token 968 with corr 0.2828310430049896 with new token with corr 0.282831072807312\n",
      "Replaced token 969 with corr 0.20891571044921875 with new token with corr 0.20891572535037994\n",
      "Replaced token 971 with corr 0.3077709674835205 with new token with corr 0.3077709972858429\n",
      "Replaced token 973 with corr 0.12015997618436813 with new token with corr 0.18991312384605408\n",
      "Replaced token 976 with corr 0.3111468553543091 with new token with corr 0.31114688515663147\n",
      "Replaced token 977 with corr 0.2920689880847931 with new token with corr 0.2920690178871155\n",
      "Replaced token 979 with corr 0.31169092655181885 with new token with corr 0.31169095635414124\n",
      "Replaced token 984 with corr 0.3147476315498352 with new token with corr 0.3147476613521576\n",
      "Replaced token 987 with corr 0.23387378454208374 with new token with corr 0.23387379944324493\n",
      "Replaced token 988 with corr 0.35393962264060974 with new token with corr 0.35393965244293213\n",
      "Replaced token 989 with corr 0.09649454057216644 with new token with corr 0.13950996100902557\n",
      "Replaced token 990 with corr 0.2908798158168793 with new token with corr 0.29087984561920166\n",
      "Replaced token 992 with corr 0.26416563987731934 with new token with corr 0.2641656696796417\n",
      "Replaced token 994 with corr 0.26467618346214294 with new token with corr 0.26467621326446533\n",
      "Replaced token 998 with corr 0.25983667373657227 with new token with corr 0.25983670353889465\n",
      "Replaced token 1000 with corr 0.260223925113678 with new token with corr 0.26022395491600037\n",
      "Replaced token 1003 with corr 0.31902819871902466 with new token with corr 0.31902822852134705\n",
      "Replaced token 1004 with corr 0.36027589440345764 with new token with corr 0.3602759540081024\n",
      "Replaced token 1007 with corr 0.29888030886650085 with new token with corr 0.29888033866882324\n",
      "Replaced token 1008 with corr 0.2619939148426056 with new token with corr 0.261993944644928\n",
      "Replaced token 1010 with corr 0.3870096504688263 with new token with corr 0.3870096802711487\n",
      "Replaced token 1015 with corr 0.3054371476173401 with new token with corr 0.3054371774196625\n",
      "Replaced token 1018 with corr 0.4122932255268097 with new token with corr 0.41229328513145447\n",
      "Replaced token 1023 with corr 0.07638375461101532 with new token with corr 0.15259888768196106\n",
      "Replaced token 1026 with corr 0.26803070306777954 with new token with corr 0.26803073287010193\n",
      "Replaced token 1031 with corr 0.10887496918439865 with new token with corr 0.21241869032382965\n",
      "Replaced token 1035 with corr 0.2407216578722 with new token with corr 0.2407216876745224\n",
      "Replaced token 1036 with corr 0.2904071509838104 with new token with corr 0.2904071807861328\n",
      "Replaced token 1037 with corr 0.3230826258659363 with new token with corr 0.32308265566825867\n",
      "Replaced token 1038 with corr 0.24510371685028076 with new token with corr 0.24510373175144196\n",
      "Replaced token 1047 with corr 0.37635475397109985 with new token with corr 0.37635478377342224\n",
      "Replaced token 1050 with corr 0.10594883561134338 with new token with corr 0.24959640204906464\n",
      "Replaced token 1057 with corr 0.08473658561706543 with new token with corr 0.22825545072555542\n",
      "Replaced token 1068 with corr 0.28840214014053345 with new token with corr 0.28840216994285583\n",
      "Replaced token 1069 with corr 0.349290132522583 with new token with corr 0.3492901623249054\n",
      "Replaced token 1072 with corr 0.2965817451477051 with new token with corr 0.29658177495002747\n",
      "Replaced token 1074 with corr 0.08387237042188644 with new token with corr 0.1788710653781891\n",
      "Replaced token 1082 with corr 0.13931381702423096 with new token with corr 0.14919304847717285\n",
      "Replaced token 1083 with corr 0.2682197690010071 with new token with corr 0.26821979880332947\n",
      "Replaced token 1089 with corr 0.09365814179182053 with new token with corr 0.23969314992427826\n",
      "Replaced token 1090 with corr 0.33009153604507446 with new token with corr 0.33009156584739685\n",
      "Replaced token 1091 with corr 0.2697637379169464 with new token with corr 0.2697637677192688\n",
      "Replaced token 1093 with corr 0.0979638621211052 with new token with corr 0.25052905082702637\n",
      "Replaced token 1095 with corr 0.12025484442710876 with new token with corr 0.16140015423297882\n",
      "Replaced token 1096 with corr 0.21762380003929138 with new token with corr 0.21762381494045258\n",
      "Replaced token 1098 with corr 0.07346440106630325 with new token with corr 0.14864100515842438\n",
      "Replaced token 1104 with corr 0.34052005410194397 with new token with corr 0.34052008390426636\n",
      "Replaced token 1110 with corr 0.10249369591474533 with new token with corr 0.17979593575000763\n",
      "Replaced token 1118 with corr 0.24889810383319855 with new token with corr 0.24889811873435974\n",
      "Replaced token 1121 with corr 0.34374454617500305 with new token with corr 0.34374457597732544\n",
      "Replaced token 1129 with corr 0.2817244231700897 with new token with corr 0.2817244529724121\n",
      "Replaced token 1131 with corr 0.08043554425239563 with new token with corr 0.1565866470336914\n",
      "Replaced token 1132 with corr 0.3295915126800537 with new token with corr 0.3295915424823761\n",
      "Replaced token 1139 with corr 0.22170990705490112 with new token with corr 0.2217099368572235\n",
      "Replaced token 1141 with corr 0.2428198903799057 with new token with corr 0.2428199201822281\n",
      "Replaced token 1144 with corr 0.30219411849975586 with new token with corr 0.30219414830207825\n",
      "Replaced token 1145 with corr 0.2721410393714905 with new token with corr 0.27214106917381287\n",
      "Replaced token 1147 with corr 0.2982047200202942 with new token with corr 0.2982047498226166\n",
      "Replaced token 1152 with corr 0.1226913258433342 with new token with corr 0.2075427621603012\n",
      "Replaced token 1153 with corr 0.10632549226284027 with new token with corr 0.2262493073940277\n",
      "Replaced token 1155 with corr 0.2785830497741699 with new token with corr 0.2785830795764923\n",
      "Replaced token 1156 with corr 0.23615925014019012 with new token with corr 0.2361592799425125\n",
      "Replaced token 1159 with corr 0.22011034190654755 with new token with corr 0.22011035680770874\n",
      "Replaced token 1160 with corr 0.12260282039642334 with new token with corr 0.14229854941368103\n",
      "Replaced token 1162 with corr 0.11809735745191574 with new token with corr 0.22573135793209076\n",
      "Replaced token 1163 with corr 0.27990347146987915 with new token with corr 0.27990350127220154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1166 with corr 0.2041267603635788 with new token with corr 0.20412677526474\n",
      "Replaced token 1168 with corr 0.2579042315483093 with new token with corr 0.2579042613506317\n",
      "Replaced token 1171 with corr 0.09213504195213318 with new token with corr 0.23409555852413177\n",
      "Replaced token 1172 with corr 0.11133114993572235 with new token with corr 0.21641553938388824\n",
      "Replaced token 1176 with corr 0.21362996101379395 with new token with corr 0.21362997591495514\n",
      "Replaced token 1183 with corr 0.24638915061950684 with new token with corr 0.24638916552066803\n",
      "Replaced token 1185 with corr 0.22116556763648987 with new token with corr 0.22116558253765106\n",
      "Replaced token 1197 with corr 0.28437498211860657 with new token with corr 0.28437501192092896\n",
      "Replaced token 1200 with corr 0.1666034758090973 with new token with corr 0.2607845067977905\n",
      "Replaced token 1202 with corr 0.12341270595788956 with new token with corr 0.22799696028232574\n",
      "Replaced token 1205 with corr 0.19409778714179993 with new token with corr 0.19409780204296112\n",
      "Replaced token 1207 with corr 0.3389151096343994 with new token with corr 0.3389151394367218\n",
      "Replaced token 1211 with corr 0.29139575362205505 with new token with corr 0.29139578342437744\n",
      "Replaced token 1213 with corr 0.12440091371536255 with new token with corr 0.23250730335712433\n",
      "Replaced token 1214 with corr 0.23830194771289825 with new token with corr 0.23830196261405945\n",
      "Replaced token 1219 with corr 0.27735888957977295 with new token with corr 0.27735891938209534\n",
      "Replaced token 1224 with corr 0.1334320306777954 with new token with corr 0.15117771923542023\n",
      "Replaced token 1225 with corr 0.23314793407917023 with new token with corr 0.23314794898033142\n",
      "Replaced token 1227 with corr 0.24837519228458405 with new token with corr 0.24837520718574524\n",
      "Replaced token 1228 with corr 0.24153190851211548 with new token with corr 0.24153193831443787\n",
      "Replaced token 1230 with corr 0.35620877146720886 with new token with corr 0.35620880126953125\n",
      "Replaced token 1240 with corr 0.1078638881444931 with new token with corr 0.255260169506073\n",
      "Replaced token 1241 with corr 0.2774861454963684 with new token with corr 0.2774861752986908\n",
      "Replaced token 1243 with corr 0.3002166450023651 with new token with corr 0.3002166748046875\n",
      "Replaced token 1245 with corr 0.32589074969291687 with new token with corr 0.32589077949523926\n",
      "Replaced token 1247 with corr 0.2185843586921692 with new token with corr 0.21858437359333038\n",
      "Replaced token 1250 with corr 0.3418409824371338 with new token with corr 0.3418410122394562\n",
      "Replaced token 1256 with corr 0.11450932174921036 with new token with corr 0.1628721058368683\n",
      "Replaced token 1257 with corr 0.24227455258369446 with new token with corr 0.24227456748485565\n",
      "Replaced token 1260 with corr 0.3034639358520508 with new token with corr 0.30346396565437317\n",
      "Replaced token 1261 with corr 0.1271013468503952 with new token with corr 0.2786852717399597\n",
      "Replaced token 1263 with corr 0.11042303591966629 with new token with corr 0.23266048729419708\n",
      "Replaced token 1264 with corr 0.12782299518585205 with new token with corr 0.2583874464035034\n",
      "Replaced token 1265 with corr 0.09573346376419067 with new token with corr 0.1466173231601715\n",
      "Replaced token 1268 with corr 0.24358239769935608 with new token with corr 0.24358241260051727\n",
      "Replaced token 1275 with corr 0.3648710548877716 with new token with corr 0.364871084690094\n",
      "Replaced token 1281 with corr 0.24084512889385223 with new token with corr 0.24084514379501343\n",
      "Replaced token 1283 with corr 0.2587752044200897 with new token with corr 0.2587752342224121\n",
      "Replaced token 1284 with corr 0.08835963159799576 with new token with corr 0.19375872611999512\n",
      "Replaced token 1292 with corr 0.26065704226493835 with new token with corr 0.26065707206726074\n",
      "Replaced token 1293 with corr 0.2519153952598572 with new token with corr 0.25191542506217957\n",
      "Replaced token 1294 with corr 0.11533965170383453 with new token with corr 0.1674846112728119\n",
      "Replaced token 1297 with corr 0.28668007254600525 with new token with corr 0.28668010234832764\n",
      "Replaced token 1298 with corr 0.3150424659252167 with new token with corr 0.31504249572753906\n",
      "Replaced token 1299 with corr 0.30289462208747864 with new token with corr 0.302894651889801\n",
      "Replaced token 1304 with corr 0.34705448150634766 with new token with corr 0.34705451130867004\n",
      "Replaced token 1305 with corr 0.2652350664138794 with new token with corr 0.2652350962162018\n",
      "Replaced token 1316 with corr 0.2984721064567566 with new token with corr 0.298472136259079\n",
      "Replaced token 1328 with corr 0.22769923508167267 with new token with corr 0.22769924998283386\n",
      "Replaced token 1334 with corr 0.2920372188091278 with new token with corr 0.2920372486114502\n",
      "Replaced token 1336 with corr 0.3003399670124054 with new token with corr 0.3003399968147278\n",
      "Replaced token 1338 with corr 0.25563400983810425 with new token with corr 0.25563403964042664\n",
      "Replaced token 1339 with corr 0.2401357889175415 with new token with corr 0.2401358038187027\n",
      "Replaced token 1346 with corr 0.25715410709381104 with new token with corr 0.2571541368961334\n",
      "Replaced token 1347 with corr 0.2366832196712494 with new token with corr 0.23668323457241058\n",
      "Replaced token 1349 with corr 0.08382277935743332 with new token with corr 0.23777472972869873\n",
      "Replaced token 1351 with corr 0.07137275487184525 with new token with corr 0.246667742729187\n",
      "Replaced token 1352 with corr 0.11622028797864914 with new token with corr 0.1512851119041443\n",
      "Replaced token 1357 with corr 0.10285451263189316 with new token with corr 0.1462312936782837\n",
      "Replaced token 1362 with corr 0.09793490171432495 with new token with corr 0.2076321393251419\n",
      "Replaced token 1363 with corr 0.07055403292179108 with new token with corr 0.20594865083694458\n",
      "Replaced token 1367 with corr 0.21838867664337158 with new token with corr 0.21838869154453278\n",
      "Replaced token 1368 with corr 0.09996118396520615 with new token with corr 0.2627990245819092\n",
      "Replaced token 1373 with corr 0.09707263112068176 with new token with corr 0.22873805463314056\n",
      "Replaced token 1376 with corr 0.26774129271507263 with new token with corr 0.267741322517395\n",
      "Replaced token 1380 with corr 0.3114556670188904 with new token with corr 0.31145569682121277\n",
      "Replaced token 1390 with corr 0.25553807616233826 with new token with corr 0.25553810596466064\n",
      "Replaced token 1394 with corr 0.12385053932666779 with new token with corr 0.2960706353187561\n",
      "Replaced token 1396 with corr 0.2507709562778473 with new token with corr 0.2507709860801697\n",
      "Replaced token 1400 with corr 0.2369937300682068 with new token with corr 0.23699374496936798\n",
      "Replaced token 1401 with corr 0.28485795855522156 with new token with corr 0.28485798835754395\n",
      "Replaced token 1408 with corr 0.3210277557373047 with new token with corr 0.3210277855396271\n",
      "Replaced token 1411 with corr 0.09213609993457794 with new token with corr 0.2126815766096115\n",
      "Replaced token 1412 with corr 0.30496934056282043 with new token with corr 0.3049693703651428\n",
      "Replaced token 1415 with corr 0.1661294549703598 with new token with corr 0.166129469871521\n",
      "Replaced token 1417 with corr 0.24701426923274994 with new token with corr 0.24701428413391113\n",
      "Replaced token 1418 with corr 0.08426766842603683 with new token with corr 0.1918579488992691\n",
      "Replaced token 1419 with corr 0.2902751564979553 with new token with corr 0.2902751863002777\n",
      "Replaced token 1421 with corr 0.3093410134315491 with new token with corr 0.30934104323387146\n",
      "Replaced token 1422 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 1424 with corr 0.2699086666107178 with new token with corr 0.26990869641304016\n",
      "Replaced token 1437 with corr 0.2476053386926651 with new token with corr 0.2476053535938263\n",
      "Replaced token 1444 with corr 0.31953009963035583 with new token with corr 0.3195301294326782\n",
      "Replaced token 1447 with corr 0.30418604612350464 with new token with corr 0.304186075925827\n",
      "Replaced token 1450 with corr 0.098807692527771 with new token with corr 0.15420272946357727\n",
      "Replaced token 1459 with corr 0.246410071849823 with new token with corr 0.2464100867509842\n",
      "Replaced token 1460 with corr 0.34476450085639954 with new token with corr 0.3447645306587219\n",
      "Replaced token 1462 with corr 0.26094090938568115 with new token with corr 0.26094093918800354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1466 with corr 0.25751152634620667 with new token with corr 0.25751155614852905\n",
      "Replaced token 1472 with corr 0.2639434039592743 with new token with corr 0.2639434337615967\n",
      "Replaced token 1473 with corr 0.30136775970458984 with new token with corr 0.30136778950691223\n",
      "Replaced token 1474 with corr 0.24993287026882172 with new token with corr 0.2499328851699829\n",
      "Replaced token 1481 with corr 0.24035239219665527 with new token with corr 0.24035240709781647\n",
      "Replaced token 1487 with corr 0.09526169300079346 with new token with corr 0.15965573489665985\n",
      "Replaced token 1489 with corr 0.1247924417257309 with new token with corr 0.33324137330055237\n",
      "Replaced token 1492 with corr 0.09415073692798615 with new token with corr 0.16341851651668549\n",
      "Replaced token 1493 with corr 0.12412174046039581 with new token with corr 0.22170911729335785\n",
      "Replaced token 1498 with corr 0.25774484872817993 with new token with corr 0.2577448785305023\n",
      "Replaced token 1499 with corr 0.11585573852062225 with new token with corr 0.15386910736560822\n",
      "Replaced token 1503 with corr 0.29561543464660645 with new token with corr 0.29561546444892883\n",
      "Replaced token 1505 with corr 0.3122961223125458 with new token with corr 0.31229615211486816\n",
      "Replaced token 1514 with corr 0.12196523696184158 with new token with corr 0.23732560873031616\n",
      "Replaced token 1519 with corr 0.24368910491466522 with new token with corr 0.24368911981582642\n",
      "Replaced token 1535 with corr 0.12499857693910599 with new token with corr 0.1514664590358734\n",
      "Replaced token 1538 with corr 0.3316771686077118 with new token with corr 0.33167722821235657\n",
      "Replaced token 1541 with corr 0.31869080662727356 with new token with corr 0.31869083642959595\n",
      "Replaced token 1545 with corr 0.2872934639453888 with new token with corr 0.2872934937477112\n",
      "Replaced token 1547 with corr 0.22767971456050873 with new token with corr 0.22767974436283112\n",
      "Replaced token 1551 with corr 0.2709994912147522 with new token with corr 0.2709995210170746\n",
      "Replaced token 1558 with corr 0.28821301460266113 with new token with corr 0.2882130444049835\n",
      "Replaced token 1562 with corr 0.24959638714790344 with new token with corr 0.24959640204906464\n",
      "Replaced token 1563 with corr 0.3271556794643402 with new token with corr 0.3271557092666626\n",
      "Replaced token 1564 with corr 0.3083542585372925 with new token with corr 0.30835428833961487\n",
      "Replaced token 1571 with corr 0.33832207322120667 with new token with corr 0.33832210302352905\n",
      "Replaced token 1572 with corr 0.1058175265789032 with new token with corr 0.2089463174343109\n",
      "Replaced token 1573 with corr 0.13325977325439453 with new token with corr 0.17801524698734283\n",
      "Replaced token 1574 with corr 0.15179938077926636 with new token with corr 0.1811733841896057\n",
      "Replaced token 1579 with corr 0.286204993724823 with new token with corr 0.2862050235271454\n",
      "Replaced token 1585 with corr 0.24426127970218658 with new token with corr 0.24426130950450897\n",
      "Replaced token 1588 with corr 0.3425000309944153 with new token with corr 0.34250006079673767\n",
      "Replaced token 1592 with corr 0.19074557721614838 with new token with corr 0.19074559211730957\n",
      "Replaced token 1593 with corr 0.3258284628391266 with new token with corr 0.325828492641449\n",
      "Replaced token 1595 with corr 0.2927840054035187 with new token with corr 0.29278403520584106\n",
      "Replaced token 1596 with corr 0.3128633499145508 with new token with corr 0.31286337971687317\n",
      "Replaced token 1597 with corr 0.3189622163772583 with new token with corr 0.3189622461795807\n",
      "Replaced token 1600 with corr 0.2321825623512268 with new token with corr 0.232182577252388\n",
      "Replaced token 1602 with corr 0.3346799910068512 with new token with corr 0.3346800208091736\n",
      "Replaced token 1608 with corr 0.27925607562065125 with new token with corr 0.27925610542297363\n",
      "Replaced token 1612 with corr 0.27057892084121704 with new token with corr 0.27057895064353943\n",
      "Replaced token 1613 with corr 0.2740519940853119 with new token with corr 0.2740520238876343\n",
      "Replaced token 1614 with corr 0.3153383433818817 with new token with corr 0.3153383731842041\n",
      "Replaced token 1615 with corr 0.27397194504737854 with new token with corr 0.2739719748497009\n",
      "Replaced token 1617 with corr 0.12679360806941986 with new token with corr 0.1484745293855667\n",
      "Replaced token 1624 with corr 0.29400739073753357 with new token with corr 0.29400742053985596\n",
      "Replaced token 1626 with corr 0.3288717269897461 with new token with corr 0.3288717567920685\n",
      "Replaced token 1627 with corr 0.26737180352211 with new token with corr 0.2673718333244324\n",
      "Replaced token 1628 with corr 0.3313246965408325 with new token with corr 0.3313247263431549\n",
      "Replaced token 1630 with corr 0.14292779564857483 with new token with corr 0.21474862098693848\n",
      "Replaced token 1640 with corr 0.31473079323768616 with new token with corr 0.31473082304000854\n",
      "Replaced token 1645 with corr 0.14035627245903015 with new token with corr 0.14863604307174683\n",
      "Replaced token 1652 with corr 0.30257919430732727 with new token with corr 0.30257922410964966\n",
      "Replaced token 1654 with corr 0.37040168046951294 with new token with corr 0.3704017102718353\n",
      "Replaced token 1656 with corr 0.3089355230331421 with new token with corr 0.3089355528354645\n",
      "Replaced token 1657 with corr 0.3158467710018158 with new token with corr 0.3158468008041382\n",
      "Replaced token 1658 with corr 0.23301279544830322 with new token with corr 0.23301281034946442\n",
      "Replaced token 1664 with corr 0.31818827986717224 with new token with corr 0.318188339471817\n",
      "Replaced token 1665 with corr 0.3412315249443054 with new token with corr 0.3412315547466278\n",
      "Replaced token 1666 with corr 0.35368120670318604 with new token with corr 0.3536812365055084\n",
      "Replaced token 1668 with corr 0.11640621721744537 with new token with corr 0.13924497365951538\n",
      "Replaced token 1674 with corr 0.10315745323896408 with new token with corr 0.2663765847682953\n",
      "Replaced token 1675 with corr 0.22170239686965942 with new token with corr 0.22170241177082062\n",
      "Replaced token 1678 with corr 0.12826283276081085 with new token with corr 0.24345025420188904\n",
      "Replaced token 1683 with corr 0.11616560071706772 with new token with corr 0.1530694216489792\n",
      "Replaced token 1685 with corr 0.28496208786964417 with new token with corr 0.28496211767196655\n",
      "Replaced token 1689 with corr 0.25267162919044495 with new token with corr 0.25267165899276733\n",
      "Replaced token 1694 with corr 0.37729260325431824 with new token with corr 0.3772926330566406\n",
      "Replaced token 1702 with corr 0.30992239713668823 with new token with corr 0.3099224269390106\n",
      "Replaced token 1704 with corr 0.23936587572097778 with new token with corr 0.23936589062213898\n",
      "Replaced token 1706 with corr 0.2977607548236847 with new token with corr 0.2977607846260071\n",
      "Replaced token 1711 with corr 0.3252178132534027 with new token with corr 0.3252178430557251\n",
      "Replaced token 1712 with corr 0.29788392782211304 with new token with corr 0.2978839576244354\n",
      "Replaced token 1713 with corr 0.3318425118923187 with new token with corr 0.3318425416946411\n",
      "Replaced token 1715 with corr 0.23761659860610962 with new token with corr 0.2376166135072708\n",
      "Replaced token 1717 with corr 0.1978810727596283 with new token with corr 0.1978810876607895\n",
      "Replaced token 1721 with corr 0.12230458110570908 with new token with corr 0.1910378485918045\n",
      "Replaced token 1723 with corr 0.2404869943857193 with new token with corr 0.2404870241880417\n",
      "Replaced token 1724 with corr 0.09965529292821884 with new token with corr 0.23894765973091125\n",
      "Replaced token 1725 with corr 0.11401858180761337 with new token with corr 0.23250730335712433\n",
      "Replaced token 1731 with corr 0.28151676058769226 with new token with corr 0.28151679039001465\n",
      "Replaced token 1734 with corr 0.2952963709831238 with new token with corr 0.29529640078544617\n",
      "Replaced token 1738 with corr 0.24705149233341217 with new token with corr 0.24705150723457336\n",
      "Replaced token 1749 with corr 0.09431915730237961 with new token with corr 0.26409608125686646\n",
      "Replaced token 1750 with corr 0.203522190451622 with new token with corr 0.2035222053527832\n",
      "Replaced token 1754 with corr 0.36329224705696106 with new token with corr 0.36329227685928345\n",
      "Replaced token 1758 with corr 0.3014308214187622 with new token with corr 0.3014308512210846\n",
      "Replaced token 1765 with corr 0.113925039768219 with new token with corr 0.23003029823303223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1766 with corr 0.28868743777275085 with new token with corr 0.28868746757507324\n",
      "Replaced token 1772 with corr 0.12538324296474457 with new token with corr 0.17466109991073608\n",
      "Replaced token 1778 with corr 0.2448357194662094 with new token with corr 0.2448357343673706\n",
      "Replaced token 1781 with corr 0.3117597699165344 with new token with corr 0.3117597997188568\n",
      "Replaced token 1782 with corr 0.29230037331581116 with new token with corr 0.29230040311813354\n",
      "Replaced token 1784 with corr 0.24960128962993622 with new token with corr 0.2496013045310974\n",
      "Replaced token 1786 with corr 0.2265506237745285 with new token with corr 0.22655066847801208\n",
      "Replaced token 1794 with corr 0.23710615932941437 with new token with corr 0.23710617423057556\n",
      "Replaced token 1796 with corr 0.10505230724811554 with new token with corr 0.19375872611999512\n",
      "Replaced token 1797 with corr 0.1041848435997963 with new token with corr 0.20226873457431793\n",
      "Replaced token 1798 with corr 0.12051334232091904 with new token with corr 0.2571505308151245\n",
      "Replaced token 1805 with corr 0.2757422626018524 with new token with corr 0.2757422924041748\n",
      "Replaced token 1806 with corr 0.20165354013442993 with new token with corr 0.20165355503559113\n",
      "Replaced token 1813 with corr 0.33314231038093567 with new token with corr 0.33314234018325806\n",
      "Replaced token 1815 with corr 0.09153895825147629 with new token with corr 0.2720903754234314\n",
      "Replaced token 1821 with corr 0.2734537124633789 with new token with corr 0.2734537422657013\n",
      "Replaced token 1822 with corr 0.28521135449409485 with new token with corr 0.28521138429641724\n",
      "Replaced token 1824 with corr 0.3406933844089508 with new token with corr 0.3406934142112732\n",
      "Replaced token 1828 with corr 0.1047699898481369 with new token with corr 0.24702207744121552\n",
      "Replaced token 1833 with corr 0.32687437534332275 with new token with corr 0.32687440514564514\n",
      "Replaced token 1835 with corr 0.3347932696342468 with new token with corr 0.3347932994365692\n",
      "Replaced token 1842 with corr 0.27682697772979736 with new token with corr 0.27682700753211975\n",
      "Replaced token 1844 with corr 0.2383463978767395 with new token with corr 0.2383464127779007\n",
      "Replaced token 1846 with corr 0.29993799328804016 with new token with corr 0.29993802309036255\n",
      "Replaced token 1851 with corr 0.14143934845924377 with new token with corr 0.21197469532489777\n",
      "Replaced token 1854 with corr 0.25851476192474365 with new token with corr 0.25851479172706604\n",
      "Replaced token 1865 with corr 0.2478196918964386 with new token with corr 0.2478197067975998\n",
      "Replaced token 1868 with corr 0.3009788990020752 with new token with corr 0.3009789288043976\n",
      "Replaced token 1869 with corr 0.09271486848592758 with new token with corr 0.14925695955753326\n",
      "Replaced token 1870 with corr 0.24355582892894745 with new token with corr 0.24355584383010864\n",
      "Replaced token 1871 with corr 0.3193080425262451 with new token with corr 0.3193080723285675\n",
      "Replaced token 1873 with corr 0.31132400035858154 with new token with corr 0.31132403016090393\n",
      "Replaced token 1875 with corr 0.31241902709007263 with new token with corr 0.312419056892395\n",
      "Replaced token 1880 with corr 0.29058465361595154 with new token with corr 0.2905846834182739\n",
      "Replaced token 1886 with corr 0.09809347987174988 with new token with corr 0.15751954913139343\n",
      "Replaced token 1889 with corr 0.3902224600315094 with new token with corr 0.3902224898338318\n",
      "Replaced token 1892 with corr 0.4046754837036133 with new token with corr 0.40467551350593567\n",
      "Replaced token 1893 with corr 0.24676626920700073 with new token with corr 0.24676628410816193\n",
      "Replaced token 1898 with corr 0.08746799826622009 with new token with corr 0.18822109699249268\n",
      "Replaced token 1899 with corr 0.2601078152656555 with new token with corr 0.2601078450679779\n",
      "Replaced token 1901 with corr 0.3075515627861023 with new token with corr 0.3075515925884247\n",
      "Replaced token 1904 with corr 0.36426249146461487 with new token with corr 0.36426252126693726\n",
      "Replaced token 1907 with corr 0.2462347000837326 with new token with corr 0.2462347149848938\n",
      "Replaced token 1911 with corr 0.10159188508987427 with new token with corr 0.2432563453912735\n",
      "Replaced token 1914 with corr 0.10121522843837738 with new token with corr 0.28528982400894165\n",
      "Replaced token 1915 with corr 0.2760462760925293 with new token with corr 0.2760463058948517\n",
      "Replaced token 1916 with corr 0.19995521008968353 with new token with corr 0.19995522499084473\n",
      "Replaced token 1919 with corr 0.1328171342611313 with new token with corr 0.2570674419403076\n",
      "Replaced token 1921 with corr 0.32253897190093994 with new token with corr 0.32253900170326233\n",
      "Replaced token 1922 with corr 0.27247318625450134 with new token with corr 0.27247321605682373\n",
      "Replaced token 1923 with corr 0.263200581073761 with new token with corr 0.2632006108760834\n",
      "Replaced token 1924 with corr 0.30496934056282043 with new token with corr 0.3049693703651428\n",
      "Replaced token 1925 with corr 0.14087232947349548 with new token with corr 0.24447175860404968\n",
      "Replaced token 1927 with corr 0.22887475788593292 with new token with corr 0.2288747876882553\n",
      "Replaced token 1934 with corr 0.14423410594463348 with new token with corr 0.15180175006389618\n",
      "Replaced token 1935 with corr 0.26793351769447327 with new token with corr 0.26793354749679565\n",
      "Replaced token 1937 with corr 0.10361011326313019 with new token with corr 0.19467350840568542\n",
      "Replaced token 1939 with corr 0.11677804589271545 with new token with corr 0.15687577426433563\n",
      "Replaced token 1949 with corr 0.28852903842926025 with new token with corr 0.28852906823158264\n",
      "Replaced token 1950 with corr 0.10692845284938812 with new token with corr 0.1659749299287796\n",
      "Replaced token 1956 with corr 0.2995045781135559 with new token with corr 0.2995046079158783\n",
      "Replaced token 1959 with corr 0.3397562801837921 with new token with corr 0.3397563099861145\n",
      "Replaced token 1967 with corr 0.0919974073767662 with new token with corr 0.15440888702869415\n",
      "Replaced token 1968 with corr 0.2861381471157074 with new token with corr 0.2861381769180298\n",
      "Replaced token 1975 with corr 0.2955193519592285 with new token with corr 0.2955193817615509\n",
      "Replaced token 1988 with corr 0.2948022782802582 with new token with corr 0.29480233788490295\n",
      "Replaced token 1994 with corr 0.07788437604904175 with new token with corr 0.15879173576831818\n",
      "Replaced token 1998 with corr 0.4107975661754608 with new token with corr 0.4107975959777832\n",
      "Replaced token 1999 with corr 0.3160415589809418 with new token with corr 0.31604158878326416\n",
      "Replaced token 2000 with corr 0.25427988171577454 with new token with corr 0.2542799115180969\n",
      "Replaced token 2003 with corr 0.20455005764961243 with new token with corr 0.20455008745193481\n",
      "Replaced token 2008 with corr 0.12380942702293396 with new token with corr 0.2583029270172119\n",
      "Replaced token 2010 with corr 0.22079136967658997 with new token with corr 0.22079138457775116\n",
      "Replaced token 2013 with corr 0.0755612924695015 with new token with corr 0.24288199841976166\n",
      "Replaced token 2014 with corr 0.10457774251699448 with new token with corr 0.20454064011573792\n",
      "Replaced token 2016 with corr 0.3039104640483856 with new token with corr 0.303910493850708\n",
      "Replaced token 2017 with corr 0.3517248034477234 with new token with corr 0.3517248332500458\n",
      "Replaced token 2020 with corr 0.23700664937496185 with new token with corr 0.23700666427612305\n",
      "Replaced token 2021 with corr 0.13518060743808746 with new token with corr 0.14125566184520721\n",
      "Replaced token 2022 with corr 0.25347524881362915 with new token with corr 0.25347527861595154\n",
      "Replaced token 2025 with corr 0.10530538856983185 with new token with corr 0.2723276913166046\n",
      "Replaced token 2027 with corr 0.23798449337482452 with new token with corr 0.23798450827598572\n",
      "Replaced token 2029 with corr 0.3013286292552948 with new token with corr 0.3013286590576172\n",
      "Replaced token 2032 with corr 0.11544646322727203 with new token with corr 0.15804436802864075\n",
      "Replaced token 2035 with corr 0.11083207279443741 with new token with corr 0.1620553880929947\n",
      "Replaced token 2036 with corr 0.2558175027370453 with new token with corr 0.2558175325393677\n",
      "Replaced token 2042 with corr 0.3198264241218567 with new token with corr 0.3198264539241791\n",
      "Replaced token 2047 with corr 0.07412855327129364 with new token with corr 0.14971689879894257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2051 with corr 0.25788402557373047 with new token with corr 0.25788405537605286\n",
      "Replaced token 2052 with corr 0.3069632649421692 with new token with corr 0.3069632947444916\n",
      "Replaced token 2053 with corr 0.09284576773643494 with new token with corr 0.15759992599487305\n",
      "Replaced token 2055 with corr 0.2509036362171173 with new token with corr 0.2509036660194397\n",
      "Replaced token 2062 with corr 0.26083317399024963 with new token with corr 0.260833203792572\n",
      "Replaced token 2070 with corr 0.27059221267700195 with new token with corr 0.27059224247932434\n",
      "Replaced token 2071 with corr 0.08480403572320938 with new token with corr 0.14924263954162598\n",
      "Replaced token 2075 with corr 0.19492687284946442 with new token with corr 0.1949268877506256\n",
      "Replaced token 2077 with corr 0.3688375651836395 with new token with corr 0.3688375949859619\n",
      "Replaced token 2082 with corr 0.347206711769104 with new token with corr 0.3472067415714264\n",
      "Replaced token 2084 with corr 0.19509585201740265 with new token with corr 0.19509586691856384\n",
      "Replaced token 2085 with corr 0.11269345879554749 with new token with corr 0.32850000262260437\n",
      "Replaced token 2087 with corr 0.11677654832601547 with new token with corr 0.18592093884944916\n",
      "Replaced token 2088 with corr 0.09122069180011749 with new token with corr 0.15591472387313843\n",
      "Replaced token 2095 with corr 0.09982489794492722 with new token with corr 0.15364058315753937\n",
      "Replaced token 2102 with corr 0.1170656755566597 with new token with corr 0.15395185351371765\n",
      "Replaced token 2105 with corr 0.33038607239723206 with new token with corr 0.33038610219955444\n",
      "Replaced token 2107 with corr 0.11210350692272186 with new token with corr 0.16555650532245636\n",
      "Replaced token 2108 with corr 0.22601564228534698 with new token with corr 0.22601565718650818\n",
      "Replaced token 2109 with corr 0.31129080057144165 with new token with corr 0.31129083037376404\n",
      "Replaced token 2110 with corr 0.22657600045204163 with new token with corr 0.22657601535320282\n",
      "Replaced token 2112 with corr 0.24228563904762268 with new token with corr 0.24228566884994507\n",
      "Replaced token 2113 with corr 0.0988474115729332 with new token with corr 0.14790397882461548\n",
      "Replaced token 2114 with corr 0.2976948320865631 with new token with corr 0.2976948618888855\n",
      "Replaced token 2119 with corr 0.11014771461486816 with new token with corr 0.19981727004051208\n",
      "Replaced token 2120 with corr 0.21221844851970673 with new token with corr 0.21221846342086792\n",
      "Replaced token 2121 with corr 0.31576627492904663 with new token with corr 0.315766304731369\n",
      "Replaced token 2122 with corr 0.32520440220832825 with new token with corr 0.32520443201065063\n",
      "Replaced token 2124 with corr 0.280360609292984 with new token with corr 0.2803606390953064\n",
      "Replaced token 2125 with corr 0.3086665868759155 with new token with corr 0.3086666166782379\n",
      "Replaced token 2132 with corr 0.08016213029623032 with new token with corr 0.1699904054403305\n",
      "Replaced token 2147 with corr 0.2794680595397949 with new token with corr 0.2794680893421173\n",
      "Replaced token 2153 with corr 0.2783994972705841 with new token with corr 0.2783995270729065\n",
      "Replaced token 2156 with corr 0.09423402696847916 with new token with corr 0.14619101583957672\n",
      "Replaced token 2160 with corr 0.30880796909332275 with new token with corr 0.30880799889564514\n",
      "Replaced token 2164 with corr 0.1118878722190857 with new token with corr 0.14630191028118134\n",
      "Replaced token 2167 with corr 0.11323433369398117 with new token with corr 0.15724734961986542\n",
      "Replaced token 2169 with corr 0.26947855949401855 with new token with corr 0.26947858929634094\n",
      "Replaced token 2170 with corr 0.2666380703449249 with new token with corr 0.2666381001472473\n",
      "Replaced token 2172 with corr 0.25435927510261536 with new token with corr 0.25435930490493774\n",
      "Replaced token 2174 with corr 0.30648282170295715 with new token with corr 0.30648285150527954\n",
      "Replaced token 2175 with corr 0.07608034461736679 with new token with corr 0.15946857631206512\n",
      "Replaced token 2179 with corr 0.11742740124464035 with new token with corr 0.15789982676506042\n",
      "Replaced token 2181 with corr 0.11763665080070496 with new token with corr 0.16208957135677338\n",
      "Replaced token 2194 with corr 0.09419893473386765 with new token with corr 0.16334612667560577\n",
      "Replaced token 2196 with corr 0.24311122298240662 with new token with corr 0.2431112378835678\n",
      "Replaced token 2198 with corr 0.3570466637611389 with new token with corr 0.3570466935634613\n",
      "Replaced token 2203 with corr 0.12454036623239517 with new token with corr 0.2125348001718521\n",
      "Replaced token 2205 with corr 0.2883314788341522 with new token with corr 0.2883315086364746\n",
      "Replaced token 2206 with corr 0.10140426456928253 with new token with corr 0.14577537775039673\n",
      "Replaced token 2208 with corr 0.2930876314640045 with new token with corr 0.2930876612663269\n",
      "Replaced token 2210 with corr 0.36871597170829773 with new token with corr 0.3687160015106201\n",
      "Replaced token 2212 with corr 0.078856460750103 with new token with corr 0.17004385590553284\n",
      "Replaced token 2213 with corr 0.2982076406478882 with new token with corr 0.29820767045021057\n",
      "Replaced token 2219 with corr 0.17792387306690216 with new token with corr 0.17792388796806335\n",
      "Replaced token 2224 with corr 0.31901830434799194 with new token with corr 0.31901833415031433\n",
      "Replaced token 2234 with corr 0.086077481508255 with new token with corr 0.15172408521175385\n",
      "Replaced token 2236 with corr 0.2783776521682739 with new token with corr 0.2783776819705963\n",
      "Replaced token 2238 with corr 0.30012860894203186 with new token with corr 0.30012863874435425\n",
      "Replaced token 2247 with corr 0.3189411759376526 with new token with corr 0.318941205739975\n",
      "Replaced token 2248 with corr 0.29666149616241455 with new token with corr 0.29666152596473694\n",
      "Replaced token 2249 with corr 0.2146950364112854 with new token with corr 0.2146950513124466\n",
      "Replaced token 2251 with corr 0.29221922159194946 with new token with corr 0.29221925139427185\n",
      "Replaced token 2254 with corr 0.08562545478343964 with new token with corr 0.13981670141220093\n",
      "Replaced token 2255 with corr 0.3374921977519989 with new token with corr 0.3374922275543213\n",
      "Replaced token 2260 with corr 0.24313679337501526 with new token with corr 0.24313680827617645\n",
      "Replaced token 2262 with corr 0.15538953244686127 with new token with corr 0.24535267055034637\n",
      "Replaced token 2264 with corr 0.29542285203933716 with new token with corr 0.29542288184165955\n",
      "Replaced token 2270 with corr 0.2792428731918335 with new token with corr 0.2792429029941559\n",
      "Replaced token 2271 with corr 0.3282772898674011 with new token with corr 0.3282773196697235\n",
      "Replaced token 2274 with corr 0.261931836605072 with new token with corr 0.2619318664073944\n",
      "Replaced token 2276 with corr 0.10801269114017487 with new token with corr 0.21808457374572754\n",
      "Replaced token 2277 with corr 0.23391565680503845 with new token with corr 0.23391568660736084\n",
      "Replaced token 2280 with corr 0.13827355206012726 with new token with corr 0.16273275017738342\n",
      "Replaced token 2281 with corr 0.24282605946063995 with new token with corr 0.24282607436180115\n",
      "Replaced token 2285 with corr 0.2642006576061249 with new token with corr 0.26420068740844727\n",
      "Replaced token 2291 with corr 0.08843442052602768 with new token with corr 0.16082386672496796\n",
      "Replaced token 2292 with corr 0.2689962387084961 with new token with corr 0.2689962685108185\n",
      "Replaced token 2294 with corr 0.29694873094558716 with new token with corr 0.29694876074790955\n",
      "Replaced token 2297 with corr 0.10756257176399231 with new token with corr 0.15493832528591156\n",
      "Replaced token 2298 with corr 0.28728973865509033 with new token with corr 0.2872897684574127\n",
      "Replaced token 2300 with corr 0.29967960715293884 with new token with corr 0.29967963695526123\n",
      "Replaced token 2301 with corr 0.08621449023485184 with new token with corr 0.1564738005399704\n",
      "Replaced token 2305 with corr 0.14443953335285187 with new token with corr 0.16530855000019073\n",
      "Replaced token 2306 with corr 0.27167898416519165 with new token with corr 0.27167901396751404\n",
      "Replaced token 2308 with corr 0.25211140513420105 with new token with corr 0.25211143493652344\n",
      "Replaced token 2309 with corr 0.2579573392868042 with new token with corr 0.2579573690891266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2310 with corr 0.3267338275909424 with new token with corr 0.32673385739326477\n",
      "Replaced token 2311 with corr 0.3320545554161072 with new token with corr 0.33205458521842957\n",
      "Replaced token 2316 with corr 0.29726263880729675 with new token with corr 0.29726266860961914\n",
      "Replaced token 2317 with corr 0.24568913877010345 with new token with corr 0.24568915367126465\n",
      "Replaced token 2319 with corr 0.13409604132175446 with new token with corr 0.16834183037281036\n",
      "Replaced token 2325 with corr 0.32335197925567627 with new token with corr 0.32335200905799866\n",
      "Replaced token 2327 with corr 0.08854228258132935 with new token with corr 0.15950819849967957\n",
      "Replaced token 2329 with corr 0.24800637364387512 with new token with corr 0.24800638854503632\n",
      "Replaced token 2332 with corr 0.08288747072219849 with new token with corr 0.15377984941005707\n",
      "Replaced token 2340 with corr 0.11191259324550629 with new token with corr 0.1576612889766693\n",
      "Replaced token 2341 with corr 0.3001132607460022 with new token with corr 0.3001132905483246\n",
      "Replaced token 2342 with corr 0.313757985830307 with new token with corr 0.3137580156326294\n",
      "Replaced token 2344 with corr 0.09841009229421616 with new token with corr 0.1914386749267578\n",
      "Replaced token 2346 with corr 0.293280690908432 with new token with corr 0.2932807207107544\n",
      "Replaced token 2352 with corr 0.24075984954833984 with new token with corr 0.24075986444950104\n",
      "Replaced token 2353 with corr 0.33969777822494507 with new token with corr 0.33969780802726746\n",
      "Replaced token 2358 with corr 0.13088653981685638 with new token with corr 0.2129574716091156\n",
      "Replaced token 2360 with corr 0.33447787165641785 with new token with corr 0.33447790145874023\n",
      "Replaced token 2361 with corr 0.313676118850708 with new token with corr 0.3136761784553528\n",
      "Replaced token 2363 with corr 0.20751219987869263 with new token with corr 0.20751221477985382\n",
      "Replaced token 2364 with corr 0.11286571621894836 with new token with corr 0.14623808860778809\n",
      "Replaced token 2365 with corr 0.10503681749105453 with new token with corr 0.1948922723531723\n",
      "Replaced token 2367 with corr 0.33759987354278564 with new token with corr 0.33759990334510803\n",
      "Replaced token 2368 with corr 0.09226346760988235 with new token with corr 0.16253669559955597\n",
      "Replaced token 2371 with corr 0.2812137305736542 with new token with corr 0.28121376037597656\n",
      "Replaced token 2378 with corr 0.23842260241508484 with new token with corr 0.23842261731624603\n",
      "Replaced token 2379 with corr 0.08703435212373734 with new token with corr 0.15441136062145233\n",
      "Replaced token 2381 with corr 0.27995914220809937 with new token with corr 0.27995917201042175\n",
      "Replaced token 2383 with corr 0.282150000333786 with new token with corr 0.2821500301361084\n",
      "Replaced token 2384 with corr 0.12280003726482391 with new token with corr 0.14209158718585968\n",
      "Replaced token 2385 with corr 0.09798111021518707 with new token with corr 0.3236064016819\n",
      "Replaced token 2386 with corr 0.10839793086051941 with new token with corr 0.17683298885822296\n",
      "Replaced token 2387 with corr 0.24104274809360504 with new token with corr 0.24104277789592743\n",
      "Replaced token 2388 with corr 0.3143964111804962 with new token with corr 0.3143964409828186\n",
      "Replaced token 2390 with corr 0.15832184255123138 with new token with corr 0.15832185745239258\n",
      "Replaced token 2393 with corr 0.1123812273144722 with new token with corr 0.16104480624198914\n",
      "Replaced token 2396 with corr 0.10801953077316284 with new token with corr 0.1671046018600464\n",
      "Replaced token 2398 with corr 0.36193543672561646 with new token with corr 0.36193546652793884\n",
      "Replaced token 2400 with corr 0.2757025361061096 with new token with corr 0.275702565908432\n",
      "Replaced token 2401 with corr 0.2822364866733551 with new token with corr 0.2822365164756775\n",
      "Replaced token 2402 with corr 0.29080504179000854 with new token with corr 0.29080507159233093\n",
      "Replaced token 2408 with corr 0.11459790915250778 with new token with corr 0.14243915677070618\n",
      "Replaced token 2410 with corr 0.257398784160614 with new token with corr 0.2573988139629364\n",
      "Replaced token 2413 with corr 0.08556809276342392 with new token with corr 0.34158772230148315\n",
      "Replaced token 2416 with corr 0.2963707447052002 with new token with corr 0.2963707745075226\n",
      "Replaced token 2419 with corr 0.2462347000837326 with new token with corr 0.2462347149848938\n",
      "Replaced token 2421 with corr 0.1937524527311325 with new token with corr 0.1937524676322937\n",
      "Replaced token 2424 with corr 0.20765498280525208 with new token with corr 0.20765499770641327\n",
      "Replaced token 2428 with corr 0.07455836236476898 with new token with corr 0.2022038847208023\n",
      "Replaced token 2434 with corr 0.12066151201725006 with new token with corr 0.17029590904712677\n",
      "Replaced token 2440 with corr 0.29343169927597046 with new token with corr 0.29343172907829285\n",
      "Replaced token 2444 with corr 0.35054782032966614 with new token with corr 0.3505478501319885\n",
      "Replaced token 2445 with corr 0.323510080575943 with new token with corr 0.3235101103782654\n",
      "Replaced token 2446 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 2447 with corr 0.25556299090385437 with new token with corr 0.25556302070617676\n",
      "Replaced token 2449 with corr 0.1201745867729187 with new token with corr 0.15526935458183289\n",
      "Replaced token 2453 with corr 0.10589312762022018 with new token with corr 0.16211055219173431\n",
      "Replaced token 2454 with corr 0.10390853136777878 with new token with corr 0.2800275385379791\n",
      "Replaced token 2458 with corr 0.36382564902305603 with new token with corr 0.3638256788253784\n",
      "Replaced token 2467 with corr 0.32076069712638855 with new token with corr 0.32076072692871094\n",
      "Replaced token 2468 with corr 0.2977660000324249 with new token with corr 0.2977660298347473\n",
      "Replaced token 2471 with corr 0.307456910610199 with new token with corr 0.30745697021484375\n",
      "Replaced token 2472 with corr 0.3476983308792114 with new token with corr 0.3476983606815338\n",
      "Replaced token 2474 with corr 0.3292624056339264 with new token with corr 0.3292624354362488\n",
      "Replaced token 2475 with corr 0.08915002644062042 with new token with corr 0.18457834422588348\n",
      "Replaced token 2480 with corr 0.09509865939617157 with new token with corr 0.16629163920879364\n",
      "Replaced token 2481 with corr 0.30183926224708557 with new token with corr 0.30183929204940796\n",
      "Replaced token 2488 with corr 0.12982840836048126 with new token with corr 0.20136673748493195\n",
      "Replaced token 2489 with corr 0.14955446124076843 with new token with corr 0.15102101862430573\n",
      "Replaced token 2491 with corr 0.11028311401605606 with new token with corr 0.1553986519575119\n",
      "Replaced token 2497 with corr 0.10846427083015442 with new token with corr 0.2654228210449219\n",
      "Replaced token 2498 with corr 0.11025235056877136 with new token with corr 0.2499328851699829\n",
      "Replaced token 2500 with corr 0.29767242074012756 with new token with corr 0.29767245054244995\n",
      "Replaced token 2501 with corr 0.2405131608247757 with new token with corr 0.2405131757259369\n",
      "Replaced token 2503 with corr 0.10148318111896515 with new token with corr 0.14484058320522308\n",
      "Replaced token 2504 with corr 0.26463207602500916 with new token with corr 0.26463210582733154\n",
      "Replaced token 2505 with corr 0.2634211480617523 with new token with corr 0.2634212076663971\n",
      "Replaced token 2509 with corr 0.13025347888469696 with new token with corr 0.2553485333919525\n",
      "Replaced token 2514 with corr 0.33602774143218994 with new token with corr 0.33602777123451233\n",
      "Replaced token 2515 with corr 0.3439788520336151 with new token with corr 0.3439788818359375\n",
      "Replaced token 2520 with corr 0.34120631217956543 with new token with corr 0.3412063717842102\n",
      "Replaced token 2522 with corr 0.0978996679186821 with new token with corr 0.1519155353307724\n",
      "Replaced token 2523 with corr 0.27967149019241333 with new token with corr 0.2796715199947357\n",
      "Replaced token 2525 with corr 0.29313090443611145 with new token with corr 0.29313093423843384\n",
      "Replaced token 2526 with corr 0.08897241204977036 with new token with corr 0.2087474912405014\n",
      "Replaced token 2527 with corr 0.09985345602035522 with new token with corr 0.15002985298633575\n",
      "Replaced token 2533 with corr 0.33447030186653137 with new token with corr 0.33447033166885376\n",
      "Replaced token 2537 with corr 0.15176093578338623 with new token with corr 0.15205664932727814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2538 with corr 0.3232862949371338 with new token with corr 0.3232863247394562\n",
      "Replaced token 2539 with corr 0.10612896829843521 with new token with corr 0.14835987985134125\n",
      "Replaced token 2546 with corr 0.358834832906723 with new token with corr 0.3588348627090454\n",
      "Replaced token 2547 with corr 0.24551577866077423 with new token with corr 0.24551580846309662\n",
      "Replaced token 2550 with corr 0.3117679953575134 with new token with corr 0.3117680251598358\n",
      "Replaced token 2551 with corr 0.132096529006958 with new token with corr 0.15377266705036163\n",
      "Replaced token 2552 with corr 0.35181406140327454 with new token with corr 0.3518140912055969\n",
      "Replaced token 2553 with corr 0.11932205408811569 with new token with corr 0.1439962536096573\n",
      "Replaced token 2559 with corr 0.0657072365283966 with new token with corr 0.14971689879894257\n",
      "Replaced token 2563 with corr 0.3469332456588745 with new token with corr 0.3469332754611969\n",
      "Replaced token 2567 with corr 0.24958397448062897 with new token with corr 0.24958398938179016\n",
      "Replaced token 2575 with corr 0.23565296828746796 with new token with corr 0.23565298318862915\n",
      "Replaced token 2576 with corr 0.30937832593917847 with new token with corr 0.30937835574150085\n",
      "Replaced token 2577 with corr 0.3292635977268219 with new token with corr 0.3292636275291443\n",
      "Replaced token 2585 with corr 0.10871854424476624 with new token with corr 0.21969276666641235\n",
      "Replaced token 2588 with corr 0.37462306022644043 with new token with corr 0.3746230900287628\n",
      "Replaced token 2591 with corr 0.3005375564098358 with new token with corr 0.3005375862121582\n",
      "Replaced token 2600 with corr 0.3151289224624634 with new token with corr 0.31512895226478577\n",
      "Replaced token 2604 with corr 0.1071554645895958 with new token with corr 0.1581401377916336\n",
      "Replaced token 2613 with corr 0.22213396430015564 with new token with corr 0.22213397920131683\n",
      "Replaced token 2620 with corr 0.3044167757034302 with new token with corr 0.30441680550575256\n",
      "Replaced token 2622 with corr 0.3231833279132843 with new token with corr 0.3231833577156067\n",
      "Replaced token 2624 with corr 0.21197715401649475 with new token with corr 0.21197716891765594\n",
      "Replaced token 2626 with corr 0.36309394240379333 with new token with corr 0.3630939722061157\n",
      "Replaced token 2627 with corr 0.22445373237133026 with new token with corr 0.22445374727249146\n",
      "Replaced token 2636 with corr 0.3389224112033844 with new token with corr 0.3389224410057068\n",
      "Replaced token 2638 with corr 0.28874778747558594 with new token with corr 0.2887478172779083\n",
      "Replaced token 2643 with corr 0.22779209911823273 with new token with corr 0.22779211401939392\n",
      "Replaced token 2646 with corr 0.2831415832042694 with new token with corr 0.2831416130065918\n",
      "Replaced token 2647 with corr 0.08146478235721588 with new token with corr 0.20139718055725098\n",
      "Replaced token 2648 with corr 0.08135887235403061 with new token with corr 0.2486138641834259\n",
      "Replaced token 2656 with corr 0.288882315158844 with new token with corr 0.2888823449611664\n",
      "Replaced token 2669 with corr 0.11446455866098404 with new token with corr 0.14383286237716675\n",
      "Replaced token 2675 with corr 0.22170990705490112 with new token with corr 0.2217099368572235\n",
      "Replaced token 2679 with corr 0.23395337164402008 with new token with corr 0.23395338654518127\n",
      "Replaced token 2683 with corr 0.2795202136039734 with new token with corr 0.2795202434062958\n",
      "Replaced token 2685 with corr 0.24545852839946747 with new token with corr 0.24545854330062866\n",
      "Replaced token 2686 with corr 0.3059993088245392 with new token with corr 0.3059993386268616\n",
      "Replaced token 2695 with corr 0.08733444660902023 with new token with corr 0.16646850109100342\n",
      "Replaced token 2696 with corr 0.2886868417263031 with new token with corr 0.2886868715286255\n",
      "Replaced token 2700 with corr 0.29301440715789795 with new token with corr 0.29301443696022034\n",
      "Replaced token 2703 with corr 0.31509828567504883 with new token with corr 0.3150983154773712\n",
      "Replaced token 2705 with corr 0.3350941836833954 with new token with corr 0.3350942134857178\n",
      "Replaced token 2710 with corr 0.27330490946769714 with new token with corr 0.27330493927001953\n",
      "Replaced token 2712 with corr 0.07433526962995529 with new token with corr 0.24520720541477203\n",
      "Replaced token 2719 with corr 0.29515838623046875 with new token with corr 0.29515841603279114\n",
      "Replaced token 2720 with corr 0.10904086381196976 with new token with corr 0.14048784971237183\n",
      "Replaced token 2725 with corr 0.1429840624332428 with new token with corr 0.16428475081920624\n",
      "Replaced token 2726 with corr 0.3762853145599365 with new token with corr 0.3762853443622589\n",
      "Replaced token 2727 with corr 0.30653825402259827 with new token with corr 0.30653828382492065\n",
      "Replaced token 2728 with corr 0.2987440824508667 with new token with corr 0.2987441122531891\n",
      "Replaced token 2731 with corr 0.2891682982444763 with new token with corr 0.2891683280467987\n",
      "Replaced token 2733 with corr 0.3137187957763672 with new token with corr 0.3137188255786896\n",
      "Replaced token 2736 with corr 0.2876114845275879 with new token with corr 0.2876115143299103\n",
      "Replaced token 2738 with corr 0.33610138297080994 with new token with corr 0.3361014127731323\n",
      "Replaced token 2741 with corr 0.26017770171165466 with new token with corr 0.26017773151397705\n",
      "Replaced token 2745 with corr 0.3433434069156647 with new token with corr 0.34334343671798706\n",
      "Replaced token 2746 with corr 0.28039005398750305 with new token with corr 0.28039008378982544\n",
      "Replaced token 2747 with corr 0.3121562898159027 with new token with corr 0.3121563196182251\n",
      "Replaced token 2759 with corr 0.21919046342372894 with new token with corr 0.21919047832489014\n",
      "Replaced token 2763 with corr 0.29221922159194946 with new token with corr 0.29221925139427185\n",
      "Replaced token 2764 with corr 0.28300046920776367 with new token with corr 0.28300049901008606\n",
      "Replaced token 2766 with corr 0.2719041109085083 with new token with corr 0.2719041407108307\n",
      "Replaced token 2768 with corr 0.2699580788612366 with new token with corr 0.26995810866355896\n",
      "Replaced token 2770 with corr 0.31884586811065674 with new token with corr 0.3188458979129791\n",
      "Replaced token 2773 with corr 0.2733740210533142 with new token with corr 0.2733740508556366\n",
      "Replaced token 2775 with corr 0.30528005957603455 with new token with corr 0.30528008937835693\n",
      "Replaced token 2777 with corr 0.27249619364738464 with new token with corr 0.27249622344970703\n",
      "Replaced token 2781 with corr 0.29683902859687805 with new token with corr 0.29683905839920044\n",
      "Replaced token 2787 with corr 0.09799249470233917 with new token with corr 0.21334560215473175\n",
      "Replaced token 2791 with corr 0.16134113073349 with new token with corr 0.16563992202281952\n",
      "Replaced token 2794 with corr 0.2798250615596771 with new token with corr 0.2798250913619995\n",
      "Replaced token 2795 with corr 0.09221586585044861 with new token with corr 0.28454074263572693\n",
      "Replaced token 2796 with corr 0.23205003142356873 with new token with corr 0.23205004632472992\n",
      "Replaced token 2798 with corr 0.28555572032928467 with new token with corr 0.28555575013160706\n",
      "Replaced token 2802 with corr 0.10049636662006378 with new token with corr 0.27976542711257935\n",
      "Replaced token 2805 with corr 0.12199008464813232 with new token with corr 0.237598717212677\n",
      "Replaced token 2806 with corr 0.24868839979171753 with new token with corr 0.24868841469287872\n",
      "Replaced token 2811 with corr 0.3474056124687195 with new token with corr 0.34740564227104187\n",
      "Replaced token 2814 with corr 0.356563001871109 with new token with corr 0.3565630316734314\n",
      "Replaced token 2815 with corr 0.25072818994522095 with new token with corr 0.25072821974754333\n",
      "Replaced token 2828 with corr 0.08878589421510696 with new token with corr 0.29726266860961914\n",
      "Replaced token 2830 with corr 0.20165354013442993 with new token with corr 0.20165355503559113\n",
      "Replaced token 2844 with corr 0.2961461544036865 with new token with corr 0.2961462140083313\n",
      "Replaced token 2845 with corr 0.31345993280410767 with new token with corr 0.31345996260643005\n",
      "Replaced token 2850 with corr 0.33283042907714844 with new token with corr 0.3328304588794708\n",
      "Replaced token 2855 with corr 0.10787904262542725 with new token with corr 0.15284587442874908\n",
      "Replaced token 2856 with corr 0.08848107606172562 with new token with corr 0.17137888073921204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2857 with corr 0.26940762996673584 with new token with corr 0.2694076597690582\n",
      "Replaced token 2858 with corr 0.315197229385376 with new token with corr 0.31519725918769836\n",
      "Replaced token 2860 with corr 0.12482638657093048 with new token with corr 0.17887961864471436\n",
      "Replaced token 2861 with corr 0.292353093624115 with new token with corr 0.2923531234264374\n",
      "Replaced token 2863 with corr 0.438101202249527 with new token with corr 0.43810123205184937\n",
      "Replaced token 2865 with corr 0.2585780620574951 with new token with corr 0.2585780918598175\n",
      "Replaced token 2866 with corr 0.3156187832355499 with new token with corr 0.3156188130378723\n",
      "Replaced token 2868 with corr 0.131745383143425 with new token with corr 0.15329201519489288\n",
      "Replaced token 2870 with corr 0.09994734823703766 with new token with corr 0.16403447091579437\n",
      "Replaced token 2872 with corr 0.3249572515487671 with new token with corr 0.3249572813510895\n",
      "Replaced token 2879 with corr 0.3983750343322754 with new token with corr 0.3983750641345978\n",
      "Replaced token 2882 with corr 0.08526802062988281 with new token with corr 0.21527671813964844\n",
      "Replaced token 2883 with corr 0.10055611282587051 with new token with corr 0.23668323457241058\n",
      "Replaced token 2887 with corr 0.2743631601333618 with new token with corr 0.2743631899356842\n",
      "Replaced token 2897 with corr 0.27121278643608093 with new token with corr 0.2712128162384033\n",
      "Replaced token 2901 with corr 0.10089803487062454 with new token with corr 0.1897086352109909\n",
      "Replaced token 2903 with corr 0.24282129108905792 with new token with corr 0.24282130599021912\n",
      "Replaced token 2906 with corr 0.2285589724779129 with new token with corr 0.22855901718139648\n",
      "Replaced token 2911 with corr 0.1145368367433548 with new token with corr 0.22872769832611084\n",
      "Replaced token 2914 with corr 0.08962295949459076 with new token with corr 0.2755124270915985\n",
      "Replaced token 2915 with corr 0.30346038937568665 with new token with corr 0.30346041917800903\n",
      "Replaced token 2923 with corr 0.24916958808898926 with new token with corr 0.24916960299015045\n",
      "Replaced token 2926 with corr 0.0813339427113533 with new token with corr 0.1766229122877121\n",
      "Replaced token 2927 with corr 0.27954116463661194 with new token with corr 0.2795411944389343\n",
      "Replaced token 2928 with corr 0.3766881823539734 with new token with corr 0.3766882121562958\n",
      "Replaced token 2931 with corr 0.10793379694223404 with new token with corr 0.3027452528476715\n",
      "Replaced token 2932 with corr 0.12502598762512207 with new token with corr 0.1574915200471878\n",
      "Replaced token 2935 with corr 0.2991573214530945 with new token with corr 0.29915735125541687\n",
      "Replaced token 2939 with corr 0.3300201892852783 with new token with corr 0.3300202190876007\n",
      "Replaced token 2942 with corr 0.1250670999288559 with new token with corr 0.1625632345676422\n",
      "Replaced token 2943 with corr 0.12474377453327179 with new token with corr 0.2676112949848175\n",
      "Replaced token 2949 with corr 0.27767401933670044 with new token with corr 0.2776740491390228\n",
      "Replaced token 2950 with corr 0.34119388461112976 with new token with corr 0.34119391441345215\n",
      "Replaced token 2951 with corr 0.2833544611930847 with new token with corr 0.2833544909954071\n",
      "Replaced token 2957 with corr 0.3698638379573822 with new token with corr 0.3698638677597046\n",
      "Replaced token 2960 with corr 0.2776823937892914 with new token with corr 0.27768242359161377\n",
      "Replaced token 2962 with corr 0.08167469501495361 with new token with corr 0.15196111798286438\n",
      "Replaced token 2964 with corr 0.270112544298172 with new token with corr 0.2701125741004944\n",
      "Replaced token 2971 with corr 0.34566861391067505 with new token with corr 0.34566864371299744\n",
      "Replaced token 2976 with corr 0.10337535291910172 with new token with corr 0.1584203541278839\n",
      "Replaced token 2977 with corr 0.11099407821893692 with new token with corr 0.14886930584907532\n",
      "Replaced token 2978 with corr 0.3511083722114563 with new token with corr 0.3511084020137787\n",
      "Replaced token 2980 with corr 0.2454444319009781 with new token with corr 0.24544444680213928\n",
      "Replaced token 2984 with corr 0.2724500596523285 with new token with corr 0.2724500894546509\n",
      "Replaced token 2987 with corr 0.28480035066604614 with new token with corr 0.28480038046836853\n",
      "Replaced token 2991 with corr 0.3307269215583801 with new token with corr 0.3307269513607025\n",
      "Replaced token 2993 with corr 0.34381458163261414 with new token with corr 0.3438146114349365\n",
      "Replaced token 2997 with corr 0.2718154788017273 with new token with corr 0.2718155086040497\n",
      "Replaced token 3001 with corr 0.2549532651901245 with new token with corr 0.2549532949924469\n",
      "Replaced token 3009 with corr 0.29477500915527344 with new token with corr 0.2947750389575958\n",
      "Replaced token 3010 with corr 0.11868207156658173 with new token with corr 0.14755398035049438\n",
      "Replaced token 3011 with corr 0.2520068883895874 with new token with corr 0.2520069181919098\n",
      "Replaced token 3013 with corr 0.2870844304561615 with new token with corr 0.2870844602584839\n",
      "Replaced token 3020 with corr 0.36311015486717224 with new token with corr 0.36311018466949463\n",
      "Replaced token 3023 with corr 0.10768715292215347 with new token with corr 0.14940567314624786\n",
      "Replaced token 3025 with corr 0.24959178268909454 with new token with corr 0.24959179759025574\n",
      "Replaced token 3027 with corr 0.11195295304059982 with new token with corr 0.2836076021194458\n",
      "Replaced token 3028 with corr 0.2808561325073242 with new token with corr 0.2808561623096466\n",
      "Replaced token 3030 with corr 0.09112260490655899 with new token with corr 0.21726897358894348\n",
      "Replaced token 3031 with corr 0.1106770858168602 with new token with corr 0.1531311273574829\n",
      "Replaced token 3033 with corr 0.3275725841522217 with new token with corr 0.32757261395454407\n",
      "Replaced token 3034 with corr 0.4182170629501343 with new token with corr 0.41821709275245667\n",
      "Replaced token 3040 with corr 0.28191205859184265 with new token with corr 0.28191208839416504\n",
      "Replaced token 3041 with corr 0.3068418502807617 with new token with corr 0.3068418800830841\n",
      "Replaced token 3042 with corr 0.24207259714603424 with new token with corr 0.24207261204719543\n",
      "Replaced token 3043 with corr 0.23321692645549774 with new token with corr 0.23321694135665894\n",
      "Replaced token 3044 with corr 0.23700664937496185 with new token with corr 0.23700666427612305\n",
      "Replaced token 3045 with corr 0.23867835104465485 with new token with corr 0.23867838084697723\n",
      "Replaced token 3048 with corr 0.2929076850414276 with new token with corr 0.29290771484375\n",
      "Replaced token 3050 with corr 0.2967861592769623 with new token with corr 0.29678618907928467\n",
      "Replaced token 3054 with corr 0.1288672685623169 with new token with corr 0.23834443092346191\n",
      "Replaced token 3057 with corr 0.3907829225063324 with new token with corr 0.3907829523086548\n",
      "Replaced token 3061 with corr 0.2352861911058426 with new token with corr 0.23528620600700378\n",
      "Replaced token 3064 with corr 0.37461230158805847 with new token with corr 0.37461233139038086\n",
      "Replaced token 3067 with corr 0.30812907218933105 with new token with corr 0.30812910199165344\n",
      "Replaced token 3068 with corr 0.234377920627594 with new token with corr 0.2343779355287552\n",
      "Replaced token 3071 with corr 0.15201009809970856 with new token with corr 0.15590743720531464\n",
      "Replaced token 3072 with corr 0.26388198137283325 with new token with corr 0.26388201117515564\n",
      "Replaced token 3075 with corr 0.2823447585105896 with new token with corr 0.282344788312912\n",
      "Replaced token 3078 with corr 0.29426464438438416 with new token with corr 0.29426467418670654\n",
      "Replaced token 3080 with corr 0.32566526532173157 with new token with corr 0.32566529512405396\n",
      "Replaced token 3082 with corr 0.2627272307872772 with new token with corr 0.2627272605895996\n",
      "Replaced token 3087 with corr 0.25576937198638916 with new token with corr 0.25576940178871155\n",
      "Replaced token 3092 with corr 0.259738028049469 with new token with corr 0.2597380578517914\n",
      "Replaced token 3093 with corr 0.1469605416059494 with new token with corr 0.15437667071819305\n",
      "Replaced token 3094 with corr 0.10854519158601761 with new token with corr 0.30788329243659973\n",
      "Replaced token 3099 with corr 0.3271556794643402 with new token with corr 0.3271557092666626\n",
      "Replaced token 3100 with corr 0.36967575550079346 with new token with corr 0.36967578530311584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3104 with corr 0.23625992238521576 with new token with corr 0.23625995218753815\n",
      "Replaced token 3109 with corr 0.10213868319988251 with new token with corr 0.25648751854896545\n",
      "Replaced token 3113 with corr 0.3272770941257477 with new token with corr 0.32727712392807007\n",
      "Replaced token 3115 with corr 0.28083154559135437 with new token with corr 0.28083157539367676\n",
      "Replaced token 3116 with corr 0.2517532706260681 with new token with corr 0.2517533004283905\n",
      "Replaced token 3124 with corr 0.3495568335056305 with new token with corr 0.3495568633079529\n",
      "Replaced token 3127 with corr 0.0960758626461029 with new token with corr 0.15783217549324036\n",
      "Replaced token 3128 with corr 0.08161012083292007 with new token with corr 0.2301304042339325\n",
      "Replaced token 3129 with corr 0.29283106327056885 with new token with corr 0.29283109307289124\n",
      "Replaced token 3130 with corr 0.29544126987457275 with new token with corr 0.29544129967689514\n",
      "Replaced token 3131 with corr 0.2885768413543701 with new token with corr 0.2885768711566925\n",
      "Replaced token 3133 with corr 0.16447652876377106 with new token with corr 0.16447654366493225\n",
      "Replaced token 3143 with corr 0.08852166682481766 with new token with corr 0.19981727004051208\n",
      "Replaced token 3148 with corr 0.29916274547576904 with new token with corr 0.29916277527809143\n",
      "Replaced token 3150 with corr 0.2926345467567444 with new token with corr 0.2926345765590668\n",
      "Replaced token 3155 with corr 0.26042112708091736 with new token with corr 0.26042115688323975\n",
      "Replaced token 3161 with corr 0.2862318754196167 with new token with corr 0.2862319052219391\n",
      "Replaced token 3164 with corr 0.23847374320030212 with new token with corr 0.23847375810146332\n",
      "Replaced token 3166 with corr 0.09498576074838638 with new token with corr 0.24592570960521698\n",
      "Replaced token 3167 with corr 0.2365710437297821 with new token with corr 0.2365710586309433\n",
      "Replaced token 3168 with corr 0.30335816740989685 with new token with corr 0.30335819721221924\n",
      "Replaced token 3172 with corr 0.24573630094528198 with new token with corr 0.24573631584644318\n",
      "Replaced token 3174 with corr 0.3108856678009033 with new token with corr 0.3108856976032257\n",
      "Replaced token 3175 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 3179 with corr 0.2831222414970398 with new token with corr 0.2831222712993622\n",
      "Replaced token 3180 with corr 0.3295915126800537 with new token with corr 0.3295915424823761\n",
      "Replaced token 3189 with corr 0.29650354385375977 with new token with corr 0.29650357365608215\n",
      "Replaced token 3192 with corr 0.3444533050060272 with new token with corr 0.3444533348083496\n",
      "Replaced token 3194 with corr 0.453325480222702 with new token with corr 0.4533255100250244\n",
      "Replaced token 3201 with corr 0.2779083549976349 with new token with corr 0.2779083847999573\n",
      "Replaced token 3202 with corr 0.3136618137359619 with new token with corr 0.3136618435382843\n",
      "Replaced token 3204 with corr 0.1083015725016594 with new token with corr 0.20106463134288788\n",
      "Replaced token 3209 with corr 0.24372412264347076 with new token with corr 0.24372415244579315\n",
      "Replaced token 3211 with corr 0.1092938631772995 with new token with corr 0.22648459672927856\n",
      "Replaced token 3213 with corr 0.09117642790079117 with new token with corr 0.16049659252166748\n",
      "Replaced token 3216 with corr 0.28376346826553345 with new token with corr 0.28376349806785583\n",
      "Replaced token 3217 with corr 0.3282027542591095 with new token with corr 0.3282027840614319\n",
      "Replaced token 3221 with corr 0.07762452960014343 with new token with corr 0.2182246446609497\n",
      "Replaced token 3223 with corr 0.09327423572540283 with new token with corr 0.2611684203147888\n",
      "Replaced token 3224 with corr 0.11905615776777267 with new token with corr 0.16442018747329712\n",
      "Replaced token 3226 with corr 0.3848671317100525 with new token with corr 0.3848671615123749\n",
      "Replaced token 3227 with corr 0.24920257925987244 with new token with corr 0.24920259416103363\n",
      "Replaced token 3230 with corr 0.11070850491523743 with new token with corr 0.14476200938224792\n",
      "Replaced token 3240 with corr 0.2630290687084198 with new token with corr 0.2630290985107422\n",
      "Replaced token 3244 with corr 0.25187742710113525 with new token with corr 0.25187745690345764\n",
      "Replaced token 3247 with corr 0.28579631447792053 with new token with corr 0.2857963442802429\n",
      "Replaced token 3252 with corr 0.2223692089319229 with new token with corr 0.2223692238330841\n",
      "Replaced token 3254 with corr 0.26653262972831726 with new token with corr 0.26653265953063965\n",
      "Replaced token 3256 with corr 0.28583747148513794 with new token with corr 0.2858375012874603\n",
      "Replaced token 3261 with corr 0.29043564200401306 with new token with corr 0.29043567180633545\n",
      "Replaced token 3263 with corr 0.22814206779003143 with new token with corr 0.22814208269119263\n",
      "Replaced token 3265 with corr 0.19253109395503998 with new token with corr 0.19253110885620117\n",
      "Replaced token 3266 with corr 0.38574984669685364 with new token with corr 0.3857499063014984\n",
      "Replaced token 3267 with corr 0.27784493565559387 with new token with corr 0.27784496545791626\n",
      "Replaced token 3268 with corr 0.28589147329330444 with new token with corr 0.28589150309562683\n",
      "Replaced token 3271 with corr 0.21919046342372894 with new token with corr 0.21919047832489014\n",
      "Replaced token 3277 with corr 0.3158162832260132 with new token with corr 0.31581631302833557\n",
      "Replaced token 3279 with corr 0.24274340271949768 with new token with corr 0.24274341762065887\n",
      "Replaced token 3288 with corr 0.22772473096847534 with new token with corr 0.22772474586963654\n",
      "Replaced token 3295 with corr 0.31833773851394653 with new token with corr 0.3183377683162689\n",
      "Replaced token 3299 with corr 0.3242455720901489 with new token with corr 0.3242456018924713\n",
      "Replaced token 3300 with corr 0.25323137640953064 with new token with corr 0.253231406211853\n",
      "Replaced token 3301 with corr 0.24892164766788483 with new token with corr 0.24892166256904602\n",
      "Replaced token 3308 with corr 0.10283837467432022 with new token with corr 0.23205004632472992\n",
      "Replaced token 3310 with corr 0.29347941279411316 with new token with corr 0.29347947239875793\n",
      "Replaced token 3315 with corr 0.2544754147529602 with new token with corr 0.2544754445552826\n",
      "Replaced token 3326 with corr 0.2679224908351898 with new token with corr 0.2679225504398346\n",
      "Replaced token 3329 with corr 0.1003747284412384 with new token with corr 0.14953385293483734\n",
      "Replaced token 3332 with corr 0.3463469445705414 with new token with corr 0.34634697437286377\n",
      "Replaced token 3334 with corr 0.2138420045375824 with new token with corr 0.2138420194387436\n",
      "Replaced token 3335 with corr 0.08474868535995483 with new token with corr 0.260865181684494\n",
      "Replaced token 3340 with corr 0.08995696157217026 with new token with corr 0.29117822647094727\n",
      "Replaced token 3343 with corr 0.105535127222538 with new token with corr 0.14037670195102692\n",
      "Replaced token 3344 with corr 0.07471393793821335 with new token with corr 0.20954430103302002\n",
      "Replaced token 3345 with corr 0.29006427526474 with new token with corr 0.2900643050670624\n",
      "Replaced token 3350 with corr 0.29346543550491333 with new token with corr 0.2934654653072357\n",
      "Replaced token 3351 with corr 0.4293423295021057 with new token with corr 0.4293423593044281\n",
      "Replaced token 3356 with corr 0.29481756687164307 with new token with corr 0.29481759667396545\n",
      "Replaced token 3357 with corr 0.29271432757377625 with new token with corr 0.29271435737609863\n",
      "Replaced token 3358 with corr 0.20528152585029602 with new token with corr 0.20528154075145721\n",
      "Replaced token 3360 with corr 0.2765789330005646 with new token with corr 0.27657899260520935\n",
      "Replaced token 3364 with corr 0.1469879299402237 with new token with corr 0.1714986264705658\n",
      "Replaced token 3369 with corr 0.2808833718299866 with new token with corr 0.28088340163230896\n",
      "Replaced token 3370 with corr 0.10360986739397049 with new token with corr 0.14797066152095795\n",
      "Replaced token 3381 with corr 0.26085951924324036 with new token with corr 0.26085954904556274\n",
      "Replaced token 3386 with corr 0.2921977639198303 with new token with corr 0.2921977937221527\n",
      "Replaced token 3388 with corr 0.3408615291118622 with new token with corr 0.34086155891418457\n",
      "Replaced token 3395 with corr 0.34285715222358704 with new token with corr 0.3428571820259094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3400 with corr 0.2829861640930176 with new token with corr 0.28298619389533997\n",
      "Replaced token 3402 with corr 0.09207748621702194 with new token with corr 0.20862500369548798\n",
      "Replaced token 3406 with corr 0.2703394591808319 with new token with corr 0.2703394889831543\n",
      "Replaced token 3407 with corr 0.2691522538661957 with new token with corr 0.26915228366851807\n",
      "Replaced token 3411 with corr 0.2059486359357834 with new token with corr 0.20594865083694458\n",
      "Replaced token 3413 with corr 0.07762213796377182 with new token with corr 0.1717095524072647\n",
      "Replaced token 3415 with corr 0.11113911122083664 with new token with corr 0.23568634688854218\n",
      "Replaced token 3419 with corr 0.29395318031311035 with new token with corr 0.29395321011543274\n",
      "Replaced token 3423 with corr 0.27556470036506653 with new token with corr 0.2755647301673889\n",
      "Replaced token 3425 with corr 0.35973069071769714 with new token with corr 0.35973072052001953\n",
      "Replaced token 3427 with corr 0.3255400061607361 with new token with corr 0.32554003596305847\n",
      "Replaced token 3431 with corr 0.3253590762615204 with new token with corr 0.3253591060638428\n",
      "Replaced token 3438 with corr 0.2319849580526352 with new token with corr 0.23198498785495758\n",
      "Replaced token 3439 with corr 0.3096863925457001 with new token with corr 0.30968642234802246\n",
      "Replaced token 3446 with corr 0.2503245770931244 with new token with corr 0.2503246068954468\n",
      "Replaced token 3451 with corr 0.09928575158119202 with new token with corr 0.2579036355018616\n",
      "Replaced token 3452 with corr 0.17020653188228607 with new token with corr 0.17020654678344727\n",
      "Replaced token 3459 with corr 0.30984213948249817 with new token with corr 0.30984216928482056\n",
      "Replaced token 3460 with corr 0.31040042638778687 with new token with corr 0.31040048599243164\n",
      "Replaced token 3464 with corr 0.1866806149482727 with new token with corr 0.1866806298494339\n",
      "Replaced token 3468 with corr 0.3440774083137512 with new token with corr 0.3440774381160736\n",
      "Replaced token 3471 with corr 0.11550285667181015 with new token with corr 0.14842289686203003\n",
      "Replaced token 3473 with corr 0.27944424748420715 with new token with corr 0.27944427728652954\n",
      "Replaced token 3479 with corr 0.09774256497621536 with new token with corr 0.18581438064575195\n",
      "Replaced token 3480 with corr 0.11261890828609467 with new token with corr 0.23385603725910187\n",
      "Replaced token 3481 with corr 0.33475708961486816 with new token with corr 0.33475711941719055\n",
      "Replaced token 3482 with corr 0.3755998909473419 with new token with corr 0.3755999207496643\n",
      "Replaced token 3485 with corr 0.27529609203338623 with new token with corr 0.2752961218357086\n",
      "Replaced token 3486 with corr 0.094296395778656 with new token with corr 0.26696982979774475\n",
      "Replaced token 3490 with corr 0.33829620480537415 with new token with corr 0.33829623460769653\n",
      "Replaced token 3491 with corr 0.3370090425014496 with new token with corr 0.337009072303772\n",
      "Replaced token 3495 with corr 0.31919530034065247 with new token with corr 0.31919533014297485\n",
      "Replaced token 3496 with corr 0.3248361051082611 with new token with corr 0.3248361349105835\n",
      "Replaced token 3500 with corr 0.34244292974472046 with new token with corr 0.34244295954704285\n",
      "Replaced token 3501 with corr 0.30752602219581604 with new token with corr 0.3075260818004608\n",
      "Replaced token 3503 with corr 0.2514297068119049 with new token with corr 0.2514297366142273\n",
      "Replaced token 3504 with corr 0.10243967920541763 with new token with corr 0.21259687840938568\n",
      "Replaced token 3508 with corr 0.11241219192743301 with new token with corr 0.3117140233516693\n",
      "Replaced token 3512 with corr 0.2211863249540329 with new token with corr 0.2211863398551941\n",
      "Replaced token 3513 with corr 0.2549532651901245 with new token with corr 0.2549532949924469\n",
      "Replaced token 3515 with corr 0.30516645312309265 with new token with corr 0.30516648292541504\n",
      "Replaced token 3519 with corr 0.24301661550998688 with new token with corr 0.24301664531230927\n",
      "Replaced token 3522 with corr 0.11608175188302994 with new token with corr 0.2361796647310257\n",
      "Replaced token 3524 with corr 0.31571459770202637 with new token with corr 0.31571462750434875\n",
      "Replaced token 3532 with corr 0.36311015486717224 with new token with corr 0.36311018466949463\n",
      "Replaced token 3533 with corr 0.3277008831501007 with new token with corr 0.3277009129524231\n",
      "Replaced token 3534 with corr 0.333200603723526 with new token with corr 0.3332006335258484\n",
      "Replaced token 3537 with corr 0.1282229721546173 with new token with corr 0.25225773453712463\n",
      "Replaced token 3540 with corr 0.0735185369849205 with new token with corr 0.18384917080402374\n",
      "Replaced token 3543 with corr 0.3055879771709442 with new token with corr 0.3055880069732666\n",
      "Replaced token 3547 with corr 0.12320207059383392 with new token with corr 0.2969287633895874\n",
      "Replaced token 3554 with corr 0.11856120079755783 with new token with corr 0.20777767896652222\n",
      "Replaced token 3555 with corr 0.2724015414714813 with new token with corr 0.2724015712738037\n",
      "Replaced token 3556 with corr 0.31979644298553467 with new token with corr 0.31979647278785706\n",
      "Replaced token 3559 with corr 0.28880438208580017 with new token with corr 0.28880441188812256\n",
      "Replaced token 3562 with corr 0.30466076731681824 with new token with corr 0.3046607971191406\n",
      "Replaced token 3564 with corr 0.36595234274864197 with new token with corr 0.36595237255096436\n",
      "Replaced token 3565 with corr 0.07344812899827957 with new token with corr 0.14897918701171875\n",
      "Replaced token 3566 with corr 0.3263932764530182 with new token with corr 0.3263933062553406\n",
      "Replaced token 3567 with corr 0.2530454695224762 with new token with corr 0.2530454993247986\n",
      "Replaced token 3569 with corr 0.3907829225063324 with new token with corr 0.3907829523086548\n",
      "Replaced token 3572 with corr 0.289568692445755 with new token with corr 0.2895687222480774\n",
      "Replaced token 3573 with corr 0.0852590948343277 with new token with corr 0.22231847047805786\n",
      "Replaced token 3575 with corr 0.2611331343650818 with new token with corr 0.2611331641674042\n",
      "Replaced token 3578 with corr 0.3398708999156952 with new token with corr 0.3398709297180176\n",
      "Replaced token 3579 with corr 0.30557534098625183 with new token with corr 0.3055753707885742\n",
      "Replaced token 3583 with corr 0.07468339055776596 with new token with corr 0.15685757994651794\n",
      "Replaced token 3584 with corr 0.27081048488616943 with new token with corr 0.2708105146884918\n",
      "Replaced token 3586 with corr 0.20032626390457153 with new token with corr 0.20032627880573273\n",
      "Replaced token 3587 with corr 0.32366257905960083 with new token with corr 0.3236626088619232\n",
      "Replaced token 3592 with corr 0.30893826484680176 with new token with corr 0.30893829464912415\n",
      "Replaced token 3593 with corr 0.12260448932647705 with new token with corr 0.15267544984817505\n",
      "Replaced token 3595 with corr 0.18890498578548431 with new token with corr 0.1889050006866455\n",
      "Replaced token 3597 with corr 0.2716728746891022 with new token with corr 0.27167290449142456\n",
      "Replaced token 3600 with corr 0.3088518977165222 with new token with corr 0.3088519275188446\n",
      "Replaced token 3605 with corr 0.15743738412857056 with new token with corr 0.24347980320453644\n",
      "Replaced token 3606 with corr 0.2864311635494232 with new token with corr 0.2864311933517456\n",
      "Replaced token 3608 with corr 0.3225267231464386 with new token with corr 0.322526752948761\n",
      "Replaced token 3609 with corr 0.22058506309986115 with new token with corr 0.22058507800102234\n",
      "Replaced token 3611 with corr 0.1045120358467102 with new token with corr 0.2583322823047638\n",
      "Replaced token 3617 with corr 0.11635561287403107 with new token with corr 0.21962647140026093\n",
      "Replaced token 3622 with corr 0.11626020818948746 with new token with corr 0.15774716436862946\n",
      "Replaced token 3623 with corr 0.09608295559883118 with new token with corr 0.20783036947250366\n",
      "Replaced token 3627 with corr 0.286204993724823 with new token with corr 0.2862050235271454\n",
      "Replaced token 3631 with corr 0.07907850295305252 with new token with corr 0.1806187927722931\n",
      "Replaced token 3638 with corr 0.07013028860092163 with new token with corr 0.1800089031457901\n",
      "Replaced token 3640 with corr 0.25649890303611755 with new token with corr 0.25649893283843994\n",
      "Replaced token 3648 with corr 0.27515286207199097 with new token with corr 0.27515289187431335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3649 with corr 0.22985851764678955 with new token with corr 0.22985853254795074\n",
      "Replaced token 3662 with corr 0.2992486357688904 with new token with corr 0.29924866557121277\n",
      "Replaced token 3667 with corr 0.10379547625780106 with new token with corr 0.2801976799964905\n",
      "Replaced token 3669 with corr 0.07176963239908218 with new token with corr 0.2982428967952728\n",
      "Replaced token 3670 with corr 0.06947410106658936 with new token with corr 0.32409781217575073\n",
      "Replaced token 3673 with corr 0.11199440062046051 with new token with corr 0.21503151953220367\n",
      "Replaced token 3674 with corr 0.1082954853773117 with new token with corr 0.34233036637306213\n",
      "Replaced token 3675 with corr 0.2199246734380722 with new token with corr 0.2199247032403946\n",
      "Replaced token 3677 with corr 0.22673791646957397 with new token with corr 0.22673793137073517\n",
      "Replaced token 3678 with corr 0.2712607681751251 with new token with corr 0.2712607979774475\n",
      "Replaced token 3679 with corr 0.08759612590074539 with new token with corr 0.23954784870147705\n",
      "Replaced token 3680 with corr 0.22838318347930908 with new token with corr 0.22838319838047028\n",
      "Replaced token 3683 with corr 0.213851198554039 with new token with corr 0.2138512134552002\n",
      "Replaced token 3685 with corr 0.31199219822883606 with new token with corr 0.31199222803115845\n",
      "Replaced token 3687 with corr 0.2618323266506195 with new token with corr 0.2618323564529419\n",
      "Replaced token 3698 with corr 0.29189616441726685 with new token with corr 0.29189619421958923\n",
      "Replaced token 3699 with corr 0.3371712267398834 with new token with corr 0.3371712565422058\n",
      "Replaced token 3700 with corr 0.30257919430732727 with new token with corr 0.30257922410964966\n",
      "Replaced token 3701 with corr 0.13045057654380798 with new token with corr 0.25759297609329224\n",
      "Replaced token 3708 with corr 0.13221634924411774 with new token with corr 0.26396578550338745\n",
      "Replaced token 3712 with corr 0.3150036036968231 with new token with corr 0.3150036334991455\n",
      "Replaced token 3713 with corr 0.0684177502989769 with new token with corr 0.2262493073940277\n",
      "Replaced token 3714 with corr 0.28491851687431335 with new token with corr 0.28491854667663574\n",
      "Replaced token 3717 with corr 0.24160708487033844 with new token with corr 0.24160709977149963\n",
      "Replaced token 3722 with corr 0.28074005246162415 with new token with corr 0.28074008226394653\n",
      "Replaced token 3723 with corr 0.17644144594669342 with new token with corr 0.17644146084785461\n",
      "Replaced token 3726 with corr 0.28484246134757996 with new token with corr 0.28484249114990234\n",
      "Replaced token 3727 with corr 0.12891528010368347 with new token with corr 0.24917134642601013\n",
      "Replaced token 3728 with corr 0.34511834383010864 with new token with corr 0.34511837363243103\n",
      "Replaced token 3735 with corr 0.11797637492418289 with new token with corr 0.2217080146074295\n",
      "Replaced token 3736 with corr 0.09470909088850021 with new token with corr 0.21329985558986664\n",
      "Replaced token 3737 with corr 0.1390988528728485 with new token with corr 0.2615695893764496\n",
      "Replaced token 3738 with corr 0.368228554725647 with new token with corr 0.36822858452796936\n",
      "Replaced token 3741 with corr 0.31349262595176697 with new token with corr 0.31349265575408936\n",
      "Replaced token 3744 with corr 0.0792054533958435 with new token with corr 0.2511129677295685\n",
      "Replaced token 3745 with corr 0.27606096863746643 with new token with corr 0.2760609984397888\n",
      "Replaced token 3746 with corr 0.3110803961753845 with new token with corr 0.3110804259777069\n",
      "Replaced token 3749 with corr 0.3582928776741028 with new token with corr 0.35829293727874756\n",
      "Replaced token 3751 with corr 0.08053730428218842 with new token with corr 0.14904911816120148\n",
      "Replaced token 3753 with corr 0.25094637274742126 with new token with corr 0.25094640254974365\n",
      "Replaced token 3756 with corr 0.2998099625110626 with new token with corr 0.299809992313385\n",
      "Replaced token 3757 with corr 0.30794578790664673 with new token with corr 0.3079458177089691\n",
      "Replaced token 3759 with corr 0.23770661652088165 with new token with corr 0.23770663142204285\n",
      "Replaced token 3760 with corr 0.12319856882095337 with new token with corr 0.16508053243160248\n",
      "Replaced token 3778 with corr 0.3226352035999298 with new token with corr 0.3226352334022522\n",
      "Replaced token 3781 with corr 0.31788691878318787 with new token with corr 0.31788694858551025\n",
      "Replaced token 3783 with corr 0.30310800671577454 with new token with corr 0.3031080365180969\n",
      "Replaced token 3785 with corr 0.08235035091638565 with new token with corr 0.19586622714996338\n",
      "Replaced token 3794 with corr 0.0956580862402916 with new token with corr 0.2699718177318573\n",
      "Replaced token 3806 with corr 0.10203952342271805 with new token with corr 0.1528431475162506\n",
      "Replaced token 3807 with corr 0.2185843586921692 with new token with corr 0.21858437359333038\n",
      "Replaced token 3810 with corr 0.29574814438819885 with new token with corr 0.29574817419052124\n",
      "Replaced token 3811 with corr 0.26074203848838806 with new token with corr 0.26074206829071045\n",
      "Replaced token 3813 with corr 0.2026224136352539 with new token with corr 0.2026224285364151\n",
      "Replaced token 3817 with corr 0.19687430560588837 with new token with corr 0.19687432050704956\n",
      "Replaced token 3818 with corr 0.1288331151008606 with new token with corr 0.23295429348945618\n",
      "Replaced token 3822 with corr 0.16054946184158325 with new token with corr 0.16640932857990265\n",
      "Replaced token 3836 with corr 0.3122139573097229 with new token with corr 0.3122139871120453\n",
      "Replaced token 3839 with corr 0.31149816513061523 with new token with corr 0.3114981949329376\n",
      "Replaced token 3841 with corr 0.09109344333410263 with new token with corr 0.1467636376619339\n",
      "Replaced token 3843 with corr 0.09166190773248672 with new token with corr 0.2591124176979065\n",
      "Replaced token 3849 with corr 0.10936854779720306 with new token with corr 0.26489901542663574\n",
      "Replaced token 3850 with corr 0.1962175965309143 with new token with corr 0.1962176114320755\n",
      "Replaced token 3851 with corr 0.10035465657711029 with new token with corr 0.22951041162014008\n",
      "Replaced token 3855 with corr 0.3065687119960785 with new token with corr 0.3065687417984009\n",
      "Replaced token 3859 with corr 0.2793242037296295 with new token with corr 0.2793242335319519\n",
      "Replaced token 3865 with corr 0.28816232085227966 with new token with corr 0.28816235065460205\n",
      "Replaced token 3867 with corr 0.2714402377605438 with new token with corr 0.2714402675628662\n",
      "Replaced token 3871 with corr 0.11843269318342209 with new token with corr 0.2503451406955719\n",
      "Replaced token 3872 with corr 0.11060427874326706 with new token with corr 0.2391880452632904\n",
      "Replaced token 3875 with corr 0.09328150004148483 with new token with corr 0.15586718916893005\n",
      "Replaced token 3878 with corr 0.24014481902122498 with new token with corr 0.24014483392238617\n",
      "Replaced token 3879 with corr 0.32275980710983276 with new token with corr 0.32275983691215515\n",
      "Replaced token 3881 with corr 0.2822769284248352 with new token with corr 0.2822769582271576\n",
      "Replaced token 3882 with corr 0.21127139031887054 with new token with corr 0.21127142012119293\n",
      "Replaced token 3885 with corr 0.0908476859331131 with new token with corr 0.2347525656223297\n",
      "Replaced token 3886 with corr 0.3676784932613373 with new token with corr 0.36767852306365967\n",
      "Replaced token 3894 with corr 0.2583465874195099 with new token with corr 0.2583466172218323\n",
      "Replaced token 3896 with corr 0.27649036049842834 with new token with corr 0.27649039030075073\n",
      "Replaced token 3901 with corr 0.3046897053718567 with new token with corr 0.3046897351741791\n",
      "Replaced token 3911 with corr 0.2971383035182953 with new token with corr 0.2971383333206177\n",
      "Replaced token 3914 with corr 0.08463185280561447 with new token with corr 0.15947912633419037\n",
      "Replaced token 3917 with corr 0.260009229183197 with new token with corr 0.2600092589855194\n",
      "Replaced token 3919 with corr 0.2223779410123825 with new token with corr 0.2223779559135437\n",
      "Replaced token 3923 with corr 0.09905815124511719 with new token with corr 0.14535480737686157\n",
      "Replaced token 3926 with corr 0.12426407635211945 with new token with corr 0.23572112619876862\n",
      "Replaced token 3928 with corr 0.09814780950546265 with new token with corr 0.2512640953063965\n",
      "Replaced token 3933 with corr 0.10581307113170624 with new token with corr 0.2439889907836914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3934 with corr 0.2730863690376282 with new token with corr 0.27308639883995056\n",
      "Replaced token 3939 with corr 0.3400017321109772 with new token with corr 0.34000176191329956\n",
      "Replaced token 3940 with corr 0.31847232580184937 with new token with corr 0.31847235560417175\n",
      "Replaced token 3943 with corr 0.22393035888671875 with new token with corr 0.22393038868904114\n",
      "Replaced token 3946 with corr 0.11236857622861862 with new token with corr 0.18822109699249268\n",
      "Replaced token 3948 with corr 0.10665471851825714 with new token with corr 0.25099965929985046\n",
      "Replaced token 3952 with corr 0.25153911113739014 with new token with corr 0.2515391409397125\n",
      "Replaced token 3957 with corr 0.11053760349750519 with new token with corr 0.1511632204055786\n",
      "Replaced token 3960 with corr 0.08955783396959305 with new token with corr 0.23699374496936798\n",
      "Replaced token 3963 with corr 0.2612976133823395 with new token with corr 0.26129764318466187\n",
      "Replaced token 3966 with corr 0.27225229144096375 with new token with corr 0.27225232124328613\n",
      "Replaced token 3967 with corr 0.26212045550346375 with new token with corr 0.26212048530578613\n",
      "Replaced token 3974 with corr 0.2794153690338135 with new token with corr 0.27941539883613586\n",
      "Replaced token 3975 with corr 0.22887475788593292 with new token with corr 0.2288747876882553\n",
      "Replaced token 3977 with corr 0.1248236894607544 with new token with corr 0.22677119076251984\n",
      "Replaced token 3978 with corr 0.268280953168869 with new token with corr 0.2682809829711914\n",
      "Replaced token 3979 with corr 0.09531667828559875 with new token with corr 0.2902751863002777\n",
      "Replaced token 3985 with corr 0.24149920046329498 with new token with corr 0.24149921536445618\n",
      "Replaced token 3987 with corr 0.09578265994787216 with new token with corr 0.18374766409397125\n",
      "Replaced token 3991 with corr 0.15551899373531342 with new token with corr 0.1657889187335968\n",
      "Replaced token 3992 with corr 0.20836299657821655 with new token with corr 0.20836301147937775\n",
      "Replaced token 3993 with corr 0.2797645926475525 with new token with corr 0.2797646224498749\n",
      "Replaced token 3994 with corr 0.24389046430587769 with new token with corr 0.24389047920703888\n",
      "Replaced token 4000 with corr 0.33340635895729065 with new token with corr 0.33340638875961304\n",
      "Replaced token 4004 with corr 0.22926998138427734 with new token with corr 0.22926999628543854\n",
      "Replaced token 4007 with corr 0.10252664983272552 with new token with corr 0.25471606850624084\n",
      "Replaced token 4010 with corr 0.14443473517894745 with new token with corr 0.1491142064332962\n",
      "Replaced token 4011 with corr 0.2663796842098236 with new token with corr 0.266379714012146\n",
      "Replaced token 4013 with corr 0.33399727940559387 with new token with corr 0.33399730920791626\n",
      "Replaced token 4022 with corr 0.10040204226970673 with new token with corr 0.21668174862861633\n",
      "Replaced token 4023 with corr 0.0731392577290535 with new token with corr 0.1712467074394226\n",
      "Replaced token 4024 with corr 0.11364530771970749 with new token with corr 0.14999864995479584\n",
      "Replaced token 4028 with corr 0.32219424843788147 with new token with corr 0.32219427824020386\n",
      "Replaced token 4029 with corr 0.2838289737701416 with new token with corr 0.283829003572464\n",
      "Replaced token 4032 with corr 0.10857785493135452 with new token with corr 0.20799802243709564\n",
      "Replaced token 4040 with corr 0.260603129863739 with new token with corr 0.2606031596660614\n",
      "Replaced token 4041 with corr 0.10823719203472137 with new token with corr 0.2075950801372528\n",
      "Replaced token 4048 with corr 0.2773479223251343 with new token with corr 0.27734795212745667\n",
      "Replaced token 4058 with corr 0.20751427114009857 with new token with corr 0.20751428604125977\n",
      "Replaced token 4063 with corr 0.2786915898323059 with new token with corr 0.2786916196346283\n",
      "Replaced token 4064 with corr 0.25259047746658325 with new token with corr 0.25259050726890564\n",
      "Replaced token 4072 with corr 0.2954484224319458 with new token with corr 0.2954484820365906\n",
      "Replaced token 4081 with corr 0.09662853181362152 with new token with corr 0.19235314428806305\n",
      "Replaced token 4082 with corr 0.358834832906723 with new token with corr 0.3588348627090454\n",
      "Replaced token 4087 with corr 0.2609933912754059 with new token with corr 0.26099342107772827\n",
      "Replaced token 4095 with corr 0.0721680223941803 with new token with corr 0.14965713024139404\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.9009 | S-BLEU: 0.76 | FMSE: 2.7284e-03 | \n",
      " G-BLEU: 0.73 | ROUGE1: 0.89| ROUGE2: 0.77 | ROUGE-L: 0.87| Token Acc: 92.48% | Label Acc: 92.48%\n",
      "Evaluating dynamic-threshold with 10\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 486, 438, 492, 512, 483, 491, 480] breached embeddings to each sentence.\n",
      "Replaced token 0 with corr 0.29624322056770325 with new token with corr 0.29624319076538086\n",
      "Replaced token 1 with corr 0.2674526274204254 with new token with corr 0.2674526572227478\n",
      "Replaced token 2 with corr 0.32132819294929504 with new token with corr 0.32132816314697266\n",
      "Replaced token 3 with corr 0.2759050130844116 with new token with corr 0.2759050130844116\n",
      "Replaced token 4 with corr 0.2886787950992584 with new token with corr 0.28867876529693604\n",
      "Replaced token 5 with corr 0.30465278029441833 with new token with corr 0.30465278029441833\n",
      "Replaced token 6 with corr 0.31131818890571594 with new token with corr 0.31131815910339355\n",
      "Replaced token 7 with corr 0.2531171143054962 with new token with corr 0.2531171143054962\n",
      "Replaced token 8 with corr 0.3138507008552551 with new token with corr 0.3138507008552551\n",
      "Replaced token 9 with corr 0.36500394344329834 with new token with corr 0.3650040030479431\n",
      "Replaced token 10 with corr 0.286239355802536 with new token with corr 0.2862393856048584\n",
      "Replaced token 11 with corr 0.2655238211154938 with new token with corr 0.26552385091781616\n",
      "Replaced token 12 with corr 0.2820606529712677 with new token with corr 0.2820606231689453\n",
      "Replaced token 13 with corr 0.2789810299873352 with new token with corr 0.2789810001850128\n",
      "Replaced token 14 with corr 0.25167837738990784 with new token with corr 0.25167837738990784\n",
      "Replaced token 15 with corr 0.302579790353775 with new token with corr 0.30257976055145264\n",
      "Replaced token 16 with corr 0.26422610878944397 with new token with corr 0.26422610878944397\n",
      "Replaced token 17 with corr 0.35594505071640015 with new token with corr 0.35594505071640015\n",
      "Replaced token 18 with corr 0.35280272364616394 with new token with corr 0.35280272364616394\n",
      "Replaced token 19 with corr 0.3014914095401764 with new token with corr 0.3014914095401764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 20 with corr 0.38110509514808655 with new token with corr 0.38110509514808655\n",
      "Replaced token 21 with corr 0.2663831412792206 with new token with corr 0.2663831114768982\n",
      "Replaced token 22 with corr 0.3186632990837097 with new token with corr 0.3186633288860321\n",
      "Replaced token 23 with corr 0.35727444291114807 with new token with corr 0.35727444291114807\n",
      "Replaced token 24 with corr 0.2962983548641205 with new token with corr 0.2962983250617981\n",
      "Replaced token 25 with corr 0.2401648610830307 with new token with corr 0.2401648461818695\n",
      "Replaced token 26 with corr 0.2536568343639374 with new token with corr 0.2536568343639374\n",
      "Replaced token 27 with corr 0.292405903339386 with new token with corr 0.2924059331417084\n",
      "Replaced token 28 with corr 0.35538339614868164 with new token with corr 0.35538342595100403\n",
      "Replaced token 29 with corr 0.2693294584751129 with new token with corr 0.2693294584751129\n",
      "Replaced token 30 with corr 0.27067065238952637 with new token with corr 0.27067065238952637\n",
      "Replaced token 31 with corr 0.27955687046051025 with new token with corr 0.27955684065818787\n",
      "Replaced token 32 with corr 0.10004569590091705 with new token with corr 0.27175667881965637\n",
      "Replaced token 33 with corr 0.294013112783432 with new token with corr 0.294013112783432\n",
      "Replaced token 34 with corr 0.28006353974342346 with new token with corr 0.28006353974342346\n",
      "Replaced token 35 with corr 0.28012433648109436 with new token with corr 0.280124306678772\n",
      "Replaced token 36 with corr 0.3043040335178375 with new token with corr 0.3043040335178375\n",
      "Replaced token 37 with corr 0.34061217308044434 with new token with corr 0.3406122028827667\n",
      "Replaced token 38 with corr 0.29537785053253174 with new token with corr 0.2953778803348541\n",
      "Replaced token 39 with corr 0.3105590343475342 with new token with corr 0.31055909395217896\n",
      "Replaced token 40 with corr 0.4822520315647125 with new token with corr 0.4822520315647125\n",
      "Replaced token 41 with corr 0.4248204827308655 with new token with corr 0.4248204827308655\n",
      "Replaced token 42 with corr 0.27460500597953796 with new token with corr 0.27460500597953796\n",
      "Replaced token 43 with corr 0.324539452791214 with new token with corr 0.3245394825935364\n",
      "Replaced token 44 with corr 0.3220812976360321 with new token with corr 0.3220813274383545\n",
      "Replaced token 45 with corr 0.3304389417171478 with new token with corr 0.3304389417171478\n",
      "Replaced token 46 with corr 0.2990463078022003 with new token with corr 0.2990463078022003\n",
      "Replaced token 47 with corr 0.23986060917377472 with new token with corr 0.23986060917377472\n",
      "Replaced token 48 with corr 0.2638159394264221 with new token with corr 0.2638159394264221\n",
      "Replaced token 49 with corr 0.3503080904483795 with new token with corr 0.3503080904483795\n",
      "Replaced token 50 with corr 0.2647840678691864 with new token with corr 0.2647840678691864\n",
      "Replaced token 51 with corr 0.31363189220428467 with new token with corr 0.3136318325996399\n",
      "Replaced token 52 with corr 0.44501566886901855 with new token with corr 0.44501563906669617\n",
      "Replaced token 53 with corr 0.34674179553985596 with new token with corr 0.34674179553985596\n",
      "Replaced token 54 with corr 0.2860049903392792 with new token with corr 0.2860049903392792\n",
      "Replaced token 55 with corr 0.36838212609291077 with new token with corr 0.36838212609291077\n",
      "Replaced token 56 with corr 0.2558310925960541 with new token with corr 0.2558310925960541\n",
      "Replaced token 57 with corr 0.31859737634658813 with new token with corr 0.31859737634658813\n",
      "Replaced token 58 with corr 0.12161212414503098 with new token with corr 0.3063763380050659\n",
      "Replaced token 59 with corr 0.3172111213207245 with new token with corr 0.3172111213207245\n",
      "Replaced token 60 with corr 0.37360090017318726 with new token with corr 0.3736008405685425\n",
      "Replaced token 61 with corr 0.13545501232147217 with new token with corr 0.15473876893520355\n",
      "Replaced token 62 with corr 0.30940836668014526 with new token with corr 0.30940836668014526\n",
      "Replaced token 63 with corr 0.2848348021507263 with new token with corr 0.28483477234840393\n",
      "Replaced token 64 with corr 0.2645499110221863 with new token with corr 0.2645499110221863\n",
      "Replaced token 65 with corr 0.28844326734542847 with new token with corr 0.28844326734542847\n",
      "Replaced token 66 with corr 0.36722037196159363 with new token with corr 0.367220401763916\n",
      "Replaced token 67 with corr 0.3570467531681061 with new token with corr 0.3570467531681061\n",
      "Replaced token 68 with corr 0.30278632044792175 with new token with corr 0.30278629064559937\n",
      "Replaced token 69 with corr 0.30092737078666687 with new token with corr 0.30092737078666687\n",
      "Replaced token 70 with corr 0.25429877638816833 with new token with corr 0.25429874658584595\n",
      "Replaced token 71 with corr 0.2785690724849701 with new token with corr 0.2785690426826477\n",
      "Replaced token 72 with corr 0.229422926902771 with new token with corr 0.2294229418039322\n",
      "Replaced token 73 with corr 0.2785085141658783 with new token with corr 0.2785085439682007\n",
      "Replaced token 74 with corr 0.31562429666519165 with new token with corr 0.31562432646751404\n",
      "Replaced token 75 with corr 0.2960885167121887 with new token with corr 0.29608848690986633\n",
      "Replaced token 76 with corr 0.2863181531429291 with new token with corr 0.2863181531429291\n",
      "Replaced token 77 with corr 0.3526734709739685 with new token with corr 0.3526734709739685\n",
      "Replaced token 78 with corr 0.4015227258205414 with new token with corr 0.40152275562286377\n",
      "Replaced token 79 with corr 0.2806752920150757 with new token with corr 0.2806752622127533\n",
      "Replaced token 80 with corr 0.3654007315635681 with new token with corr 0.3654007315635681\n",
      "Replaced token 81 with corr 0.3779279291629791 with new token with corr 0.3779279291629791\n",
      "Replaced token 82 with corr 0.2131631076335907 with new token with corr 0.2131631076335907\n",
      "Replaced token 83 with corr 0.2552436888217926 with new token with corr 0.2552436888217926\n",
      "Replaced token 84 with corr 0.31879496574401855 with new token with corr 0.31879499554634094\n",
      "Replaced token 85 with corr 0.30465590953826904 with new token with corr 0.30465587973594666\n",
      "Replaced token 86 with corr 0.2819841802120209 with new token with corr 0.2819841802120209\n",
      "Replaced token 87 with corr 0.206870436668396 with new token with corr 0.206870436668396\n",
      "Replaced token 88 with corr 0.2486138790845871 with new token with corr 0.2486138641834259\n",
      "Replaced token 89 with corr 0.2501673996448517 with new token with corr 0.2501674294471741\n",
      "Replaced token 90 with corr 0.37250518798828125 with new token with corr 0.37250518798828125\n",
      "Replaced token 91 with corr 0.29092326760292053 with new token with corr 0.29092323780059814\n",
      "Replaced token 92 with corr 0.2865796387195587 with new token with corr 0.28657960891723633\n",
      "Replaced token 93 with corr 0.2801499664783478 with new token with corr 0.2801499664783478\n",
      "Replaced token 94 with corr 0.26698195934295654 with new token with corr 0.26698195934295654\n",
      "Replaced token 95 with corr 0.2557787299156189 with new token with corr 0.2557787001132965\n",
      "Replaced token 96 with corr 0.09464694559574127 with new token with corr 0.2000071108341217\n",
      "Replaced token 97 with corr 0.3042442500591278 with new token with corr 0.3042442798614502\n",
      "Replaced token 98 with corr 0.3305807411670685 with new token with corr 0.33058077096939087\n",
      "Replaced token 99 with corr 0.3328363597393036 with new token with corr 0.3328363299369812\n",
      "Replaced token 100 with corr 0.11622016131877899 with new token with corr 0.2580813467502594\n",
      "Replaced token 101 with corr 0.27328115701675415 with new token with corr 0.27328115701675415\n",
      "Replaced token 102 with corr 0.36428505182266235 with new token with corr 0.36428502202033997\n",
      "Replaced token 103 with corr 0.3151671290397644 with new token with corr 0.315167099237442\n",
      "Replaced token 104 with corr 0.3251657485961914 with new token with corr 0.3251657783985138\n",
      "Replaced token 105 with corr 0.2928563058376312 with new token with corr 0.29285627603530884\n",
      "Replaced token 106 with corr 0.2845872640609741 with new token with corr 0.2845872640609741\n",
      "Replaced token 107 with corr 0.3126908242702484 with new token with corr 0.3126908540725708\n",
      "Replaced token 108 with corr 0.2819071114063263 with new token with corr 0.2819071114063263\n",
      "Replaced token 109 with corr 0.282394140958786 with new token with corr 0.2823942005634308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 110 with corr 0.3001983165740967 with new token with corr 0.3001983165740967\n",
      "Replaced token 111 with corr 0.31014201045036316 with new token with corr 0.31014198064804077\n",
      "Replaced token 112 with corr 0.31658217310905457 with new token with corr 0.31658217310905457\n",
      "Replaced token 113 with corr 0.2692374885082245 with new token with corr 0.2692375183105469\n",
      "Replaced token 114 with corr 0.3627115786075592 with new token with corr 0.3627115786075592\n",
      "Replaced token 115 with corr 0.31671401858329773 with new token with corr 0.31671401858329773\n",
      "Replaced token 116 with corr 0.34479859471321106 with new token with corr 0.34479862451553345\n",
      "Replaced token 117 with corr 0.2647795081138611 with new token with corr 0.2647795081138611\n",
      "Replaced token 118 with corr 0.34250202775001526 with new token with corr 0.34250202775001526\n",
      "Replaced token 119 with corr 0.30347496271133423 with new token with corr 0.3034749925136566\n",
      "Replaced token 120 with corr 0.37612834572792053 with new token with corr 0.3761284053325653\n",
      "Replaced token 121 with corr 0.31555798649787903 with new token with corr 0.3155580163002014\n",
      "Replaced token 122 with corr 0.282888263463974 with new token with corr 0.282888263463974\n",
      "Replaced token 123 with corr 0.10482989251613617 with new token with corr 0.221369206905365\n",
      "Replaced token 124 with corr 0.29378730058670044 with new token with corr 0.29378730058670044\n",
      "Replaced token 125 with corr 0.25944194197654724 with new token with corr 0.25944197177886963\n",
      "Replaced token 126 with corr 0.2848605513572693 with new token with corr 0.2848605215549469\n",
      "Replaced token 127 with corr 0.31051671504974365 with new token with corr 0.31051668524742126\n",
      "Replaced token 128 with corr 0.2589492201805115 with new token with corr 0.2589491903781891\n",
      "Replaced token 129 with corr 0.2600403428077698 with new token with corr 0.2600403428077698\n",
      "Replaced token 130 with corr 0.35590222477912903 with new token with corr 0.35590222477912903\n",
      "Replaced token 131 with corr 0.3425096571445465 with new token with corr 0.3425096273422241\n",
      "Replaced token 132 with corr 0.29523518681526184 with new token with corr 0.29523515701293945\n",
      "Replaced token 133 with corr 0.3108554780483246 with new token with corr 0.3108554780483246\n",
      "Replaced token 134 with corr 0.2858940064907074 with new token with corr 0.2858940064907074\n",
      "Replaced token 135 with corr 0.2556568682193756 with new token with corr 0.2556568384170532\n",
      "Replaced token 136 with corr 0.24297067523002625 with new token with corr 0.24297070503234863\n",
      "Replaced token 137 with corr 0.30141887068748474 with new token with corr 0.30141884088516235\n",
      "Replaced token 138 with corr 0.29608482122421265 with new token with corr 0.29608482122421265\n",
      "Replaced token 139 with corr 0.2638460099697113 with new token with corr 0.2638460099697113\n",
      "Replaced token 140 with corr 0.3568125069141388 with new token with corr 0.3568125069141388\n",
      "Replaced token 141 with corr 0.23994313180446625 with new token with corr 0.23994316160678864\n",
      "Replaced token 142 with corr 0.1426793485879898 with new token with corr 0.24854715168476105\n",
      "Replaced token 143 with corr 0.26121705770492554 with new token with corr 0.26121702790260315\n",
      "Replaced token 144 with corr 0.137878879904747 with new token with corr 0.15511299669742584\n",
      "Replaced token 145 with corr 0.3040132522583008 with new token with corr 0.3040132522583008\n",
      "Replaced token 146 with corr 0.34281912446022034 with new token with corr 0.34281909465789795\n",
      "Replaced token 147 with corr 0.09084136039018631 with new token with corr 0.13877294957637787\n",
      "Replaced token 148 with corr 0.11775460094213486 with new token with corr 0.1684461236000061\n",
      "Replaced token 149 with corr 0.39941444993019104 with new token with corr 0.3994144797325134\n",
      "Replaced token 150 with corr 0.26948797702789307 with new token with corr 0.2694879472255707\n",
      "Replaced token 151 with corr 0.2441306710243225 with new token with corr 0.2441307008266449\n",
      "Replaced token 152 with corr 0.14698071777820587 with new token with corr 0.17307201027870178\n",
      "Replaced token 153 with corr 0.27315953373908997 with new token with corr 0.2731595039367676\n",
      "Replaced token 154 with corr 0.3848671317100525 with new token with corr 0.3848671615123749\n",
      "Replaced token 155 with corr 0.33148062229156494 with new token with corr 0.33148062229156494\n",
      "Replaced token 156 with corr 0.0995953381061554 with new token with corr 0.19734443724155426\n",
      "Replaced token 157 with corr 0.2830312252044678 with new token with corr 0.28303125500679016\n",
      "Replaced token 158 with corr 0.3177517056465149 with new token with corr 0.3177517354488373\n",
      "Replaced token 159 with corr 0.4435468912124634 with new token with corr 0.4435468912124634\n",
      "Replaced token 160 with corr 0.3071191906929016 with new token with corr 0.307119220495224\n",
      "Replaced token 161 with corr 0.2691815197467804 with new token with corr 0.2691815197467804\n",
      "Replaced token 162 with corr 0.36477038264274597 with new token with corr 0.36477041244506836\n",
      "Replaced token 163 with corr 0.28676947951316833 with new token with corr 0.28676947951316833\n",
      "Replaced token 164 with corr 0.2999100685119629 with new token with corr 0.2999100983142853\n",
      "Replaced token 165 with corr 0.35519808530807495 with new token with corr 0.35519805550575256\n",
      "Replaced token 166 with corr 0.08978059887886047 with new token with corr 0.3762853443622589\n",
      "Replaced token 167 with corr 0.29930686950683594 with new token with corr 0.2993068993091583\n",
      "Replaced token 168 with corr 0.3123878836631775 with new token with corr 0.3123878836631775\n",
      "Replaced token 169 with corr 0.2581603527069092 with new token with corr 0.2581603229045868\n",
      "Replaced token 170 with corr 0.353546679019928 with new token with corr 0.3535466492176056\n",
      "Replaced token 171 with corr 0.27183103561401367 with new token with corr 0.27183103561401367\n",
      "Replaced token 172 with corr 0.09863615036010742 with new token with corr 0.1725509762763977\n",
      "Replaced token 173 with corr 0.2703535556793213 with new token with corr 0.2703535258769989\n",
      "Replaced token 174 with corr 0.2621551752090454 with new token with corr 0.2621552050113678\n",
      "Replaced token 175 with corr 0.32127517461776733 with new token with corr 0.32127517461776733\n",
      "Replaced token 176 with corr 0.2976067364215851 with new token with corr 0.2976067066192627\n",
      "Replaced token 177 with corr 0.2866688668727875 with new token with corr 0.2866688668727875\n",
      "Replaced token 178 with corr 0.3616720736026764 with new token with corr 0.3616721034049988\n",
      "Replaced token 179 with corr 0.30156588554382324 with new token with corr 0.30156585574150085\n",
      "Replaced token 180 with corr 0.2524653971195221 with new token with corr 0.2524653971195221\n",
      "Replaced token 181 with corr 0.3275141417980194 with new token with corr 0.327514111995697\n",
      "Replaced token 182 with corr 0.3140784502029419 with new token with corr 0.3140784502029419\n",
      "Replaced token 183 with corr 0.24735955893993378 with new token with corr 0.24735955893993378\n",
      "Replaced token 184 with corr 0.26696252822875977 with new token with corr 0.26696252822875977\n",
      "Replaced token 185 with corr 0.3098199963569641 with new token with corr 0.3098199963569641\n",
      "Replaced token 186 with corr 0.2799527049064636 with new token with corr 0.2799527049064636\n",
      "Replaced token 187 with corr 0.27781912684440613 with new token with corr 0.27781912684440613\n",
      "Replaced token 188 with corr 0.09136594831943512 with new token with corr 0.23894765973091125\n",
      "Replaced token 189 with corr 0.2469366490840912 with new token with corr 0.24693666398525238\n",
      "Replaced token 190 with corr 0.33064040541648865 with new token with corr 0.33064040541648865\n",
      "Replaced token 191 with corr 0.1137547567486763 with new token with corr 0.26309698820114136\n",
      "Replaced token 192 with corr 0.3340425193309784 with new token with corr 0.3340424597263336\n",
      "Replaced token 193 with corr 0.3221936821937561 with new token with corr 0.3221936523914337\n",
      "Replaced token 194 with corr 0.39924705028533936 with new token with corr 0.39924710988998413\n",
      "Replaced token 195 with corr 0.36966362595558167 with new token with corr 0.36966362595558167\n",
      "Replaced token 196 with corr 0.27597999572753906 with new token with corr 0.27597999572753906\n",
      "Replaced token 197 with corr 0.3165879249572754 with new token with corr 0.316587895154953\n",
      "Replaced token 198 with corr 0.27421143651008606 with new token with corr 0.27421143651008606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 199 with corr 0.28455784916877747 with new token with corr 0.28455784916877747\n",
      "Replaced token 200 with corr 0.29279571771621704 with new token with corr 0.29279568791389465\n",
      "Replaced token 201 with corr 0.3224773406982422 with new token with corr 0.3224773406982422\n",
      "Replaced token 202 with corr 0.1084042489528656 with new token with corr 0.15070481598377228\n",
      "Replaced token 203 with corr 0.24837519228458405 with new token with corr 0.24837520718574524\n",
      "Replaced token 204 with corr 0.24914488196372986 with new token with corr 0.24914486706256866\n",
      "Replaced token 205 with corr 0.0792447179555893 with new token with corr 0.2740797698497772\n",
      "Replaced token 206 with corr 0.5394882559776306 with new token with corr 0.5394882559776306\n",
      "Replaced token 207 with corr 0.29537278413772583 with new token with corr 0.29537278413772583\n",
      "Replaced token 208 with corr 0.28792810440063477 with new token with corr 0.2879280745983124\n",
      "Replaced token 209 with corr 0.2917640805244446 with new token with corr 0.2917640507221222\n",
      "Replaced token 210 with corr 0.2699717879295349 with new token with corr 0.2699718177318573\n",
      "Replaced token 211 with corr 0.23796449601650238 with new token with corr 0.23796451091766357\n",
      "Replaced token 212 with corr 0.3258630633354187 with new token with corr 0.3258630633354187\n",
      "Replaced token 213 with corr 0.2494819611310959 with new token with corr 0.2494819611310959\n",
      "Replaced token 214 with corr 0.288124680519104 with new token with corr 0.2881247103214264\n",
      "Replaced token 215 with corr 0.379149854183197 with new token with corr 0.37914982438087463\n",
      "Replaced token 216 with corr 0.2580609619617462 with new token with corr 0.2580609619617462\n",
      "Replaced token 217 with corr 0.3141634464263916 with new token with corr 0.314163476228714\n",
      "Replaced token 218 with corr 0.34955936670303345 with new token with corr 0.34955936670303345\n",
      "Replaced token 219 with corr 0.28749868273735046 with new token with corr 0.28749871253967285\n",
      "Replaced token 220 with corr 0.28198832273483276 with new token with corr 0.28198832273483276\n",
      "Replaced token 221 with corr 0.2901389002799988 with new token with corr 0.29013893008232117\n",
      "Replaced token 222 with corr 0.2669738531112671 with new token with corr 0.2669738531112671\n",
      "Replaced token 223 with corr 0.3473162353038788 with new token with corr 0.3473162353038788\n",
      "Replaced token 224 with corr 0.30100733041763306 with new token with corr 0.30100733041763306\n",
      "Replaced token 225 with corr 0.3712586462497711 with new token with corr 0.3712586462497711\n",
      "Replaced token 226 with corr 0.3175605237483978 with new token with corr 0.3175605237483978\n",
      "Replaced token 227 with corr 0.28655102849006653 with new token with corr 0.28655102849006653\n",
      "Replaced token 228 with corr 0.2840108573436737 with new token with corr 0.2840108275413513\n",
      "Replaced token 229 with corr 0.22757217288017273 with new token with corr 0.22757218778133392\n",
      "Replaced token 230 with corr 0.26100030541419983 with new token with corr 0.26100027561187744\n",
      "Replaced token 231 with corr 0.281585693359375 with new token with corr 0.2815856635570526\n",
      "Replaced token 232 with corr 0.2719724178314209 with new token with corr 0.2719723880290985\n",
      "Replaced token 233 with corr 0.2551631033420563 with new token with corr 0.2551630735397339\n",
      "Replaced token 234 with corr 0.24186378717422485 with new token with corr 0.24186378717422485\n",
      "Replaced token 235 with corr 0.2960316240787506 with new token with corr 0.2960315942764282\n",
      "Replaced token 236 with corr 0.2980910837650299 with new token with corr 0.2980910539627075\n",
      "Replaced token 237 with corr 0.32524925470352173 with new token with corr 0.32524925470352173\n",
      "Replaced token 238 with corr 0.29347941279411316 with new token with corr 0.29347947239875793\n",
      "Replaced token 239 with corr 0.26715174317359924 with new token with corr 0.26715174317359924\n",
      "Replaced token 240 with corr 0.27888745069503784 with new token with corr 0.27888745069503784\n",
      "Replaced token 241 with corr 0.27317652106285095 with new token with corr 0.27317652106285095\n",
      "Replaced token 242 with corr 0.3106670677661896 with new token with corr 0.31066709756851196\n",
      "Replaced token 243 with corr 0.3164600431919098 with new token with corr 0.3164600431919098\n",
      "Replaced token 244 with corr 0.26161718368530273 with new token with corr 0.26161718368530273\n",
      "Replaced token 245 with corr 0.2587068974971771 with new token with corr 0.2587068974971771\n",
      "Replaced token 246 with corr 0.3033102750778198 with new token with corr 0.3033103048801422\n",
      "Replaced token 247 with corr 0.3270534574985504 with new token with corr 0.327053427696228\n",
      "Replaced token 248 with corr 0.28932011127471924 with new token with corr 0.28932011127471924\n",
      "Replaced token 249 with corr 0.2633703947067261 with new token with corr 0.2633703649044037\n",
      "Replaced token 250 with corr 0.2958488464355469 with new token with corr 0.2958488464355469\n",
      "Replaced token 251 with corr 0.27076345682144165 with new token with corr 0.27076345682144165\n",
      "Replaced token 252 with corr 0.3497617542743683 with new token with corr 0.3497617542743683\n",
      "Replaced token 253 with corr 0.3228110074996948 with new token with corr 0.3228110074996948\n",
      "Replaced token 254 with corr 0.3160652220249176 with new token with corr 0.3160652220249176\n",
      "Replaced token 255 with corr 0.330448716878891 with new token with corr 0.330448716878891\n",
      "Replaced token 256 with corr 0.32879430055618286 with new token with corr 0.32879430055618286\n",
      "Replaced token 257 with corr 0.09256129711866379 with new token with corr 0.24084514379501343\n",
      "Replaced token 258 with corr 0.3150699734687805 with new token with corr 0.31506994366645813\n",
      "Replaced token 259 with corr 0.14304155111312866 with new token with corr 0.16333922743797302\n",
      "Replaced token 260 with corr 0.2721193730831146 with new token with corr 0.2721193730831146\n",
      "Replaced token 261 with corr 0.2956090271472931 with new token with corr 0.2956090271472931\n",
      "Replaced token 262 with corr 0.3418198227882385 with new token with corr 0.34181979298591614\n",
      "Replaced token 263 with corr 0.3238969147205353 with new token with corr 0.3238969147205353\n",
      "Replaced token 264 with corr 0.3440370559692383 with new token with corr 0.3440370261669159\n",
      "Replaced token 265 with corr 0.09990415722131729 with new token with corr 0.26489901542663574\n",
      "Replaced token 266 with corr 0.09759923070669174 with new token with corr 0.2242376208305359\n",
      "Replaced token 267 with corr 0.23155586421489716 with new token with corr 0.23155584931373596\n",
      "Replaced token 268 with corr 0.33958232402801514 with new token with corr 0.33958232402801514\n",
      "Replaced token 269 with corr 0.30203765630722046 with new token with corr 0.30203765630722046\n",
      "Replaced token 270 with corr 0.2844935953617096 with new token with corr 0.2844935953617096\n",
      "Replaced token 271 with corr 0.30255311727523804 with new token with corr 0.30255311727523804\n",
      "Replaced token 272 with corr 0.25169992446899414 with new token with corr 0.25169992446899414\n",
      "Replaced token 273 with corr 0.2656761705875397 with new token with corr 0.2656761407852173\n",
      "Replaced token 274 with corr 0.38926437497138977 with new token with corr 0.38926437497138977\n",
      "Replaced token 275 with corr 0.3172079622745514 with new token with corr 0.3172079920768738\n",
      "Replaced token 276 with corr 0.3621801733970642 with new token with corr 0.3621801733970642\n",
      "Replaced token 277 with corr 0.3053363859653473 with new token with corr 0.3053363561630249\n",
      "Replaced token 278 with corr 0.344415545463562 with new token with corr 0.344415545463562\n",
      "Replaced token 279 with corr 0.3325203061103821 with new token with corr 0.3325203061103821\n",
      "Replaced token 280 with corr 0.42467907071113586 with new token with corr 0.42467907071113586\n",
      "Replaced token 281 with corr 0.25117048621177673 with new token with corr 0.25117048621177673\n",
      "Replaced token 282 with corr 0.301003098487854 with new token with corr 0.3010030686855316\n",
      "Replaced token 283 with corr 0.2536979913711548 with new token with corr 0.2536979913711548\n",
      "Replaced token 284 with corr 0.1906612515449524 with new token with corr 0.1906612366437912\n",
      "Replaced token 285 with corr 0.30604133009910583 with new token with corr 0.30604133009910583\n",
      "Replaced token 286 with corr 0.2796718180179596 with new token with corr 0.279671847820282\n",
      "Replaced token 287 with corr 0.23490487039089203 with new token with corr 0.23490487039089203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 288 with corr 0.32713109254837036 with new token with corr 0.32713109254837036\n",
      "Replaced token 289 with corr 0.2703753113746643 with new token with corr 0.2703753113746643\n",
      "Replaced token 290 with corr 0.31375494599342346 with new token with corr 0.31375494599342346\n",
      "Replaced token 291 with corr 0.3448554575443268 with new token with corr 0.3448554277420044\n",
      "Replaced token 292 with corr 0.2911415696144104 with new token with corr 0.2911415696144104\n",
      "Replaced token 293 with corr 0.27968859672546387 with new token with corr 0.27968859672546387\n",
      "Replaced token 294 with corr 0.2583777904510498 with new token with corr 0.2583777904510498\n",
      "Replaced token 295 with corr 0.3337595760822296 with new token with corr 0.3337595462799072\n",
      "Replaced token 296 with corr 0.27066338062286377 with new token with corr 0.27066341042518616\n",
      "Replaced token 297 with corr 0.2399093508720398 with new token with corr 0.2399093508720398\n",
      "Replaced token 298 with corr 0.2592736482620239 with new token with corr 0.2592736482620239\n",
      "Replaced token 299 with corr 0.38134777545928955 with new token with corr 0.38134780526161194\n",
      "Replaced token 300 with corr 0.353583425283432 with new token with corr 0.3535834848880768\n",
      "Replaced token 301 with corr 0.344942182302475 with new token with corr 0.3449421525001526\n",
      "Replaced token 302 with corr 0.32828447222709656 with new token with corr 0.32828444242477417\n",
      "Replaced token 303 with corr 0.31020328402519226 with new token with corr 0.31020328402519226\n",
      "Replaced token 304 with corr 0.2511068284511566 with new token with corr 0.2511068284511566\n",
      "Replaced token 305 with corr 0.3138698637485504 with new token with corr 0.313869833946228\n",
      "Replaced token 306 with corr 0.3482334613800049 with new token with corr 0.3482334613800049\n",
      "Replaced token 307 with corr 0.2811070680618286 with new token with corr 0.2811070680618286\n",
      "Replaced token 308 with corr 0.35673490166664124 with new token with corr 0.35673484206199646\n",
      "Replaced token 309 with corr 0.37231701612472534 with new token with corr 0.37231701612472534\n",
      "Replaced token 310 with corr 0.30350470542907715 with new token with corr 0.30350473523139954\n",
      "Replaced token 311 with corr 0.27485641837120056 with new token with corr 0.27485644817352295\n",
      "Replaced token 312 with corr 0.13131514191627502 with new token with corr 0.15758179128170013\n",
      "Replaced token 313 with corr 0.31624624133110046 with new token with corr 0.31624630093574524\n",
      "Replaced token 314 with corr 0.28679001331329346 with new token with corr 0.28678998351097107\n",
      "Replaced token 315 with corr 0.19899380207061768 with new token with corr 0.19899378716945648\n",
      "Replaced token 316 with corr 0.2159544676542282 with new token with corr 0.2159544825553894\n",
      "Replaced token 317 with corr 0.2986120581626892 with new token with corr 0.2986120581626892\n",
      "Replaced token 318 with corr 0.33701127767562866 with new token with corr 0.33701127767562866\n",
      "Replaced token 319 with corr 0.3575341999530792 with new token with corr 0.3575341999530792\n",
      "Replaced token 320 with corr 0.25791698694229126 with new token with corr 0.25791698694229126\n",
      "Replaced token 321 with corr 0.2700173556804657 with new token with corr 0.2700173556804657\n",
      "Replaced token 322 with corr 0.30310890078544617 with new token with corr 0.3031088709831238\n",
      "Replaced token 323 with corr 0.24597983062267303 with new token with corr 0.24597981572151184\n",
      "Replaced token 324 with corr 0.35034942626953125 with new token with corr 0.35034942626953125\n",
      "Replaced token 325 with corr 0.23777471482753754 with new token with corr 0.23777472972869873\n",
      "Replaced token 326 with corr 0.07846662402153015 with new token with corr 0.15889431536197662\n",
      "Replaced token 327 with corr 0.22529558837413788 with new token with corr 0.22529557347297668\n",
      "Replaced token 328 with corr 0.32393866777420044 with new token with corr 0.32393866777420044\n",
      "Replaced token 329 with corr 0.3311023712158203 with new token with corr 0.3311024010181427\n",
      "Replaced token 330 with corr 0.3004607558250427 with new token with corr 0.3004607856273651\n",
      "Replaced token 331 with corr 0.3168715238571167 with new token with corr 0.3168715536594391\n",
      "Replaced token 332 with corr 0.30744680762290955 with new token with corr 0.30744677782058716\n",
      "Replaced token 333 with corr 0.3072673976421356 with new token with corr 0.307267427444458\n",
      "Replaced token 334 with corr 0.2661397159099579 with new token with corr 0.2661397159099579\n",
      "Replaced token 335 with corr 0.28089872002601624 with new token with corr 0.28089872002601624\n",
      "Replaced token 336 with corr 0.33639806509017944 with new token with corr 0.33639806509017944\n",
      "Replaced token 337 with corr 0.31519684195518494 with new token with corr 0.31519684195518494\n",
      "Replaced token 338 with corr 0.2960056960582733 with new token with corr 0.2960056960582733\n",
      "Replaced token 339 with corr 0.2592484652996063 with new token with corr 0.2592484652996063\n",
      "Replaced token 340 with corr 0.27671682834625244 with new token with corr 0.27671682834625244\n",
      "Replaced token 341 with corr 0.3773229420185089 with new token with corr 0.3773229122161865\n",
      "Replaced token 342 with corr 0.3136376440525055 with new token with corr 0.3136376440525055\n",
      "Replaced token 343 with corr 0.3554314970970154 with new token with corr 0.35543152689933777\n",
      "Replaced token 344 with corr 0.24982815980911255 with new token with corr 0.24982815980911255\n",
      "Replaced token 345 with corr 0.28696730732917786 with new token with corr 0.28696727752685547\n",
      "Replaced token 346 with corr 0.2637815773487091 with new token with corr 0.2637815773487091\n",
      "Replaced token 347 with corr 0.29772135615348816 with new token with corr 0.29772132635116577\n",
      "Replaced token 348 with corr 0.2082279622554779 with new token with corr 0.2082279771566391\n",
      "Replaced token 349 with corr 0.3182736337184906 with new token with corr 0.3182736337184906\n",
      "Replaced token 350 with corr 0.2679618000984192 with new token with corr 0.2679618000984192\n",
      "Replaced token 351 with corr 0.31164899468421936 with new token with corr 0.31164899468421936\n",
      "Replaced token 352 with corr 0.2962186634540558 with new token with corr 0.2962186634540558\n",
      "Replaced token 353 with corr 0.3934192359447479 with new token with corr 0.3934192359447479\n",
      "Replaced token 354 with corr 0.29080504179000854 with new token with corr 0.29080507159233093\n",
      "Replaced token 355 with corr 0.36796459555625916 with new token with corr 0.36796459555625916\n",
      "Replaced token 356 with corr 0.3253614902496338 with new token with corr 0.3253615200519562\n",
      "Replaced token 357 with corr 0.11765756458044052 with new token with corr 0.25508594512939453\n",
      "Replaced token 358 with corr 0.2648935616016388 with new token with corr 0.2648935616016388\n",
      "Replaced token 359 with corr 0.3224485516548157 with new token with corr 0.32244858145713806\n",
      "Replaced token 360 with corr 0.3965667188167572 with new token with corr 0.3965667188167572\n",
      "Replaced token 361 with corr 0.27661392092704773 with new token with corr 0.27661389112472534\n",
      "Replaced token 362 with corr 0.39228880405426025 with new token with corr 0.39228880405426025\n",
      "Replaced token 363 with corr 0.11083157360553741 with new token with corr 0.22495022416114807\n",
      "Replaced token 364 with corr 0.24758419394493103 with new token with corr 0.24758419394493103\n",
      "Replaced token 365 with corr 0.34158772230148315 with new token with corr 0.34158772230148315\n",
      "Replaced token 366 with corr 0.22810214757919312 with new token with corr 0.2281021624803543\n",
      "Replaced token 367 with corr 0.340427428483963 with new token with corr 0.3404274582862854\n",
      "Replaced token 368 with corr 0.38209468126296997 with new token with corr 0.3820946514606476\n",
      "Replaced token 369 with corr 0.2693816125392914 with new token with corr 0.2693816125392914\n",
      "Replaced token 370 with corr 0.2960706353187561 with new token with corr 0.2960706353187561\n",
      "Replaced token 371 with corr 0.3027452826499939 with new token with corr 0.3027452528476715\n",
      "Replaced token 372 with corr 0.3201034665107727 with new token with corr 0.3201034963130951\n",
      "Replaced token 373 with corr 0.27527710795402527 with new token with corr 0.27527713775634766\n",
      "Replaced token 374 with corr 0.2146993726491928 with new token with corr 0.2146993726491928\n",
      "Replaced token 375 with corr 0.2432563602924347 with new token with corr 0.2432563453912735\n",
      "Replaced token 376 with corr 0.22739331424236298 with new token with corr 0.22739331424236298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 377 with corr 0.24988622963428497 with new token with corr 0.24988621473312378\n",
      "Replaced token 378 with corr 0.2320198267698288 with new token with corr 0.2320198118686676\n",
      "Replaced token 379 with corr 0.3461817800998688 with new token with corr 0.3461817800998688\n",
      "Replaced token 380 with corr 0.26534104347229004 with new token with corr 0.26534104347229004\n",
      "Replaced token 381 with corr 0.34412112832069397 with new token with corr 0.3441210985183716\n",
      "Replaced token 382 with corr 0.27983376383781433 with new token with corr 0.27983376383781433\n",
      "Replaced token 383 with corr 0.23858346045017242 with new token with corr 0.23858346045017242\n",
      "Replaced token 384 with corr 0.3410945236682892 with new token with corr 0.3410944938659668\n",
      "Replaced token 385 with corr 0.32608160376548767 with new token with corr 0.32608160376548767\n",
      "Replaced token 386 with corr 0.32360541820526123 with new token with corr 0.32360541820526123\n",
      "Replaced token 387 with corr 0.3168452978134155 with new token with corr 0.3168452978134155\n",
      "Replaced token 388 with corr 0.3104345500469208 with new token with corr 0.3104345500469208\n",
      "Replaced token 389 with corr 0.12040932476520538 with new token with corr 0.2243054360151291\n",
      "Replaced token 390 with corr 0.28963443636894226 with new token with corr 0.2896344065666199\n",
      "Replaced token 391 with corr 0.2575244903564453 with new token with corr 0.2575244903564453\n",
      "Replaced token 392 with corr 0.2698120176792145 with new token with corr 0.2698119878768921\n",
      "Replaced token 393 with corr 0.2867830991744995 with new token with corr 0.2867830991744995\n",
      "Replaced token 394 with corr 0.3061142563819885 with new token with corr 0.3061142563819885\n",
      "Replaced token 395 with corr 0.3597051203250885 with new token with corr 0.3597050905227661\n",
      "Replaced token 396 with corr 0.348484605550766 with new token with corr 0.348484605550766\n",
      "Replaced token 397 with corr 0.3831709027290344 with new token with corr 0.3831709027290344\n",
      "Replaced token 398 with corr 0.334679514169693 with new token with corr 0.3346795439720154\n",
      "Replaced token 399 with corr 0.29721325635910034 with new token with corr 0.29721322655677795\n",
      "Replaced token 400 with corr 0.3258182406425476 with new token with corr 0.3258182406425476\n",
      "Replaced token 401 with corr 0.30817317962646484 with new token with corr 0.30817314982414246\n",
      "Replaced token 402 with corr 0.3181767761707306 with new token with corr 0.3181767463684082\n",
      "Replaced token 403 with corr 0.32424744963645935 with new token with corr 0.32424741983413696\n",
      "Replaced token 404 with corr 0.3108719289302826 with new token with corr 0.3108719289302826\n",
      "Replaced token 405 with corr 0.26698094606399536 with new token with corr 0.26698094606399536\n",
      "Replaced token 406 with corr 0.23949848115444183 with new token with corr 0.23949848115444183\n",
      "Replaced token 407 with corr 0.33975091576576233 with new token with corr 0.33975088596343994\n",
      "Replaced token 408 with corr 0.23042196035385132 with new token with corr 0.23042196035385132\n",
      "Replaced token 409 with corr 0.3534989058971405 with new token with corr 0.3534988760948181\n",
      "Replaced token 410 with corr 0.31709858775138855 with new token with corr 0.31709855794906616\n",
      "Replaced token 411 with corr 0.2850368022918701 with new token with corr 0.2850368022918701\n",
      "Replaced token 412 with corr 0.2416706681251526 with new token with corr 0.2416706681251526\n",
      "Replaced token 413 with corr 0.306596040725708 with new token with corr 0.306596040725708\n",
      "Replaced token 414 with corr 0.25316524505615234 with new token with corr 0.25316524505615234\n",
      "Replaced token 415 with corr 0.29935020208358765 with new token with corr 0.29935020208358765\n",
      "Replaced token 416 with corr 0.39526188373565674 with new token with corr 0.39526182413101196\n",
      "Replaced token 417 with corr 0.28452181816101074 with new token with corr 0.28452181816101074\n",
      "Replaced token 418 with corr 0.2861172556877136 with new token with corr 0.2861172556877136\n",
      "Replaced token 419 with corr 0.29117870330810547 with new token with corr 0.2911786735057831\n",
      "Replaced token 420 with corr 0.34427961707115173 with new token with corr 0.3442796468734741\n",
      "Replaced token 421 with corr 0.3746826648712158 with new token with corr 0.37468263506889343\n",
      "Replaced token 422 with corr 0.09864215552806854 with new token with corr 0.2360743284225464\n",
      "Replaced token 423 with corr 0.3269392251968384 with new token with corr 0.3269392251968384\n",
      "Replaced token 424 with corr 0.35145822167396545 with new token with corr 0.35145822167396545\n",
      "Replaced token 425 with corr 0.31076017022132874 with new token with corr 0.31076017022132874\n",
      "Replaced token 426 with corr 0.29870057106018066 with new token with corr 0.29870060086250305\n",
      "Replaced token 427 with corr 0.28646597266197205 with new token with corr 0.28646597266197205\n",
      "Replaced token 428 with corr 0.36768826842308044 with new token with corr 0.36768826842308044\n",
      "Replaced token 429 with corr 0.3244364857673645 with new token with corr 0.3244364857673645\n",
      "Replaced token 430 with corr 0.35800060629844666 with new token with corr 0.35800060629844666\n",
      "Replaced token 431 with corr 0.3406613767147064 with new token with corr 0.3406613767147064\n",
      "Replaced token 432 with corr 0.29983505606651306 with new token with corr 0.29983505606651306\n",
      "Replaced token 433 with corr 0.2367805391550064 with new token with corr 0.2367805540561676\n",
      "Replaced token 434 with corr 0.3366210162639618 with new token with corr 0.3366209864616394\n",
      "Replaced token 435 with corr 0.26827895641326904 with new token with corr 0.26827892661094666\n",
      "Replaced token 436 with corr 0.3144870400428772 with new token with corr 0.3144870400428772\n",
      "Replaced token 437 with corr 0.3061242699623108 with new token with corr 0.3061242401599884\n",
      "Replaced token 438 with corr 0.2695387899875641 with new token with corr 0.2695387899875641\n",
      "Replaced token 439 with corr 0.31499361991882324 with new token with corr 0.31499361991882324\n",
      "Replaced token 440 with corr 0.09062034636735916 with new token with corr 0.15890830755233765\n",
      "Replaced token 441 with corr 0.3009411692619324 with new token with corr 0.3009411692619324\n",
      "Replaced token 442 with corr 0.22020284831523895 with new token with corr 0.22020284831523895\n",
      "Replaced token 443 with corr 0.32826313376426697 with new token with corr 0.32826313376426697\n",
      "Replaced token 444 with corr 0.32975518703460693 with new token with corr 0.3297552168369293\n",
      "Replaced token 445 with corr 0.26062268018722534 with new token with corr 0.26062268018722534\n",
      "Replaced token 446 with corr 0.302798330783844 with new token with corr 0.302798330783844\n",
      "Replaced token 447 with corr 0.24815182387828827 with new token with corr 0.24815180897712708\n",
      "Replaced token 448 with corr 0.2613864541053772 with new token with corr 0.2613864541053772\n",
      "Replaced token 449 with corr 0.3502384424209595 with new token with corr 0.3502384126186371\n",
      "Replaced token 450 with corr 0.24680112302303314 with new token with corr 0.24680112302303314\n",
      "Replaced token 451 with corr 0.2952258288860321 with new token with corr 0.2952258288860321\n",
      "Replaced token 452 with corr 0.3160269856452942 with new token with corr 0.3160269856452942\n",
      "Replaced token 453 with corr 0.24636158347129822 with new token with corr 0.24636158347129822\n",
      "Replaced token 454 with corr 0.293735533952713 with new token with corr 0.293735533952713\n",
      "Replaced token 455 with corr 0.3189704120159149 with new token with corr 0.3189704418182373\n",
      "Replaced token 456 with corr 0.2922859191894531 with new token with corr 0.2922859191894531\n",
      "Replaced token 457 with corr 0.2627004086971283 with new token with corr 0.2627004086971283\n",
      "Replaced token 458 with corr 0.11354941129684448 with new token with corr 0.3059351146221161\n",
      "Replaced token 459 with corr 0.3077709674835205 with new token with corr 0.3077709972858429\n",
      "Replaced token 460 with corr 0.25687122344970703 with new token with corr 0.25687122344970703\n",
      "Replaced token 461 with corr 0.3277008831501007 with new token with corr 0.3277009129524231\n",
      "Replaced token 462 with corr 0.32882875204086304 with new token with corr 0.32882875204086304\n",
      "Replaced token 463 with corr 0.21326711773872375 with new token with corr 0.21326713263988495\n",
      "Replaced token 464 with corr 0.3476310670375824 with new token with corr 0.3476310670375824\n",
      "Replaced token 465 with corr 0.286563515663147 with new token with corr 0.286563515663147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 466 with corr 0.3456181287765503 with new token with corr 0.3456181287765503\n",
      "Replaced token 467 with corr 0.2836076021194458 with new token with corr 0.2836076021194458\n",
      "Replaced token 468 with corr 0.2700333893299103 with new token with corr 0.2700333893299103\n",
      "Replaced token 469 with corr 0.3411365747451782 with new token with corr 0.34113654494285583\n",
      "Replaced token 470 with corr 0.2559410035610199 with new token with corr 0.2559410035610199\n",
      "Replaced token 471 with corr 0.3228808641433716 with new token with corr 0.3228808641433716\n",
      "Replaced token 472 with corr 0.2583029270172119 with new token with corr 0.2583029270172119\n",
      "Replaced token 473 with corr 0.3819849193096161 with new token with corr 0.3819848895072937\n",
      "Replaced token 474 with corr 0.206318661570549 with new token with corr 0.2063186764717102\n",
      "Replaced token 475 with corr 0.3191225528717041 with new token with corr 0.3191225826740265\n",
      "Replaced token 476 with corr 0.3118493854999542 with new token with corr 0.31184935569763184\n",
      "Replaced token 477 with corr 0.3617229759693146 with new token with corr 0.36172300577163696\n",
      "Replaced token 478 with corr 0.27128365635871887 with new token with corr 0.27128365635871887\n",
      "Replaced token 479 with corr 0.2684403359889984 with new token with corr 0.2684403657913208\n",
      "Replaced token 480 with corr 0.2607404589653015 with new token with corr 0.2607404887676239\n",
      "Replaced token 481 with corr 0.31306692957878113 with new token with corr 0.3130669593811035\n",
      "Replaced token 482 with corr 0.2623278498649597 with new token with corr 0.2623278498649597\n",
      "Replaced token 483 with corr 0.27904611825942993 with new token with corr 0.27904611825942993\n",
      "Replaced token 484 with corr 0.3327536880970001 with new token with corr 0.3327536880970001\n",
      "Replaced token 485 with corr 0.3369792401790619 with new token with corr 0.3369792401790619\n",
      "Replaced token 486 with corr 0.2521030008792877 with new token with corr 0.2521030008792877\n",
      "Replaced token 487 with corr 0.11485637724399567 with new token with corr 0.25687742233276367\n",
      "Replaced token 488 with corr 0.10698159784078598 with new token with corr 0.22048774361610413\n",
      "Replaced token 489 with corr 0.3282724618911743 with new token with corr 0.3282724916934967\n",
      "Replaced token 490 with corr 0.09709368646144867 with new token with corr 0.31151992082595825\n",
      "Replaced token 491 with corr 0.3256787359714508 with new token with corr 0.3256787061691284\n",
      "Replaced token 492 with corr 0.3374210596084595 with new token with corr 0.3374210596084595\n",
      "Replaced token 493 with corr 0.29209059476852417 with new token with corr 0.29209062457084656\n",
      "Replaced token 494 with corr 0.28228721022605896 with new token with corr 0.2822871804237366\n",
      "Replaced token 495 with corr 0.29432880878448486 with new token with corr 0.29432880878448486\n",
      "Replaced token 496 with corr 0.33308330178260803 with new token with corr 0.33308330178260803\n",
      "Replaced token 497 with corr 0.28241634368896484 with new token with corr 0.28241634368896484\n",
      "Replaced token 498 with corr 0.3929188847541809 with new token with corr 0.3929188847541809\n",
      "Replaced token 499 with corr 0.25468477606773376 with new token with corr 0.25468477606773376\n",
      "Replaced token 500 with corr 0.33748859167099 with new token with corr 0.3374886214733124\n",
      "Replaced token 501 with corr 0.2586807608604431 with new token with corr 0.2586807608604431\n",
      "Replaced token 502 with corr 0.3472011983394623 with new token with corr 0.3472011685371399\n",
      "Replaced token 503 with corr 0.2655034065246582 with new token with corr 0.2655034363269806\n",
      "Replaced token 504 with corr 0.3715022802352905 with new token with corr 0.37150225043296814\n",
      "Replaced token 505 with corr 0.2721036672592163 with new token with corr 0.2721036970615387\n",
      "Replaced token 506 with corr 0.33680981397628784 with new token with corr 0.33680984377861023\n",
      "Replaced token 507 with corr 0.3322814106941223 with new token with corr 0.3322814106941223\n",
      "Replaced token 508 with corr 0.2773788273334503 with new token with corr 0.2773788273334503\n",
      "Replaced token 509 with corr 0.2868875563144684 with new token with corr 0.28688758611679077\n",
      "Replaced token 510 with corr 0.2611418068408966 with new token with corr 0.2611418068408966\n",
      "Replaced token 511 with corr 0.07224166393280029 with new token with corr 0.14823205769062042\n",
      "Replaced token 512 with corr 0.3245687484741211 with new token with corr 0.3245687484741211\n",
      "Replaced token 513 with corr 0.28047916293144226 with new token with corr 0.28047916293144226\n",
      "Replaced token 514 with corr 0.3025040924549103 with new token with corr 0.3025040924549103\n",
      "Replaced token 515 with corr 0.40664196014404297 with new token with corr 0.40664198994636536\n",
      "Replaced token 516 with corr 0.34337443113327026 with new token with corr 0.34337443113327026\n",
      "Replaced token 517 with corr 0.28831395506858826 with new token with corr 0.28831395506858826\n",
      "Replaced token 518 with corr 0.28230020403862 with new token with corr 0.2823002338409424\n",
      "Replaced token 519 with corr 0.24173203110694885 with new token with corr 0.24173203110694885\n",
      "Replaced token 520 with corr 0.3080454170703888 with new token with corr 0.3080454468727112\n",
      "Replaced token 521 with corr 0.2646641433238983 with new token with corr 0.2646641433238983\n",
      "Replaced token 522 with corr 0.33167287707328796 with new token with corr 0.3316728472709656\n",
      "Replaced token 523 with corr 0.26085394620895386 with new token with corr 0.26085397601127625\n",
      "Replaced token 524 with corr 0.29095810651779175 with new token with corr 0.29095810651779175\n",
      "Replaced token 525 with corr 0.11561029404401779 with new token with corr 0.25178301334381104\n",
      "Replaced token 526 with corr 0.2930709719657898 with new token with corr 0.2930710017681122\n",
      "Replaced token 527 with corr 0.18727780878543854 with new token with corr 0.18727783858776093\n",
      "Replaced token 528 with corr 0.24507273733615875 with new token with corr 0.24507273733615875\n",
      "Replaced token 529 with corr 0.35396337509155273 with new token with corr 0.35396337509155273\n",
      "Replaced token 530 with corr 0.3450479507446289 with new token with corr 0.3450479805469513\n",
      "Replaced token 531 with corr 0.2878386974334717 with new token with corr 0.2878386974334717\n",
      "Replaced token 532 with corr 0.3723316788673401 with new token with corr 0.3723316788673401\n",
      "Replaced token 533 with corr 0.2589218020439148 with new token with corr 0.2589217722415924\n",
      "Replaced token 534 with corr 0.30788329243659973 with new token with corr 0.30788329243659973\n",
      "Replaced token 535 with corr 0.33887922763824463 with new token with corr 0.33887919783592224\n",
      "Replaced token 536 with corr 0.32570669054985046 with new token with corr 0.3257066309452057\n",
      "Replaced token 537 with corr 0.2704886198043823 with new token with corr 0.2704886198043823\n",
      "Replaced token 538 with corr 0.09454026818275452 with new token with corr 0.15348148345947266\n",
      "Replaced token 539 with corr 0.3447246849536896 with new token with corr 0.3447246849536896\n",
      "Replaced token 540 with corr 0.3101338744163513 with new token with corr 0.31013384461402893\n",
      "Replaced token 541 with corr 0.33442145586013794 with new token with corr 0.33442145586013794\n",
      "Replaced token 542 with corr 0.2846052348613739 with new token with corr 0.2846052348613739\n",
      "Replaced token 543 with corr 0.2899876534938812 with new token with corr 0.2899876832962036\n",
      "Replaced token 544 with corr 0.30692511796951294 with new token with corr 0.30692511796951294\n",
      "Replaced token 545 with corr 0.26717111468315125 with new token with corr 0.26717111468315125\n",
      "Replaced token 546 with corr 0.30629485845565796 with new token with corr 0.30629485845565796\n",
      "Replaced token 547 with corr 0.25193965435028076 with new token with corr 0.25193965435028076\n",
      "Replaced token 548 with corr 0.21977825462818146 with new token with corr 0.21977822482585907\n",
      "Replaced token 549 with corr 0.32850000262260437 with new token with corr 0.32850000262260437\n",
      "Replaced token 550 with corr 0.28826746344566345 with new token with corr 0.28826746344566345\n",
      "Replaced token 551 with corr 0.3072321116924286 with new token with corr 0.3072321116924286\n",
      "Replaced token 552 with corr 0.3161534368991852 with new token with corr 0.3161534368991852\n",
      "Replaced token 553 with corr 0.40346559882164 with new token with corr 0.4034655690193176\n",
      "Replaced token 554 with corr 0.25856801867485046 with new token with corr 0.25856801867485046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 555 with corr 0.3017609417438507 with new token with corr 0.3017609715461731\n",
      "Replaced token 556 with corr 0.3702855110168457 with new token with corr 0.3702854514122009\n",
      "Replaced token 557 with corr 0.33455416560173035 with new token with corr 0.33455416560173035\n",
      "Replaced token 558 with corr 0.39254724979400635 with new token with corr 0.39254721999168396\n",
      "Replaced token 559 with corr 0.33055275678634644 with new token with corr 0.3305527865886688\n",
      "Replaced token 560 with corr 0.27857011556625366 with new token with corr 0.27857014536857605\n",
      "Replaced token 561 with corr 0.301175057888031 with new token with corr 0.3011750876903534\n",
      "Replaced token 562 with corr 0.3843349516391754 with new token with corr 0.384334921836853\n",
      "Replaced token 563 with corr 0.2830307185649872 with new token with corr 0.2830307185649872\n",
      "Replaced token 564 with corr 0.4156951606273651 with new token with corr 0.4156951904296875\n",
      "Replaced token 565 with corr 0.28488603234291077 with new token with corr 0.28488603234291077\n",
      "Replaced token 566 with corr 0.11152159422636032 with new token with corr 0.22072097659111023\n",
      "Replaced token 567 with corr 0.37368667125701904 with new token with corr 0.37368667125701904\n",
      "Replaced token 568 with corr 0.2473011463880539 with new token with corr 0.2473011314868927\n",
      "Replaced token 569 with corr 0.33718082308769226 with new token with corr 0.33718085289001465\n",
      "Replaced token 570 with corr 0.296532541513443 with new token with corr 0.296532541513443\n",
      "Replaced token 571 with corr 0.3120698034763336 with new token with corr 0.3120698034763336\n",
      "Replaced token 572 with corr 0.10247683525085449 with new token with corr 0.1441391110420227\n",
      "Replaced token 573 with corr 0.23777711391448975 with new token with corr 0.23777711391448975\n",
      "Replaced token 574 with corr 0.18085679411888123 with new token with corr 0.18085679411888123\n",
      "Replaced token 575 with corr 0.2663864493370056 with new token with corr 0.2663864493370056\n",
      "Replaced token 576 with corr 0.2806705832481384 with new token with corr 0.2806705832481384\n",
      "Replaced token 577 with corr 0.2080012708902359 with new token with corr 0.2080012857913971\n",
      "Replaced token 578 with corr 0.35067301988601685 with new token with corr 0.35067301988601685\n",
      "Replaced token 579 with corr 0.267463743686676 with new token with corr 0.267463743686676\n",
      "Replaced token 580 with corr 0.30301403999328613 with new token with corr 0.30301403999328613\n",
      "Replaced token 581 with corr 0.24087417125701904 with new token with corr 0.24087415635585785\n",
      "Replaced token 582 with corr 0.3055356442928314 with new token with corr 0.30553561449050903\n",
      "Replaced token 583 with corr 0.3208770751953125 with new token with corr 0.3208770751953125\n",
      "Replaced token 584 with corr 0.24447892606258392 with new token with corr 0.2444789558649063\n",
      "Replaced token 585 with corr 0.33404719829559326 with new token with corr 0.33404719829559326\n",
      "Replaced token 586 with corr 0.31526753306388855 with new token with corr 0.31526753306388855\n",
      "Replaced token 587 with corr 0.33769506216049194 with new token with corr 0.33769503235816956\n",
      "Replaced token 588 with corr 0.20640777051448822 with new token with corr 0.20640777051448822\n",
      "Replaced token 589 with corr 0.24893702566623688 with new token with corr 0.24893702566623688\n",
      "Replaced token 590 with corr 0.3106013238430023 with new token with corr 0.3106013536453247\n",
      "Replaced token 591 with corr 0.2592960000038147 with new token with corr 0.2592960000038147\n",
      "Replaced token 592 with corr 0.09372688829898834 with new token with corr 0.31124797463417053\n",
      "Replaced token 593 with corr 0.45158660411834717 with new token with corr 0.4515865743160248\n",
      "Replaced token 594 with corr 0.24842488765716553 with new token with corr 0.24842488765716553\n",
      "Replaced token 595 with corr 0.32686612010002136 with new token with corr 0.32686614990234375\n",
      "Replaced token 596 with corr 0.2592151463031769 with new token with corr 0.25921517610549927\n",
      "Replaced token 597 with corr 0.3448876142501831 with new token with corr 0.3448876142501831\n",
      "Replaced token 598 with corr 0.2840786278247833 with new token with corr 0.2840786278247833\n",
      "Replaced token 599 with corr 0.09186166524887085 with new token with corr 0.20139718055725098\n",
      "Replaced token 600 with corr 0.2992485463619232 with new token with corr 0.2992485463619232\n",
      "Replaced token 601 with corr 0.2650850713253021 with new token with corr 0.2650850713253021\n",
      "Replaced token 602 with corr 0.36022284626960754 with new token with corr 0.36022287607192993\n",
      "Replaced token 603 with corr 0.4034614861011505 with new token with corr 0.4034614861011505\n",
      "Replaced token 604 with corr 0.30694955587387085 with new token with corr 0.30694958567619324\n",
      "Replaced token 605 with corr 0.24073874950408936 with new token with corr 0.24073877930641174\n",
      "Replaced token 606 with corr 0.2574733793735504 with new token with corr 0.2574734091758728\n",
      "Replaced token 607 with corr 0.23287850618362427 with new token with corr 0.23287852108478546\n",
      "Replaced token 608 with corr 0.25145506858825684 with new token with corr 0.25145503878593445\n",
      "Replaced token 609 with corr 0.30764633417129517 with new token with corr 0.30764636397361755\n",
      "Replaced token 610 with corr 0.34958651661872864 with new token with corr 0.34958645701408386\n",
      "Replaced token 611 with corr 0.30697453022003174 with new token with corr 0.30697453022003174\n",
      "Replaced token 612 with corr 0.32499709725379944 with new token with corr 0.32499709725379944\n",
      "Replaced token 613 with corr 0.26740798354148865 with new token with corr 0.26740798354148865\n",
      "Replaced token 614 with corr 0.29683229327201843 with new token with corr 0.29683229327201843\n",
      "Replaced token 615 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 616 with corr 0.2589925229549408 with new token with corr 0.2589924931526184\n",
      "Replaced token 617 with corr 0.3004583716392517 with new token with corr 0.3004583716392517\n",
      "Replaced token 618 with corr 0.11568886786699295 with new token with corr 0.23867349326610565\n",
      "Replaced token 619 with corr 0.3717444837093353 with new token with corr 0.3717445135116577\n",
      "Replaced token 620 with corr 0.3207038640975952 with new token with corr 0.3207038640975952\n",
      "Replaced token 621 with corr 0.3463515043258667 with new token with corr 0.3463515043258667\n",
      "Replaced token 622 with corr 0.2652343213558197 with new token with corr 0.2652343213558197\n",
      "Replaced token 623 with corr 0.3479503095149994 with new token with corr 0.3479503393173218\n",
      "Replaced token 624 with corr 0.2929403483867645 with new token with corr 0.2929403483867645\n",
      "Replaced token 625 with corr 0.19889305531978607 with new token with corr 0.19889307022094727\n",
      "Replaced token 626 with corr 0.3236023187637329 with new token with corr 0.3236023485660553\n",
      "Replaced token 627 with corr 0.36129704117774963 with new token with corr 0.361297070980072\n",
      "Replaced token 628 with corr 0.35011565685272217 with new token with corr 0.35011565685272217\n",
      "Replaced token 629 with corr 0.29186922311782837 with new token with corr 0.29186925292015076\n",
      "Replaced token 630 with corr 0.30822858214378357 with new token with corr 0.30822858214378357\n",
      "Replaced token 631 with corr 0.30765673518180847 with new token with corr 0.30765673518180847\n",
      "Replaced token 632 with corr 0.35741084814071655 with new token with corr 0.35741084814071655\n",
      "Replaced token 633 with corr 0.29686424136161804 with new token with corr 0.29686421155929565\n",
      "Replaced token 634 with corr 0.2606591582298279 with new token with corr 0.26065918803215027\n",
      "Replaced token 635 with corr 0.31186944246292114 with new token with corr 0.31186941266059875\n",
      "Replaced token 636 with corr 0.2833510637283325 with new token with corr 0.28335103392601013\n",
      "Replaced token 637 with corr 0.30114734172821045 with new token with corr 0.30114734172821045\n",
      "Replaced token 638 with corr 0.28530755639076233 with new token with corr 0.28530752658843994\n",
      "Replaced token 639 with corr 0.31051671504974365 with new token with corr 0.31051668524742126\n",
      "Replaced token 640 with corr 0.12705056369304657 with new token with corr 0.29355359077453613\n",
      "Replaced token 641 with corr 0.12931184470653534 with new token with corr 0.1511695832014084\n",
      "Replaced token 642 with corr 0.3530570864677429 with new token with corr 0.3530570864677429\n",
      "Replaced token 643 with corr 0.4927208423614502 with new token with corr 0.4927207827568054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 644 with corr 0.29581090807914734 with new token with corr 0.29581090807914734\n",
      "Replaced token 645 with corr 0.3391302525997162 with new token with corr 0.3391302824020386\n",
      "Replaced token 646 with corr 0.3478705585002899 with new token with corr 0.3478705585002899\n",
      "Replaced token 647 with corr 0.13254739344120026 with new token with corr 0.14750154316425323\n",
      "Replaced token 648 with corr 0.2886868417263031 with new token with corr 0.2886868715286255\n",
      "Replaced token 649 with corr 0.32970333099365234 with new token with corr 0.32970333099365234\n",
      "Replaced token 650 with corr 0.27243393659591675 with new token with corr 0.27243393659591675\n",
      "Replaced token 651 with corr 0.28915533423423767 with new token with corr 0.2891553044319153\n",
      "Replaced token 652 with corr 0.29299402236938477 with new token with corr 0.2929939925670624\n",
      "Replaced token 653 with corr 0.4569304287433624 with new token with corr 0.4569304883480072\n",
      "Replaced token 654 with corr 0.08123092353343964 with new token with corr 0.17212828993797302\n",
      "Replaced token 655 with corr 0.2669297456741333 with new token with corr 0.2669297456741333\n",
      "Replaced token 656 with corr 0.3781803250312805 with new token with corr 0.3781803548336029\n",
      "Replaced token 657 with corr 0.3046676516532898 with new token with corr 0.3046676516532898\n",
      "Replaced token 658 with corr 0.24509631097316742 with new token with corr 0.2450963258743286\n",
      "Replaced token 659 with corr 0.2485974133014679 with new token with corr 0.2485974282026291\n",
      "Replaced token 660 with corr 0.10303323715925217 with new token with corr 0.14963647723197937\n",
      "Replaced token 661 with corr 0.07817701250314713 with new token with corr 0.29225459694862366\n",
      "Replaced token 662 with corr 0.3874678909778595 with new token with corr 0.3874679207801819\n",
      "Replaced token 663 with corr 0.2353769838809967 with new token with corr 0.2353769689798355\n",
      "Replaced token 664 with corr 0.20357927680015564 with new token with corr 0.20357929170131683\n",
      "Replaced token 665 with corr 0.2706763744354248 with new token with corr 0.2706763744354248\n",
      "Replaced token 666 with corr 0.3148716390132904 with new token with corr 0.3148716390132904\n",
      "Replaced token 667 with corr 0.21153804659843445 with new token with corr 0.21153804659843445\n",
      "Replaced token 668 with corr 0.2504396140575409 with new token with corr 0.2504396140575409\n",
      "Replaced token 669 with corr 0.3240914046764374 with new token with corr 0.32409143447875977\n",
      "Replaced token 670 with corr 0.37028297781944275 with new token with corr 0.37028294801712036\n",
      "Replaced token 671 with corr 0.26975303888320923 with new token with corr 0.2697530686855316\n",
      "Replaced token 672 with corr 0.3169524669647217 with new token with corr 0.3169524073600769\n",
      "Replaced token 673 with corr 0.24275338649749756 with new token with corr 0.24275340139865875\n",
      "Replaced token 674 with corr 0.2944198548793793 with new token with corr 0.2944198250770569\n",
      "Replaced token 675 with corr 0.2982773780822754 with new token with corr 0.2982773780822754\n",
      "Replaced token 676 with corr 0.27787020802497864 with new token with corr 0.27787020802497864\n",
      "Replaced token 677 with corr 0.2993912100791931 with new token with corr 0.2993911802768707\n",
      "Replaced token 678 with corr 0.3828619122505188 with new token with corr 0.3828619122505188\n",
      "Replaced token 679 with corr 0.3194821774959564 with new token with corr 0.3194821774959564\n",
      "Replaced token 680 with corr 0.3125503659248352 with new token with corr 0.3125503361225128\n",
      "Replaced token 681 with corr 0.11854878813028336 with new token with corr 0.14750728011131287\n",
      "Replaced token 682 with corr 0.36206701397895813 with new token with corr 0.36206698417663574\n",
      "Replaced token 683 with corr 0.27670595049858093 with new token with corr 0.2767059803009033\n",
      "Replaced token 684 with corr 0.3147428035736084 with new token with corr 0.314742773771286\n",
      "Replaced token 685 with corr 0.25724223256111145 with new token with corr 0.25724223256111145\n",
      "Replaced token 686 with corr 0.25988101959228516 with new token with corr 0.25988101959228516\n",
      "Replaced token 687 with corr 0.23770661652088165 with new token with corr 0.23770663142204285\n",
      "Replaced token 688 with corr 0.29042190313339233 with new token with corr 0.29042190313339233\n",
      "Replaced token 689 with corr 0.3425636291503906 with new token with corr 0.3425636291503906\n",
      "Replaced token 690 with corr 0.267993301153183 with new token with corr 0.2679932713508606\n",
      "Replaced token 691 with corr 0.27973058819770813 with new token with corr 0.27973058819770813\n",
      "Replaced token 692 with corr 0.2614949643611908 with new token with corr 0.2614949345588684\n",
      "Replaced token 693 with corr 0.1978810727596283 with new token with corr 0.1978810876607895\n",
      "Replaced token 694 with corr 0.314931184053421 with new token with corr 0.31493115425109863\n",
      "Replaced token 695 with corr 0.2980956435203552 with new token with corr 0.2980956435203552\n",
      "Replaced token 696 with corr 0.41501492261886597 with new token with corr 0.4150148928165436\n",
      "Replaced token 697 with corr 0.3664337396621704 with new token with corr 0.3664337396621704\n",
      "Replaced token 698 with corr 0.30688074231147766 with new token with corr 0.30688074231147766\n",
      "Replaced token 699 with corr 0.25948086380958557 with new token with corr 0.25948086380958557\n",
      "Replaced token 700 with corr 0.2634603679180145 with new token with corr 0.2634603977203369\n",
      "Replaced token 701 with corr 0.3075481355190277 with new token with corr 0.3075481355190277\n",
      "Replaced token 702 with corr 0.2683555781841278 with new token with corr 0.2683555781841278\n",
      "Replaced token 703 with corr 0.3226839601993561 with new token with corr 0.32268399000167847\n",
      "Replaced token 704 with corr 0.3034822940826416 with new token with corr 0.3034822940826416\n",
      "Replaced token 705 with corr 0.2791193425655365 with new token with corr 0.2791193425655365\n",
      "Replaced token 706 with corr 0.34748271107673645 with new token with corr 0.34748271107673645\n",
      "Replaced token 707 with corr 0.3121676743030548 with new token with corr 0.3121676445007324\n",
      "Replaced token 708 with corr 0.08453399688005447 with new token with corr 0.15257667005062103\n",
      "Replaced token 709 with corr 0.29388219118118286 with new token with corr 0.29388219118118286\n",
      "Replaced token 710 with corr 0.28649038076400757 with new token with corr 0.28649038076400757\n",
      "Replaced token 711 with corr 0.29547131061553955 with new token with corr 0.29547131061553955\n",
      "Replaced token 712 with corr 0.2430734932422638 with new token with corr 0.24307352304458618\n",
      "Replaced token 713 with corr 0.0795915424823761 with new token with corr 0.19586622714996338\n",
      "Replaced token 714 with corr 0.29002365469932556 with new token with corr 0.29002365469932556\n",
      "Replaced token 715 with corr 0.09467495232820511 with new token with corr 0.20234717428684235\n",
      "Replaced token 716 with corr 0.25930655002593994 with new token with corr 0.25930655002593994\n",
      "Replaced token 717 with corr 0.328487366437912 with new token with corr 0.328487366437912\n",
      "Replaced token 718 with corr 0.30656084418296814 with new token with corr 0.30656081438064575\n",
      "Replaced token 719 with corr 0.28332871198654175 with new token with corr 0.28332868218421936\n",
      "Replaced token 720 with corr 0.0878865048289299 with new token with corr 0.1572844237089157\n",
      "Replaced token 721 with corr 0.2916219234466553 with new token with corr 0.29162195324897766\n",
      "Replaced token 722 with corr 0.3082667887210846 with new token with corr 0.308266818523407\n",
      "Replaced token 723 with corr 0.3133787214756012 with new token with corr 0.3133787214756012\n",
      "Replaced token 724 with corr 0.17813892662525177 with new token with corr 0.17813891172409058\n",
      "Replaced token 725 with corr 0.08259778469800949 with new token with corr 0.22294455766677856\n",
      "Replaced token 726 with corr 0.2704533636569977 with new token with corr 0.2704533338546753\n",
      "Replaced token 727 with corr 0.33033403754234314 with new token with corr 0.33033403754234314\n",
      "Replaced token 728 with corr 0.25273120403289795 with new token with corr 0.25273123383522034\n",
      "Replaced token 729 with corr 0.28356197476387024 with new token with corr 0.28356197476387024\n",
      "Replaced token 730 with corr 0.2890554964542389 with new token with corr 0.2890554964542389\n",
      "Replaced token 731 with corr 0.10537471622228622 with new token with corr 0.22179755568504333\n",
      "Replaced token 732 with corr 0.34706911444664 with new token with corr 0.3470690846443176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 733 with corr 0.316491961479187 with new token with corr 0.316491961479187\n",
      "Replaced token 734 with corr 0.2786327600479126 with new token with corr 0.278632789850235\n",
      "Replaced token 735 with corr 0.34789714217185974 with new token with corr 0.34789714217185974\n",
      "Replaced token 736 with corr 0.12210801243782043 with new token with corr 0.14934375882148743\n",
      "Replaced token 737 with corr 0.3330170512199402 with new token with corr 0.3330170512199402\n",
      "Replaced token 738 with corr 0.2532397210597992 with new token with corr 0.2532397210597992\n",
      "Replaced token 739 with corr 0.2991703748703003 with new token with corr 0.2991704046726227\n",
      "Replaced token 740 with corr 0.27359306812286377 with new token with corr 0.2735930383205414\n",
      "Replaced token 741 with corr 0.23962482810020447 with new token with corr 0.23962482810020447\n",
      "Replaced token 742 with corr 0.2689153850078583 with new token with corr 0.2689153552055359\n",
      "Replaced token 743 with corr 0.2933766841888428 with new token with corr 0.2933766543865204\n",
      "Replaced token 744 with corr 0.2805511951446533 with new token with corr 0.2805511951446533\n",
      "Replaced token 745 with corr 0.3002951741218567 with new token with corr 0.3002952039241791\n",
      "Replaced token 746 with corr 0.2709086835384369 with new token with corr 0.2709086835384369\n",
      "Replaced token 747 with corr 0.3892812132835388 with new token with corr 0.3892812132835388\n",
      "Replaced token 748 with corr 0.2980910837650299 with new token with corr 0.2980910539627075\n",
      "Replaced token 749 with corr 0.25569775700569153 with new token with corr 0.2556977868080139\n",
      "Replaced token 750 with corr 0.3377458453178406 with new token with corr 0.33774587512016296\n",
      "Replaced token 751 with corr 0.2974153757095337 with new token with corr 0.2974153757095337\n",
      "Replaced token 752 with corr 0.2583874464035034 with new token with corr 0.2583874464035034\n",
      "Replaced token 753 with corr 0.317114919424057 with new token with corr 0.317114919424057\n",
      "Replaced token 754 with corr 0.27976542711257935 with new token with corr 0.27976542711257935\n",
      "Replaced token 755 with corr 0.25741007924079895 with new token with corr 0.25741007924079895\n",
      "Replaced token 756 with corr 0.30463656783103943 with new token with corr 0.30463656783103943\n",
      "Replaced token 757 with corr 0.3403818607330322 with new token with corr 0.3403818905353546\n",
      "Replaced token 758 with corr 0.10030191391706467 with new token with corr 0.15615716576576233\n",
      "Replaced token 759 with corr 0.23386308550834656 with new token with corr 0.23386310040950775\n",
      "Replaced token 760 with corr 0.2735257148742676 with new token with corr 0.27352574467658997\n",
      "Replaced token 761 with corr 0.3417925238609314 with new token with corr 0.3417925536632538\n",
      "Replaced token 762 with corr 0.28613507747650146 with new token with corr 0.2861350476741791\n",
      "Replaced token 763 with corr 0.2955772280693054 with new token with corr 0.2955772280693054\n",
      "Replaced token 764 with corr 0.28125885128974915 with new token with corr 0.28125888109207153\n",
      "Replaced token 765 with corr 0.2591884136199951 with new token with corr 0.2591884136199951\n",
      "Replaced token 766 with corr 0.3148666024208069 with new token with corr 0.3148665726184845\n",
      "Replaced token 767 with corr 0.2816186845302582 with new token with corr 0.2816186845302582\n",
      "Replaced token 768 with corr 0.33430996537208557 with new token with corr 0.3343099355697632\n",
      "Replaced token 769 with corr 0.08440469950437546 with new token with corr 0.14953385293483734\n",
      "Replaced token 770 with corr 0.312633216381073 with new token with corr 0.3126331865787506\n",
      "Replaced token 771 with corr 0.09703671932220459 with new token with corr 0.302799254655838\n",
      "Replaced token 772 with corr 0.28463202714920044 with new token with corr 0.28463202714920044\n",
      "Replaced token 773 with corr 0.09112171828746796 with new token with corr 0.16130287945270538\n",
      "Replaced token 774 with corr 0.31958797574043274 with new token with corr 0.31958794593811035\n",
      "Replaced token 775 with corr 0.29776591062545776 with new token with corr 0.29776591062545776\n",
      "Replaced token 776 with corr 0.340976357460022 with new token with corr 0.340976357460022\n",
      "Replaced token 777 with corr 0.09922241419553757 with new token with corr 0.2945486605167389\n",
      "Replaced token 778 with corr 0.2619212865829468 with new token with corr 0.26192131638526917\n",
      "Replaced token 779 with corr 0.252188503742218 with new token with corr 0.252188503742218\n",
      "Replaced token 780 with corr 0.2911781966686249 with new token with corr 0.29117822647094727\n",
      "Replaced token 781 with corr 0.3367655277252197 with new token with corr 0.3367655277252197\n",
      "Replaced token 782 with corr 0.25986579060554504 with new token with corr 0.25986582040786743\n",
      "Replaced token 783 with corr 0.3145674467086792 with new token with corr 0.3145674467086792\n",
      "Replaced token 784 with corr 0.2653442919254303 with new token with corr 0.2653442919254303\n",
      "Replaced token 785 with corr 0.3283681571483612 with new token with corr 0.3283681571483612\n",
      "Replaced token 786 with corr 0.3349821865558624 with new token with corr 0.3349821865558624\n",
      "Replaced token 787 with corr 0.2871410548686981 with new token with corr 0.2871410846710205\n",
      "Replaced token 788 with corr 0.2768309414386749 with new token with corr 0.2768309712409973\n",
      "Replaced token 789 with corr 0.3136841058731079 with new token with corr 0.3136841058731079\n",
      "Replaced token 790 with corr 0.3633148968219757 with new token with corr 0.3633148968219757\n",
      "Replaced token 791 with corr 0.07144638150930405 with new token with corr 0.17704078555107117\n",
      "Replaced token 792 with corr 0.09265730530023575 with new token with corr 0.14915414154529572\n",
      "Replaced token 793 with corr 0.2413710355758667 with new token with corr 0.2413710206747055\n",
      "Replaced token 794 with corr 0.3216423988342285 with new token with corr 0.32164236903190613\n",
      "Replaced token 795 with corr 0.3458792567253113 with new token with corr 0.3458792269229889\n",
      "Replaced token 796 with corr 0.20148316025733948 with new token with corr 0.20148317515850067\n",
      "Replaced token 797 with corr 0.33395397663116455 with new token with corr 0.33395394682884216\n",
      "Replaced token 798 with corr 0.09041425585746765 with new token with corr 0.20528154075145721\n",
      "Replaced token 799 with corr 0.2886373698711395 with new token with corr 0.2886373698711395\n",
      "Replaced token 800 with corr 0.09082973748445511 with new token with corr 0.14501212537288666\n",
      "Replaced token 801 with corr 0.30000510811805725 with new token with corr 0.30000510811805725\n",
      "Replaced token 802 with corr 0.3299565613269806 with new token with corr 0.3299565613269806\n",
      "Replaced token 803 with corr 0.3585287630558014 with new token with corr 0.3585287928581238\n",
      "Replaced token 804 with corr 0.26981320977211 with new token with corr 0.26981320977211\n",
      "Replaced token 805 with corr 0.3707592785358429 with new token with corr 0.3707592785358429\n",
      "Replaced token 806 with corr 0.2754391133785248 with new token with corr 0.2754391133785248\n",
      "Replaced token 807 with corr 0.34288254380226135 with new token with corr 0.34288251399993896\n",
      "Replaced token 808 with corr 0.31249821186065674 with new token with corr 0.31249818205833435\n",
      "Replaced token 809 with corr 0.30287277698516846 with new token with corr 0.30287277698516846\n",
      "Replaced token 810 with corr 0.2921363115310669 with new token with corr 0.2921363115310669\n",
      "Replaced token 811 with corr 0.28320297598838806 with new token with corr 0.2832029461860657\n",
      "Replaced token 812 with corr 0.34513407945632935 with new token with corr 0.34513407945632935\n",
      "Replaced token 813 with corr 0.2347525656223297 with new token with corr 0.2347525656223297\n",
      "Replaced token 814 with corr 0.30981433391571045 with new token with corr 0.30981436371803284\n",
      "Replaced token 815 with corr 0.33278846740722656 with new token with corr 0.33278846740722656\n",
      "Replaced token 816 with corr 0.3122565448284149 with new token with corr 0.31225651502609253\n",
      "Replaced token 817 with corr 0.2696199417114258 with new token with corr 0.2696199119091034\n",
      "Replaced token 818 with corr 0.2579154968261719 with new token with corr 0.2579154670238495\n",
      "Replaced token 819 with corr 0.3214397728443146 with new token with corr 0.3214397728443146\n",
      "Replaced token 820 with corr 0.2654397189617157 with new token with corr 0.2654397487640381\n",
      "Replaced token 821 with corr 0.3088933527469635 with new token with corr 0.3088933527469635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 822 with corr 0.2840288281440735 with new token with corr 0.2840288281440735\n",
      "Replaced token 823 with corr 0.3070230185985565 with new token with corr 0.3070230484008789\n",
      "Replaced token 824 with corr 0.23703938722610474 with new token with corr 0.23703937232494354\n",
      "Replaced token 825 with corr 0.36872008442878723 with new token with corr 0.36872008442878723\n",
      "Replaced token 826 with corr 0.28679001331329346 with new token with corr 0.28678998351097107\n",
      "Replaced token 827 with corr 0.20617343485355377 with new token with corr 0.20617343485355377\n",
      "Replaced token 828 with corr 0.2910290062427521 with new token with corr 0.29102903604507446\n",
      "Replaced token 829 with corr 0.3277224600315094 with new token with corr 0.327722430229187\n",
      "Replaced token 830 with corr 0.31941744685173035 with new token with corr 0.31941747665405273\n",
      "Replaced token 831 with corr 0.284047931432724 with new token with corr 0.2840479016304016\n",
      "Replaced token 832 with corr 0.27321451902389526 with new token with corr 0.27321451902389526\n",
      "Replaced token 833 with corr 0.2700173556804657 with new token with corr 0.2700173556804657\n",
      "Replaced token 834 with corr 0.2564462721347809 with new token with corr 0.25644630193710327\n",
      "Replaced token 835 with corr 0.30892476439476013 with new token with corr 0.30892476439476013\n",
      "Replaced token 836 with corr 0.3589988648891449 with new token with corr 0.3589989244937897\n",
      "Replaced token 837 with corr 0.3485250174999237 with new token with corr 0.3485250174999237\n",
      "Replaced token 838 with corr 0.29150399565696716 with new token with corr 0.29150399565696716\n",
      "Replaced token 839 with corr 0.09296030551195145 with new token with corr 0.246667742729187\n",
      "Replaced token 840 with corr 0.3503414988517761 with new token with corr 0.3503414988517761\n",
      "Replaced token 841 with corr 0.373872846364975 with new token with corr 0.37387287616729736\n",
      "Replaced token 842 with corr 0.35084232687950134 with new token with corr 0.35084232687950134\n",
      "Replaced token 843 with corr 0.355962872505188 with new token with corr 0.355962872505188\n",
      "Replaced token 844 with corr 0.34744328260421753 with new token with corr 0.34744325280189514\n",
      "Replaced token 845 with corr 0.2851109802722931 with new token with corr 0.2851109802722931\n",
      "Replaced token 846 with corr 0.31342440843582153 with new token with corr 0.31342437863349915\n",
      "Replaced token 847 with corr 0.29504767060279846 with new token with corr 0.29504767060279846\n",
      "Replaced token 848 with corr 0.10579328238964081 with new token with corr 0.14981573820114136\n",
      "Replaced token 849 with corr 0.36313074827194214 with new token with corr 0.36313071846961975\n",
      "Replaced token 850 with corr 0.1880614161491394 with new token with corr 0.1880614459514618\n",
      "Replaced token 851 with corr 0.28029415011405945 with new token with corr 0.28029415011405945\n",
      "Replaced token 852 with corr 0.26242202520370483 with new token with corr 0.2624220550060272\n",
      "Replaced token 853 with corr 0.2839922308921814 with new token with corr 0.283992201089859\n",
      "Replaced token 854 with corr 0.26410096883773804 with new token with corr 0.26410093903541565\n",
      "Replaced token 855 with corr 0.25151628255844116 with new token with corr 0.25151628255844116\n",
      "Replaced token 856 with corr 0.29034698009490967 with new token with corr 0.2903469502925873\n",
      "Replaced token 857 with corr 0.2844964265823364 with new token with corr 0.2844964265823364\n",
      "Replaced token 858 with corr 0.30012357234954834 with new token with corr 0.30012357234954834\n",
      "Replaced token 859 with corr 0.30124905705451965 with new token with corr 0.30124908685684204\n",
      "Replaced token 860 with corr 0.3117857277393341 with new token with corr 0.3117856979370117\n",
      "Replaced token 861 with corr 0.22873805463314056 with new token with corr 0.22873805463314056\n",
      "Replaced token 862 with corr 0.3421434462070465 with new token with corr 0.3421434164047241\n",
      "Replaced token 863 with corr 0.25280800461769104 with new token with corr 0.25280800461769104\n",
      "Replaced token 864 with corr 0.30253711342811584 with new token with corr 0.30253714323043823\n",
      "Replaced token 865 with corr 0.40313202142715454 with new token with corr 0.40313202142715454\n",
      "Replaced token 866 with corr 0.3465314507484436 with new token with corr 0.346531480550766\n",
      "Replaced token 867 with corr 0.09563031792640686 with new token with corr 0.16406835615634918\n",
      "Replaced token 868 with corr 0.2978651821613312 with new token with corr 0.2978651523590088\n",
      "Replaced token 869 with corr 0.24129560589790344 with new token with corr 0.24129559099674225\n",
      "Replaced token 870 with corr 0.07660464197397232 with new token with corr 0.31718987226486206\n",
      "Replaced token 871 with corr 0.2607625126838684 with new token with corr 0.2607625126838684\n",
      "Replaced token 872 with corr 0.36593061685562134 with new token with corr 0.3659306466579437\n",
      "Replaced token 873 with corr 0.27538594603538513 with new token with corr 0.2753859758377075\n",
      "Replaced token 874 with corr 0.2981685698032379 with new token with corr 0.2981685698032379\n",
      "Replaced token 875 with corr 0.28178805112838745 with new token with corr 0.28178808093070984\n",
      "Replaced token 876 with corr 0.23467157781124115 with new token with corr 0.23467159271240234\n",
      "Replaced token 877 with corr 0.33842238783836365 with new token with corr 0.33842241764068604\n",
      "Replaced token 878 with corr 0.2475002110004425 with new token with corr 0.2475001960992813\n",
      "Replaced token 879 with corr 0.3605293929576874 with new token with corr 0.36052942276000977\n",
      "Replaced token 880 with corr 0.2800469696521759 with new token with corr 0.2800470292568207\n",
      "Replaced token 881 with corr 0.341238409280777 with new token with corr 0.341238409280777\n",
      "Replaced token 882 with corr 0.3105632960796356 with new token with corr 0.3105632960796356\n",
      "Replaced token 883 with corr 0.2984027862548828 with new token with corr 0.2984027564525604\n",
      "Replaced token 884 with corr 0.27597498893737793 with new token with corr 0.27597498893737793\n",
      "Replaced token 885 with corr 0.2706550061702728 with new token with corr 0.2706550061702728\n",
      "Replaced token 886 with corr 0.29850536584854126 with new token with corr 0.2985053062438965\n",
      "Replaced token 887 with corr 0.29357171058654785 with new token with corr 0.29357171058654785\n",
      "Replaced token 888 with corr 0.25026071071624756 with new token with corr 0.25026071071624756\n",
      "Replaced token 889 with corr 0.3414590060710907 with new token with corr 0.3414589762687683\n",
      "Replaced token 890 with corr 0.2894229292869568 with new token with corr 0.2894229590892792\n",
      "Replaced token 891 with corr 0.3011820316314697 with new token with corr 0.3011820316314697\n",
      "Replaced token 892 with corr 0.31239187717437744 with new token with corr 0.31239184737205505\n",
      "Replaced token 893 with corr 0.36681386828422546 with new token with corr 0.36681386828422546\n",
      "Replaced token 894 with corr 0.2837253212928772 with new token with corr 0.2837253212928772\n",
      "Replaced token 895 with corr 0.27539440989494324 with new token with corr 0.27539440989494324\n",
      "Replaced token 896 with corr 0.3217064142227173 with new token with corr 0.3217064142227173\n",
      "Replaced token 897 with corr 0.3460370600223541 with new token with corr 0.3460370600223541\n",
      "Replaced token 898 with corr 0.3721875846385956 with new token with corr 0.3721875250339508\n",
      "Replaced token 899 with corr 0.11751987785100937 with new token with corr 0.14607861638069153\n",
      "Replaced token 900 with corr 0.2906261086463928 with new token with corr 0.2906261086463928\n",
      "Replaced token 901 with corr 0.2508731186389923 with new token with corr 0.2508731186389923\n",
      "Replaced token 902 with corr 0.29908818006515503 with new token with corr 0.2990882098674774\n",
      "Replaced token 903 with corr 0.3296390175819397 with new token with corr 0.3296390473842621\n",
      "Replaced token 904 with corr 0.2844149172306061 with new token with corr 0.28441494703292847\n",
      "Replaced token 905 with corr 0.28979742527008057 with new token with corr 0.28979742527008057\n",
      "Replaced token 906 with corr 0.30530211329460144 with new token with corr 0.30530214309692383\n",
      "Replaced token 907 with corr 0.3079712986946106 with new token with corr 0.3079712986946106\n",
      "Replaced token 908 with corr 0.2682100236415863 with new token with corr 0.2682100236415863\n",
      "Replaced token 909 with corr 0.37556642293930054 with new token with corr 0.37556642293930054\n",
      "Replaced token 910 with corr 0.13502371311187744 with new token with corr 0.153864324092865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 911 with corr 0.2619192600250244 with new token with corr 0.2619192600250244\n",
      "Replaced token 912 with corr 0.5055534839630127 with new token with corr 0.5055534839630127\n",
      "Replaced token 913 with corr 0.27915796637535095 with new token with corr 0.27915796637535095\n",
      "Replaced token 914 with corr 0.3337106704711914 with new token with corr 0.3337106704711914\n",
      "Replaced token 915 with corr 0.33041825890541077 with new token with corr 0.33041825890541077\n",
      "Replaced token 916 with corr 0.2838912606239319 with new token with corr 0.2838912904262543\n",
      "Replaced token 917 with corr 0.2952483296394348 with new token with corr 0.2952483296394348\n",
      "Replaced token 918 with corr 0.3105373680591583 with new token with corr 0.3105373680591583\n",
      "Replaced token 919 with corr 0.09916584193706512 with new token with corr 0.18581438064575195\n",
      "Replaced token 920 with corr 0.226896733045578 with new token with corr 0.2268967479467392\n",
      "Replaced token 921 with corr 0.3232072591781616 with new token with corr 0.3232072591781616\n",
      "Replaced token 922 with corr 0.30770063400268555 with new token with corr 0.30770060420036316\n",
      "Replaced token 923 with corr 0.14851413667201996 with new token with corr 0.16132427752017975\n",
      "Replaced token 924 with corr 0.31286388635635376 with new token with corr 0.31286391615867615\n",
      "Replaced token 925 with corr 0.2318374663591385 with new token with corr 0.23183748126029968\n",
      "Replaced token 926 with corr 0.30453935265541077 with new token with corr 0.3045393228530884\n",
      "Replaced token 927 with corr 0.32866171002388 with new token with corr 0.32866171002388\n",
      "Replaced token 928 with corr 0.34306254982948303 with new token with corr 0.34306254982948303\n",
      "Replaced token 929 with corr 0.310619980096817 with new token with corr 0.310619980096817\n",
      "Replaced token 930 with corr 0.35378721356391907 with new token with corr 0.3537871837615967\n",
      "Replaced token 931 with corr 0.29225653409957886 with new token with corr 0.29225653409957886\n",
      "Replaced token 932 with corr 0.25534120202064514 with new token with corr 0.25534120202064514\n",
      "Replaced token 933 with corr 0.35396039485931396 with new token with corr 0.35396039485931396\n",
      "Replaced token 934 with corr 0.2613554298877716 with new token with corr 0.261355459690094\n",
      "Replaced token 935 with corr 0.30912455916404724 with new token with corr 0.30912455916404724\n",
      "Replaced token 936 with corr 0.3068039119243622 with new token with corr 0.3068038821220398\n",
      "Replaced token 937 with corr 0.2844567894935608 with new token with corr 0.2844567596912384\n",
      "Replaced token 938 with corr 0.3960937261581421 with new token with corr 0.3960936963558197\n",
      "Replaced token 939 with corr 0.28688856959342957 with new token with corr 0.28688856959342957\n",
      "Replaced token 940 with corr 0.3232796788215637 with new token with corr 0.32327964901924133\n",
      "Replaced token 941 with corr 0.34538066387176514 with new token with corr 0.3453806936740875\n",
      "Replaced token 942 with corr 0.30757805705070496 with new token with corr 0.30757805705070496\n",
      "Replaced token 943 with corr 0.32519495487213135 with new token with corr 0.32519495487213135\n",
      "Replaced token 944 with corr 0.33165442943573 with new token with corr 0.33165445923805237\n",
      "Replaced token 945 with corr 0.3398485779762268 with new token with corr 0.3398485779762268\n",
      "Replaced token 946 with corr 0.29203668236732483 with new token with corr 0.2920367121696472\n",
      "Replaced token 947 with corr 0.27824896574020386 with new token with corr 0.27824896574020386\n",
      "Replaced token 948 with corr 0.35920628905296326 with new token with corr 0.35920625925064087\n",
      "Replaced token 949 with corr 0.24079136550426483 with new token with corr 0.24079136550426483\n",
      "Replaced token 950 with corr 0.23268327116966248 with new token with corr 0.23268328607082367\n",
      "Replaced token 951 with corr 0.3269917070865631 with new token with corr 0.3269917070865631\n",
      "Replaced token 952 with corr 0.3226957321166992 with new token with corr 0.3226957619190216\n",
      "Replaced token 953 with corr 0.3911118805408478 with new token with corr 0.39111191034317017\n",
      "Replaced token 954 with corr 0.23573358356952667 with new token with corr 0.23573355376720428\n",
      "Replaced token 955 with corr 0.29184454679489136 with new token with corr 0.29184451699256897\n",
      "Replaced token 956 with corr 0.39126652479171753 with new token with corr 0.39126652479171753\n",
      "Replaced token 957 with corr 0.09542372822761536 with new token with corr 0.23909063637256622\n",
      "Replaced token 958 with corr 0.35887986421585083 with new token with corr 0.35887983441352844\n",
      "Replaced token 959 with corr 0.16140145063400269 with new token with corr 0.16140145063400269\n",
      "Replaced token 960 with corr 0.29104161262512207 with new token with corr 0.29104164242744446\n",
      "Replaced token 961 with corr 0.29953354597091675 with new token with corr 0.29953354597091675\n",
      "Replaced token 962 with corr 0.3011241555213928 with new token with corr 0.3011241555213928\n",
      "Replaced token 963 with corr 0.299529105424881 with new token with corr 0.2995290756225586\n",
      "Replaced token 964 with corr 0.2894633114337921 with new token with corr 0.2894633114337921\n",
      "Replaced token 965 with corr 0.2638876438140869 with new token with corr 0.2638876438140869\n",
      "Replaced token 966 with corr 0.324074387550354 with new token with corr 0.3240743577480316\n",
      "Replaced token 967 with corr 0.33954566717147827 with new token with corr 0.33954566717147827\n",
      "Replaced token 968 with corr 0.2828310430049896 with new token with corr 0.282831072807312\n",
      "Replaced token 969 with corr 0.20891571044921875 with new token with corr 0.20891572535037994\n",
      "Replaced token 970 with corr 0.326213538646698 with new token with corr 0.326213538646698\n",
      "Replaced token 971 with corr 0.3077709674835205 with new token with corr 0.3077709972858429\n",
      "Replaced token 972 with corr 0.29614880681037903 with new token with corr 0.29614880681037903\n",
      "Replaced token 973 with corr 0.12015997618436813 with new token with corr 0.18991312384605408\n",
      "Replaced token 974 with corr 0.3124566972255707 with new token with corr 0.3124566674232483\n",
      "Replaced token 975 with corr 0.34419891238212585 with new token with corr 0.34419891238212585\n",
      "Replaced token 976 with corr 0.3111468553543091 with new token with corr 0.31114688515663147\n",
      "Replaced token 977 with corr 0.2920689880847931 with new token with corr 0.2920690178871155\n",
      "Replaced token 978 with corr 0.34691405296325684 with new token with corr 0.34691402316093445\n",
      "Replaced token 979 with corr 0.31169092655181885 with new token with corr 0.31169095635414124\n",
      "Replaced token 980 with corr 0.2700333893299103 with new token with corr 0.2700333893299103\n",
      "Replaced token 981 with corr 0.3003123700618744 with new token with corr 0.3003123700618744\n",
      "Replaced token 982 with corr 0.30910956859588623 with new token with corr 0.30910956859588623\n",
      "Replaced token 983 with corr 0.29535168409347534 with new token with corr 0.29535165429115295\n",
      "Replaced token 984 with corr 0.3147476315498352 with new token with corr 0.3147476613521576\n",
      "Replaced token 985 with corr 0.3428260385990143 with new token with corr 0.3428260385990143\n",
      "Replaced token 986 with corr 0.27896374464035034 with new token with corr 0.27896374464035034\n",
      "Replaced token 987 with corr 0.23387378454208374 with new token with corr 0.23387379944324493\n",
      "Replaced token 988 with corr 0.35393962264060974 with new token with corr 0.35393965244293213\n",
      "Replaced token 989 with corr 0.09649454057216644 with new token with corr 0.13950996100902557\n",
      "Replaced token 990 with corr 0.2908798158168793 with new token with corr 0.29087984561920166\n",
      "Replaced token 991 with corr 0.24858036637306213 with new token with corr 0.24858035147190094\n",
      "Replaced token 992 with corr 0.26416563987731934 with new token with corr 0.2641656696796417\n",
      "Replaced token 993 with corr 0.34590667486190796 with new token with corr 0.34590667486190796\n",
      "Replaced token 994 with corr 0.26467618346214294 with new token with corr 0.26467621326446533\n",
      "Replaced token 995 with corr 0.2859174907207489 with new token with corr 0.2859174609184265\n",
      "Replaced token 996 with corr 0.30794674158096313 with new token with corr 0.30794671177864075\n",
      "Replaced token 997 with corr 0.2993178069591522 with new token with corr 0.2993178069591522\n",
      "Replaced token 998 with corr 0.25983667373657227 with new token with corr 0.25983670353889465\n",
      "Replaced token 999 with corr 0.2679675221443176 with new token with corr 0.2679675221443176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1000 with corr 0.260223925113678 with new token with corr 0.26022395491600037\n",
      "Replaced token 1001 with corr 0.2667328715324402 with new token with corr 0.2667328715324402\n",
      "Replaced token 1002 with corr 0.25620394945144653 with new token with corr 0.25620394945144653\n",
      "Replaced token 1003 with corr 0.31902819871902466 with new token with corr 0.31902822852134705\n",
      "Replaced token 1004 with corr 0.36027589440345764 with new token with corr 0.3602759540081024\n",
      "Replaced token 1005 with corr 0.32129356265068054 with new token with corr 0.32129356265068054\n",
      "Replaced token 1006 with corr 0.2711121737957001 with new token with corr 0.2711121439933777\n",
      "Replaced token 1007 with corr 0.29888030886650085 with new token with corr 0.29888033866882324\n",
      "Replaced token 1008 with corr 0.2619939148426056 with new token with corr 0.261993944644928\n",
      "Replaced token 1009 with corr 0.28241634368896484 with new token with corr 0.28241634368896484\n",
      "Replaced token 1010 with corr 0.3870096504688263 with new token with corr 0.3870096802711487\n",
      "Replaced token 1011 with corr 0.3774506449699402 with new token with corr 0.3774506151676178\n",
      "Replaced token 1012 with corr 0.26335427165031433 with new token with corr 0.26335427165031433\n",
      "Replaced token 1013 with corr 0.32979223132133484 with new token with corr 0.32979220151901245\n",
      "Replaced token 1014 with corr 0.24237112700939178 with new token with corr 0.24237112700939178\n",
      "Replaced token 1015 with corr 0.3054371476173401 with new token with corr 0.3054371774196625\n",
      "Replaced token 1016 with corr 0.3580520749092102 with new token with corr 0.3580520749092102\n",
      "Replaced token 1017 with corr 0.3106372356414795 with new token with corr 0.3106371760368347\n",
      "Replaced token 1018 with corr 0.4122932255268097 with new token with corr 0.41229328513145447\n",
      "Replaced token 1019 with corr 0.320848673582077 with new token with corr 0.32084864377975464\n",
      "Replaced token 1020 with corr 0.4021033048629761 with new token with corr 0.4021032452583313\n",
      "Replaced token 1021 with corr 0.22585409879684448 with new token with corr 0.22585409879684448\n",
      "Replaced token 1022 with corr 0.21174763143062592 with new token with corr 0.21174763143062592\n",
      "Replaced token 1023 with corr 0.07638375461101532 with new token with corr 0.15259888768196106\n",
      "Replaced token 1024 with corr 0.2984194755554199 with new token with corr 0.2984194755554199\n",
      "Replaced token 1025 with corr 0.29409128427505493 with new token with corr 0.29409128427505493\n",
      "Replaced token 1026 with corr 0.26803070306777954 with new token with corr 0.26803073287010193\n",
      "Replaced token 1027 with corr 0.24582792818546295 with new token with corr 0.24582791328430176\n",
      "Replaced token 1028 with corr 0.2643759548664093 with new token with corr 0.2643759548664093\n",
      "Replaced token 1029 with corr 0.29630398750305176 with new token with corr 0.29630398750305176\n",
      "Replaced token 1030 with corr 0.27434220910072327 with new token with corr 0.2743421792984009\n",
      "Replaced token 1031 with corr 0.10887496918439865 with new token with corr 0.21241869032382965\n",
      "Replaced token 1032 with corr 0.36529088020324707 with new token with corr 0.36529088020324707\n",
      "Replaced token 1033 with corr 0.22812993824481964 with new token with corr 0.22812993824481964\n",
      "Replaced token 1034 with corr 0.2504531741142273 with new token with corr 0.2504531741142273\n",
      "Replaced token 1035 with corr 0.2407216578722 with new token with corr 0.2407216876745224\n",
      "Replaced token 1036 with corr 0.2904071509838104 with new token with corr 0.2904071807861328\n",
      "Replaced token 1037 with corr 0.3230826258659363 with new token with corr 0.32308265566825867\n",
      "Replaced token 1038 with corr 0.24510371685028076 with new token with corr 0.24510373175144196\n",
      "Replaced token 1039 with corr 0.2076488882303238 with new token with corr 0.2076488733291626\n",
      "Replaced token 1040 with corr 0.2861422896385193 with new token with corr 0.2861422896385193\n",
      "Replaced token 1041 with corr 0.2765340507030487 with new token with corr 0.2765340209007263\n",
      "Replaced token 1042 with corr 0.2659647762775421 with new token with corr 0.2659647464752197\n",
      "Replaced token 1043 with corr 0.2779989540576935 with new token with corr 0.2779989540576935\n",
      "Replaced token 1044 with corr 0.35919997096061707 with new token with corr 0.35919997096061707\n",
      "Replaced token 1045 with corr 0.3230521082878113 with new token with corr 0.3230520784854889\n",
      "Replaced token 1046 with corr 0.24901121854782104 with new token with corr 0.24901120364665985\n",
      "Replaced token 1047 with corr 0.37635475397109985 with new token with corr 0.37635478377342224\n",
      "Replaced token 1048 with corr 0.29067155718803406 with new token with corr 0.29067155718803406\n",
      "Replaced token 1049 with corr 0.2739894986152649 with new token with corr 0.2739894390106201\n",
      "Replaced token 1050 with corr 0.10594883561134338 with new token with corr 0.24959640204906464\n",
      "Replaced token 1051 with corr 0.2583322823047638 with new token with corr 0.2583322823047638\n",
      "Replaced token 1052 with corr 0.31756392121315 with new token with corr 0.31756392121315\n",
      "Replaced token 1053 with corr 0.2411004602909088 with new token with corr 0.2411004602909088\n",
      "Replaced token 1054 with corr 0.25682350993156433 with new token with corr 0.25682350993156433\n",
      "Replaced token 1055 with corr 0.2673253118991852 with new token with corr 0.2673253118991852\n",
      "Replaced token 1056 with corr 0.2679121494293213 with new token with corr 0.2679121494293213\n",
      "Replaced token 1057 with corr 0.08473658561706543 with new token with corr 0.22825545072555542\n",
      "Replaced token 1058 with corr 0.28006353974342346 with new token with corr 0.28006353974342346\n",
      "Replaced token 1059 with corr 0.2648746073246002 with new token with corr 0.2648746073246002\n",
      "Replaced token 1060 with corr 0.2553883492946625 with new token with corr 0.2553883492946625\n",
      "Replaced token 1061 with corr 0.25648754835128784 with new token with corr 0.25648751854896545\n",
      "Replaced token 1062 with corr 0.21725167334079742 with new token with corr 0.21725165843963623\n",
      "Replaced token 1063 with corr 0.3463745713233948 with new token with corr 0.3463745713233948\n",
      "Replaced token 1064 with corr 0.26356154680252075 with new token with corr 0.26356154680252075\n",
      "Replaced token 1065 with corr 0.3292689323425293 with new token with corr 0.3292689025402069\n",
      "Replaced token 1066 with corr 0.180293470621109 with new token with corr 0.180293470621109\n",
      "Replaced token 1067 with corr 0.38232919573783875 with new token with corr 0.38232919573783875\n",
      "Replaced token 1068 with corr 0.28840214014053345 with new token with corr 0.28840216994285583\n",
      "Replaced token 1069 with corr 0.349290132522583 with new token with corr 0.3492901623249054\n",
      "Replaced token 1070 with corr 0.37553170323371887 with new token with corr 0.3755316734313965\n",
      "Replaced token 1071 with corr 0.36302128434181213 with new token with corr 0.36302128434181213\n",
      "Replaced token 1072 with corr 0.2965817451477051 with new token with corr 0.29658177495002747\n",
      "Replaced token 1073 with corr 0.29033973813056946 with new token with corr 0.29033973813056946\n",
      "Replaced token 1074 with corr 0.08387237042188644 with new token with corr 0.1788710653781891\n",
      "Replaced token 1075 with corr 0.2861202657222748 with new token with corr 0.2861202359199524\n",
      "Replaced token 1076 with corr 0.3377581536769867 with new token with corr 0.3377581536769867\n",
      "Replaced token 1077 with corr 0.17026476562023163 with new token with corr 0.17026476562023163\n",
      "Replaced token 1078 with corr 0.30757424235343933 with new token with corr 0.30757421255111694\n",
      "Replaced token 1079 with corr 0.30030056834220886 with new token with corr 0.30030056834220886\n",
      "Replaced token 1080 with corr 0.23013043403625488 with new token with corr 0.2301304042339325\n",
      "Replaced token 1081 with corr 0.2924647629261017 with new token with corr 0.2924647629261017\n",
      "Replaced token 1082 with corr 0.13931381702423096 with new token with corr 0.14919304847717285\n",
      "Replaced token 1083 with corr 0.2682197690010071 with new token with corr 0.26821979880332947\n",
      "Replaced token 1084 with corr 0.3361486494541168 with new token with corr 0.3361486494541168\n",
      "Replaced token 1085 with corr 0.23891586065292358 with new token with corr 0.23891586065292358\n",
      "Replaced token 1086 with corr 0.27181780338287354 with new token with corr 0.27181780338287354\n",
      "Replaced token 1087 with corr 0.3295285105705261 with new token with corr 0.3295285105705261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1088 with corr 0.2582075297832489 with new token with corr 0.2582075297832489\n",
      "Replaced token 1089 with corr 0.09365814179182053 with new token with corr 0.23969314992427826\n",
      "Replaced token 1090 with corr 0.33009153604507446 with new token with corr 0.33009156584739685\n",
      "Replaced token 1091 with corr 0.2697637379169464 with new token with corr 0.2697637677192688\n",
      "Replaced token 1092 with corr 0.23369204998016357 with new token with corr 0.23369203507900238\n",
      "Replaced token 1093 with corr 0.0979638621211052 with new token with corr 0.25052905082702637\n",
      "Replaced token 1094 with corr 0.25429877638816833 with new token with corr 0.25429874658584595\n",
      "Replaced token 1095 with corr 0.12025484442710876 with new token with corr 0.16140015423297882\n",
      "Replaced token 1096 with corr 0.21762380003929138 with new token with corr 0.21762381494045258\n",
      "Replaced token 1097 with corr 0.3318924307823181 with new token with corr 0.3318924307823181\n",
      "Replaced token 1098 with corr 0.07346440106630325 with new token with corr 0.14864100515842438\n",
      "Replaced token 1099 with corr 0.24927736818790436 with new token with corr 0.24927736818790436\n",
      "Replaced token 1100 with corr 0.25002381205558777 with new token with corr 0.25002381205558777\n",
      "Replaced token 1101 with corr 0.23208191990852356 with new token with corr 0.23208190500736237\n",
      "Replaced token 1102 with corr 0.366035133600235 with new token with corr 0.366035133600235\n",
      "Replaced token 1103 with corr 0.2806752920150757 with new token with corr 0.2806752622127533\n",
      "Replaced token 1104 with corr 0.34052005410194397 with new token with corr 0.34052008390426636\n",
      "Replaced token 1105 with corr 0.3138341009616852 with new token with corr 0.3138341009616852\n",
      "Replaced token 1106 with corr 0.2782491147518158 with new token with corr 0.2782490849494934\n",
      "Replaced token 1107 with corr 0.2649839222431183 with new token with corr 0.2649839222431183\n",
      "Replaced token 1108 with corr 0.26559510827064514 with new token with corr 0.26559507846832275\n",
      "Replaced token 1109 with corr 0.2982429265975952 with new token with corr 0.2982428967952728\n",
      "Replaced token 1110 with corr 0.10249369591474533 with new token with corr 0.17979593575000763\n",
      "Replaced token 1111 with corr 0.3584314286708832 with new token with corr 0.3584313988685608\n",
      "Replaced token 1112 with corr 0.31057676672935486 with new token with corr 0.31057676672935486\n",
      "Replaced token 1113 with corr 0.25389939546585083 with new token with corr 0.25389939546585083\n",
      "Replaced token 1114 with corr 0.34233036637306213 with new token with corr 0.34233036637306213\n",
      "Replaced token 1115 with corr 0.3578662872314453 with new token with corr 0.3578662872314453\n",
      "Replaced token 1116 with corr 0.2526836693286896 with new token with corr 0.2526836693286896\n",
      "Replaced token 1117 with corr 0.2175707221031189 with new token with corr 0.2175707072019577\n",
      "Replaced token 1118 with corr 0.24889810383319855 with new token with corr 0.24889811873435974\n",
      "Replaced token 1119 with corr 0.2615891695022583 with new token with corr 0.2615891695022583\n",
      "Replaced token 1120 with corr 0.2000071108341217 with new token with corr 0.2000071108341217\n",
      "Replaced token 1121 with corr 0.34374454617500305 with new token with corr 0.34374457597732544\n",
      "Replaced token 1122 with corr 0.2586458623409271 with new token with corr 0.2586458623409271\n",
      "Replaced token 1123 with corr 0.34710538387298584 with new token with corr 0.34710538387298584\n",
      "Replaced token 1124 with corr 0.25287842750549316 with new token with corr 0.25287842750549316\n",
      "Replaced token 1125 with corr 0.28209343552589417 with new token with corr 0.28209343552589417\n",
      "Replaced token 1126 with corr 0.28600913286209106 with new token with corr 0.2860091030597687\n",
      "Replaced token 1127 with corr 0.2629604637622833 with new token with corr 0.2629604637622833\n",
      "Replaced token 1128 with corr 0.30467814207077026 with new token with corr 0.3046781122684479\n",
      "Replaced token 1129 with corr 0.2817244231700897 with new token with corr 0.2817244529724121\n",
      "Replaced token 1130 with corr 0.24334867298603058 with new token with corr 0.24334865808486938\n",
      "Replaced token 1131 with corr 0.08043554425239563 with new token with corr 0.1565866470336914\n",
      "Replaced token 1132 with corr 0.3295915126800537 with new token with corr 0.3295915424823761\n",
      "Replaced token 1133 with corr 0.32168829441070557 with new token with corr 0.32168829441070557\n",
      "Replaced token 1134 with corr 0.2934398949146271 with new token with corr 0.2934398949146271\n",
      "Replaced token 1135 with corr 0.30953091382980347 with new token with corr 0.3095308840274811\n",
      "Replaced token 1136 with corr 0.3413051962852478 with new token with corr 0.341305136680603\n",
      "Replaced token 1137 with corr 0.2883823812007904 with new token with corr 0.28838232159614563\n",
      "Replaced token 1138 with corr 0.3715715706348419 with new token with corr 0.37157154083251953\n",
      "Replaced token 1139 with corr 0.22170990705490112 with new token with corr 0.2217099368572235\n",
      "Replaced token 1140 with corr 0.33332911133766174 with new token with corr 0.33332911133766174\n",
      "Replaced token 1141 with corr 0.2428198903799057 with new token with corr 0.2428199201822281\n",
      "Replaced token 1142 with corr 0.2874373197555542 with new token with corr 0.2874372899532318\n",
      "Replaced token 1143 with corr 0.2925712466239929 with new token with corr 0.2925712466239929\n",
      "Replaced token 1144 with corr 0.30219411849975586 with new token with corr 0.30219414830207825\n",
      "Replaced token 1145 with corr 0.2721410393714905 with new token with corr 0.27214106917381287\n",
      "Replaced token 1146 with corr 0.3148330748081207 with new token with corr 0.3148330748081207\n",
      "Replaced token 1147 with corr 0.2982047200202942 with new token with corr 0.2982047498226166\n",
      "Replaced token 1148 with corr 0.2753099501132965 with new token with corr 0.2753099501132965\n",
      "Replaced token 1149 with corr 0.32382532954216003 with new token with corr 0.32382532954216003\n",
      "Replaced token 1150 with corr 0.3279629349708557 with new token with corr 0.3279629349708557\n",
      "Replaced token 1151 with corr 0.25850915908813477 with new token with corr 0.2585091292858124\n",
      "Replaced token 1152 with corr 0.1226913258433342 with new token with corr 0.2075427621603012\n",
      "Replaced token 1153 with corr 0.10632549226284027 with new token with corr 0.2262493073940277\n",
      "Replaced token 1154 with corr 0.31341734528541565 with new token with corr 0.31341734528541565\n",
      "Replaced token 1155 with corr 0.2785830497741699 with new token with corr 0.2785830795764923\n",
      "Replaced token 1156 with corr 0.23615925014019012 with new token with corr 0.2361592799425125\n",
      "Replaced token 1157 with corr 0.2637174725532532 with new token with corr 0.2637174427509308\n",
      "Replaced token 1158 with corr 0.24764131009578705 with new token with corr 0.24764131009578705\n",
      "Replaced token 1159 with corr 0.22011034190654755 with new token with corr 0.22011035680770874\n",
      "Replaced token 1160 with corr 0.12260282039642334 with new token with corr 0.14229854941368103\n",
      "Replaced token 1161 with corr 0.25967204570770264 with new token with corr 0.25967204570770264\n",
      "Replaced token 1162 with corr 0.11809735745191574 with new token with corr 0.22573135793209076\n",
      "Replaced token 1163 with corr 0.27990347146987915 with new token with corr 0.27990350127220154\n",
      "Replaced token 1164 with corr 0.2702924609184265 with new token with corr 0.2702924609184265\n",
      "Replaced token 1165 with corr 0.20943273603916168 with new token with corr 0.20943273603916168\n",
      "Replaced token 1166 with corr 0.2041267603635788 with new token with corr 0.20412677526474\n",
      "Replaced token 1167 with corr 0.2573917508125305 with new token with corr 0.2573917508125305\n",
      "Replaced token 1168 with corr 0.2579042315483093 with new token with corr 0.2579042613506317\n",
      "Replaced token 1169 with corr 0.35581767559051514 with new token with corr 0.35581764578819275\n",
      "Replaced token 1170 with corr 0.26821717619895935 with new token with corr 0.26821717619895935\n",
      "Replaced token 1171 with corr 0.09213504195213318 with new token with corr 0.23409555852413177\n",
      "Replaced token 1172 with corr 0.11133114993572235 with new token with corr 0.21641553938388824\n",
      "Replaced token 1173 with corr 0.2579382061958313 with new token with corr 0.2579382061958313\n",
      "Replaced token 1174 with corr 0.26712051033973694 with new token with corr 0.26712051033973694\n",
      "Replaced token 1175 with corr 0.2611684203147888 with new token with corr 0.2611684203147888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1176 with corr 0.21362996101379395 with new token with corr 0.21362997591495514\n",
      "Replaced token 1177 with corr 0.27748632431030273 with new token with corr 0.27748629450798035\n",
      "Replaced token 1178 with corr 0.31297415494918823 with new token with corr 0.31297415494918823\n",
      "Replaced token 1179 with corr 0.2532772719860077 with new token with corr 0.2532772719860077\n",
      "Replaced token 1180 with corr 0.2625221908092499 with new token with corr 0.2625221610069275\n",
      "Replaced token 1181 with corr 0.2734266221523285 with new token with corr 0.2734266221523285\n",
      "Replaced token 1182 with corr 0.36977916955947876 with new token with corr 0.36977913975715637\n",
      "Replaced token 1183 with corr 0.24638915061950684 with new token with corr 0.24638916552066803\n",
      "Replaced token 1184 with corr 0.24807193875312805 with new token with corr 0.24807190895080566\n",
      "Replaced token 1185 with corr 0.22116556763648987 with new token with corr 0.22116558253765106\n",
      "Replaced token 1186 with corr 0.33706727623939514 with new token with corr 0.33706727623939514\n",
      "Replaced token 1187 with corr 0.2757948040962219 with new token with corr 0.2757948040962219\n",
      "Replaced token 1188 with corr 0.27787020802497864 with new token with corr 0.27787020802497864\n",
      "Replaced token 1189 with corr 0.3521553575992584 with new token with corr 0.35215532779693604\n",
      "Replaced token 1190 with corr 0.3138250708580017 with new token with corr 0.3138250708580017\n",
      "Replaced token 1191 with corr 0.268410861492157 with new token with corr 0.268410861492157\n",
      "Replaced token 1192 with corr 0.2874504327774048 with new token with corr 0.2874504327774048\n",
      "Replaced token 1193 with corr 0.2419762760400772 with new token with corr 0.2419762760400772\n",
      "Replaced token 1194 with corr 0.3110351860523224 with new token with corr 0.3110351860523224\n",
      "Replaced token 1195 with corr 0.2499489188194275 with new token with corr 0.2499489188194275\n",
      "Replaced token 1196 with corr 0.29063841700553894 with new token with corr 0.29063841700553894\n",
      "Replaced token 1197 with corr 0.28437498211860657 with new token with corr 0.28437501192092896\n",
      "Replaced token 1198 with corr 0.36702725291252136 with new token with corr 0.367027223110199\n",
      "Replaced token 1199 with corr 0.25874996185302734 with new token with corr 0.25874996185302734\n",
      "Replaced token 1200 with corr 0.1666034758090973 with new token with corr 0.2607845067977905\n",
      "Replaced token 1201 with corr 0.31352660059928894 with new token with corr 0.31352657079696655\n",
      "Replaced token 1202 with corr 0.12341270595788956 with new token with corr 0.22799696028232574\n",
      "Replaced token 1203 with corr 0.227500319480896 with new token with corr 0.227500319480896\n",
      "Replaced token 1204 with corr 0.2604811191558838 with new token with corr 0.2604811191558838\n",
      "Replaced token 1205 with corr 0.19409778714179993 with new token with corr 0.19409780204296112\n",
      "Replaced token 1206 with corr 0.314931184053421 with new token with corr 0.31493115425109863\n",
      "Replaced token 1207 with corr 0.3389151096343994 with new token with corr 0.3389151394367218\n",
      "Replaced token 1208 with corr 0.24060945212841034 with new token with corr 0.24060942232608795\n",
      "Replaced token 1209 with corr 0.2490919530391693 with new token with corr 0.24909193813800812\n",
      "Replaced token 1210 with corr 0.31130412220954895 with new token with corr 0.31130412220954895\n",
      "Replaced token 1211 with corr 0.29139575362205505 with new token with corr 0.29139578342437744\n",
      "Replaced token 1212 with corr 0.3213239014148712 with new token with corr 0.3213239014148712\n",
      "Replaced token 1213 with corr 0.12440091371536255 with new token with corr 0.23250730335712433\n",
      "Replaced token 1214 with corr 0.23830194771289825 with new token with corr 0.23830196261405945\n",
      "Replaced token 1215 with corr 0.26309698820114136 with new token with corr 0.26309698820114136\n",
      "Replaced token 1216 with corr 0.3034822940826416 with new token with corr 0.3034822940826416\n",
      "Replaced token 1217 with corr 0.3703498840332031 with new token with corr 0.3703498840332031\n",
      "Replaced token 1218 with corr 0.3338249623775482 with new token with corr 0.3338249623775482\n",
      "Replaced token 1219 with corr 0.27735888957977295 with new token with corr 0.27735891938209534\n",
      "Replaced token 1220 with corr 0.3676812946796417 with new token with corr 0.36768126487731934\n",
      "Replaced token 1221 with corr 0.32871001958847046 with new token with corr 0.32870998978614807\n",
      "Replaced token 1222 with corr 0.30588439106941223 with new token with corr 0.30588439106941223\n",
      "Replaced token 1223 with corr 0.2852208912372589 with new token with corr 0.2852208614349365\n",
      "Replaced token 1224 with corr 0.1334320306777954 with new token with corr 0.15117771923542023\n",
      "Replaced token 1225 with corr 0.23314793407917023 with new token with corr 0.23314794898033142\n",
      "Replaced token 1226 with corr 0.3358295261859894 with new token with corr 0.335829496383667\n",
      "Replaced token 1227 with corr 0.24837519228458405 with new token with corr 0.24837520718574524\n",
      "Replaced token 1228 with corr 0.24153190851211548 with new token with corr 0.24153193831443787\n",
      "Replaced token 1229 with corr 0.2740797698497772 with new token with corr 0.2740797698497772\n",
      "Replaced token 1230 with corr 0.35620877146720886 with new token with corr 0.35620880126953125\n",
      "Replaced token 1231 with corr 0.25908732414245605 with new token with corr 0.25908729434013367\n",
      "Replaced token 1232 with corr 0.29266518354415894 with new token with corr 0.29266518354415894\n",
      "Replaced token 1233 with corr 0.2647364139556885 with new token with corr 0.2647364139556885\n",
      "Replaced token 1234 with corr 0.25950607657432556 with new token with corr 0.25950607657432556\n",
      "Replaced token 1235 with corr 0.2556132972240448 with new token with corr 0.2556132972240448\n",
      "Replaced token 1236 with corr 0.2841786742210388 with new token with corr 0.28417864441871643\n",
      "Replaced token 1237 with corr 0.22294457256793976 with new token with corr 0.22294455766677856\n",
      "Replaced token 1238 with corr 0.2892836928367615 with new token with corr 0.2892836332321167\n",
      "Replaced token 1239 with corr 0.26463431119918823 with new token with corr 0.26463431119918823\n",
      "Replaced token 1240 with corr 0.1078638881444931 with new token with corr 0.255260169506073\n",
      "Replaced token 1241 with corr 0.2774861454963684 with new token with corr 0.2774861752986908\n",
      "Replaced token 1242 with corr 0.3433200716972351 with new token with corr 0.3433200716972351\n",
      "Replaced token 1243 with corr 0.3002166450023651 with new token with corr 0.3002166748046875\n",
      "Replaced token 1244 with corr 0.29562926292419434 with new token with corr 0.29562926292419434\n",
      "Replaced token 1245 with corr 0.32589074969291687 with new token with corr 0.32589077949523926\n",
      "Replaced token 1246 with corr 0.2629513144493103 with new token with corr 0.2629513144493103\n",
      "Replaced token 1247 with corr 0.2185843586921692 with new token with corr 0.21858437359333038\n",
      "Replaced token 1248 with corr 0.302461713552475 with new token with corr 0.302461713552475\n",
      "Replaced token 1249 with corr 0.312153697013855 with new token with corr 0.3121536672115326\n",
      "Replaced token 1250 with corr 0.3418409824371338 with new token with corr 0.3418410122394562\n",
      "Replaced token 1251 with corr 0.3303360939025879 with new token with corr 0.3303360939025879\n",
      "Replaced token 1252 with corr 0.3097248375415802 with new token with corr 0.3097248375415802\n",
      "Replaced token 1253 with corr 0.24859733879566193 with new token with corr 0.24859732389450073\n",
      "Replaced token 1254 with corr 0.2649906277656555 with new token with corr 0.2649906277656555\n",
      "Replaced token 1255 with corr 0.2585436701774597 with new token with corr 0.25854364037513733\n",
      "Replaced token 1256 with corr 0.11450932174921036 with new token with corr 0.1628721058368683\n",
      "Replaced token 1257 with corr 0.24227455258369446 with new token with corr 0.24227456748485565\n",
      "Replaced token 1258 with corr 0.32094240188598633 with new token with corr 0.32094240188598633\n",
      "Replaced token 1259 with corr 0.28454074263572693 with new token with corr 0.28454074263572693\n",
      "Replaced token 1260 with corr 0.3034639358520508 with new token with corr 0.30346396565437317\n",
      "Replaced token 1261 with corr 0.1271013468503952 with new token with corr 0.2786852717399597\n",
      "Replaced token 1262 with corr 0.3041747510433197 with new token with corr 0.3041747510433197\n",
      "Replaced token 1263 with corr 0.11042303591966629 with new token with corr 0.23266048729419708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1264 with corr 0.12782299518585205 with new token with corr 0.2583874464035034\n",
      "Replaced token 1265 with corr 0.09573346376419067 with new token with corr 0.1466173231601715\n",
      "Replaced token 1266 with corr 0.2825409173965454 with new token with corr 0.2825409173965454\n",
      "Replaced token 1267 with corr 0.21052010357379913 with new token with corr 0.21052010357379913\n",
      "Replaced token 1268 with corr 0.24358239769935608 with new token with corr 0.24358241260051727\n",
      "Replaced token 1269 with corr 0.18140371143817902 with new token with corr 0.18140371143817902\n",
      "Replaced token 1270 with corr 0.29759564995765686 with new token with corr 0.29759564995765686\n",
      "Replaced token 1271 with corr 0.25689035654067993 with new token with corr 0.25689035654067993\n",
      "Replaced token 1272 with corr 0.3107004463672638 with new token with corr 0.3107004165649414\n",
      "Replaced token 1273 with corr 0.2636753022670746 with new token with corr 0.2636753022670746\n",
      "Replaced token 1274 with corr 0.27112898230552673 with new token with corr 0.27112895250320435\n",
      "Replaced token 1275 with corr 0.3648710548877716 with new token with corr 0.364871084690094\n",
      "Replaced token 1276 with corr 0.29205456376075745 with new token with corr 0.29205453395843506\n",
      "Replaced token 1277 with corr 0.275508314371109 with new token with corr 0.275508314371109\n",
      "Replaced token 1278 with corr 0.24663136899471283 with new token with corr 0.24663135409355164\n",
      "Replaced token 1279 with corr 0.3216519355773926 with new token with corr 0.3216519355773926\n",
      "Replaced token 1280 with corr 0.25174394249916077 with new token with corr 0.25174394249916077\n",
      "Replaced token 1281 with corr 0.24084512889385223 with new token with corr 0.24084514379501343\n",
      "Replaced token 1282 with corr 0.2819851338863373 with new token with corr 0.2819851338863373\n",
      "Replaced token 1283 with corr 0.2587752044200897 with new token with corr 0.2587752342224121\n",
      "Replaced token 1284 with corr 0.08835963159799576 with new token with corr 0.19375872611999512\n",
      "Replaced token 1285 with corr 0.28436657786369324 with new token with corr 0.28436657786369324\n",
      "Replaced token 1286 with corr 0.26823726296424866 with new token with corr 0.26823726296424866\n",
      "Replaced token 1287 with corr 0.260865181684494 with new token with corr 0.260865181684494\n",
      "Replaced token 1288 with corr 0.3363501727581024 with new token with corr 0.3363501727581024\n",
      "Replaced token 1289 with corr 0.3094301223754883 with new token with corr 0.3094300925731659\n",
      "Replaced token 1290 with corr 0.2631147503852844 with new token with corr 0.2631147503852844\n",
      "Replaced token 1291 with corr 0.252188503742218 with new token with corr 0.252188503742218\n",
      "Replaced token 1292 with corr 0.26065704226493835 with new token with corr 0.26065707206726074\n",
      "Replaced token 1293 with corr 0.2519153952598572 with new token with corr 0.25191542506217957\n",
      "Replaced token 1294 with corr 0.11533965170383453 with new token with corr 0.1674846112728119\n",
      "Replaced token 1295 with corr 0.2911449074745178 with new token with corr 0.2911449074745178\n",
      "Replaced token 1296 with corr 0.2095443159341812 with new token with corr 0.20954430103302002\n",
      "Replaced token 1297 with corr 0.28668007254600525 with new token with corr 0.28668010234832764\n",
      "Replaced token 1298 with corr 0.3150424659252167 with new token with corr 0.31504249572753906\n",
      "Replaced token 1299 with corr 0.30289462208747864 with new token with corr 0.302894651889801\n",
      "Replaced token 1300 with corr 0.36991798877716064 with new token with corr 0.36991798877716064\n",
      "Replaced token 1301 with corr 0.3154200613498688 with new token with corr 0.3154200613498688\n",
      "Replaced token 1302 with corr 0.3633148968219757 with new token with corr 0.3633148968219757\n",
      "Replaced token 1303 with corr 0.2720903754234314 with new token with corr 0.2720903754234314\n",
      "Replaced token 1304 with corr 0.34705448150634766 with new token with corr 0.34705451130867004\n",
      "Replaced token 1305 with corr 0.2652350664138794 with new token with corr 0.2652350962162018\n",
      "Replaced token 1306 with corr 0.301003098487854 with new token with corr 0.3010030686855316\n",
      "Replaced token 1307 with corr 0.24104394018650055 with new token with corr 0.24104392528533936\n",
      "Replaced token 1308 with corr 0.2525675892829895 with new token with corr 0.2525675892829895\n",
      "Replaced token 1309 with corr 0.22722966969013214 with new token with corr 0.22722966969013214\n",
      "Replaced token 1310 with corr 0.30442366003990173 with new token with corr 0.30442366003990173\n",
      "Replaced token 1311 with corr 0.27808260917663574 with new token with corr 0.27808260917663574\n",
      "Replaced token 1312 with corr 0.22217407822608948 with new token with corr 0.22217406332492828\n",
      "Replaced token 1313 with corr 0.19086924195289612 with new token with corr 0.19086924195289612\n",
      "Replaced token 1314 with corr 0.33485251665115356 with new token with corr 0.33485251665115356\n",
      "Replaced token 1315 with corr 0.3336535394191742 with new token with corr 0.3336535096168518\n",
      "Replaced token 1316 with corr 0.2984721064567566 with new token with corr 0.298472136259079\n",
      "Replaced token 1317 with corr 0.3136570453643799 with new token with corr 0.3136570453643799\n",
      "Replaced token 1318 with corr 0.26407408714294434 with new token with corr 0.26407408714294434\n",
      "Replaced token 1319 with corr 0.34306612610816956 with new token with corr 0.34306612610816956\n",
      "Replaced token 1320 with corr 0.2720789909362793 with new token with corr 0.2720789909362793\n",
      "Replaced token 1321 with corr 0.28715330362319946 with new token with corr 0.28715330362319946\n",
      "Replaced token 1322 with corr 0.23836292326450348 with new token with corr 0.23836292326450348\n",
      "Replaced token 1323 with corr 0.2650372087955475 with new token with corr 0.2650372087955475\n",
      "Replaced token 1324 with corr 0.2932141125202179 with new token with corr 0.2932141125202179\n",
      "Replaced token 1325 with corr 0.2744310200214386 with new token with corr 0.2744310200214386\n",
      "Replaced token 1326 with corr 0.3048846423625946 with new token with corr 0.3048846125602722\n",
      "Replaced token 1327 with corr 0.30004778504371643 with new token with corr 0.30004775524139404\n",
      "Replaced token 1328 with corr 0.22769923508167267 with new token with corr 0.22769924998283386\n",
      "Replaced token 1329 with corr 0.2696199417114258 with new token with corr 0.2696199119091034\n",
      "Replaced token 1330 with corr 0.2798851430416107 with new token with corr 0.27988511323928833\n",
      "Replaced token 1331 with corr 0.26621270179748535 with new token with corr 0.26621270179748535\n",
      "Replaced token 1332 with corr 0.3362441956996918 with new token with corr 0.3362441658973694\n",
      "Replaced token 1333 with corr 0.3569912612438202 with new token with corr 0.3569912314414978\n",
      "Replaced token 1334 with corr 0.2920372188091278 with new token with corr 0.2920372486114502\n",
      "Replaced token 1335 with corr 0.25836026668548584 with new token with corr 0.25836026668548584\n",
      "Replaced token 1336 with corr 0.3003399670124054 with new token with corr 0.3003399968147278\n",
      "Replaced token 1337 with corr 0.3125499188899994 with new token with corr 0.3125499188899994\n",
      "Replaced token 1338 with corr 0.25563400983810425 with new token with corr 0.25563403964042664\n",
      "Replaced token 1339 with corr 0.2401357889175415 with new token with corr 0.2401358038187027\n",
      "Replaced token 1340 with corr 0.20821210741996765 with new token with corr 0.20821210741996765\n",
      "Replaced token 1341 with corr 0.1948922723531723 with new token with corr 0.1948922723531723\n",
      "Replaced token 1342 with corr 0.28663551807403564 with new token with corr 0.28663551807403564\n",
      "Replaced token 1343 with corr 0.38075146079063416 with new token with corr 0.38075146079063416\n",
      "Replaced token 1344 with corr 0.3478289544582367 with new token with corr 0.3478289544582367\n",
      "Replaced token 1345 with corr 0.27667462825775146 with new token with corr 0.27667462825775146\n",
      "Replaced token 1346 with corr 0.25715410709381104 with new token with corr 0.2571541368961334\n",
      "Replaced token 1347 with corr 0.2366832196712494 with new token with corr 0.23668323457241058\n",
      "Replaced token 1348 with corr 0.3913652002811432 with new token with corr 0.3913652002811432\n",
      "Replaced token 1349 with corr 0.08382277935743332 with new token with corr 0.23777472972869873\n",
      "Replaced token 1350 with corr 0.28684964776039124 with new token with corr 0.28684961795806885\n",
      "Replaced token 1351 with corr 0.07137275487184525 with new token with corr 0.246667742729187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1352 with corr 0.11622028797864914 with new token with corr 0.1512851119041443\n",
      "Replaced token 1353 with corr 0.2903963327407837 with new token with corr 0.2903963327407837\n",
      "Replaced token 1354 with corr 0.15947914123535156 with new token with corr 0.15947912633419037\n",
      "Replaced token 1355 with corr 0.2852882146835327 with new token with corr 0.2852882146835327\n",
      "Replaced token 1356 with corr 0.2771128714084625 with new token with corr 0.2771128714084625\n",
      "Replaced token 1357 with corr 0.10285451263189316 with new token with corr 0.1462312936782837\n",
      "Replaced token 1358 with corr 0.21284396946430206 with new token with corr 0.21284395456314087\n",
      "Replaced token 1359 with corr 0.2884562909603119 with new token with corr 0.2884562611579895\n",
      "Replaced token 1360 with corr 0.1986403912305832 with new token with corr 0.1986403912305832\n",
      "Replaced token 1361 with corr 0.3236064016819 with new token with corr 0.3236064016819\n",
      "Replaced token 1362 with corr 0.09793490171432495 with new token with corr 0.2076321393251419\n",
      "Replaced token 1363 with corr 0.07055403292179108 with new token with corr 0.20594865083694458\n",
      "Replaced token 1364 with corr 0.3027653992176056 with new token with corr 0.3027653992176056\n",
      "Replaced token 1365 with corr 0.1766785830259323 with new token with corr 0.1766785830259323\n",
      "Replaced token 1366 with corr 0.265624076128006 with new token with corr 0.265624076128006\n",
      "Replaced token 1367 with corr 0.21838867664337158 with new token with corr 0.21838869154453278\n",
      "Replaced token 1368 with corr 0.09996118396520615 with new token with corr 0.2627990245819092\n",
      "Replaced token 1369 with corr 0.36504462361335754 with new token with corr 0.36504462361335754\n",
      "Replaced token 1370 with corr 0.2445414662361145 with new token with corr 0.2445414662361145\n",
      "Replaced token 1371 with corr 0.29772135615348816 with new token with corr 0.29772132635116577\n",
      "Replaced token 1372 with corr 0.27654990553855896 with new token with corr 0.27654990553855896\n",
      "Replaced token 1373 with corr 0.09707263112068176 with new token with corr 0.22873805463314056\n",
      "Replaced token 1374 with corr 0.3248628079891205 with new token with corr 0.3248628079891205\n",
      "Replaced token 1375 with corr 0.25211259722709656 with new token with corr 0.25211259722709656\n",
      "Replaced token 1376 with corr 0.26774129271507263 with new token with corr 0.267741322517395\n",
      "Replaced token 1377 with corr 0.2949063181877136 with new token with corr 0.2949063181877136\n",
      "Replaced token 1378 with corr 0.32931238412857056 with new token with corr 0.32931238412857056\n",
      "Replaced token 1379 with corr 0.30592551827430725 with new token with corr 0.30592548847198486\n",
      "Replaced token 1380 with corr 0.3114556670188904 with new token with corr 0.31145569682121277\n",
      "Replaced token 1381 with corr 0.2815975844860077 with new token with corr 0.2815975546836853\n",
      "Replaced token 1382 with corr 0.31718990206718445 with new token with corr 0.31718987226486206\n",
      "Replaced token 1383 with corr 0.2361564338207245 with new token with corr 0.2361564189195633\n",
      "Replaced token 1384 with corr 0.28685256838798523 with new token with corr 0.28685253858566284\n",
      "Replaced token 1385 with corr 0.2385278046131134 with new token with corr 0.23852777481079102\n",
      "Replaced token 1386 with corr 0.2848924696445465 with new token with corr 0.2848924696445465\n",
      "Replaced token 1387 with corr 0.22461912035942078 with new token with corr 0.22461912035942078\n",
      "Replaced token 1388 with corr 0.24366888403892517 with new token with corr 0.24366888403892517\n",
      "Replaced token 1389 with corr 0.2817305028438568 with new token with corr 0.2817305028438568\n",
      "Replaced token 1390 with corr 0.25553807616233826 with new token with corr 0.25553810596466064\n",
      "Replaced token 1391 with corr 0.25648221373558044 with new token with corr 0.25648221373558044\n",
      "Replaced token 1392 with corr 0.2844226360321045 with new token with corr 0.2844226360321045\n",
      "Replaced token 1393 with corr 0.31869783997535706 with new token with corr 0.31869781017303467\n",
      "Replaced token 1394 with corr 0.12385053932666779 with new token with corr 0.2960706353187561\n",
      "Replaced token 1395 with corr 0.2867746949195862 with new token with corr 0.2867746949195862\n",
      "Replaced token 1396 with corr 0.2507709562778473 with new token with corr 0.2507709860801697\n",
      "Replaced token 1397 with corr 0.27987369894981384 with new token with corr 0.27987369894981384\n",
      "Replaced token 1398 with corr 0.26428091526031494 with new token with corr 0.26428091526031494\n",
      "Replaced token 1399 with corr 0.27864959836006165 with new token with corr 0.27864959836006165\n",
      "Replaced token 1400 with corr 0.2369937300682068 with new token with corr 0.23699374496936798\n",
      "Replaced token 1401 with corr 0.28485795855522156 with new token with corr 0.28485798835754395\n",
      "Replaced token 1402 with corr 0.28528982400894165 with new token with corr 0.28528982400894165\n",
      "Replaced token 1403 with corr 0.25790366530418396 with new token with corr 0.2579036355018616\n",
      "Replaced token 1404 with corr 0.1662689745426178 with new token with corr 0.1662689745426178\n",
      "Replaced token 1405 with corr 0.348282128572464 with new token with corr 0.3482820987701416\n",
      "Replaced token 1406 with corr 0.30605581402778625 with new token with corr 0.30605581402778625\n",
      "Replaced token 1407 with corr 0.23021607100963593 with new token with corr 0.23021607100963593\n",
      "Replaced token 1408 with corr 0.3210277557373047 with new token with corr 0.3210277855396271\n",
      "Replaced token 1409 with corr 0.26163914799690247 with new token with corr 0.26163914799690247\n",
      "Replaced token 1410 with corr 0.3251500725746155 with new token with corr 0.3251500427722931\n",
      "Replaced token 1411 with corr 0.09213609993457794 with new token with corr 0.2126815766096115\n",
      "Replaced token 1412 with corr 0.30496934056282043 with new token with corr 0.3049693703651428\n",
      "Replaced token 1413 with corr 0.2243054360151291 with new token with corr 0.2243054360151291\n",
      "Replaced token 1414 with corr 0.31556087732315063 with new token with corr 0.31556087732315063\n",
      "Replaced token 1415 with corr 0.1661294549703598 with new token with corr 0.166129469871521\n",
      "Replaced token 1416 with corr 0.28213632106781006 with new token with corr 0.28213629126548767\n",
      "Replaced token 1417 with corr 0.24701426923274994 with new token with corr 0.24701428413391113\n",
      "Replaced token 1418 with corr 0.08426766842603683 with new token with corr 0.1918579488992691\n",
      "Replaced token 1419 with corr 0.2902751564979553 with new token with corr 0.2902751863002777\n",
      "Replaced token 1420 with corr 0.3179941177368164 with new token with corr 0.3179941177368164\n",
      "Replaced token 1421 with corr 0.3093410134315491 with new token with corr 0.30934104323387146\n",
      "Replaced token 1422 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 1423 with corr 0.2531101405620575 with new token with corr 0.2531101107597351\n",
      "Replaced token 1424 with corr 0.2699086666107178 with new token with corr 0.26990869641304016\n",
      "Replaced token 1425 with corr 0.26447793841362 with new token with corr 0.26447793841362\n",
      "Replaced token 1426 with corr 0.31312957406044006 with new token with corr 0.31312957406044006\n",
      "Replaced token 1427 with corr 0.31429150700569153 with new token with corr 0.31429147720336914\n",
      "Replaced token 1428 with corr 0.3062669634819031 with new token with corr 0.3062669336795807\n",
      "Replaced token 1429 with corr 0.24017976224422455 with new token with corr 0.24017976224422455\n",
      "Replaced token 1430 with corr 0.3428552448749542 with new token with corr 0.3428552448749542\n",
      "Replaced token 1431 with corr 0.28362196683883667 with new token with corr 0.28362196683883667\n",
      "Replaced token 1432 with corr 0.23734790086746216 with new token with corr 0.23734790086746216\n",
      "Replaced token 1433 with corr 0.35224485397338867 with new token with corr 0.3522448241710663\n",
      "Replaced token 1434 with corr 0.3301384449005127 with new token with corr 0.3301384449005127\n",
      "Replaced token 1435 with corr 0.26382914185523987 with new token with corr 0.26382914185523987\n",
      "Replaced token 1436 with corr 0.214265376329422 with new token with corr 0.2142653614282608\n",
      "Replaced token 1437 with corr 0.2476053386926651 with new token with corr 0.2476053535938263\n",
      "Replaced token 1438 with corr 0.26696985960006714 with new token with corr 0.26696982979774475\n",
      "Replaced token 1439 with corr 0.2830933928489685 with new token with corr 0.2830933928489685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1440 with corr 0.3574952483177185 with new token with corr 0.3574952483177185\n",
      "Replaced token 1441 with corr 0.2940201163291931 with new token with corr 0.2940201163291931\n",
      "Replaced token 1442 with corr 0.23025763034820557 with new token with corr 0.23025761544704437\n",
      "Replaced token 1443 with corr 0.31838828325271606 with new token with corr 0.3183882534503937\n",
      "Replaced token 1444 with corr 0.31953009963035583 with new token with corr 0.3195301294326782\n",
      "Replaced token 1445 with corr 0.30433687567710876 with new token with corr 0.30433687567710876\n",
      "Replaced token 1446 with corr 0.2938019633293152 with new token with corr 0.2938019633293152\n",
      "Replaced token 1447 with corr 0.30418604612350464 with new token with corr 0.304186075925827\n",
      "Replaced token 1448 with corr 0.2822645902633667 with new token with corr 0.2822645902633667\n",
      "Replaced token 1449 with corr 0.2961947023868561 with new token with corr 0.2961947023868561\n",
      "Replaced token 1450 with corr 0.098807692527771 with new token with corr 0.15420272946357727\n",
      "Replaced token 1451 with corr 0.24450691044330597 with new token with corr 0.24450691044330597\n",
      "Replaced token 1452 with corr 0.2773374915122986 with new token with corr 0.2773374915122986\n",
      "Replaced token 1453 with corr 0.35638776421546936 with new token with corr 0.3563877046108246\n",
      "Replaced token 1454 with corr 0.30311501026153564 with new token with corr 0.30311498045921326\n",
      "Replaced token 1455 with corr 0.3218454420566559 with new token with corr 0.3218454420566559\n",
      "Replaced token 1456 with corr 0.2931331992149353 with new token with corr 0.2931331992149353\n",
      "Replaced token 1457 with corr 0.3562907576560974 with new token with corr 0.3562907576560974\n",
      "Replaced token 1458 with corr 0.30157405138015747 with new token with corr 0.30157405138015747\n",
      "Replaced token 1459 with corr 0.246410071849823 with new token with corr 0.2464100867509842\n",
      "Replaced token 1460 with corr 0.34476450085639954 with new token with corr 0.3447645306587219\n",
      "Replaced token 1461 with corr 0.32153818011283875 with new token with corr 0.32153818011283875\n",
      "Replaced token 1462 with corr 0.26094090938568115 with new token with corr 0.26094093918800354\n",
      "Replaced token 1463 with corr 0.2381570190191269 with new token with corr 0.2381570190191269\n",
      "Replaced token 1464 with corr 0.2781299352645874 with new token with corr 0.278129905462265\n",
      "Replaced token 1465 with corr 0.30149343609809875 with new token with corr 0.30149343609809875\n",
      "Replaced token 1466 with corr 0.25751152634620667 with new token with corr 0.25751155614852905\n",
      "Replaced token 1467 with corr 0.2708076238632202 with new token with corr 0.2708076238632202\n",
      "Replaced token 1468 with corr 0.32233330607414246 with new token with corr 0.32233330607414246\n",
      "Replaced token 1469 with corr 0.31038951873779297 with new token with corr 0.31038951873779297\n",
      "Replaced token 1470 with corr 0.30206745862960815 with new token with corr 0.30206745862960815\n",
      "Replaced token 1471 with corr 0.19448216259479523 with new token with corr 0.19448216259479523\n",
      "Replaced token 1472 with corr 0.2639434039592743 with new token with corr 0.2639434337615967\n",
      "Replaced token 1473 with corr 0.30136775970458984 with new token with corr 0.30136778950691223\n",
      "Replaced token 1474 with corr 0.24993287026882172 with new token with corr 0.2499328851699829\n",
      "Replaced token 1475 with corr 0.24110481142997742 with new token with corr 0.24110479652881622\n",
      "Replaced token 1476 with corr 0.34884482622146606 with new token with corr 0.34884482622146606\n",
      "Replaced token 1477 with corr 0.3068949580192566 with new token with corr 0.3068949580192566\n",
      "Replaced token 1478 with corr 0.31525352597236633 with new token with corr 0.31525352597236633\n",
      "Replaced token 1479 with corr 0.2667441964149475 with new token with corr 0.2667441964149475\n",
      "Replaced token 1480 with corr 0.2720317840576172 with new token with corr 0.2720317840576172\n",
      "Replaced token 1481 with corr 0.24035239219665527 with new token with corr 0.24035240709781647\n",
      "Replaced token 1482 with corr 0.29011479020118713 with new token with corr 0.29011476039886475\n",
      "Replaced token 1483 with corr 0.34322917461395264 with new token with corr 0.34322911500930786\n",
      "Replaced token 1484 with corr 0.36865463852882385 with new token with corr 0.36865463852882385\n",
      "Replaced token 1485 with corr 0.2553485333919525 with new token with corr 0.2553485333919525\n",
      "Replaced token 1486 with corr 0.3082188069820404 with new token with corr 0.3082188069820404\n",
      "Replaced token 1487 with corr 0.09526169300079346 with new token with corr 0.15965573489665985\n",
      "Replaced token 1488 with corr 0.2312563806772232 with new token with corr 0.2312563806772232\n",
      "Replaced token 1489 with corr 0.1247924417257309 with new token with corr 0.33324137330055237\n",
      "Replaced token 1490 with corr 0.30854082107543945 with new token with corr 0.30854082107543945\n",
      "Replaced token 1491 with corr 0.24792051315307617 with new token with corr 0.24792051315307617\n",
      "Replaced token 1492 with corr 0.09415073692798615 with new token with corr 0.16341851651668549\n",
      "Replaced token 1493 with corr 0.12412174046039581 with new token with corr 0.22170911729335785\n",
      "Replaced token 1494 with corr 0.22840456664562225 with new token with corr 0.22840456664562225\n",
      "Replaced token 1495 with corr 0.2758498191833496 with new token with corr 0.2758498191833496\n",
      "Replaced token 1496 with corr 0.27247729897499084 with new token with corr 0.27247729897499084\n",
      "Replaced token 1497 with corr 0.34953388571739197 with new token with corr 0.3495338559150696\n",
      "Replaced token 1498 with corr 0.25774484872817993 with new token with corr 0.2577448785305023\n",
      "Replaced token 1499 with corr 0.11585573852062225 with new token with corr 0.15386910736560822\n",
      "Replaced token 1500 with corr 0.32206714153289795 with new token with corr 0.32206714153289795\n",
      "Replaced token 1501 with corr 0.3097856044769287 with new token with corr 0.3097856044769287\n",
      "Replaced token 1502 with corr 0.2502279579639435 with new token with corr 0.2502279281616211\n",
      "Replaced token 1503 with corr 0.29561543464660645 with new token with corr 0.29561546444892883\n",
      "Replaced token 1504 with corr 0.3179675042629242 with new token with corr 0.3179675042629242\n",
      "Replaced token 1505 with corr 0.3122961223125458 with new token with corr 0.31229615211486816\n",
      "Replaced token 1506 with corr 0.2761838138103485 with new token with corr 0.2761838138103485\n",
      "Replaced token 1507 with corr 0.25270944833755493 with new token with corr 0.25270941853523254\n",
      "Replaced token 1508 with corr 0.29185932874679565 with new token with corr 0.29185932874679565\n",
      "Replaced token 1509 with corr 0.33045494556427 with new token with corr 0.33045494556427\n",
      "Replaced token 1510 with corr 0.15614140033721924 with new token with corr 0.15614140033721924\n",
      "Replaced token 1511 with corr 0.31230616569519043 with new token with corr 0.31230616569519043\n",
      "Replaced token 1512 with corr 0.2610754668712616 with new token with corr 0.2610754668712616\n",
      "Replaced token 1513 with corr 0.25853776931762695 with new token with corr 0.25853776931762695\n",
      "Replaced token 1514 with corr 0.12196523696184158 with new token with corr 0.23732560873031616\n",
      "Replaced token 1515 with corr 0.30379369854927063 with new token with corr 0.30379369854927063\n",
      "Replaced token 1516 with corr 0.34286418557167053 with new token with corr 0.34286415576934814\n",
      "Replaced token 1517 with corr 0.34598326683044434 with new token with corr 0.34598323702812195\n",
      "Replaced token 1518 with corr 0.20932385325431824 with new token with corr 0.20932385325431824\n",
      "Replaced token 1519 with corr 0.24368910491466522 with new token with corr 0.24368911981582642\n",
      "Replaced token 1520 with corr 0.33298227190971375 with new token with corr 0.33298224210739136\n",
      "Replaced token 1521 with corr 0.31002211570739746 with new token with corr 0.31002211570739746\n",
      "Replaced token 1522 with corr 0.35920998454093933 with new token with corr 0.35920998454093933\n",
      "Replaced token 1523 with corr 0.2930919826030731 with new token with corr 0.2930919826030731\n",
      "Replaced token 1524 with corr 0.33661946654319763 with new token with corr 0.33661943674087524\n",
      "Replaced token 1525 with corr 0.24926482141017914 with new token with corr 0.24926480650901794\n",
      "Replaced token 1526 with corr 0.3472011983394623 with new token with corr 0.3472011685371399\n",
      "Replaced token 1527 with corr 0.31664514541625977 with new token with corr 0.31664514541625977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1528 with corr 0.3264705240726471 with new token with corr 0.3264705240726471\n",
      "Replaced token 1529 with corr 0.30099743604660034 with new token with corr 0.30099740624427795\n",
      "Replaced token 1530 with corr 0.32316726446151733 with new token with corr 0.32316726446151733\n",
      "Replaced token 1531 with corr 0.29223769903182983 with new token with corr 0.29223766922950745\n",
      "Replaced token 1532 with corr 0.2691344618797302 with new token with corr 0.26913443207740784\n",
      "Replaced token 1533 with corr 0.26247933506965637 with new token with corr 0.262479305267334\n",
      "Replaced token 1534 with corr 0.233734130859375 with new token with corr 0.233734130859375\n",
      "Replaced token 1535 with corr 0.12499857693910599 with new token with corr 0.1514664590358734\n",
      "Replaced token 1536 with corr 0.257733553647995 with new token with corr 0.257733553647995\n",
      "Replaced token 1537 with corr 0.27733683586120605 with new token with corr 0.27733680605888367\n",
      "Replaced token 1538 with corr 0.3316771686077118 with new token with corr 0.33167722821235657\n",
      "Replaced token 1539 with corr 0.3722340166568756 with new token with corr 0.3722339868545532\n",
      "Replaced token 1540 with corr 0.21233037114143372 with new token with corr 0.21233037114143372\n",
      "Replaced token 1541 with corr 0.31869080662727356 with new token with corr 0.31869083642959595\n",
      "Replaced token 1542 with corr 0.2523091435432434 with new token with corr 0.252309113740921\n",
      "Replaced token 1543 with corr 0.2790279984474182 with new token with corr 0.2790279686450958\n",
      "Replaced token 1544 with corr 0.2632332146167755 with new token with corr 0.2632332146167755\n",
      "Replaced token 1545 with corr 0.2872934639453888 with new token with corr 0.2872934937477112\n",
      "Replaced token 1546 with corr 0.29490190744400024 with new token with corr 0.29490190744400024\n",
      "Replaced token 1547 with corr 0.22767971456050873 with new token with corr 0.22767974436283112\n",
      "Replaced token 1548 with corr 0.2814459204673767 with new token with corr 0.2814459204673767\n",
      "Replaced token 1549 with corr 0.2765718996524811 with new token with corr 0.2765718698501587\n",
      "Replaced token 1550 with corr 0.2595529854297638 with new token with corr 0.2595529556274414\n",
      "Replaced token 1551 with corr 0.2709994912147522 with new token with corr 0.2709995210170746\n",
      "Replaced token 1552 with corr 0.27156972885131836 with new token with corr 0.27156972885131836\n",
      "Replaced token 1553 with corr 0.22850751876831055 with new token with corr 0.22850750386714935\n",
      "Replaced token 1554 with corr 0.346832275390625 with new token with corr 0.3468322455883026\n",
      "Replaced token 1555 with corr 0.30301281809806824 with new token with corr 0.30301278829574585\n",
      "Replaced token 1556 with corr 0.3214470148086548 with new token with corr 0.3214469850063324\n",
      "Replaced token 1557 with corr 0.2513244152069092 with new token with corr 0.2513244152069092\n",
      "Replaced token 1558 with corr 0.28821301460266113 with new token with corr 0.2882130444049835\n",
      "Replaced token 1559 with corr 0.39210301637649536 with new token with corr 0.392102986574173\n",
      "Replaced token 1560 with corr 0.3118358850479126 with new token with corr 0.3118358552455902\n",
      "Replaced token 1561 with corr 0.2358042299747467 with new token with corr 0.2358042150735855\n",
      "Replaced token 1562 with corr 0.24959638714790344 with new token with corr 0.24959640204906464\n",
      "Replaced token 1563 with corr 0.3271556794643402 with new token with corr 0.3271557092666626\n",
      "Replaced token 1564 with corr 0.3083542585372925 with new token with corr 0.30835428833961487\n",
      "Replaced token 1565 with corr 0.32541507482528687 with new token with corr 0.3254150450229645\n",
      "Replaced token 1566 with corr 0.2602280080318451 with new token with corr 0.2602280080318451\n",
      "Replaced token 1567 with corr 0.2819870412349701 with new token with corr 0.2819870114326477\n",
      "Replaced token 1568 with corr 0.27175667881965637 with new token with corr 0.27175667881965637\n",
      "Replaced token 1569 with corr 0.26324230432510376 with new token with corr 0.26324227452278137\n",
      "Replaced token 1570 with corr 0.31748151779174805 with new token with corr 0.31748148798942566\n",
      "Replaced token 1571 with corr 0.33832207322120667 with new token with corr 0.33832210302352905\n",
      "Replaced token 1572 with corr 0.1058175265789032 with new token with corr 0.2089463174343109\n",
      "Replaced token 1573 with corr 0.13325977325439453 with new token with corr 0.17801524698734283\n",
      "Replaced token 1574 with corr 0.15179938077926636 with new token with corr 0.1811733841896057\n",
      "Replaced token 1575 with corr 0.2775035500526428 with new token with corr 0.2775035500526428\n",
      "Replaced token 1576 with corr 0.316942036151886 with new token with corr 0.316942036151886\n",
      "Replaced token 1577 with corr 0.3236774206161499 with new token with corr 0.3236774206161499\n",
      "Replaced token 1578 with corr 0.2618856132030487 with new token with corr 0.2618856132030487\n",
      "Replaced token 1579 with corr 0.286204993724823 with new token with corr 0.2862050235271454\n",
      "Replaced token 1580 with corr 0.2931859791278839 with new token with corr 0.2931859791278839\n",
      "Replaced token 1581 with corr 0.3473828136920929 with new token with corr 0.3473828136920929\n",
      "Replaced token 1582 with corr 0.3566684424877167 with new token with corr 0.3566684126853943\n",
      "Replaced token 1583 with corr 0.2460666447877884 with new token with corr 0.2460666447877884\n",
      "Replaced token 1584 with corr 0.25420552492141724 with new token with corr 0.25420552492141724\n",
      "Replaced token 1585 with corr 0.24426127970218658 with new token with corr 0.24426130950450897\n",
      "Replaced token 1586 with corr 0.22407221794128418 with new token with corr 0.22407221794128418\n",
      "Replaced token 1587 with corr 0.26506108045578003 with new token with corr 0.26506108045578003\n",
      "Replaced token 1588 with corr 0.3425000309944153 with new token with corr 0.34250006079673767\n",
      "Replaced token 1589 with corr 0.25574883818626404 with new token with corr 0.25574883818626404\n",
      "Replaced token 1590 with corr 0.2538883090019226 with new token with corr 0.2538883090019226\n",
      "Replaced token 1591 with corr 0.33095914125442505 with new token with corr 0.33095914125442505\n",
      "Replaced token 1592 with corr 0.19074557721614838 with new token with corr 0.19074559211730957\n",
      "Replaced token 1593 with corr 0.3258284628391266 with new token with corr 0.325828492641449\n",
      "Replaced token 1594 with corr 0.33087530732154846 with new token with corr 0.3308752775192261\n",
      "Replaced token 1595 with corr 0.2927840054035187 with new token with corr 0.29278403520584106\n",
      "Replaced token 1596 with corr 0.3128633499145508 with new token with corr 0.31286337971687317\n",
      "Replaced token 1597 with corr 0.3189622163772583 with new token with corr 0.3189622461795807\n",
      "Replaced token 1598 with corr 0.26231011748313904 with new token with corr 0.26231008768081665\n",
      "Replaced token 1599 with corr 0.304768443107605 with new token with corr 0.304768443107605\n",
      "Replaced token 1600 with corr 0.2321825623512268 with new token with corr 0.232182577252388\n",
      "Replaced token 1601 with corr 0.2971112132072449 with new token with corr 0.2971111834049225\n",
      "Replaced token 1602 with corr 0.3346799910068512 with new token with corr 0.3346800208091736\n",
      "Replaced token 1603 with corr 0.3034900724887848 with new token with corr 0.3034900724887848\n",
      "Replaced token 1604 with corr 0.3623088002204895 with new token with corr 0.3623087704181671\n",
      "Replaced token 1605 with corr 0.3075210452079773 with new token with corr 0.3075210154056549\n",
      "Replaced token 1606 with corr 0.29788365960121155 with new token with corr 0.29788365960121155\n",
      "Replaced token 1607 with corr 0.30043667554855347 with new token with corr 0.30043667554855347\n",
      "Replaced token 1608 with corr 0.27925607562065125 with new token with corr 0.27925610542297363\n",
      "Replaced token 1609 with corr 0.2735860049724579 with new token with corr 0.2735859751701355\n",
      "Replaced token 1610 with corr 0.3350563645362854 with new token with corr 0.3350563645362854\n",
      "Replaced token 1611 with corr 0.29479148983955383 with new token with corr 0.29479146003723145\n",
      "Replaced token 1612 with corr 0.27057892084121704 with new token with corr 0.27057895064353943\n",
      "Replaced token 1613 with corr 0.2740519940853119 with new token with corr 0.2740520238876343\n",
      "Replaced token 1614 with corr 0.3153383433818817 with new token with corr 0.3153383731842041\n",
      "Replaced token 1615 with corr 0.27397194504737854 with new token with corr 0.2739719748497009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1616 with corr 0.24453149735927582 with new token with corr 0.24453149735927582\n",
      "Replaced token 1617 with corr 0.12679360806941986 with new token with corr 0.1484745293855667\n",
      "Replaced token 1618 with corr 0.23646844923496246 with new token with corr 0.23646844923496246\n",
      "Replaced token 1619 with corr 0.2565123736858368 with new token with corr 0.2565123736858368\n",
      "Replaced token 1620 with corr 0.3189677596092224 with new token with corr 0.3189677596092224\n",
      "Replaced token 1621 with corr 0.30465590953826904 with new token with corr 0.30465587973594666\n",
      "Replaced token 1622 with corr 0.32409781217575073 with new token with corr 0.32409781217575073\n",
      "Replaced token 1623 with corr 0.28403571248054504 with new token with corr 0.28403571248054504\n",
      "Replaced token 1624 with corr 0.29400739073753357 with new token with corr 0.29400742053985596\n",
      "Replaced token 1625 with corr 0.23527584969997406 with new token with corr 0.23527583479881287\n",
      "Replaced token 1626 with corr 0.3288717269897461 with new token with corr 0.3288717567920685\n",
      "Replaced token 1627 with corr 0.26737180352211 with new token with corr 0.2673718333244324\n",
      "Replaced token 1628 with corr 0.3313246965408325 with new token with corr 0.3313247263431549\n",
      "Replaced token 1629 with corr 0.2658188045024872 with new token with corr 0.2658188045024872\n",
      "Replaced token 1630 with corr 0.14292779564857483 with new token with corr 0.21474862098693848\n",
      "Replaced token 1631 with corr 0.22730550169944763 with new token with corr 0.22730550169944763\n",
      "Replaced token 1632 with corr 0.31252944469451904 with new token with corr 0.31252941489219666\n",
      "Replaced token 1633 with corr 0.28494390845298767 with new token with corr 0.28494390845298767\n",
      "Replaced token 1634 with corr 0.2559632360935211 with new token with corr 0.2559632360935211\n",
      "Replaced token 1635 with corr 0.299514502286911 with new token with corr 0.2995144724845886\n",
      "Replaced token 1636 with corr 0.25060880184173584 with new token with corr 0.25060877203941345\n",
      "Replaced token 1637 with corr 0.2970682382583618 with new token with corr 0.2970682382583618\n",
      "Replaced token 1638 with corr 0.29201969504356384 with new token with corr 0.29201969504356384\n",
      "Replaced token 1639 with corr 0.2665337324142456 with new token with corr 0.2665337324142456\n",
      "Replaced token 1640 with corr 0.31473079323768616 with new token with corr 0.31473082304000854\n",
      "Replaced token 1641 with corr 0.2983607053756714 with new token with corr 0.2983607053756714\n",
      "Replaced token 1642 with corr 0.2603406608104706 with new token with corr 0.2603406608104706\n",
      "Replaced token 1643 with corr 0.39843055605888367 with new token with corr 0.39843055605888367\n",
      "Replaced token 1644 with corr 0.344120055437088 with new token with corr 0.3441200256347656\n",
      "Replaced token 1645 with corr 0.14035627245903015 with new token with corr 0.14863604307174683\n",
      "Replaced token 1646 with corr 0.23899126052856445 with new token with corr 0.23899126052856445\n",
      "Replaced token 1647 with corr 0.3389991819858551 with new token with corr 0.3389991819858551\n",
      "Replaced token 1648 with corr 0.30798593163490295 with new token with corr 0.30798593163490295\n",
      "Replaced token 1649 with corr 0.18447597324848175 with new token with corr 0.18447597324848175\n",
      "Replaced token 1650 with corr 0.36900386214256287 with new token with corr 0.36900386214256287\n",
      "Replaced token 1651 with corr 0.34389162063598633 with new token with corr 0.34389162063598633\n",
      "Replaced token 1652 with corr 0.30257919430732727 with new token with corr 0.30257922410964966\n",
      "Replaced token 1653 with corr 0.33322542905807495 with new token with corr 0.33322542905807495\n",
      "Replaced token 1654 with corr 0.37040168046951294 with new token with corr 0.3704017102718353\n",
      "Replaced token 1655 with corr 0.3083488643169403 with new token with corr 0.3083488345146179\n",
      "Replaced token 1656 with corr 0.3089355230331421 with new token with corr 0.3089355528354645\n",
      "Replaced token 1657 with corr 0.3158467710018158 with new token with corr 0.3158468008041382\n",
      "Replaced token 1658 with corr 0.23301279544830322 with new token with corr 0.23301281034946442\n",
      "Replaced token 1659 with corr 0.24168555438518524 with new token with corr 0.24168555438518524\n",
      "Replaced token 1660 with corr 0.2403554618358612 with new token with corr 0.2403554469347\n",
      "Replaced token 1661 with corr 0.30114734172821045 with new token with corr 0.30114734172821045\n",
      "Replaced token 1662 with corr 0.30466121435165405 with new token with corr 0.30466118454933167\n",
      "Replaced token 1663 with corr 0.3555120825767517 with new token with corr 0.3555120527744293\n",
      "Replaced token 1664 with corr 0.31818827986717224 with new token with corr 0.318188339471817\n",
      "Replaced token 1665 with corr 0.3412315249443054 with new token with corr 0.3412315547466278\n",
      "Replaced token 1666 with corr 0.35368120670318604 with new token with corr 0.3536812365055084\n",
      "Replaced token 1667 with corr 0.35508644580841064 with new token with corr 0.35508644580841064\n",
      "Replaced token 1668 with corr 0.11640621721744537 with new token with corr 0.13924497365951538\n",
      "Replaced token 1669 with corr 0.3511323034763336 with new token with corr 0.3511323034763336\n",
      "Replaced token 1670 with corr 0.32925131916999817 with new token with corr 0.32925131916999817\n",
      "Replaced token 1671 with corr 0.26766955852508545 with new token with corr 0.26766952872276306\n",
      "Replaced token 1672 with corr 0.2773377597332001 with new token with corr 0.2773377597332001\n",
      "Replaced token 1673 with corr 0.32817763090133667 with new token with corr 0.3281775712966919\n",
      "Replaced token 1674 with corr 0.10315745323896408 with new token with corr 0.2663765847682953\n",
      "Replaced token 1675 with corr 0.22170239686965942 with new token with corr 0.22170241177082062\n",
      "Replaced token 1676 with corr 0.2556067407131195 with new token with corr 0.2556067407131195\n",
      "Replaced token 1677 with corr 0.24525626003742218 with new token with corr 0.24525626003742218\n",
      "Replaced token 1678 with corr 0.12826283276081085 with new token with corr 0.24345025420188904\n",
      "Replaced token 1679 with corr 0.24130406975746155 with new token with corr 0.24130406975746155\n",
      "Replaced token 1680 with corr 0.3453759551048279 with new token with corr 0.3453759551048279\n",
      "Replaced token 1681 with corr 0.22638286650180817 with new token with corr 0.22638286650180817\n",
      "Replaced token 1682 with corr 0.32624486088752747 with new token with corr 0.3262448310852051\n",
      "Replaced token 1683 with corr 0.11616560071706772 with new token with corr 0.1530694216489792\n",
      "Replaced token 1684 with corr 0.2692159414291382 with new token with corr 0.2692159116268158\n",
      "Replaced token 1685 with corr 0.28496208786964417 with new token with corr 0.28496211767196655\n",
      "Replaced token 1686 with corr 0.2494477927684784 with new token with corr 0.2494477927684784\n",
      "Replaced token 1687 with corr 0.17596273124217987 with new token with corr 0.17596273124217987\n",
      "Replaced token 1688 with corr 0.24720147252082825 with new token with corr 0.24720145761966705\n",
      "Replaced token 1689 with corr 0.25267162919044495 with new token with corr 0.25267165899276733\n",
      "Replaced token 1690 with corr 0.30270588397979736 with new token with corr 0.30270588397979736\n",
      "Replaced token 1691 with corr 0.2125348001718521 with new token with corr 0.2125348001718521\n",
      "Replaced token 1692 with corr 0.3091452121734619 with new token with corr 0.3091452121734619\n",
      "Replaced token 1693 with corr 0.2620888352394104 with new token with corr 0.2620888352394104\n",
      "Replaced token 1694 with corr 0.37729260325431824 with new token with corr 0.3772926330566406\n",
      "Replaced token 1695 with corr 0.3336438834667206 with new token with corr 0.3336438834667206\n",
      "Replaced token 1696 with corr 0.2936997711658478 with new token with corr 0.2936997711658478\n",
      "Replaced token 1697 with corr 0.2901906371116638 with new token with corr 0.2901906371116638\n",
      "Replaced token 1698 with corr 0.3403967022895813 with new token with corr 0.3403967022895813\n",
      "Replaced token 1699 with corr 0.3090672194957733 with new token with corr 0.3090671896934509\n",
      "Replaced token 1700 with corr 0.3093051314353943 with new token with corr 0.3093051314353943\n",
      "Replaced token 1701 with corr 0.3322944641113281 with new token with corr 0.33229443430900574\n",
      "Replaced token 1702 with corr 0.30992239713668823 with new token with corr 0.3099224269390106\n",
      "Replaced token 1703 with corr 0.32170915603637695 with new token with corr 0.32170912623405457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1704 with corr 0.23936587572097778 with new token with corr 0.23936589062213898\n",
      "Replaced token 1705 with corr 0.25870734453201294 with new token with corr 0.25870734453201294\n",
      "Replaced token 1706 with corr 0.2977607548236847 with new token with corr 0.2977607846260071\n",
      "Replaced token 1707 with corr 0.24647468328475952 with new token with corr 0.24647466838359833\n",
      "Replaced token 1708 with corr 0.28595003485679626 with new token with corr 0.28595003485679626\n",
      "Replaced token 1709 with corr 0.2832009196281433 with new token with corr 0.2832009196281433\n",
      "Replaced token 1710 with corr 0.30041322112083435 with new token with corr 0.30041322112083435\n",
      "Replaced token 1711 with corr 0.3252178132534027 with new token with corr 0.3252178430557251\n",
      "Replaced token 1712 with corr 0.29788392782211304 with new token with corr 0.2978839576244354\n",
      "Replaced token 1713 with corr 0.3318425118923187 with new token with corr 0.3318425416946411\n",
      "Replaced token 1714 with corr 0.3036014437675476 with new token with corr 0.3036014437675476\n",
      "Replaced token 1715 with corr 0.23761659860610962 with new token with corr 0.2376166135072708\n",
      "Replaced token 1716 with corr 0.25094854831695557 with new token with corr 0.2509485185146332\n",
      "Replaced token 1717 with corr 0.1978810727596283 with new token with corr 0.1978810876607895\n",
      "Replaced token 1718 with corr 0.2870648205280304 with new token with corr 0.2870648205280304\n",
      "Replaced token 1719 with corr 0.25697559118270874 with new token with corr 0.25697556138038635\n",
      "Replaced token 1720 with corr 0.26466459035873413 with new token with corr 0.26466459035873413\n",
      "Replaced token 1721 with corr 0.12230458110570908 with new token with corr 0.1910378485918045\n",
      "Replaced token 1722 with corr 0.3086070418357849 with new token with corr 0.3086070120334625\n",
      "Replaced token 1723 with corr 0.2404869943857193 with new token with corr 0.2404870241880417\n",
      "Replaced token 1724 with corr 0.09965529292821884 with new token with corr 0.23894765973091125\n",
      "Replaced token 1725 with corr 0.11401858180761337 with new token with corr 0.23250730335712433\n",
      "Replaced token 1726 with corr 0.30442699790000916 with new token with corr 0.30442699790000916\n",
      "Replaced token 1727 with corr 0.31180065870285034 with new token with corr 0.31180065870285034\n",
      "Replaced token 1728 with corr 0.30838149785995483 with new token with corr 0.30838149785995483\n",
      "Replaced token 1729 with corr 0.3273896276950836 with new token with corr 0.3273896276950836\n",
      "Replaced token 1730 with corr 0.36927831172943115 with new token with corr 0.36927831172943115\n",
      "Replaced token 1731 with corr 0.28151676058769226 with new token with corr 0.28151679039001465\n",
      "Replaced token 1732 with corr 0.2632019817829132 with new token with corr 0.2632019817829132\n",
      "Replaced token 1733 with corr 0.33855733275413513 with new token with corr 0.33855733275413513\n",
      "Replaced token 1734 with corr 0.2952963709831238 with new token with corr 0.29529640078544617\n",
      "Replaced token 1735 with corr 0.3126879334449768 with new token with corr 0.3126879334449768\n",
      "Replaced token 1736 with corr 0.28533488512039185 with new token with corr 0.28533488512039185\n",
      "Replaced token 1737 with corr 0.3286929726600647 with new token with corr 0.3286929428577423\n",
      "Replaced token 1738 with corr 0.24705149233341217 with new token with corr 0.24705150723457336\n",
      "Replaced token 1739 with corr 0.4095652997493744 with new token with corr 0.4095652997493744\n",
      "Replaced token 1740 with corr 0.24189867079257965 with new token with corr 0.24189864099025726\n",
      "Replaced token 1741 with corr 0.29493406414985657 with new token with corr 0.29493406414985657\n",
      "Replaced token 1742 with corr 0.28853827714920044 with new token with corr 0.28853827714920044\n",
      "Replaced token 1743 with corr 0.26323381066322327 with new token with corr 0.26323381066322327\n",
      "Replaced token 1744 with corr 0.25329798460006714 with new token with corr 0.25329795479774475\n",
      "Replaced token 1745 with corr 0.2831933796405792 with new token with corr 0.28319334983825684\n",
      "Replaced token 1746 with corr 0.2738480865955353 with new token with corr 0.2738480865955353\n",
      "Replaced token 1747 with corr 0.22420845925807953 with new token with corr 0.22420845925807953\n",
      "Replaced token 1748 with corr 0.31393349170684814 with new token with corr 0.31393349170684814\n",
      "Replaced token 1749 with corr 0.09431915730237961 with new token with corr 0.26409608125686646\n",
      "Replaced token 1750 with corr 0.203522190451622 with new token with corr 0.2035222053527832\n",
      "Replaced token 1751 with corr 0.29632019996643066 with new token with corr 0.29632019996643066\n",
      "Replaced token 1752 with corr 0.27851399779319763 with new token with corr 0.27851399779319763\n",
      "Replaced token 1753 with corr 0.2667514979839325 with new token with corr 0.2667514979839325\n",
      "Replaced token 1754 with corr 0.36329224705696106 with new token with corr 0.36329227685928345\n",
      "Replaced token 1755 with corr 0.27726730704307556 with new token with corr 0.27726730704307556\n",
      "Replaced token 1756 with corr 0.29562926292419434 with new token with corr 0.29562926292419434\n",
      "Replaced token 1757 with corr 0.30801063776016235 with new token with corr 0.30801063776016235\n",
      "Replaced token 1758 with corr 0.3014308214187622 with new token with corr 0.3014308512210846\n",
      "Replaced token 1759 with corr 0.23235636949539185 with new token with corr 0.23235636949539185\n",
      "Replaced token 1760 with corr 0.3039146065711975 with new token with corr 0.3039146065711975\n",
      "Replaced token 1761 with corr 0.321353018283844 with new token with corr 0.321353018283844\n",
      "Replaced token 1762 with corr 0.269371896982193 with new token with corr 0.269371896982193\n",
      "Replaced token 1763 with corr 0.28655102849006653 with new token with corr 0.28655102849006653\n",
      "Replaced token 1764 with corr 0.2883510887622833 with new token with corr 0.2883510887622833\n",
      "Replaced token 1765 with corr 0.113925039768219 with new token with corr 0.23003029823303223\n",
      "Replaced token 1766 with corr 0.28868743777275085 with new token with corr 0.28868746757507324\n",
      "Replaced token 1767 with corr 0.29404714703559875 with new token with corr 0.29404714703559875\n",
      "Replaced token 1768 with corr 0.2572043836116791 with new token with corr 0.2572043836116791\n",
      "Replaced token 1769 with corr 0.2646189033985138 with new token with corr 0.2646188735961914\n",
      "Replaced token 1770 with corr 0.2501319646835327 with new token with corr 0.2501319646835327\n",
      "Replaced token 1771 with corr 0.3145243227481842 with new token with corr 0.3145243227481842\n",
      "Replaced token 1772 with corr 0.12538324296474457 with new token with corr 0.17466109991073608\n",
      "Replaced token 1773 with corr 0.2191021889448166 with new token with corr 0.2191021889448166\n",
      "Replaced token 1774 with corr 0.21978548169136047 with new token with corr 0.21978548169136047\n",
      "Replaced token 1775 with corr 0.309720903635025 with new token with corr 0.309720903635025\n",
      "Replaced token 1776 with corr 0.3449975550174713 with new token with corr 0.3449975550174713\n",
      "Replaced token 1777 with corr 0.21379195153713226 with new token with corr 0.21379193663597107\n",
      "Replaced token 1778 with corr 0.2448357194662094 with new token with corr 0.2448357343673706\n",
      "Replaced token 1779 with corr 0.2573840916156769 with new token with corr 0.2573840916156769\n",
      "Replaced token 1780 with corr 0.24362456798553467 with new token with corr 0.24362456798553467\n",
      "Replaced token 1781 with corr 0.3117597699165344 with new token with corr 0.3117597997188568\n",
      "Replaced token 1782 with corr 0.29230037331581116 with new token with corr 0.29230040311813354\n",
      "Replaced token 1783 with corr 0.25594645738601685 with new token with corr 0.25594645738601685\n",
      "Replaced token 1784 with corr 0.24960128962993622 with new token with corr 0.2496013045310974\n",
      "Replaced token 1785 with corr 0.2609631419181824 with new token with corr 0.2609631419181824\n",
      "Replaced token 1786 with corr 0.2265506237745285 with new token with corr 0.22655066847801208\n",
      "Replaced token 1787 with corr 0.3463136851787567 with new token with corr 0.3463136851787567\n",
      "Replaced token 1788 with corr 0.28620362281799316 with new token with corr 0.28620362281799316\n",
      "Replaced token 1789 with corr 0.23028838634490967 with new token with corr 0.23028838634490967\n",
      "Replaced token 1790 with corr 0.24366235733032227 with new token with corr 0.24366235733032227\n",
      "Replaced token 1791 with corr 0.2640243470668793 with new token with corr 0.2640243470668793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1792 with corr 0.283767431974411 with new token with corr 0.283767431974411\n",
      "Replaced token 1793 with corr 0.3717728853225708 with new token with corr 0.3717728853225708\n",
      "Replaced token 1794 with corr 0.23710615932941437 with new token with corr 0.23710617423057556\n",
      "Replaced token 1795 with corr 0.2591124176979065 with new token with corr 0.2591124176979065\n",
      "Replaced token 1796 with corr 0.10505230724811554 with new token with corr 0.19375872611999512\n",
      "Replaced token 1797 with corr 0.1041848435997963 with new token with corr 0.20226873457431793\n",
      "Replaced token 1798 with corr 0.12051334232091904 with new token with corr 0.2571505308151245\n",
      "Replaced token 1799 with corr 0.2757832407951355 with new token with corr 0.2757832407951355\n",
      "Replaced token 1800 with corr 0.2718140482902527 with new token with corr 0.2718140482902527\n",
      "Replaced token 1801 with corr 0.2945486605167389 with new token with corr 0.2945486605167389\n",
      "Replaced token 1802 with corr 0.29742252826690674 with new token with corr 0.29742252826690674\n",
      "Replaced token 1803 with corr 0.2434154599905014 with new token with corr 0.24341541528701782\n",
      "Replaced token 1804 with corr 0.27722465991973877 with new token with corr 0.2772246301174164\n",
      "Replaced token 1805 with corr 0.2757422626018524 with new token with corr 0.2757422924041748\n",
      "Replaced token 1806 with corr 0.20165354013442993 with new token with corr 0.20165355503559113\n",
      "Replaced token 1807 with corr 0.2679024636745453 with new token with corr 0.2679024636745453\n",
      "Replaced token 1808 with corr 0.25169992446899414 with new token with corr 0.25169992446899414\n",
      "Replaced token 1809 with corr 0.3283681571483612 with new token with corr 0.3283681571483612\n",
      "Replaced token 1810 with corr 0.2581276297569275 with new token with corr 0.2581276297569275\n",
      "Replaced token 1811 with corr 0.21419881284236908 with new token with corr 0.21419879794120789\n",
      "Replaced token 1812 with corr 0.24166624248027802 with new token with corr 0.24166624248027802\n",
      "Replaced token 1813 with corr 0.33314231038093567 with new token with corr 0.33314234018325806\n",
      "Replaced token 1814 with corr 0.3307993710041046 with new token with corr 0.3307993710041046\n",
      "Replaced token 1815 with corr 0.09153895825147629 with new token with corr 0.2720903754234314\n",
      "Replaced token 1816 with corr 0.42467907071113586 with new token with corr 0.42467907071113586\n",
      "Replaced token 1817 with corr 0.25039830803871155 with new token with corr 0.25039827823638916\n",
      "Replaced token 1818 with corr 0.3208744525909424 with new token with corr 0.3208744525909424\n",
      "Replaced token 1819 with corr 0.22589251399040222 with new token with corr 0.22589251399040222\n",
      "Replaced token 1820 with corr 0.24598023295402527 with new token with corr 0.24598021805286407\n",
      "Replaced token 1821 with corr 0.2734537124633789 with new token with corr 0.2734537422657013\n",
      "Replaced token 1822 with corr 0.28521135449409485 with new token with corr 0.28521138429641724\n",
      "Replaced token 1823 with corr 0.3082122504711151 with new token with corr 0.3082122206687927\n",
      "Replaced token 1824 with corr 0.3406933844089508 with new token with corr 0.3406934142112732\n",
      "Replaced token 1825 with corr 0.25289493799209595 with new token with corr 0.25289493799209595\n",
      "Replaced token 1826 with corr 0.2758445143699646 with new token with corr 0.2758445143699646\n",
      "Replaced token 1827 with corr 0.25955650210380554 with new token with corr 0.25955650210380554\n",
      "Replaced token 1828 with corr 0.1047699898481369 with new token with corr 0.24702207744121552\n",
      "Replaced token 1829 with corr 0.30248093605041504 with new token with corr 0.30248090624809265\n",
      "Replaced token 1830 with corr 0.28700345754623413 with new token with corr 0.28700345754623413\n",
      "Replaced token 1831 with corr 0.3193833827972412 with new token with corr 0.3193833529949188\n",
      "Replaced token 1832 with corr 0.32045283913612366 with new token with corr 0.32045280933380127\n",
      "Replaced token 1833 with corr 0.32687437534332275 with new token with corr 0.32687440514564514\n",
      "Replaced token 1834 with corr 0.27432116866111755 with new token with corr 0.27432116866111755\n",
      "Replaced token 1835 with corr 0.3347932696342468 with new token with corr 0.3347932994365692\n",
      "Replaced token 1836 with corr 0.3648262023925781 with new token with corr 0.36482617259025574\n",
      "Replaced token 1837 with corr 0.24439460039138794 with new token with corr 0.24439460039138794\n",
      "Replaced token 1838 with corr 0.31748872995376587 with new token with corr 0.3174887001514435\n",
      "Replaced token 1839 with corr 0.3314344584941864 with new token with corr 0.3314344584941864\n",
      "Replaced token 1840 with corr 0.23177765309810638 with new token with corr 0.23177765309810638\n",
      "Replaced token 1841 with corr 0.2286970168352127 with new token with corr 0.2286970168352127\n",
      "Replaced token 1842 with corr 0.27682697772979736 with new token with corr 0.27682700753211975\n",
      "Replaced token 1843 with corr 0.21492736041545868 with new token with corr 0.21492736041545868\n",
      "Replaced token 1844 with corr 0.2383463978767395 with new token with corr 0.2383464127779007\n",
      "Replaced token 1845 with corr 0.2789953947067261 with new token with corr 0.2789953649044037\n",
      "Replaced token 1846 with corr 0.29993799328804016 with new token with corr 0.29993802309036255\n",
      "Replaced token 1847 with corr 0.2678418755531311 with new token with corr 0.2678418457508087\n",
      "Replaced token 1848 with corr 0.26088136434555054 with new token with corr 0.26088136434555054\n",
      "Replaced token 1849 with corr 0.3152318000793457 with new token with corr 0.3152318000793457\n",
      "Replaced token 1850 with corr 0.295623242855072 with new token with corr 0.295623242855072\n",
      "Replaced token 1851 with corr 0.14143934845924377 with new token with corr 0.21197469532489777\n",
      "Replaced token 1852 with corr 0.3004995286464691 with new token with corr 0.3004995286464691\n",
      "Replaced token 1853 with corr 0.28028178215026855 with new token with corr 0.28028178215026855\n",
      "Replaced token 1854 with corr 0.25851476192474365 with new token with corr 0.25851479172706604\n",
      "Replaced token 1855 with corr 0.37119060754776 with new token with corr 0.37119060754776\n",
      "Replaced token 1856 with corr 0.25116172432899475 with new token with corr 0.25116172432899475\n",
      "Replaced token 1857 with corr 0.32318469882011414 with new token with corr 0.32318469882011414\n",
      "Replaced token 1858 with corr 0.2530992031097412 with new token with corr 0.2530991733074188\n",
      "Replaced token 1859 with corr 0.23236577212810516 with new token with corr 0.23236575722694397\n",
      "Replaced token 1860 with corr 0.29339560866355896 with new token with corr 0.29339560866355896\n",
      "Replaced token 1861 with corr 0.4063623249530792 with new token with corr 0.4063623249530792\n",
      "Replaced token 1862 with corr 0.2612230181694031 with new token with corr 0.2612230181694031\n",
      "Replaced token 1863 with corr 0.2854422926902771 with new token with corr 0.2854422926902771\n",
      "Replaced token 1864 with corr 0.31587040424346924 with new token with corr 0.31587040424346924\n",
      "Replaced token 1865 with corr 0.2478196918964386 with new token with corr 0.2478197067975998\n",
      "Replaced token 1866 with corr 0.2709738612174988 with new token with corr 0.2709738612174988\n",
      "Replaced token 1867 with corr 0.26339954137802124 with new token with corr 0.26339954137802124\n",
      "Replaced token 1868 with corr 0.3009788990020752 with new token with corr 0.3009789288043976\n",
      "Replaced token 1869 with corr 0.09271486848592758 with new token with corr 0.14925695955753326\n",
      "Replaced token 1870 with corr 0.24355582892894745 with new token with corr 0.24355584383010864\n",
      "Replaced token 1871 with corr 0.3193080425262451 with new token with corr 0.3193080723285675\n",
      "Replaced token 1872 with corr 0.25065675377845764 with new token with corr 0.25065672397613525\n",
      "Replaced token 1873 with corr 0.31132400035858154 with new token with corr 0.31132403016090393\n",
      "Replaced token 1874 with corr 0.27238643169403076 with new token with corr 0.27238643169403076\n",
      "Replaced token 1875 with corr 0.31241902709007263 with new token with corr 0.312419056892395\n",
      "Replaced token 1876 with corr 0.20710821449756622 with new token with corr 0.20710821449756622\n",
      "Replaced token 1877 with corr 0.20543190836906433 with new token with corr 0.20543190836906433\n",
      "Replaced token 1878 with corr 0.18903475999832153 with new token with corr 0.18903475999832153\n",
      "Replaced token 1879 with corr 0.29332536458969116 with new token with corr 0.29332536458969116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1880 with corr 0.29058465361595154 with new token with corr 0.2905846834182739\n",
      "Replaced token 1881 with corr 0.2549596130847931 with new token with corr 0.2549596130847931\n",
      "Replaced token 1882 with corr 0.26020917296409607 with new token with corr 0.26020917296409607\n",
      "Replaced token 1883 with corr 0.23652298748493195 with new token with corr 0.23652298748493195\n",
      "Replaced token 1884 with corr 0.2807815968990326 with new token with corr 0.2807815968990326\n",
      "Replaced token 1885 with corr 0.23349234461784363 with new token with corr 0.23349231481552124\n",
      "Replaced token 1886 with corr 0.09809347987174988 with new token with corr 0.15751954913139343\n",
      "Replaced token 1887 with corr 0.22872769832611084 with new token with corr 0.22872769832611084\n",
      "Replaced token 1888 with corr 0.2859970033168793 with new token with corr 0.2859970033168793\n",
      "Replaced token 1889 with corr 0.3902224600315094 with new token with corr 0.3902224898338318\n",
      "Replaced token 1890 with corr 0.29660436511039734 with new token with corr 0.29660436511039734\n",
      "Replaced token 1891 with corr 0.33408063650131226 with new token with corr 0.33408063650131226\n",
      "Replaced token 1892 with corr 0.4046754837036133 with new token with corr 0.40467551350593567\n",
      "Replaced token 1893 with corr 0.24676626920700073 with new token with corr 0.24676628410816193\n",
      "Replaced token 1894 with corr 0.29778945446014404 with new token with corr 0.29778942465782166\n",
      "Replaced token 1895 with corr 0.26121872663497925 with new token with corr 0.26121872663497925\n",
      "Replaced token 1896 with corr 0.28685256838798523 with new token with corr 0.28685253858566284\n",
      "Replaced token 1897 with corr 0.3187873959541321 with new token with corr 0.3187873959541321\n",
      "Replaced token 1898 with corr 0.08746799826622009 with new token with corr 0.18822109699249268\n",
      "Replaced token 1899 with corr 0.2601078152656555 with new token with corr 0.2601078450679779\n",
      "Replaced token 1900 with corr 0.2773882746696472 with new token with corr 0.2773882746696472\n",
      "Replaced token 1901 with corr 0.3075515627861023 with new token with corr 0.3075515925884247\n",
      "Replaced token 1902 with corr 0.21363985538482666 with new token with corr 0.21363984048366547\n",
      "Replaced token 1903 with corr 0.27381572127342224 with new token with corr 0.27381572127342224\n",
      "Replaced token 1904 with corr 0.36426249146461487 with new token with corr 0.36426252126693726\n",
      "Replaced token 1905 with corr 0.2919442355632782 with new token with corr 0.2919442057609558\n",
      "Replaced token 1906 with corr 0.3315027356147766 with new token with corr 0.3315027356147766\n",
      "Replaced token 1907 with corr 0.2462347000837326 with new token with corr 0.2462347149848938\n",
      "Replaced token 1908 with corr 0.3013938069343567 with new token with corr 0.3013938069343567\n",
      "Replaced token 1909 with corr 0.2322474867105484 with new token with corr 0.2322474867105484\n",
      "Replaced token 1910 with corr 0.3310333788394928 with new token with corr 0.3310333788394928\n",
      "Replaced token 1911 with corr 0.10159188508987427 with new token with corr 0.2432563453912735\n",
      "Replaced token 1912 with corr 0.2650746703147888 with new token with corr 0.2650746703147888\n",
      "Replaced token 1913 with corr 0.20417466759681702 with new token with corr 0.20417465269565582\n",
      "Replaced token 1914 with corr 0.10121522843837738 with new token with corr 0.28528982400894165\n",
      "Replaced token 1915 with corr 0.2760462760925293 with new token with corr 0.2760463058948517\n",
      "Replaced token 1916 with corr 0.19995521008968353 with new token with corr 0.19995522499084473\n",
      "Replaced token 1917 with corr 0.32777321338653564 with new token with corr 0.32777321338653564\n",
      "Replaced token 1918 with corr 0.24878011643886566 with new token with corr 0.24878008663654327\n",
      "Replaced token 1919 with corr 0.1328171342611313 with new token with corr 0.2570674419403076\n",
      "Replaced token 1920 with corr 0.299273282289505 with new token with corr 0.299273282289505\n",
      "Replaced token 1921 with corr 0.32253897190093994 with new token with corr 0.32253900170326233\n",
      "Replaced token 1922 with corr 0.27247318625450134 with new token with corr 0.27247321605682373\n",
      "Replaced token 1923 with corr 0.263200581073761 with new token with corr 0.2632006108760834\n",
      "Replaced token 1924 with corr 0.30496934056282043 with new token with corr 0.3049693703651428\n",
      "Replaced token 1925 with corr 0.14087232947349548 with new token with corr 0.24447175860404968\n",
      "Replaced token 1926 with corr 0.31892141699790955 with new token with corr 0.31892138719558716\n",
      "Replaced token 1927 with corr 0.22887475788593292 with new token with corr 0.2288747876882553\n",
      "Replaced token 1928 with corr 0.28213632106781006 with new token with corr 0.28213629126548767\n",
      "Replaced token 1929 with corr 0.2878096103668213 with new token with corr 0.2878096103668213\n",
      "Replaced token 1930 with corr 0.2828010022640228 with new token with corr 0.2828010022640228\n",
      "Replaced token 1931 with corr 0.34314554929733276 with new token with corr 0.3431455194950104\n",
      "Replaced token 1932 with corr 0.2654641270637512 with new token with corr 0.26546409726142883\n",
      "Replaced token 1933 with corr 0.3023092448711395 with new token with corr 0.30230921506881714\n",
      "Replaced token 1934 with corr 0.14423410594463348 with new token with corr 0.15180175006389618\n",
      "Replaced token 1935 with corr 0.26793351769447327 with new token with corr 0.26793354749679565\n",
      "Replaced token 1936 with corr 0.2566379904747009 with new token with corr 0.2566379904747009\n",
      "Replaced token 1937 with corr 0.10361011326313019 with new token with corr 0.19467350840568542\n",
      "Replaced token 1938 with corr 0.2812332510948181 with new token with corr 0.2812332212924957\n",
      "Replaced token 1939 with corr 0.11677804589271545 with new token with corr 0.15687577426433563\n",
      "Replaced token 1940 with corr 0.25452950596809387 with new token with corr 0.2545294761657715\n",
      "Replaced token 1941 with corr 0.21609492599964142 with new token with corr 0.21609492599964142\n",
      "Replaced token 1942 with corr 0.2916799783706665 with new token with corr 0.2916799783706665\n",
      "Replaced token 1943 with corr 0.3262655735015869 with new token with corr 0.3262655735015869\n",
      "Replaced token 1944 with corr 0.33823904395103455 with new token with corr 0.33823901414871216\n",
      "Replaced token 1945 with corr 0.34378165006637573 with new token with corr 0.34378165006637573\n",
      "Replaced token 1946 with corr 0.28976354002952576 with new token with corr 0.28976351022720337\n",
      "Replaced token 1947 with corr 0.20820318162441254 with new token with corr 0.20820318162441254\n",
      "Replaced token 1948 with corr 0.33908072113990784 with new token with corr 0.33908069133758545\n",
      "Replaced token 1949 with corr 0.28852903842926025 with new token with corr 0.28852906823158264\n",
      "Replaced token 1950 with corr 0.10692845284938812 with new token with corr 0.1659749299287796\n",
      "Replaced token 1951 with corr 0.35375162959098816 with new token with corr 0.35375162959098816\n",
      "Replaced token 1952 with corr 0.3284211754798889 with new token with corr 0.3284211754798889\n",
      "Replaced token 1953 with corr 0.30112090706825256 with new token with corr 0.30112090706825256\n",
      "Replaced token 1954 with corr 0.3227536082267761 with new token with corr 0.32275357842445374\n",
      "Replaced token 1955 with corr 0.30666086077690125 with new token with corr 0.30666086077690125\n",
      "Replaced token 1956 with corr 0.2995045781135559 with new token with corr 0.2995046079158783\n",
      "Replaced token 1957 with corr 0.40654563903808594 with new token with corr 0.40654563903808594\n",
      "Replaced token 1958 with corr 0.2776798903942108 with new token with corr 0.2776798903942108\n",
      "Replaced token 1959 with corr 0.3397562801837921 with new token with corr 0.3397563099861145\n",
      "Replaced token 1960 with corr 0.3396955728530884 with new token with corr 0.3396955728530884\n",
      "Replaced token 1961 with corr 0.28442615270614624 with new token with corr 0.28442615270614624\n",
      "Replaced token 1962 with corr 0.2805393636226654 with new token with corr 0.2805393636226654\n",
      "Replaced token 1963 with corr 0.24450691044330597 with new token with corr 0.24450691044330597\n",
      "Replaced token 1964 with corr 0.339769572019577 with new token with corr 0.339769572019577\n",
      "Replaced token 1965 with corr 0.3543531894683838 with new token with corr 0.3543531894683838\n",
      "Replaced token 1966 with corr 0.3682456910610199 with new token with corr 0.3682456910610199\n",
      "Replaced token 1967 with corr 0.0919974073767662 with new token with corr 0.15440888702869415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 1968 with corr 0.2861381471157074 with new token with corr 0.2861381769180298\n",
      "Replaced token 1969 with corr 0.3269195854663849 with new token with corr 0.3269195854663849\n",
      "Replaced token 1970 with corr 0.3081527352333069 with new token with corr 0.3081527352333069\n",
      "Replaced token 1971 with corr 0.23015546798706055 with new token with corr 0.23015546798706055\n",
      "Replaced token 1972 with corr 0.3204062879085541 with new token with corr 0.3204062879085541\n",
      "Replaced token 1973 with corr 0.3616875112056732 with new token with corr 0.3616875112056732\n",
      "Replaced token 1974 with corr 0.337212473154068 with new token with corr 0.337212473154068\n",
      "Replaced token 1975 with corr 0.2955193519592285 with new token with corr 0.2955193817615509\n",
      "Replaced token 1976 with corr 0.28037557005882263 with new token with corr 0.28037557005882263\n",
      "Replaced token 1977 with corr 0.3377477526664734 with new token with corr 0.3377477526664734\n",
      "Replaced token 1978 with corr 0.2629573345184326 with new token with corr 0.2629573345184326\n",
      "Replaced token 1979 with corr 0.2524596154689789 with new token with corr 0.2524595856666565\n",
      "Replaced token 1980 with corr 0.3412180542945862 with new token with corr 0.3412180542945862\n",
      "Replaced token 1981 with corr 0.25139790773391724 with new token with corr 0.25139790773391724\n",
      "Replaced token 1982 with corr 0.3229273855686188 with new token with corr 0.3229273855686188\n",
      "Replaced token 1983 with corr 0.2302946299314499 with new token with corr 0.2302946299314499\n",
      "Replaced token 1984 with corr 0.29552164673805237 with new token with corr 0.29552161693573\n",
      "Replaced token 1985 with corr 0.28617042303085327 with new token with corr 0.2861703932285309\n",
      "Replaced token 1986 with corr 0.24022062122821808 with new token with corr 0.24022062122821808\n",
      "Replaced token 1987 with corr 0.2723167836666107 with new token with corr 0.2723167836666107\n",
      "Replaced token 1988 with corr 0.2948022782802582 with new token with corr 0.29480233788490295\n",
      "Replaced token 1989 with corr 0.23794615268707275 with new token with corr 0.23794613778591156\n",
      "Replaced token 1990 with corr 0.2822260856628418 with new token with corr 0.2822260856628418\n",
      "Replaced token 1991 with corr 0.2631118595600128 with new token with corr 0.2631118595600128\n",
      "Replaced token 1992 with corr 0.26632124185562134 with new token with corr 0.26632124185562134\n",
      "Replaced token 1993 with corr 0.28844398260116577 with new token with corr 0.28844398260116577\n",
      "Replaced token 1994 with corr 0.07788437604904175 with new token with corr 0.15879173576831818\n",
      "Replaced token 1995 with corr 0.25075212121009827 with new token with corr 0.25075212121009827\n",
      "Replaced token 1996 with corr 0.2895812392234802 with new token with corr 0.2895812392234802\n",
      "Replaced token 1997 with corr 0.3374064564704895 with new token with corr 0.3374064564704895\n",
      "Replaced token 1998 with corr 0.4107975661754608 with new token with corr 0.4107975959777832\n",
      "Replaced token 1999 with corr 0.3160415589809418 with new token with corr 0.31604158878326416\n",
      "Replaced token 2000 with corr 0.25427988171577454 with new token with corr 0.2542799115180969\n",
      "Replaced token 2001 with corr 0.25225773453712463 with new token with corr 0.25225773453712463\n",
      "Replaced token 2002 with corr 0.32919585704803467 with new token with corr 0.32919585704803467\n",
      "Replaced token 2003 with corr 0.20455005764961243 with new token with corr 0.20455008745193481\n",
      "Replaced token 2004 with corr 0.30615565180778503 with new token with corr 0.30615562200546265\n",
      "Replaced token 2005 with corr 0.33397606015205383 with new token with corr 0.33397606015205383\n",
      "Replaced token 2006 with corr 0.2735776901245117 with new token with corr 0.2735776901245117\n",
      "Replaced token 2007 with corr 0.27109861373901367 with new token with corr 0.27109861373901367\n",
      "Replaced token 2008 with corr 0.12380942702293396 with new token with corr 0.2583029270172119\n",
      "Replaced token 2009 with corr 0.36067265272140503 with new token with corr 0.36067265272140503\n",
      "Replaced token 2010 with corr 0.22079136967658997 with new token with corr 0.22079138457775116\n",
      "Replaced token 2011 with corr 0.2969287931919098 with new token with corr 0.2969287633895874\n",
      "Replaced token 2012 with corr 0.33806270360946655 with new token with corr 0.33806270360946655\n",
      "Replaced token 2013 with corr 0.0755612924695015 with new token with corr 0.24288199841976166\n",
      "Replaced token 2014 with corr 0.10457774251699448 with new token with corr 0.20454064011573792\n",
      "Replaced token 2015 with corr 0.2877858281135559 with new token with corr 0.2877858281135559\n",
      "Replaced token 2016 with corr 0.3039104640483856 with new token with corr 0.303910493850708\n",
      "Replaced token 2017 with corr 0.3517248034477234 with new token with corr 0.3517248332500458\n",
      "Replaced token 2018 with corr 0.23182570934295654 with new token with corr 0.23182570934295654\n",
      "Replaced token 2019 with corr 0.22621610760688782 with new token with corr 0.22621610760688782\n",
      "Replaced token 2020 with corr 0.23700664937496185 with new token with corr 0.23700666427612305\n",
      "Replaced token 2021 with corr 0.13518060743808746 with new token with corr 0.14125566184520721\n",
      "Replaced token 2022 with corr 0.25347524881362915 with new token with corr 0.25347527861595154\n",
      "Replaced token 2023 with corr 0.2792341113090515 with new token with corr 0.2792341113090515\n",
      "Replaced token 2024 with corr 0.25648659467697144 with new token with corr 0.25648659467697144\n",
      "Replaced token 2025 with corr 0.10530538856983185 with new token with corr 0.2723276913166046\n",
      "Replaced token 2026 with corr 0.3265978991985321 with new token with corr 0.3265978693962097\n",
      "Replaced token 2027 with corr 0.23798449337482452 with new token with corr 0.23798450827598572\n",
      "Replaced token 2028 with corr 0.32366475462913513 with new token with corr 0.32366475462913513\n",
      "Replaced token 2029 with corr 0.3013286292552948 with new token with corr 0.3013286590576172\n",
      "Replaced token 2030 with corr 0.42679595947265625 with new token with corr 0.42679592967033386\n",
      "Replaced token 2031 with corr 0.26590776443481445 with new token with corr 0.26590773463249207\n",
      "Replaced token 2032 with corr 0.11544646322727203 with new token with corr 0.15804436802864075\n",
      "Replaced token 2033 with corr 0.19235318899154663 with new token with corr 0.19235314428806305\n",
      "Replaced token 2034 with corr 0.39954185485839844 with new token with corr 0.39954182505607605\n",
      "Replaced token 2035 with corr 0.11083207279443741 with new token with corr 0.1620553880929947\n",
      "Replaced token 2036 with corr 0.2558175027370453 with new token with corr 0.2558175325393677\n",
      "Replaced token 2037 with corr 0.3216118812561035 with new token with corr 0.3216118812561035\n",
      "Replaced token 2038 with corr 0.28465595841407776 with new token with corr 0.28465595841407776\n",
      "Replaced token 2039 with corr 0.3040354549884796 with new token with corr 0.3040354549884796\n",
      "Replaced token 2040 with corr 0.3223825991153717 with new token with corr 0.3223825991153717\n",
      "Replaced token 2041 with corr 0.31113365292549133 with new token with corr 0.31113365292549133\n",
      "Replaced token 2042 with corr 0.3198264241218567 with new token with corr 0.3198264539241791\n",
      "Replaced token 2043 with corr 0.2690655589103699 with new token with corr 0.2690655291080475\n",
      "Replaced token 2044 with corr 0.2484024465084076 with new token with corr 0.2484024465084076\n",
      "Replaced token 2045 with corr 0.23138783872127533 with new token with corr 0.23138782382011414\n",
      "Replaced token 2046 with corr 0.24890120327472687 with new token with corr 0.24890120327472687\n",
      "Replaced token 2047 with corr 0.07412855327129364 with new token with corr 0.14971689879894257\n",
      "Replaced token 2048 with corr 0.2997874319553375 with new token with corr 0.29978740215301514\n",
      "Replaced token 2049 with corr 0.24824433028697968 with new token with corr 0.24824433028697968\n",
      "Replaced token 2050 with corr 0.21506142616271973 with new token with corr 0.21506142616271973\n",
      "Replaced token 2051 with corr 0.25788402557373047 with new token with corr 0.25788405537605286\n",
      "Replaced token 2052 with corr 0.3069632649421692 with new token with corr 0.3069632947444916\n",
      "Replaced token 2053 with corr 0.09284576773643494 with new token with corr 0.15759992599487305\n",
      "Replaced token 2054 with corr 0.29925039410591125 with new token with corr 0.29925036430358887\n",
      "Replaced token 2055 with corr 0.2509036362171173 with new token with corr 0.2509036660194397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2056 with corr 0.2987033426761627 with new token with corr 0.29870331287384033\n",
      "Replaced token 2057 with corr 0.22812993824481964 with new token with corr 0.22812993824481964\n",
      "Replaced token 2058 with corr 0.28511616587638855 with new token with corr 0.28511616587638855\n",
      "Replaced token 2059 with corr 0.23182345926761627 with new token with corr 0.23182342946529388\n",
      "Replaced token 2060 with corr 0.2968263030052185 with new token with corr 0.2968263030052185\n",
      "Replaced token 2061 with corr 0.3253076672554016 with new token with corr 0.3253076672554016\n",
      "Replaced token 2062 with corr 0.26083317399024963 with new token with corr 0.260833203792572\n",
      "Replaced token 2063 with corr 0.28656306862831116 with new token with corr 0.28656306862831116\n",
      "Replaced token 2064 with corr 0.32610654830932617 with new token with corr 0.32610654830932617\n",
      "Replaced token 2065 with corr 0.3279411792755127 with new token with corr 0.3279411792755127\n",
      "Replaced token 2066 with corr 0.3050965368747711 with new token with corr 0.30509650707244873\n",
      "Replaced token 2067 with corr 0.2878745496273041 with new token with corr 0.2878745496273041\n",
      "Replaced token 2068 with corr 0.3384358882904053 with new token with corr 0.3384358882904053\n",
      "Replaced token 2069 with corr 0.22256457805633545 with new token with corr 0.22256454825401306\n",
      "Replaced token 2070 with corr 0.27059221267700195 with new token with corr 0.27059224247932434\n",
      "Replaced token 2071 with corr 0.08480403572320938 with new token with corr 0.14924263954162598\n",
      "Replaced token 2072 with corr 0.3258180618286133 with new token with corr 0.3258180618286133\n",
      "Replaced token 2073 with corr 0.2750581204891205 with new token with corr 0.2750581204891205\n",
      "Replaced token 2074 with corr 0.32324692606925964 with new token with corr 0.32324692606925964\n",
      "Replaced token 2075 with corr 0.19492687284946442 with new token with corr 0.1949268877506256\n",
      "Replaced token 2076 with corr 0.33648279309272766 with new token with corr 0.33648279309272766\n",
      "Replaced token 2077 with corr 0.3688375651836395 with new token with corr 0.3688375949859619\n",
      "Replaced token 2078 with corr 0.2819589674472809 with new token with corr 0.2819589376449585\n",
      "Replaced token 2079 with corr 0.3034098446369171 with new token with corr 0.3034098446369171\n",
      "Replaced token 2080 with corr 0.33402013778686523 with new token with corr 0.33402013778686523\n",
      "Replaced token 2081 with corr 0.3079260587692261 with new token with corr 0.3079260587692261\n",
      "Replaced token 2082 with corr 0.347206711769104 with new token with corr 0.3472067415714264\n",
      "Replaced token 2083 with corr 0.24713687598705292 with new token with corr 0.24713687598705292\n",
      "Replaced token 2084 with corr 0.19509585201740265 with new token with corr 0.19509586691856384\n",
      "Replaced token 2085 with corr 0.11269345879554749 with new token with corr 0.32850000262260437\n",
      "Replaced token 2086 with corr 0.3468100428581238 with new token with corr 0.3468100428581238\n",
      "Replaced token 2087 with corr 0.11677654832601547 with new token with corr 0.18592093884944916\n",
      "Replaced token 2088 with corr 0.09122069180011749 with new token with corr 0.15591472387313843\n",
      "Replaced token 2089 with corr 0.31874582171440125 with new token with corr 0.31874579191207886\n",
      "Replaced token 2090 with corr 0.25721675157546997 with new token with corr 0.2572167217731476\n",
      "Replaced token 2091 with corr 0.33959871530532837 with new token with corr 0.33959871530532837\n",
      "Replaced token 2092 with corr 0.3277415931224823 with new token with corr 0.3277415633201599\n",
      "Replaced token 2093 with corr 0.39228224754333496 with new token with corr 0.39228224754333496\n",
      "Replaced token 2094 with corr 0.2990463078022003 with new token with corr 0.2990463078022003\n",
      "Replaced token 2095 with corr 0.09982489794492722 with new token with corr 0.15364058315753937\n",
      "Replaced token 2096 with corr 0.25710585713386536 with new token with corr 0.25710585713386536\n",
      "Replaced token 2097 with corr 0.2997892200946808 with new token with corr 0.2997892200946808\n",
      "Replaced token 2098 with corr 0.2898580729961395 with new token with corr 0.2898580729961395\n",
      "Replaced token 2099 with corr 0.35705438256263733 with new token with corr 0.35705438256263733\n",
      "Replaced token 2100 with corr 0.3483547568321228 with new token with corr 0.3483547270298004\n",
      "Replaced token 2101 with corr 0.28419777750968933 with new token with corr 0.28419774770736694\n",
      "Replaced token 2102 with corr 0.1170656755566597 with new token with corr 0.15395185351371765\n",
      "Replaced token 2103 with corr 0.3000449240207672 with new token with corr 0.3000449240207672\n",
      "Replaced token 2104 with corr 0.3290843069553375 with new token with corr 0.32908427715301514\n",
      "Replaced token 2105 with corr 0.33038607239723206 with new token with corr 0.33038610219955444\n",
      "Replaced token 2106 with corr 0.27702829241752625 with new token with corr 0.27702829241752625\n",
      "Replaced token 2107 with corr 0.11210350692272186 with new token with corr 0.16555650532245636\n",
      "Replaced token 2108 with corr 0.22601564228534698 with new token with corr 0.22601565718650818\n",
      "Replaced token 2109 with corr 0.31129080057144165 with new token with corr 0.31129083037376404\n",
      "Replaced token 2110 with corr 0.22657600045204163 with new token with corr 0.22657601535320282\n",
      "Replaced token 2111 with corr 0.24164395034313202 with new token with corr 0.24164393544197083\n",
      "Replaced token 2112 with corr 0.24228563904762268 with new token with corr 0.24228566884994507\n",
      "Replaced token 2113 with corr 0.0988474115729332 with new token with corr 0.14790397882461548\n",
      "Replaced token 2114 with corr 0.2976948320865631 with new token with corr 0.2976948618888855\n",
      "Replaced token 2115 with corr 0.28413623571395874 with new token with corr 0.28413623571395874\n",
      "Replaced token 2116 with corr 0.3352449834346771 with new token with corr 0.3352449834346771\n",
      "Replaced token 2117 with corr 0.25052908062934875 with new token with corr 0.25052905082702637\n",
      "Replaced token 2118 with corr 0.3153778612613678 with new token with corr 0.3153778612613678\n",
      "Replaced token 2119 with corr 0.11014771461486816 with new token with corr 0.19981727004051208\n",
      "Replaced token 2120 with corr 0.21221844851970673 with new token with corr 0.21221846342086792\n",
      "Replaced token 2121 with corr 0.31576627492904663 with new token with corr 0.315766304731369\n",
      "Replaced token 2122 with corr 0.32520440220832825 with new token with corr 0.32520443201065063\n",
      "Replaced token 2123 with corr 0.26632222533226013 with new token with corr 0.26632222533226013\n",
      "Replaced token 2124 with corr 0.280360609292984 with new token with corr 0.2803606390953064\n",
      "Replaced token 2125 with corr 0.3086665868759155 with new token with corr 0.3086666166782379\n",
      "Replaced token 2126 with corr 0.38323700428009033 with new token with corr 0.38323697447776794\n",
      "Replaced token 2127 with corr 0.2617613673210144 with new token with corr 0.2617613673210144\n",
      "Replaced token 2128 with corr 0.34331297874450684 with new token with corr 0.34331297874450684\n",
      "Replaced token 2129 with corr 0.3138341009616852 with new token with corr 0.3138341009616852\n",
      "Replaced token 2130 with corr 0.2778257429599762 with new token with corr 0.2778257429599762\n",
      "Replaced token 2131 with corr 0.31508177518844604 with new token with corr 0.31508177518844604\n",
      "Replaced token 2132 with corr 0.08016213029623032 with new token with corr 0.1699904054403305\n",
      "Replaced token 2133 with corr 0.2818198502063751 with new token with corr 0.28181982040405273\n",
      "Replaced token 2134 with corr 0.2911876440048218 with new token with corr 0.2911876440048218\n",
      "Replaced token 2135 with corr 0.2732938528060913 with new token with corr 0.2732938528060913\n",
      "Replaced token 2136 with corr 0.3033713102340698 with new token with corr 0.3033713102340698\n",
      "Replaced token 2137 with corr 0.2934929132461548 with new token with corr 0.2934929132461548\n",
      "Replaced token 2138 with corr 0.29293298721313477 with new token with corr 0.29293298721313477\n",
      "Replaced token 2139 with corr 0.340131551027298 with new token with corr 0.340131551027298\n",
      "Replaced token 2140 with corr 0.29220640659332275 with new token with corr 0.29220640659332275\n",
      "Replaced token 2141 with corr 0.2633155882358551 with new token with corr 0.2633155882358551\n",
      "Replaced token 2142 with corr 0.26357677578926086 with new token with corr 0.26357677578926086\n",
      "Replaced token 2143 with corr 0.26899340748786926 with new token with corr 0.2689933776855469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2144 with corr 0.25168511271476746 with new token with corr 0.25168511271476746\n",
      "Replaced token 2145 with corr 0.2956514358520508 with new token with corr 0.2956514358520508\n",
      "Replaced token 2146 with corr 0.26056966185569763 with new token with corr 0.26056966185569763\n",
      "Replaced token 2147 with corr 0.2794680595397949 with new token with corr 0.2794680893421173\n",
      "Replaced token 2148 with corr 0.3046434819698334 with new token with corr 0.304643452167511\n",
      "Replaced token 2149 with corr 0.27328115701675415 with new token with corr 0.27328115701675415\n",
      "Replaced token 2150 with corr 0.29713916778564453 with new token with corr 0.29713916778564453\n",
      "Replaced token 2151 with corr 0.22794118523597717 with new token with corr 0.22794115543365479\n",
      "Replaced token 2152 with corr 0.2895243465900421 with new token with corr 0.2895243465900421\n",
      "Replaced token 2153 with corr 0.2783994972705841 with new token with corr 0.2783995270729065\n",
      "Replaced token 2154 with corr 0.2757263779640198 with new token with corr 0.2757263779640198\n",
      "Replaced token 2155 with corr 0.2942078411579132 with new token with corr 0.2942078113555908\n",
      "Replaced token 2156 with corr 0.09423402696847916 with new token with corr 0.14619101583957672\n",
      "Replaced token 2157 with corr 0.2777148187160492 with new token with corr 0.2777148187160492\n",
      "Replaced token 2158 with corr 0.26266321539878845 with new token with corr 0.26266321539878845\n",
      "Replaced token 2159 with corr 0.29811713099479675 with new token with corr 0.29811713099479675\n",
      "Replaced token 2160 with corr 0.30880796909332275 with new token with corr 0.30880799889564514\n",
      "Replaced token 2161 with corr 0.2769496738910675 with new token with corr 0.2769496440887451\n",
      "Replaced token 2162 with corr 0.35706594586372375 with new token with corr 0.35706594586372375\n",
      "Replaced token 2163 with corr 0.3383886516094208 with new token with corr 0.3383886516094208\n",
      "Replaced token 2164 with corr 0.1118878722190857 with new token with corr 0.14630191028118134\n",
      "Replaced token 2165 with corr 0.29387348890304565 with new token with corr 0.29387348890304565\n",
      "Replaced token 2166 with corr 0.3408741354942322 with new token with corr 0.3408741354942322\n",
      "Replaced token 2167 with corr 0.11323433369398117 with new token with corr 0.15724734961986542\n",
      "Replaced token 2168 with corr 0.32435667514801025 with new token with corr 0.32435667514801025\n",
      "Replaced token 2169 with corr 0.26947855949401855 with new token with corr 0.26947858929634094\n",
      "Replaced token 2170 with corr 0.2666380703449249 with new token with corr 0.2666381001472473\n",
      "Replaced token 2171 with corr 0.2528184950351715 with new token with corr 0.2528184950351715\n",
      "Replaced token 2172 with corr 0.25435927510261536 with new token with corr 0.25435930490493774\n",
      "Replaced token 2173 with corr 0.2367447167634964 with new token with corr 0.2367447018623352\n",
      "Replaced token 2174 with corr 0.30648282170295715 with new token with corr 0.30648285150527954\n",
      "Replaced token 2175 with corr 0.07608034461736679 with new token with corr 0.15946857631206512\n",
      "Replaced token 2176 with corr 0.2933640480041504 with new token with corr 0.2933640480041504\n",
      "Replaced token 2177 with corr 0.30915817618370056 with new token with corr 0.30915817618370056\n",
      "Replaced token 2178 with corr 0.289913147687912 with new token with corr 0.289913147687912\n",
      "Replaced token 2179 with corr 0.11742740124464035 with new token with corr 0.15789982676506042\n",
      "Replaced token 2180 with corr 0.28927111625671387 with new token with corr 0.28927111625671387\n",
      "Replaced token 2181 with corr 0.11763665080070496 with new token with corr 0.16208957135677338\n",
      "Replaced token 2182 with corr 0.2759973108768463 with new token with corr 0.2759972810745239\n",
      "Replaced token 2183 with corr 0.27473485469818115 with new token with corr 0.27473485469818115\n",
      "Replaced token 2184 with corr 0.23664166033267975 with new token with corr 0.23664164543151855\n",
      "Replaced token 2185 with corr 0.27611327171325684 with new token with corr 0.27611324191093445\n",
      "Replaced token 2186 with corr 0.31294548511505127 with new token with corr 0.31294548511505127\n",
      "Replaced token 2187 with corr 0.2906927168369293 with new token with corr 0.2906927168369293\n",
      "Replaced token 2188 with corr 0.2749820947647095 with new token with corr 0.2749820947647095\n",
      "Replaced token 2189 with corr 0.2659737765789032 with new token with corr 0.2659737765789032\n",
      "Replaced token 2190 with corr 0.18807925283908844 with new token with corr 0.18807925283908844\n",
      "Replaced token 2191 with corr 0.26121705770492554 with new token with corr 0.26121702790260315\n",
      "Replaced token 2192 with corr 0.32330596446990967 with new token with corr 0.32330596446990967\n",
      "Replaced token 2193 with corr 0.3703776001930237 with new token with corr 0.3703776001930237\n",
      "Replaced token 2194 with corr 0.09419893473386765 with new token with corr 0.16334612667560577\n",
      "Replaced token 2195 with corr 0.16735434532165527 with new token with corr 0.16735434532165527\n",
      "Replaced token 2196 with corr 0.24311122298240662 with new token with corr 0.2431112378835678\n",
      "Replaced token 2197 with corr 0.23176778852939606 with new token with corr 0.23176775872707367\n",
      "Replaced token 2198 with corr 0.3570466637611389 with new token with corr 0.3570466935634613\n",
      "Replaced token 2199 with corr 0.30375438928604126 with new token with corr 0.30375435948371887\n",
      "Replaced token 2200 with corr 0.24253641068935394 with new token with corr 0.24253639578819275\n",
      "Replaced token 2201 with corr 0.2567189335823059 with new token with corr 0.2567189335823059\n",
      "Replaced token 2202 with corr 0.32866957783699036 with new token with corr 0.32866954803466797\n",
      "Replaced token 2203 with corr 0.12454036623239517 with new token with corr 0.2125348001718521\n",
      "Replaced token 2204 with corr 0.25284329056739807 with new token with corr 0.25284329056739807\n",
      "Replaced token 2205 with corr 0.2883314788341522 with new token with corr 0.2883315086364746\n",
      "Replaced token 2206 with corr 0.10140426456928253 with new token with corr 0.14577537775039673\n",
      "Replaced token 2207 with corr 0.2603621780872345 with new token with corr 0.2603621780872345\n",
      "Replaced token 2208 with corr 0.2930876314640045 with new token with corr 0.2930876612663269\n",
      "Replaced token 2209 with corr 0.22485320270061493 with new token with corr 0.22485320270061493\n",
      "Replaced token 2210 with corr 0.36871597170829773 with new token with corr 0.3687160015106201\n",
      "Replaced token 2211 with corr 0.37248125672340393 with new token with corr 0.37248125672340393\n",
      "Replaced token 2212 with corr 0.078856460750103 with new token with corr 0.17004385590553284\n",
      "Replaced token 2213 with corr 0.2982076406478882 with new token with corr 0.29820767045021057\n",
      "Replaced token 2214 with corr 0.3328900635242462 with new token with corr 0.3328900635242462\n",
      "Replaced token 2215 with corr 0.268410861492157 with new token with corr 0.268410861492157\n",
      "Replaced token 2216 with corr 0.2905665934085846 with new token with corr 0.2905665636062622\n",
      "Replaced token 2217 with corr 0.28197574615478516 with new token with corr 0.28197571635246277\n",
      "Replaced token 2218 with corr 0.3247305750846863 with new token with corr 0.3247305452823639\n",
      "Replaced token 2219 with corr 0.17792387306690216 with new token with corr 0.17792388796806335\n",
      "Replaced token 2220 with corr 0.21956777572631836 with new token with corr 0.21956777572631836\n",
      "Replaced token 2221 with corr 0.23910431563854218 with new token with corr 0.23910430073738098\n",
      "Replaced token 2222 with corr 0.36702725291252136 with new token with corr 0.367027223110199\n",
      "Replaced token 2223 with corr 0.24323876202106476 with new token with corr 0.24323874711990356\n",
      "Replaced token 2224 with corr 0.31901830434799194 with new token with corr 0.31901833415031433\n",
      "Replaced token 2225 with corr 0.23788748681545258 with new token with corr 0.23788748681545258\n",
      "Replaced token 2226 with corr 0.318441241979599 with new token with corr 0.318441241979599\n",
      "Replaced token 2227 with corr 0.2575682997703552 with new token with corr 0.2575682997703552\n",
      "Replaced token 2228 with corr 0.22595956921577454 with new token with corr 0.22595955431461334\n",
      "Replaced token 2229 with corr 0.32811763882637024 with new token with corr 0.32811760902404785\n",
      "Replaced token 2230 with corr 0.30131271481513977 with new token with corr 0.30131271481513977\n",
      "Replaced token 2231 with corr 0.24735955893993378 with new token with corr 0.24735955893993378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2232 with corr 0.3053067624568939 with new token with corr 0.3053067624568939\n",
      "Replaced token 2233 with corr 0.3098199963569641 with new token with corr 0.3098199963569641\n",
      "Replaced token 2234 with corr 0.086077481508255 with new token with corr 0.15172408521175385\n",
      "Replaced token 2235 with corr 0.2562054693698883 with new token with corr 0.2562054395675659\n",
      "Replaced token 2236 with corr 0.2783776521682739 with new token with corr 0.2783776819705963\n",
      "Replaced token 2237 with corr 0.28958648443222046 with new token with corr 0.28958648443222046\n",
      "Replaced token 2238 with corr 0.30012860894203186 with new token with corr 0.30012863874435425\n",
      "Replaced token 2239 with corr 0.3344400227069855 with new token with corr 0.3344400227069855\n",
      "Replaced token 2240 with corr 0.3271155059337616 with new token with corr 0.3271154761314392\n",
      "Replaced token 2241 with corr 0.2861098051071167 with new token with corr 0.2861098051071167\n",
      "Replaced token 2242 with corr 0.33656877279281616 with new token with corr 0.3365687429904938\n",
      "Replaced token 2243 with corr 0.30892303586006165 with new token with corr 0.30892303586006165\n",
      "Replaced token 2244 with corr 0.3726465702056885 with new token with corr 0.3726465702056885\n",
      "Replaced token 2245 with corr 0.24875128269195557 with new token with corr 0.24875128269195557\n",
      "Replaced token 2246 with corr 0.2941197454929352 with new token with corr 0.2941197156906128\n",
      "Replaced token 2247 with corr 0.3189411759376526 with new token with corr 0.318941205739975\n",
      "Replaced token 2248 with corr 0.29666149616241455 with new token with corr 0.29666152596473694\n",
      "Replaced token 2249 with corr 0.2146950364112854 with new token with corr 0.2146950513124466\n",
      "Replaced token 2250 with corr 0.25498631596565247 with new token with corr 0.25498631596565247\n",
      "Replaced token 2251 with corr 0.29221922159194946 with new token with corr 0.29221925139427185\n",
      "Replaced token 2252 with corr 0.24849766492843628 with new token with corr 0.24849765002727509\n",
      "Replaced token 2253 with corr 0.32879355549812317 with new token with corr 0.3287935256958008\n",
      "Replaced token 2254 with corr 0.08562545478343964 with new token with corr 0.13981670141220093\n",
      "Replaced token 2255 with corr 0.3374921977519989 with new token with corr 0.3374922275543213\n",
      "Replaced token 2256 with corr 0.28792810440063477 with new token with corr 0.2879280745983124\n",
      "Replaced token 2257 with corr 0.2900208830833435 with new token with corr 0.2900208830833435\n",
      "Replaced token 2258 with corr 0.2566961944103241 with new token with corr 0.2566961944103241\n",
      "Replaced token 2259 with corr 0.26837727427482605 with new token with corr 0.26837727427482605\n",
      "Replaced token 2260 with corr 0.24313679337501526 with new token with corr 0.24313680827617645\n",
      "Replaced token 2261 with corr 0.24912463128566742 with new token with corr 0.24912463128566742\n",
      "Replaced token 2262 with corr 0.15538953244686127 with new token with corr 0.24535267055034637\n",
      "Replaced token 2263 with corr 0.34632086753845215 with new token with corr 0.34632083773612976\n",
      "Replaced token 2264 with corr 0.29542285203933716 with new token with corr 0.29542288184165955\n",
      "Replaced token 2265 with corr 0.3196865916252136 with new token with corr 0.3196865916252136\n",
      "Replaced token 2266 with corr 0.3819132149219513 with new token with corr 0.3819132149219513\n",
      "Replaced token 2267 with corr 0.2758190631866455 with new token with corr 0.2758190631866455\n",
      "Replaced token 2268 with corr 0.23756267130374908 with new token with corr 0.23756267130374908\n",
      "Replaced token 2269 with corr 0.25244787335395813 with new token with corr 0.25244784355163574\n",
      "Replaced token 2270 with corr 0.2792428731918335 with new token with corr 0.2792429029941559\n",
      "Replaced token 2271 with corr 0.3282772898674011 with new token with corr 0.3282773196697235\n",
      "Replaced token 2272 with corr 0.27460211515426636 with new token with corr 0.27460211515426636\n",
      "Replaced token 2273 with corr 0.30824336409568787 with new token with corr 0.30824336409568787\n",
      "Replaced token 2274 with corr 0.261931836605072 with new token with corr 0.2619318664073944\n",
      "Replaced token 2275 with corr 0.28939005732536316 with new token with corr 0.28939005732536316\n",
      "Replaced token 2276 with corr 0.10801269114017487 with new token with corr 0.21808457374572754\n",
      "Replaced token 2277 with corr 0.23391565680503845 with new token with corr 0.23391568660736084\n",
      "Replaced token 2278 with corr 0.2629716992378235 with new token with corr 0.2629716992378235\n",
      "Replaced token 2279 with corr 0.28644055128097534 with new token with corr 0.28644052147865295\n",
      "Replaced token 2280 with corr 0.13827355206012726 with new token with corr 0.16273275017738342\n",
      "Replaced token 2281 with corr 0.24282605946063995 with new token with corr 0.24282607436180115\n",
      "Replaced token 2282 with corr 0.34964942932128906 with new token with corr 0.34964942932128906\n",
      "Replaced token 2283 with corr 0.37619757652282715 with new token with corr 0.37619757652282715\n",
      "Replaced token 2284 with corr 0.37476465106010437 with new token with corr 0.37476465106010437\n",
      "Replaced token 2285 with corr 0.2642006576061249 with new token with corr 0.26420068740844727\n",
      "Replaced token 2286 with corr 0.2704947590827942 with new token with corr 0.2704947292804718\n",
      "Replaced token 2287 with corr 0.24810537695884705 with new token with corr 0.24810537695884705\n",
      "Replaced token 2288 with corr 0.2911323606967926 with new token with corr 0.2911323606967926\n",
      "Replaced token 2289 with corr 0.27975594997406006 with new token with corr 0.27975592017173767\n",
      "Replaced token 2290 with corr 0.28344446420669556 with new token with corr 0.28344443440437317\n",
      "Replaced token 2291 with corr 0.08843442052602768 with new token with corr 0.16082386672496796\n",
      "Replaced token 2292 with corr 0.2689962387084961 with new token with corr 0.2689962685108185\n",
      "Replaced token 2293 with corr 0.31669244170188904 with new token with corr 0.31669244170188904\n",
      "Replaced token 2294 with corr 0.29694873094558716 with new token with corr 0.29694876074790955\n",
      "Replaced token 2295 with corr 0.3093431293964386 with new token with corr 0.3093430995941162\n",
      "Replaced token 2296 with corr 0.20894081890583038 with new token with corr 0.20894081890583038\n",
      "Replaced token 2297 with corr 0.10756257176399231 with new token with corr 0.15493832528591156\n",
      "Replaced token 2298 with corr 0.28728973865509033 with new token with corr 0.2872897684574127\n",
      "Replaced token 2299 with corr 0.3982105851173401 with new token with corr 0.3982105553150177\n",
      "Replaced token 2300 with corr 0.29967960715293884 with new token with corr 0.29967963695526123\n",
      "Replaced token 2301 with corr 0.08621449023485184 with new token with corr 0.1564738005399704\n",
      "Replaced token 2302 with corr 0.3347192704677582 with new token with corr 0.3347192704677582\n",
      "Replaced token 2303 with corr 0.32920920848846436 with new token with corr 0.32920917868614197\n",
      "Replaced token 2304 with corr 0.28795188665390015 with new token with corr 0.28795188665390015\n",
      "Replaced token 2305 with corr 0.14443953335285187 with new token with corr 0.16530855000019073\n",
      "Replaced token 2306 with corr 0.27167898416519165 with new token with corr 0.27167901396751404\n",
      "Replaced token 2307 with corr 0.3103907108306885 with new token with corr 0.3103906810283661\n",
      "Replaced token 2308 with corr 0.25211140513420105 with new token with corr 0.25211143493652344\n",
      "Replaced token 2309 with corr 0.2579573392868042 with new token with corr 0.2579573690891266\n",
      "Replaced token 2310 with corr 0.3267338275909424 with new token with corr 0.32673385739326477\n",
      "Replaced token 2311 with corr 0.3320545554161072 with new token with corr 0.33205458521842957\n",
      "Replaced token 2312 with corr 0.33653053641319275 with new token with corr 0.33653050661087036\n",
      "Replaced token 2313 with corr 0.28336822986602783 with new token with corr 0.28336822986602783\n",
      "Replaced token 2314 with corr 0.22423763573169708 with new token with corr 0.2242376208305359\n",
      "Replaced token 2315 with corr 0.2331438660621643 with new token with corr 0.2331438511610031\n",
      "Replaced token 2316 with corr 0.29726263880729675 with new token with corr 0.29726266860961914\n",
      "Replaced token 2317 with corr 0.24568913877010345 with new token with corr 0.24568915367126465\n",
      "Replaced token 2318 with corr 0.26835817098617554 with new token with corr 0.26835817098617554\n",
      "Replaced token 2319 with corr 0.13409604132175446 with new token with corr 0.16834183037281036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2320 with corr 0.2665938436985016 with new token with corr 0.2665938138961792\n",
      "Replaced token 2321 with corr 0.36534029245376587 with new token with corr 0.36534029245376587\n",
      "Replaced token 2322 with corr 0.3369531035423279 with new token with corr 0.3369530737400055\n",
      "Replaced token 2323 with corr 0.21419881284236908 with new token with corr 0.21419879794120789\n",
      "Replaced token 2324 with corr 0.24003899097442627 with new token with corr 0.24003899097442627\n",
      "Replaced token 2325 with corr 0.32335197925567627 with new token with corr 0.32335200905799866\n",
      "Replaced token 2326 with corr 0.26116707921028137 with new token with corr 0.26116707921028137\n",
      "Replaced token 2327 with corr 0.08854228258132935 with new token with corr 0.15950819849967957\n",
      "Replaced token 2328 with corr 0.3768825829029083 with new token with corr 0.37688255310058594\n",
      "Replaced token 2329 with corr 0.24800637364387512 with new token with corr 0.24800638854503632\n",
      "Replaced token 2330 with corr 0.29308435320854187 with new token with corr 0.2930843234062195\n",
      "Replaced token 2331 with corr 0.2641672194004059 with new token with corr 0.2641672194004059\n",
      "Replaced token 2332 with corr 0.08288747072219849 with new token with corr 0.15377984941005707\n",
      "Replaced token 2333 with corr 0.315156489610672 with new token with corr 0.315156489610672\n",
      "Replaced token 2334 with corr 0.3116205334663391 with new token with corr 0.3116205334663391\n",
      "Replaced token 2335 with corr 0.24818916618824005 with new token with corr 0.24818916618824005\n",
      "Replaced token 2336 with corr 0.24176806211471558 with new token with corr 0.24176806211471558\n",
      "Replaced token 2337 with corr 0.28280937671661377 with new token with corr 0.28280937671661377\n",
      "Replaced token 2338 with corr 0.3108104169368744 with new token with corr 0.3108104169368744\n",
      "Replaced token 2339 with corr 0.29377079010009766 with new token with corr 0.29377079010009766\n",
      "Replaced token 2340 with corr 0.11191259324550629 with new token with corr 0.1576612889766693\n",
      "Replaced token 2341 with corr 0.3001132607460022 with new token with corr 0.3001132905483246\n",
      "Replaced token 2342 with corr 0.313757985830307 with new token with corr 0.3137580156326294\n",
      "Replaced token 2343 with corr 0.34306612610816956 with new token with corr 0.34306612610816956\n",
      "Replaced token 2344 with corr 0.09841009229421616 with new token with corr 0.1914386749267578\n",
      "Replaced token 2345 with corr 0.2557547390460968 with new token with corr 0.2557547390460968\n",
      "Replaced token 2346 with corr 0.293280690908432 with new token with corr 0.2932807207107544\n",
      "Replaced token 2347 with corr 0.35856592655181885 with new token with corr 0.35856592655181885\n",
      "Replaced token 2348 with corr 0.37328648567199707 with new token with corr 0.37328648567199707\n",
      "Replaced token 2349 with corr 0.27136772871017456 with new token with corr 0.2713676989078522\n",
      "Replaced token 2350 with corr 0.3344339430332184 with new token with corr 0.334433913230896\n",
      "Replaced token 2351 with corr 0.28635984659194946 with new token with corr 0.28635984659194946\n",
      "Replaced token 2352 with corr 0.24075984954833984 with new token with corr 0.24075986444950104\n",
      "Replaced token 2353 with corr 0.33969777822494507 with new token with corr 0.33969780802726746\n",
      "Replaced token 2354 with corr 0.34575843811035156 with new token with corr 0.3457584083080292\n",
      "Replaced token 2355 with corr 0.33309870958328247 with new token with corr 0.33309870958328247\n",
      "Replaced token 2356 with corr 0.34634509682655334 with new token with corr 0.34634509682655334\n",
      "Replaced token 2357 with corr 0.32680192589759827 with new token with corr 0.32680192589759827\n",
      "Replaced token 2358 with corr 0.13088653981685638 with new token with corr 0.2129574716091156\n",
      "Replaced token 2359 with corr 0.27271369099617004 with new token with corr 0.27271366119384766\n",
      "Replaced token 2360 with corr 0.33447787165641785 with new token with corr 0.33447790145874023\n",
      "Replaced token 2361 with corr 0.313676118850708 with new token with corr 0.3136761784553528\n",
      "Replaced token 2362 with corr 0.25888964533805847 with new token with corr 0.25888964533805847\n",
      "Replaced token 2363 with corr 0.20751219987869263 with new token with corr 0.20751221477985382\n",
      "Replaced token 2364 with corr 0.11286571621894836 with new token with corr 0.14623808860778809\n",
      "Replaced token 2365 with corr 0.10503681749105453 with new token with corr 0.1948922723531723\n",
      "Replaced token 2366 with corr 0.2659556269645691 with new token with corr 0.2659556269645691\n",
      "Replaced token 2367 with corr 0.33759987354278564 with new token with corr 0.33759990334510803\n",
      "Replaced token 2368 with corr 0.09226346760988235 with new token with corr 0.16253669559955597\n",
      "Replaced token 2369 with corr 0.35794487595558167 with new token with corr 0.35794487595558167\n",
      "Replaced token 2370 with corr 0.28353407979011536 with new token with corr 0.28353407979011536\n",
      "Replaced token 2371 with corr 0.2812137305736542 with new token with corr 0.28121376037597656\n",
      "Replaced token 2372 with corr 0.38019809126853943 with new token with corr 0.38019809126853943\n",
      "Replaced token 2373 with corr 0.3738952577114105 with new token with corr 0.3738952577114105\n",
      "Replaced token 2374 with corr 0.25581562519073486 with new token with corr 0.25581562519073486\n",
      "Replaced token 2375 with corr 0.2910464107990265 with new token with corr 0.2910464107990265\n",
      "Replaced token 2376 with corr 0.3360348045825958 with new token with corr 0.3360348045825958\n",
      "Replaced token 2377 with corr 0.316906213760376 with new token with corr 0.3169061839580536\n",
      "Replaced token 2378 with corr 0.23842260241508484 with new token with corr 0.23842261731624603\n",
      "Replaced token 2379 with corr 0.08703435212373734 with new token with corr 0.15441136062145233\n",
      "Replaced token 2380 with corr 0.3059101700782776 with new token with corr 0.3059101402759552\n",
      "Replaced token 2381 with corr 0.27995914220809937 with new token with corr 0.27995917201042175\n",
      "Replaced token 2382 with corr 0.30435118079185486 with new token with corr 0.30435118079185486\n",
      "Replaced token 2383 with corr 0.282150000333786 with new token with corr 0.2821500301361084\n",
      "Replaced token 2384 with corr 0.12280003726482391 with new token with corr 0.14209158718585968\n",
      "Replaced token 2385 with corr 0.09798111021518707 with new token with corr 0.3236064016819\n",
      "Replaced token 2386 with corr 0.10839793086051941 with new token with corr 0.17683298885822296\n",
      "Replaced token 2387 with corr 0.24104274809360504 with new token with corr 0.24104277789592743\n",
      "Replaced token 2388 with corr 0.3143964111804962 with new token with corr 0.3143964409828186\n",
      "Replaced token 2389 with corr 0.203019380569458 with new token with corr 0.20301936566829681\n",
      "Replaced token 2390 with corr 0.15832184255123138 with new token with corr 0.15832185745239258\n",
      "Replaced token 2391 with corr 0.2875964939594269 with new token with corr 0.2875964939594269\n",
      "Replaced token 2392 with corr 0.2709762454032898 with new token with corr 0.2709762156009674\n",
      "Replaced token 2393 with corr 0.1123812273144722 with new token with corr 0.16104480624198914\n",
      "Replaced token 2394 with corr 0.2162538468837738 with new token with corr 0.21625381708145142\n",
      "Replaced token 2395 with corr 0.360003262758255 with new token with corr 0.3600032329559326\n",
      "Replaced token 2396 with corr 0.10801953077316284 with new token with corr 0.1671046018600464\n",
      "Replaced token 2397 with corr 0.2999666929244995 with new token with corr 0.2999666929244995\n",
      "Replaced token 2398 with corr 0.36193543672561646 with new token with corr 0.36193546652793884\n",
      "Replaced token 2399 with corr 0.300992488861084 with new token with corr 0.3009924590587616\n",
      "Replaced token 2400 with corr 0.2757025361061096 with new token with corr 0.275702565908432\n",
      "Replaced token 2401 with corr 0.2822364866733551 with new token with corr 0.2822365164756775\n",
      "Replaced token 2402 with corr 0.29080504179000854 with new token with corr 0.29080507159233093\n",
      "Replaced token 2403 with corr 0.34722182154655457 with new token with corr 0.34722182154655457\n",
      "Replaced token 2404 with corr 0.30250346660614014 with new token with corr 0.30250346660614014\n",
      "Replaced token 2405 with corr 0.30290549993515015 with new token with corr 0.30290549993515015\n",
      "Replaced token 2406 with corr 0.24951402842998505 with new token with corr 0.24951402842998505\n",
      "Replaced token 2407 with corr 0.328118234872818 with new token with corr 0.328118234872818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2408 with corr 0.11459790915250778 with new token with corr 0.14243915677070618\n",
      "Replaced token 2409 with corr 0.32657983899116516 with new token with corr 0.3265798091888428\n",
      "Replaced token 2410 with corr 0.257398784160614 with new token with corr 0.2573988139629364\n",
      "Replaced token 2411 with corr 0.265575647354126 with new token with corr 0.2655756175518036\n",
      "Replaced token 2412 with corr 0.25119462609291077 with new token with corr 0.25119462609291077\n",
      "Replaced token 2413 with corr 0.08556809276342392 with new token with corr 0.34158772230148315\n",
      "Replaced token 2414 with corr 0.23855900764465332 with new token with corr 0.23855899274349213\n",
      "Replaced token 2415 with corr 0.3178226947784424 with new token with corr 0.3178226947784424\n",
      "Replaced token 2416 with corr 0.2963707447052002 with new token with corr 0.2963707745075226\n",
      "Replaced token 2417 with corr 0.2626577913761139 with new token with corr 0.2626577615737915\n",
      "Replaced token 2418 with corr 0.33229920268058777 with new token with corr 0.33229920268058777\n",
      "Replaced token 2419 with corr 0.2462347000837326 with new token with corr 0.2462347149848938\n",
      "Replaced token 2420 with corr 0.24991407990455627 with new token with corr 0.2499140501022339\n",
      "Replaced token 2421 with corr 0.1937524527311325 with new token with corr 0.1937524676322937\n",
      "Replaced token 2422 with corr 0.26541730761528015 with new token with corr 0.26541727781295776\n",
      "Replaced token 2423 with corr 0.31389865279197693 with new token with corr 0.31389865279197693\n",
      "Replaced token 2424 with corr 0.20765498280525208 with new token with corr 0.20765499770641327\n",
      "Replaced token 2425 with corr 0.27143269777297974 with new token with corr 0.27143266797065735\n",
      "Replaced token 2426 with corr 0.281762033700943 with new token with corr 0.281762033700943\n",
      "Replaced token 2427 with corr 0.2811938524246216 with new token with corr 0.2811938524246216\n",
      "Replaced token 2428 with corr 0.07455836236476898 with new token with corr 0.2022038847208023\n",
      "Replaced token 2429 with corr 0.32753637433052063 with new token with corr 0.32753637433052063\n",
      "Replaced token 2430 with corr 0.30187931656837463 with new token with corr 0.30187928676605225\n",
      "Replaced token 2431 with corr 0.25519439578056335 with new token with corr 0.25519439578056335\n",
      "Replaced token 2432 with corr 0.3665054142475128 with new token with corr 0.3665054142475128\n",
      "Replaced token 2433 with corr 0.2752950191497803 with new token with corr 0.2752949893474579\n",
      "Replaced token 2434 with corr 0.12066151201725006 with new token with corr 0.17029590904712677\n",
      "Replaced token 2435 with corr 0.2216341197490692 with new token with corr 0.2216341197490692\n",
      "Replaced token 2436 with corr 0.27235138416290283 with new token with corr 0.27235138416290283\n",
      "Replaced token 2437 with corr 0.27222952246665955 with new token with corr 0.27222952246665955\n",
      "Replaced token 2438 with corr 0.3510424792766571 with new token with corr 0.3510424792766571\n",
      "Replaced token 2439 with corr 0.2963464558124542 with new token with corr 0.29634642601013184\n",
      "Replaced token 2440 with corr 0.29343169927597046 with new token with corr 0.29343172907829285\n",
      "Replaced token 2441 with corr 0.2711735963821411 with new token with corr 0.2711735963821411\n",
      "Replaced token 2442 with corr 0.2870759069919586 with new token with corr 0.28707587718963623\n",
      "Replaced token 2443 with corr 0.224661186337471 with new token with corr 0.224661186337471\n",
      "Replaced token 2444 with corr 0.35054782032966614 with new token with corr 0.3505478501319885\n",
      "Replaced token 2445 with corr 0.323510080575943 with new token with corr 0.3235101103782654\n",
      "Replaced token 2446 with corr 0.10710965842008591 with new token with corr 0.23547768592834473\n",
      "Replaced token 2447 with corr 0.25556299090385437 with new token with corr 0.25556302070617676\n",
      "Replaced token 2448 with corr 0.29905420541763306 with new token with corr 0.29905420541763306\n",
      "Replaced token 2449 with corr 0.1201745867729187 with new token with corr 0.15526935458183289\n",
      "Replaced token 2450 with corr 0.27228742837905884 with new token with corr 0.27228739857673645\n",
      "Replaced token 2451 with corr 0.3069666922092438 with new token with corr 0.3069666624069214\n",
      "Replaced token 2452 with corr 0.2868647873401642 with new token with corr 0.2868647575378418\n",
      "Replaced token 2453 with corr 0.10589312762022018 with new token with corr 0.16211055219173431\n",
      "Replaced token 2454 with corr 0.10390853136777878 with new token with corr 0.2800275385379791\n",
      "Replaced token 2455 with corr 0.3100425601005554 with new token with corr 0.31004253029823303\n",
      "Replaced token 2456 with corr 0.2981671988964081 with new token with corr 0.2981671988964081\n",
      "Replaced token 2457 with corr 0.2926184833049774 with new token with corr 0.2926184833049774\n",
      "Replaced token 2458 with corr 0.36382564902305603 with new token with corr 0.3638256788253784\n",
      "Replaced token 2459 with corr 0.26190438866615295 with new token with corr 0.26190438866615295\n",
      "Replaced token 2460 with corr 0.3121853172779083 with new token with corr 0.3121853172779083\n",
      "Replaced token 2461 with corr 0.29532691836357117 with new token with corr 0.29532691836357117\n",
      "Replaced token 2462 with corr 0.3167436122894287 with new token with corr 0.3167436122894287\n",
      "Replaced token 2463 with corr 0.34623295068740845 with new token with corr 0.34623292088508606\n",
      "Replaced token 2464 with corr 0.267754465341568 with new token with corr 0.267754465341568\n",
      "Replaced token 2465 with corr 0.310619980096817 with new token with corr 0.310619980096817\n",
      "Replaced token 2466 with corr 0.34675759077072144 with new token with corr 0.34675759077072144\n",
      "Replaced token 2467 with corr 0.32076069712638855 with new token with corr 0.32076072692871094\n",
      "Replaced token 2468 with corr 0.2977660000324249 with new token with corr 0.2977660298347473\n",
      "Replaced token 2469 with corr 0.4058384299278259 with new token with corr 0.4058384299278259\n",
      "Replaced token 2470 with corr 0.26473990082740784 with new token with corr 0.26473990082740784\n",
      "Replaced token 2471 with corr 0.307456910610199 with new token with corr 0.30745697021484375\n",
      "Replaced token 2472 with corr 0.3476983308792114 with new token with corr 0.3476983606815338\n",
      "Replaced token 2473 with corr 0.2853144407272339 with new token with corr 0.2853144407272339\n",
      "Replaced token 2474 with corr 0.3292624056339264 with new token with corr 0.3292624354362488\n",
      "Replaced token 2475 with corr 0.08915002644062042 with new token with corr 0.18457834422588348\n",
      "Replaced token 2476 with corr 0.2773374915122986 with new token with corr 0.2773374915122986\n",
      "Replaced token 2477 with corr 0.35128143429756165 with new token with corr 0.35128143429756165\n",
      "Replaced token 2478 with corr 0.29708218574523926 with new token with corr 0.29708218574523926\n",
      "Replaced token 2479 with corr 0.3321651816368103 with new token with corr 0.3321651518344879\n",
      "Replaced token 2480 with corr 0.09509865939617157 with new token with corr 0.16629163920879364\n",
      "Replaced token 2481 with corr 0.30183926224708557 with new token with corr 0.30183929204940796\n",
      "Replaced token 2482 with corr 0.3173758387565613 with new token with corr 0.3173758387565613\n",
      "Replaced token 2483 with corr 0.32675012946128845 with new token with corr 0.32675012946128845\n",
      "Replaced token 2484 with corr 0.34285515546798706 with new token with corr 0.3428551256656647\n",
      "Replaced token 2485 with corr 0.2875491678714752 with new token with corr 0.28754913806915283\n",
      "Replaced token 2486 with corr 0.2695387899875641 with new token with corr 0.2695387899875641\n",
      "Replaced token 2487 with corr 0.26373666524887085 with new token with corr 0.26373663544654846\n",
      "Replaced token 2488 with corr 0.12982840836048126 with new token with corr 0.20136673748493195\n",
      "Replaced token 2489 with corr 0.14955446124076843 with new token with corr 0.15102101862430573\n",
      "Replaced token 2490 with corr 0.251158744096756 with new token with corr 0.2511587142944336\n",
      "Replaced token 2491 with corr 0.11028311401605606 with new token with corr 0.1553986519575119\n",
      "Replaced token 2492 with corr 0.34746941924095154 with new token with corr 0.34746941924095154\n",
      "Replaced token 2493 with corr 0.29124361276626587 with new token with corr 0.2912435829639435\n",
      "Replaced token 2494 with corr 0.3011809289455414 with new token with corr 0.3011809289455414\n",
      "Replaced token 2495 with corr 0.2842205762863159 with new token with corr 0.2842205762863159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2496 with corr 0.24391493201255798 with new token with corr 0.24391493201255798\n",
      "Replaced token 2497 with corr 0.10846427083015442 with new token with corr 0.2654228210449219\n",
      "Replaced token 2498 with corr 0.11025235056877136 with new token with corr 0.2499328851699829\n",
      "Replaced token 2499 with corr 0.29224881529808044 with new token with corr 0.29224878549575806\n",
      "Replaced token 2500 with corr 0.29767242074012756 with new token with corr 0.29767245054244995\n",
      "Replaced token 2501 with corr 0.2405131608247757 with new token with corr 0.2405131757259369\n",
      "Replaced token 2502 with corr 0.3364332318305969 with new token with corr 0.3364332318305969\n",
      "Replaced token 2503 with corr 0.10148318111896515 with new token with corr 0.14484058320522308\n",
      "Replaced token 2504 with corr 0.26463207602500916 with new token with corr 0.26463210582733154\n",
      "Replaced token 2505 with corr 0.2634211480617523 with new token with corr 0.2634212076663971\n",
      "Replaced token 2506 with corr 0.29011479020118713 with new token with corr 0.29011476039886475\n",
      "Replaced token 2507 with corr 0.2861105501651764 with new token with corr 0.2861105501651764\n",
      "Replaced token 2508 with corr 0.32023513317108154 with new token with corr 0.32023513317108154\n",
      "Replaced token 2509 with corr 0.13025347888469696 with new token with corr 0.2553485333919525\n",
      "Replaced token 2510 with corr 0.2968338131904602 with new token with corr 0.2968338131904602\n",
      "Replaced token 2511 with corr 0.24730059504508972 with new token with corr 0.24730059504508972\n",
      "Replaced token 2512 with corr 0.2988625168800354 with new token with corr 0.298862487077713\n",
      "Replaced token 2513 with corr 0.2667683959007263 with new token with corr 0.2667683959007263\n",
      "Replaced token 2514 with corr 0.33602774143218994 with new token with corr 0.33602777123451233\n",
      "Replaced token 2515 with corr 0.3439788520336151 with new token with corr 0.3439788818359375\n",
      "Replaced token 2516 with corr 0.26163575053215027 with new token with corr 0.26163575053215027\n",
      "Replaced token 2517 with corr 0.26474103331565857 with new token with corr 0.26474103331565857\n",
      "Replaced token 2518 with corr 0.30032098293304443 with new token with corr 0.30032098293304443\n",
      "Replaced token 2519 with corr 0.3098439872264862 with new token with corr 0.3098439872264862\n",
      "Replaced token 2520 with corr 0.34120631217956543 with new token with corr 0.3412063717842102\n",
      "Replaced token 2521 with corr 0.3782431483268738 with new token with corr 0.3782431483268738\n",
      "Replaced token 2522 with corr 0.0978996679186821 with new token with corr 0.1519155353307724\n",
      "Replaced token 2523 with corr 0.27967149019241333 with new token with corr 0.2796715199947357\n",
      "Replaced token 2524 with corr 0.31790778040885925 with new token with corr 0.31790778040885925\n",
      "Replaced token 2525 with corr 0.29313090443611145 with new token with corr 0.29313093423843384\n",
      "Replaced token 2526 with corr 0.08897241204977036 with new token with corr 0.2087474912405014\n",
      "Replaced token 2527 with corr 0.09985345602035522 with new token with corr 0.15002985298633575\n",
      "Replaced token 2528 with corr 0.31107965111732483 with new token with corr 0.31107962131500244\n",
      "Replaced token 2529 with corr 0.2659524977207184 with new token with corr 0.2659524977207184\n",
      "Replaced token 2530 with corr 0.31142711639404297 with new token with corr 0.31142711639404297\n",
      "Replaced token 2531 with corr 0.37629857659339905 with new token with corr 0.37629857659339905\n",
      "Replaced token 2532 with corr 0.33798322081565857 with new token with corr 0.3379831910133362\n",
      "Replaced token 2533 with corr 0.33447030186653137 with new token with corr 0.33447033166885376\n",
      "Replaced token 2534 with corr 0.30449262261390686 with new token with corr 0.3044925928115845\n",
      "Replaced token 2535 with corr 0.21313197910785675 with new token with corr 0.21313197910785675\n",
      "Replaced token 2536 with corr 0.3511573076248169 with new token with corr 0.3511572778224945\n",
      "Replaced token 2537 with corr 0.15176093578338623 with new token with corr 0.15205664932727814\n",
      "Replaced token 2538 with corr 0.3232862949371338 with new token with corr 0.3232863247394562\n",
      "Replaced token 2539 with corr 0.10612896829843521 with new token with corr 0.14835987985134125\n",
      "Replaced token 2540 with corr 0.351868599653244 with new token with corr 0.351868599653244\n",
      "Replaced token 2541 with corr 0.3470957577228546 with new token with corr 0.3470957577228546\n",
      "Replaced token 2542 with corr 0.33029705286026 with new token with corr 0.3302970230579376\n",
      "Replaced token 2543 with corr 0.2928001880645752 with new token with corr 0.2928001582622528\n",
      "Replaced token 2544 with corr 0.32644835114479065 with new token with corr 0.32644835114479065\n",
      "Replaced token 2545 with corr 0.31002211570739746 with new token with corr 0.31002211570739746\n",
      "Replaced token 2546 with corr 0.358834832906723 with new token with corr 0.3588348627090454\n",
      "Replaced token 2547 with corr 0.24551577866077423 with new token with corr 0.24551580846309662\n",
      "Replaced token 2548 with corr 0.31816956400871277 with new token with corr 0.3181695342063904\n",
      "Replaced token 2549 with corr 0.3262881338596344 with new token with corr 0.3262881338596344\n",
      "Replaced token 2550 with corr 0.3117679953575134 with new token with corr 0.3117680251598358\n",
      "Replaced token 2551 with corr 0.132096529006958 with new token with corr 0.15377266705036163\n",
      "Replaced token 2552 with corr 0.35181406140327454 with new token with corr 0.3518140912055969\n",
      "Replaced token 2553 with corr 0.11932205408811569 with new token with corr 0.1439962536096573\n",
      "Replaced token 2554 with corr 0.34276214241981506 with new token with corr 0.34276214241981506\n",
      "Replaced token 2555 with corr 0.29173269867897034 with new token with corr 0.29173266887664795\n",
      "Replaced token 2556 with corr 0.29792657494544983 with new token with corr 0.29792657494544983\n",
      "Replaced token 2557 with corr 0.3114372193813324 with new token with corr 0.31143718957901\n",
      "Replaced token 2558 with corr 0.2217589020729065 with new token with corr 0.2217589020729065\n",
      "Replaced token 2559 with corr 0.0657072365283966 with new token with corr 0.14971689879894257\n",
      "Replaced token 2560 with corr 0.2903388440608978 with new token with corr 0.2903388440608978\n",
      "Replaced token 2561 with corr 0.2610422372817993 with new token with corr 0.2610422372817993\n",
      "Replaced token 2562 with corr 0.27686765789985657 with new token with corr 0.27686765789985657\n",
      "Replaced token 2563 with corr 0.3469332456588745 with new token with corr 0.3469332754611969\n",
      "Replaced token 2564 with corr 0.32416483759880066 with new token with corr 0.3241647779941559\n",
      "Replaced token 2565 with corr 0.2694476246833801 with new token with corr 0.2694476246833801\n",
      "Replaced token 2566 with corr 0.24534989893436432 with new token with corr 0.24534988403320312\n",
      "Replaced token 2567 with corr 0.24958397448062897 with new token with corr 0.24958398938179016\n",
      "Replaced token 2568 with corr 0.334965318441391 with new token with corr 0.334965318441391\n",
      "Replaced token 2569 with corr 0.2984406352043152 with new token with corr 0.2984406054019928\n",
      "Replaced token 2570 with corr 0.2778298556804657 with new token with corr 0.2778298556804657\n",
      "Replaced token 2571 with corr 0.2267654538154602 with new token with corr 0.2267654538154602\n",
      "Replaced token 2572 with corr 0.23571570217609406 with new token with corr 0.23571568727493286\n",
      "Replaced token 2573 with corr 0.2436845451593399 with new token with corr 0.2436845451593399\n",
      "Replaced token 2574 with corr 0.2537340223789215 with new token with corr 0.2537340223789215\n",
      "Replaced token 2575 with corr 0.23565296828746796 with new token with corr 0.23565298318862915\n",
      "Replaced token 2576 with corr 0.30937832593917847 with new token with corr 0.30937835574150085\n",
      "Replaced token 2577 with corr 0.3292635977268219 with new token with corr 0.3292636275291443\n",
      "Replaced token 2578 with corr 0.30371320247650146 with new token with corr 0.3037131726741791\n",
      "Replaced token 2579 with corr 0.26201316714286804 with new token with corr 0.26201316714286804\n",
      "Replaced token 2580 with corr 0.39462926983833313 with new token with corr 0.39462926983833313\n",
      "Replaced token 2581 with corr 0.2589218020439148 with new token with corr 0.2589217722415924\n",
      "Replaced token 2582 with corr 0.28441092371940613 with new token with corr 0.28441089391708374\n",
      "Replaced token 2583 with corr 0.41388028860092163 with new token with corr 0.41388025879859924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2584 with corr 0.31911778450012207 with new token with corr 0.3191177546977997\n",
      "Replaced token 2585 with corr 0.10871854424476624 with new token with corr 0.21969276666641235\n",
      "Replaced token 2586 with corr 0.2828555405139923 with new token with corr 0.2828555405139923\n",
      "Replaced token 2587 with corr 0.283551961183548 with new token with corr 0.283551961183548\n",
      "Replaced token 2588 with corr 0.37462306022644043 with new token with corr 0.3746230900287628\n",
      "Replaced token 2589 with corr 0.33846715092658997 with new token with corr 0.33846715092658997\n",
      "Replaced token 2590 with corr 0.2763989567756653 with new token with corr 0.2763989269733429\n",
      "Replaced token 2591 with corr 0.3005375564098358 with new token with corr 0.3005375862121582\n",
      "Replaced token 2592 with corr 0.2291175276041031 with new token with corr 0.2291174978017807\n",
      "Replaced token 2593 with corr 0.32447218894958496 with new token with corr 0.3244721591472626\n",
      "Replaced token 2594 with corr 0.3451049029827118 with new token with corr 0.3451049029827118\n",
      "Replaced token 2595 with corr 0.2525177597999573 with new token with corr 0.2525177597999573\n",
      "Replaced token 2596 with corr 0.28943347930908203 with new token with corr 0.28943344950675964\n",
      "Replaced token 2597 with corr 0.3075200617313385 with new token with corr 0.3075200617313385\n",
      "Replaced token 2598 with corr 0.3443085253238678 with new token with corr 0.3443085253238678\n",
      "Replaced token 2599 with corr 0.26566454768180847 with new token with corr 0.26566454768180847\n",
      "Replaced token 2600 with corr 0.3151289224624634 with new token with corr 0.31512895226478577\n",
      "Replaced token 2601 with corr 0.30627214908599854 with new token with corr 0.30627214908599854\n",
      "Replaced token 2602 with corr 0.27094754576683044 with new token with corr 0.27094751596450806\n",
      "Replaced token 2603 with corr 0.32099682092666626 with new token with corr 0.32099682092666626\n",
      "Replaced token 2604 with corr 0.1071554645895958 with new token with corr 0.1581401377916336\n",
      "Replaced token 2605 with corr 0.3632311224937439 with new token with corr 0.3632311224937439\n",
      "Replaced token 2606 with corr 0.3320283889770508 with new token with corr 0.3320283889770508\n",
      "Replaced token 2607 with corr 0.36063051223754883 with new token with corr 0.36063051223754883\n",
      "Replaced token 2608 with corr 0.26426833868026733 with new token with corr 0.26426833868026733\n",
      "Replaced token 2609 with corr 0.31178832054138184 with new token with corr 0.31178832054138184\n",
      "Replaced token 2610 with corr 0.3140840232372284 with new token with corr 0.314083993434906\n",
      "Replaced token 2611 with corr 0.3085378110408783 with new token with corr 0.3085378110408783\n",
      "Replaced token 2612 with corr 0.37886881828308105 with new token with corr 0.37886881828308105\n",
      "Replaced token 2613 with corr 0.22213396430015564 with new token with corr 0.22213397920131683\n",
      "Replaced token 2614 with corr 0.29048001766204834 with new token with corr 0.29048001766204834\n",
      "Replaced token 2615 with corr 0.3611564338207245 with new token with corr 0.3611564338207245\n",
      "Replaced token 2616 with corr 0.3035559058189392 with new token with corr 0.30355584621429443\n",
      "Replaced token 2617 with corr 0.31859737634658813 with new token with corr 0.31859737634658813\n",
      "Replaced token 2618 with corr 0.3063763380050659 with new token with corr 0.3063763380050659\n",
      "Replaced token 2619 with corr 0.26216602325439453 with new token with corr 0.26216602325439453\n",
      "Replaced token 2620 with corr 0.3044167757034302 with new token with corr 0.30441680550575256\n",
      "Replaced token 2621 with corr 0.3110641837120056 with new token with corr 0.3110641837120056\n",
      "Replaced token 2622 with corr 0.3231833279132843 with new token with corr 0.3231833577156067\n",
      "Replaced token 2623 with corr 0.27708059549331665 with new token with corr 0.27708059549331665\n",
      "Replaced token 2624 with corr 0.21197715401649475 with new token with corr 0.21197716891765594\n",
      "Replaced token 2625 with corr 0.27025076746940613 with new token with corr 0.27025076746940613\n",
      "Replaced token 2626 with corr 0.36309394240379333 with new token with corr 0.3630939722061157\n",
      "Replaced token 2627 with corr 0.22445373237133026 with new token with corr 0.22445374727249146\n",
      "Replaced token 2628 with corr 0.2616274058818817 with new token with corr 0.2616274058818817\n",
      "Replaced token 2629 with corr 0.30092737078666687 with new token with corr 0.30092737078666687\n",
      "Replaced token 2630 with corr 0.2688765823841095 with new token with corr 0.2688765525817871\n",
      "Replaced token 2631 with corr 0.2933915853500366 with new token with corr 0.2933915853500366\n",
      "Replaced token 2632 with corr 0.27376267313957214 with new token with corr 0.27376267313957214\n",
      "Replaced token 2633 with corr 0.30724164843559265 with new token with corr 0.30724164843559265\n",
      "Replaced token 2634 with corr 0.188979834318161 with new token with corr 0.188979834318161\n",
      "Replaced token 2635 with corr 0.2766667604446411 with new token with corr 0.2766667604446411\n",
      "Replaced token 2636 with corr 0.3389224112033844 with new token with corr 0.3389224410057068\n",
      "Replaced token 2637 with corr 0.3326554000377655 with new token with corr 0.3326554000377655\n",
      "Replaced token 2638 with corr 0.28874778747558594 with new token with corr 0.2887478172779083\n",
      "Replaced token 2639 with corr 0.304708868265152 with new token with corr 0.304708868265152\n",
      "Replaced token 2640 with corr 0.29139164090156555 with new token with corr 0.29139161109924316\n",
      "Replaced token 2641 with corr 0.2579440772533417 with new token with corr 0.2579440772533417\n",
      "Replaced token 2642 with corr 0.26386550068855286 with new token with corr 0.26386550068855286\n",
      "Replaced token 2643 with corr 0.22779209911823273 with new token with corr 0.22779211401939392\n",
      "Replaced token 2644 with corr 0.24258165061473846 with new token with corr 0.24258165061473846\n",
      "Replaced token 2645 with corr 0.31282559037208557 with new token with corr 0.3128255605697632\n",
      "Replaced token 2646 with corr 0.2831415832042694 with new token with corr 0.2831416130065918\n",
      "Replaced token 2647 with corr 0.08146478235721588 with new token with corr 0.20139718055725098\n",
      "Replaced token 2648 with corr 0.08135887235403061 with new token with corr 0.2486138641834259\n",
      "Replaced token 2649 with corr 0.31453585624694824 with new token with corr 0.31453585624694824\n",
      "Replaced token 2650 with corr 0.34642285108566284 with new token with corr 0.34642285108566284\n",
      "Replaced token 2651 with corr 0.30649685859680176 with new token with corr 0.30649682879447937\n",
      "Replaced token 2652 with corr 0.2526836693286896 with new token with corr 0.2526836693286896\n",
      "Replaced token 2653 with corr 0.3567233979701996 with new token with corr 0.3567233979701996\n",
      "Replaced token 2654 with corr 0.28150704503059387 with new token with corr 0.2815070152282715\n",
      "Replaced token 2655 with corr 0.25582680106163025 with new token with corr 0.25582680106163025\n",
      "Replaced token 2656 with corr 0.288882315158844 with new token with corr 0.2888823449611664\n",
      "Replaced token 2657 with corr 0.3166210949420929 with new token with corr 0.3166210949420929\n",
      "Replaced token 2658 with corr 0.24692918360233307 with new token with corr 0.24692918360233307\n",
      "Replaced token 2659 with corr 0.33113011717796326 with new token with corr 0.33113008737564087\n",
      "Replaced token 2660 with corr 0.284414142370224 with new token with corr 0.284414142370224\n",
      "Replaced token 2661 with corr 0.28819870948791504 with new token with corr 0.28819870948791504\n",
      "Replaced token 2662 with corr 0.32110118865966797 with new token with corr 0.32110118865966797\n",
      "Replaced token 2663 with corr 0.2976894676685333 with new token with corr 0.2976894676685333\n",
      "Replaced token 2664 with corr 0.29620683193206787 with new token with corr 0.29620683193206787\n",
      "Replaced token 2665 with corr 0.3335820436477661 with new token with corr 0.3335820138454437\n",
      "Replaced token 2666 with corr 0.25943318009376526 with new token with corr 0.25943318009376526\n",
      "Replaced token 2667 with corr 0.30761417746543884 with new token with corr 0.30761417746543884\n",
      "Replaced token 2668 with corr 0.30359259247779846 with new token with corr 0.30359259247779846\n",
      "Replaced token 2669 with corr 0.11446455866098404 with new token with corr 0.14383286237716675\n",
      "Replaced token 2670 with corr 0.3086678087711334 with new token with corr 0.3086678087711334\n",
      "Replaced token 2671 with corr 0.3389991819858551 with new token with corr 0.3389991819858551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2672 with corr 0.2908974587917328 with new token with corr 0.2908974587917328\n",
      "Replaced token 2673 with corr 0.24893708527088165 with new token with corr 0.24893708527088165\n",
      "Replaced token 2674 with corr 0.3376678228378296 with new token with corr 0.3376678228378296\n",
      "Replaced token 2675 with corr 0.22170990705490112 with new token with corr 0.2217099368572235\n",
      "Replaced token 2676 with corr 0.31918463110923767 with new token with corr 0.3191846013069153\n",
      "Replaced token 2677 with corr 0.34275493025779724 with new token with corr 0.34275493025779724\n",
      "Replaced token 2678 with corr 0.29654979705810547 with new token with corr 0.29654979705810547\n",
      "Replaced token 2679 with corr 0.23395337164402008 with new token with corr 0.23395338654518127\n",
      "Replaced token 2680 with corr 0.3661142587661743 with new token with corr 0.36611419916152954\n",
      "Replaced token 2681 with corr 0.21709595620632172 with new token with corr 0.21709595620632172\n",
      "Replaced token 2682 with corr 0.23067955672740936 with new token with corr 0.23067954182624817\n",
      "Replaced token 2683 with corr 0.2795202136039734 with new token with corr 0.2795202434062958\n",
      "Replaced token 2684 with corr 0.2745794951915741 with new token with corr 0.2745794653892517\n",
      "Replaced token 2685 with corr 0.24545852839946747 with new token with corr 0.24545854330062866\n",
      "Replaced token 2686 with corr 0.3059993088245392 with new token with corr 0.3059993386268616\n",
      "Replaced token 2687 with corr 0.3535359799861908 with new token with corr 0.3535359799861908\n",
      "Replaced token 2688 with corr 0.2075427770614624 with new token with corr 0.2075427621603012\n",
      "Replaced token 2689 with corr 0.3221876323223114 with new token with corr 0.3221876323223114\n",
      "Replaced token 2690 with corr 0.3241457939147949 with new token with corr 0.3241457939147949\n",
      "Replaced token 2691 with corr 0.27538520097732544 with new token with corr 0.27538520097732544\n",
      "Replaced token 2692 with corr 0.29140788316726685 with new token with corr 0.29140788316726685\n",
      "Replaced token 2693 with corr 0.3104209303855896 with new token with corr 0.3104209303855896\n",
      "Replaced token 2694 with corr 0.30371421575546265 with new token with corr 0.30371421575546265\n",
      "Replaced token 2695 with corr 0.08733444660902023 with new token with corr 0.16646850109100342\n",
      "Replaced token 2696 with corr 0.2886868417263031 with new token with corr 0.2886868715286255\n",
      "Replaced token 2697 with corr 0.2959006726741791 with new token with corr 0.2959006726741791\n",
      "Replaced token 2698 with corr 0.26923754811286926 with new token with corr 0.26923754811286926\n",
      "Replaced token 2699 with corr 0.2946716845035553 with new token with corr 0.2946716845035553\n",
      "Replaced token 2700 with corr 0.29301440715789795 with new token with corr 0.29301443696022034\n",
      "Replaced token 2701 with corr 0.24191327393054962 with new token with corr 0.24191325902938843\n",
      "Replaced token 2702 with corr 0.3029789924621582 with new token with corr 0.3029789924621582\n",
      "Replaced token 2703 with corr 0.31509828567504883 with new token with corr 0.3150983154773712\n",
      "Replaced token 2704 with corr 0.3676353693008423 with new token with corr 0.3676353693008423\n",
      "Replaced token 2705 with corr 0.3350941836833954 with new token with corr 0.3350942134857178\n",
      "Replaced token 2706 with corr 0.2961191236972809 with new token with corr 0.2961190938949585\n",
      "Replaced token 2707 with corr 0.2509048283100128 with new token with corr 0.2509048283100128\n",
      "Replaced token 2708 with corr 0.26173749566078186 with new token with corr 0.26173749566078186\n",
      "Replaced token 2709 with corr 0.23902849853038788 with new token with corr 0.23902849853038788\n",
      "Replaced token 2710 with corr 0.27330490946769714 with new token with corr 0.27330493927001953\n",
      "Replaced token 2711 with corr 0.24283693730831146 with new token with corr 0.24283692240715027\n",
      "Replaced token 2712 with corr 0.07433526962995529 with new token with corr 0.24520720541477203\n",
      "Replaced token 2713 with corr 0.2615695893764496 with new token with corr 0.2615695893764496\n",
      "Replaced token 2714 with corr 0.30275261402130127 with new token with corr 0.30275261402130127\n",
      "Replaced token 2715 with corr 0.26740744709968567 with new token with corr 0.2674074172973633\n",
      "Replaced token 2716 with corr 0.3067018687725067 with new token with corr 0.3067018687725067\n",
      "Replaced token 2717 with corr 0.2410835325717926 with new token with corr 0.2410835325717926\n",
      "Replaced token 2718 with corr 0.30745992064476013 with new token with corr 0.30745992064476013\n",
      "Replaced token 2719 with corr 0.29515838623046875 with new token with corr 0.29515841603279114\n",
      "Replaced token 2720 with corr 0.10904086381196976 with new token with corr 0.14048784971237183\n",
      "Replaced token 2721 with corr 0.3131803870201111 with new token with corr 0.3131803870201111\n",
      "Replaced token 2722 with corr 0.2585141360759735 with new token with corr 0.2585141062736511\n",
      "Replaced token 2723 with corr 0.2318219542503357 with new token with corr 0.2318219393491745\n",
      "Replaced token 2724 with corr 0.2736370265483856 with new token with corr 0.2736370265483856\n",
      "Replaced token 2725 with corr 0.1429840624332428 with new token with corr 0.16428475081920624\n",
      "Replaced token 2726 with corr 0.3762853145599365 with new token with corr 0.3762853443622589\n",
      "Replaced token 2727 with corr 0.30653825402259827 with new token with corr 0.30653828382492065\n",
      "Replaced token 2728 with corr 0.2987440824508667 with new token with corr 0.2987441122531891\n",
      "Replaced token 2729 with corr 0.25515881180763245 with new token with corr 0.25515881180763245\n",
      "Replaced token 2730 with corr 0.36206701397895813 with new token with corr 0.36206698417663574\n",
      "Replaced token 2731 with corr 0.2891682982444763 with new token with corr 0.2891683280467987\n",
      "Replaced token 2732 with corr 0.33063599467277527 with new token with corr 0.3306359648704529\n",
      "Replaced token 2733 with corr 0.3137187957763672 with new token with corr 0.3137188255786896\n",
      "Replaced token 2734 with corr 0.3854750394821167 with new token with corr 0.3854750394821167\n",
      "Replaced token 2735 with corr 0.25874996185302734 with new token with corr 0.25874996185302734\n",
      "Replaced token 2736 with corr 0.2876114845275879 with new token with corr 0.2876115143299103\n",
      "Replaced token 2737 with corr 0.2497086375951767 with new token with corr 0.2497086077928543\n",
      "Replaced token 2738 with corr 0.33610138297080994 with new token with corr 0.3361014127731323\n",
      "Replaced token 2739 with corr 0.28645002841949463 with new token with corr 0.28645002841949463\n",
      "Replaced token 2740 with corr 0.22717492282390594 with new token with corr 0.22717492282390594\n",
      "Replaced token 2741 with corr 0.26017770171165466 with new token with corr 0.26017773151397705\n",
      "Replaced token 2742 with corr 0.2639171779155731 with new token with corr 0.2639171779155731\n",
      "Replaced token 2743 with corr 0.334201455116272 with new token with corr 0.3342014253139496\n",
      "Replaced token 2744 with corr 0.27773207426071167 with new token with corr 0.27773207426071167\n",
      "Replaced token 2745 with corr 0.3433434069156647 with new token with corr 0.34334343671798706\n",
      "Replaced token 2746 with corr 0.28039005398750305 with new token with corr 0.28039008378982544\n",
      "Replaced token 2747 with corr 0.3121562898159027 with new token with corr 0.3121563196182251\n",
      "Replaced token 2748 with corr 0.3490593731403351 with new token with corr 0.3490593731403351\n",
      "Replaced token 2749 with corr 0.2502122223377228 with new token with corr 0.2502122223377228\n",
      "Replaced token 2750 with corr 0.2641334533691406 with new token with corr 0.2641334533691406\n",
      "Replaced token 2751 with corr 0.2854037284851074 with new token with corr 0.2854037284851074\n",
      "Replaced token 2752 with corr 0.3114693760871887 with new token with corr 0.31146934628486633\n",
      "Replaced token 2753 with corr 0.24669423699378967 with new token with corr 0.24669422209262848\n",
      "Replaced token 2754 with corr 0.38149306178092957 with new token with corr 0.38149306178092957\n",
      "Replaced token 2755 with corr 0.32287028431892395 with new token with corr 0.32287028431892395\n",
      "Replaced token 2756 with corr 0.2647097408771515 with new token with corr 0.2647097408771515\n",
      "Replaced token 2757 with corr 0.3165879249572754 with new token with corr 0.316587895154953\n",
      "Replaced token 2758 with corr 0.28649038076400757 with new token with corr 0.28649038076400757\n",
      "Replaced token 2759 with corr 0.21919046342372894 with new token with corr 0.21919047832489014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2760 with corr 0.30247408151626587 with new token with corr 0.3024740517139435\n",
      "Replaced token 2761 with corr 0.2745416760444641 with new token with corr 0.2745416760444641\n",
      "Replaced token 2762 with corr 0.2739614248275757 with new token with corr 0.2739614248275757\n",
      "Replaced token 2763 with corr 0.29221922159194946 with new token with corr 0.29221925139427185\n",
      "Replaced token 2764 with corr 0.28300046920776367 with new token with corr 0.28300049901008606\n",
      "Replaced token 2765 with corr 0.32197168469429016 with new token with corr 0.32197168469429016\n",
      "Replaced token 2766 with corr 0.2719041109085083 with new token with corr 0.2719041407108307\n",
      "Replaced token 2767 with corr 0.29710525274276733 with new token with corr 0.29710522294044495\n",
      "Replaced token 2768 with corr 0.2699580788612366 with new token with corr 0.26995810866355896\n",
      "Replaced token 2769 with corr 0.33460861444473267 with new token with corr 0.3346085846424103\n",
      "Replaced token 2770 with corr 0.31884586811065674 with new token with corr 0.3188458979129791\n",
      "Replaced token 2771 with corr 0.2748074531555176 with new token with corr 0.2748074531555176\n",
      "Replaced token 2772 with corr 0.3049740195274353 with new token with corr 0.3049740195274353\n",
      "Replaced token 2773 with corr 0.2733740210533142 with new token with corr 0.2733740508556366\n",
      "Replaced token 2774 with corr 0.2858654856681824 with new token with corr 0.28586545586586\n",
      "Replaced token 2775 with corr 0.30528005957603455 with new token with corr 0.30528008937835693\n",
      "Replaced token 2776 with corr 0.2859567701816559 with new token with corr 0.2859567403793335\n",
      "Replaced token 2777 with corr 0.27249619364738464 with new token with corr 0.27249622344970703\n",
      "Replaced token 2778 with corr 0.33588284254074097 with new token with corr 0.33588284254074097\n",
      "Replaced token 2779 with corr 0.2590414583683014 with new token with corr 0.2590414583683014\n",
      "Replaced token 2780 with corr 0.2980993688106537 with new token with corr 0.2980993390083313\n",
      "Replaced token 2781 with corr 0.29683902859687805 with new token with corr 0.29683905839920044\n",
      "Replaced token 2782 with corr 0.26940247416496277 with new token with corr 0.26940247416496277\n",
      "Replaced token 2783 with corr 0.23235636949539185 with new token with corr 0.23235636949539185\n",
      "Replaced token 2784 with corr 0.2207922488451004 with new token with corr 0.2207922488451004\n",
      "Replaced token 2785 with corr 0.36619874835014343 with new token with corr 0.36619868874549866\n",
      "Replaced token 2786 with corr 0.3227582275867462 with new token with corr 0.32275819778442383\n",
      "Replaced token 2787 with corr 0.09799249470233917 with new token with corr 0.21334560215473175\n",
      "Replaced token 2788 with corr 0.2801832854747772 with new token with corr 0.2801832854747772\n",
      "Replaced token 2789 with corr 0.23962482810020447 with new token with corr 0.23962482810020447\n",
      "Replaced token 2790 with corr 0.26322004199028015 with new token with corr 0.26322001218795776\n",
      "Replaced token 2791 with corr 0.16134113073349 with new token with corr 0.16563992202281952\n",
      "Replaced token 2792 with corr 0.33082279562950134 with new token with corr 0.33082276582717896\n",
      "Replaced token 2793 with corr 0.3004613518714905 with new token with corr 0.3004613518714905\n",
      "Replaced token 2794 with corr 0.2798250615596771 with new token with corr 0.2798250913619995\n",
      "Replaced token 2795 with corr 0.09221586585044861 with new token with corr 0.28454074263572693\n",
      "Replaced token 2796 with corr 0.23205003142356873 with new token with corr 0.23205004632472992\n",
      "Replaced token 2797 with corr 0.3085041642189026 with new token with corr 0.3085041344165802\n",
      "Replaced token 2798 with corr 0.28555572032928467 with new token with corr 0.28555575013160706\n",
      "Replaced token 2799 with corr 0.26465746760368347 with new token with corr 0.26465746760368347\n",
      "Replaced token 2800 with corr 0.26523175835609436 with new token with corr 0.26523175835609436\n",
      "Replaced token 2801 with corr 0.24698272347450256 with new token with corr 0.24698272347450256\n",
      "Replaced token 2802 with corr 0.10049636662006378 with new token with corr 0.27976542711257935\n",
      "Replaced token 2803 with corr 0.262136310338974 with new token with corr 0.262136310338974\n",
      "Replaced token 2804 with corr 0.2906356453895569 with new token with corr 0.2906356453895569\n",
      "Replaced token 2805 with corr 0.12199008464813232 with new token with corr 0.237598717212677\n",
      "Replaced token 2806 with corr 0.24868839979171753 with new token with corr 0.24868841469287872\n",
      "Replaced token 2807 with corr 0.24953097105026245 with new token with corr 0.24953097105026245\n",
      "Replaced token 2808 with corr 0.3033660352230072 with new token with corr 0.3033660352230072\n",
      "Replaced token 2809 with corr 0.26606717705726624 with new token with corr 0.26606717705726624\n",
      "Replaced token 2810 with corr 0.2958488464355469 with new token with corr 0.2958488464355469\n",
      "Replaced token 2811 with corr 0.3474056124687195 with new token with corr 0.34740564227104187\n",
      "Replaced token 2812 with corr 0.23759867250919342 with new token with corr 0.23759865760803223\n",
      "Replaced token 2813 with corr 0.25458118319511414 with new token with corr 0.25458118319511414\n",
      "Replaced token 2814 with corr 0.356563001871109 with new token with corr 0.3565630316734314\n",
      "Replaced token 2815 with corr 0.25072818994522095 with new token with corr 0.25072821974754333\n",
      "Replaced token 2816 with corr 0.32879430055618286 with new token with corr 0.32879430055618286\n",
      "Replaced token 2817 with corr 0.3717728853225708 with new token with corr 0.3717728853225708\n",
      "Replaced token 2818 with corr 0.2687458097934723 with new token with corr 0.2687458097934723\n",
      "Replaced token 2819 with corr 0.27956581115722656 with new token with corr 0.27956581115722656\n",
      "Replaced token 2820 with corr 0.22151122987270355 with new token with corr 0.22151122987270355\n",
      "Replaced token 2821 with corr 0.28981852531433105 with new token with corr 0.28981852531433105\n",
      "Replaced token 2822 with corr 0.303772509098053 with new token with corr 0.3037724494934082\n",
      "Replaced token 2823 with corr 0.3238969147205353 with new token with corr 0.3238969147205353\n",
      "Replaced token 2824 with corr 0.3613503873348236 with new token with corr 0.3613503575325012\n",
      "Replaced token 2825 with corr 0.26315000653266907 with new token with corr 0.26315000653266907\n",
      "Replaced token 2826 with corr 0.26298582553863525 with new token with corr 0.26298579573631287\n",
      "Replaced token 2827 with corr 0.22951042652130127 with new token with corr 0.22951041162014008\n",
      "Replaced token 2828 with corr 0.08878589421510696 with new token with corr 0.29726266860961914\n",
      "Replaced token 2829 with corr 0.2933420240879059 with new token with corr 0.2933419942855835\n",
      "Replaced token 2830 with corr 0.20165354013442993 with new token with corr 0.20165355503559113\n",
      "Replaced token 2831 with corr 0.27021777629852295 with new token with corr 0.27021774649620056\n",
      "Replaced token 2832 with corr 0.31579670310020447 with new token with corr 0.3157966732978821\n",
      "Replaced token 2833 with corr 0.3280692994594574 with new token with corr 0.328069269657135\n",
      "Replaced token 2834 with corr 0.33151814341545105 with new token with corr 0.33151811361312866\n",
      "Replaced token 2835 with corr 0.27734723687171936 with new token with corr 0.27734723687171936\n",
      "Replaced token 2836 with corr 0.32972583174705505 with new token with corr 0.32972583174705505\n",
      "Replaced token 2837 with corr 0.3465122580528259 with new token with corr 0.3465122580528259\n",
      "Replaced token 2838 with corr 0.3062092065811157 with new token with corr 0.3062092065811157\n",
      "Replaced token 2839 with corr 0.325134813785553 with new token with corr 0.325134813785553\n",
      "Replaced token 2840 with corr 0.32268545031547546 with new token with corr 0.32268545031547546\n",
      "Replaced token 2841 with corr 0.2413710355758667 with new token with corr 0.2413710206747055\n",
      "Replaced token 2842 with corr 0.2520052194595337 with new token with corr 0.2520052194595337\n",
      "Replaced token 2843 with corr 0.2357548028230667 with new token with corr 0.23575478792190552\n",
      "Replaced token 2844 with corr 0.2961461544036865 with new token with corr 0.2961462140083313\n",
      "Replaced token 2845 with corr 0.31345993280410767 with new token with corr 0.31345996260643005\n",
      "Replaced token 2846 with corr 0.3198065161705017 with new token with corr 0.3198065161705017\n",
      "Replaced token 2847 with corr 0.21777568757534027 with new token with corr 0.21777568757534027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2848 with corr 0.3067866861820221 with new token with corr 0.3067866563796997\n",
      "Replaced token 2849 with corr 0.2183353453874588 with new token with corr 0.2183353304862976\n",
      "Replaced token 2850 with corr 0.33283042907714844 with new token with corr 0.3328304588794708\n",
      "Replaced token 2851 with corr 0.2671043574810028 with new token with corr 0.2671043276786804\n",
      "Replaced token 2852 with corr 0.21350370347499847 with new token with corr 0.21350370347499847\n",
      "Replaced token 2853 with corr 0.30248093605041504 with new token with corr 0.30248090624809265\n",
      "Replaced token 2854 with corr 0.2542282044887543 with new token with corr 0.2542281746864319\n",
      "Replaced token 2855 with corr 0.10787904262542725 with new token with corr 0.15284587442874908\n",
      "Replaced token 2856 with corr 0.08848107606172562 with new token with corr 0.17137888073921204\n",
      "Replaced token 2857 with corr 0.26940762996673584 with new token with corr 0.2694076597690582\n",
      "Replaced token 2858 with corr 0.315197229385376 with new token with corr 0.31519725918769836\n",
      "Replaced token 2859 with corr 0.2968900501728058 with new token with corr 0.2968900501728058\n",
      "Replaced token 2860 with corr 0.12482638657093048 with new token with corr 0.17887961864471436\n",
      "Replaced token 2861 with corr 0.292353093624115 with new token with corr 0.2923531234264374\n",
      "Replaced token 2862 with corr 0.31414225697517395 with new token with corr 0.31414222717285156\n",
      "Replaced token 2863 with corr 0.438101202249527 with new token with corr 0.43810123205184937\n",
      "Replaced token 2864 with corr 0.2774585783481598 with new token with corr 0.2774585485458374\n",
      "Replaced token 2865 with corr 0.2585780620574951 with new token with corr 0.2585780918598175\n",
      "Replaced token 2866 with corr 0.3156187832355499 with new token with corr 0.3156188130378723\n",
      "Replaced token 2867 with corr 0.23154732584953308 with new token with corr 0.2315473109483719\n",
      "Replaced token 2868 with corr 0.131745383143425 with new token with corr 0.15329201519489288\n",
      "Replaced token 2869 with corr 0.36376938223838806 with new token with corr 0.3637693226337433\n",
      "Replaced token 2870 with corr 0.09994734823703766 with new token with corr 0.16403447091579437\n",
      "Replaced token 2871 with corr 0.3136526942253113 with new token with corr 0.3136526942253113\n",
      "Replaced token 2872 with corr 0.3249572515487671 with new token with corr 0.3249572813510895\n",
      "Replaced token 2873 with corr 0.3249828517436981 with new token with corr 0.3249828517436981\n",
      "Replaced token 2874 with corr 0.21038228273391724 with new token with corr 0.21038228273391724\n",
      "Replaced token 2875 with corr 0.23968590795993805 with new token with corr 0.23968589305877686\n",
      "Replaced token 2876 with corr 0.3169795870780945 with new token with corr 0.3169795572757721\n",
      "Replaced token 2877 with corr 0.32436180114746094 with new token with corr 0.32436177134513855\n",
      "Replaced token 2878 with corr 0.33499592542648315 with new token with corr 0.33499592542648315\n",
      "Replaced token 2879 with corr 0.3983750343322754 with new token with corr 0.3983750641345978\n",
      "Replaced token 2880 with corr 0.24862967431545258 with new token with corr 0.24862965941429138\n",
      "Replaced token 2881 with corr 0.3341231048107147 with new token with corr 0.33412307500839233\n",
      "Replaced token 2882 with corr 0.08526802062988281 with new token with corr 0.21527671813964844\n",
      "Replaced token 2883 with corr 0.10055611282587051 with new token with corr 0.23668323457241058\n",
      "Replaced token 2884 with corr 0.3689287006855011 with new token with corr 0.3689286708831787\n",
      "Replaced token 2885 with corr 0.34343960881233215 with new token with corr 0.34343960881233215\n",
      "Replaced token 2886 with corr 0.28688085079193115 with new token with corr 0.28688085079193115\n",
      "Replaced token 2887 with corr 0.2743631601333618 with new token with corr 0.2743631899356842\n",
      "Replaced token 2888 with corr 0.34227249026298523 with new token with corr 0.34227246046066284\n",
      "Replaced token 2889 with corr 0.34242671728134155 with new token with corr 0.34242668747901917\n",
      "Replaced token 2890 with corr 0.3215048015117645 with new token with corr 0.3215048015117645\n",
      "Replaced token 2891 with corr 0.290465384721756 with new token with corr 0.290465384721756\n",
      "Replaced token 2892 with corr 0.3207411468029022 with new token with corr 0.3207411468029022\n",
      "Replaced token 2893 with corr 0.30816781520843506 with new token with corr 0.30816781520843506\n",
      "Replaced token 2894 with corr 0.2557085454463959 with new token with corr 0.2557085454463959\n",
      "Replaced token 2895 with corr 0.29844406247138977 with new token with corr 0.29844406247138977\n",
      "Replaced token 2896 with corr 0.1986403912305832 with new token with corr 0.1986403912305832\n",
      "Replaced token 2897 with corr 0.27121278643608093 with new token with corr 0.2712128162384033\n",
      "Replaced token 2898 with corr 0.29497823119163513 with new token with corr 0.29497823119163513\n",
      "Replaced token 2899 with corr 0.2862793207168579 with new token with corr 0.2862792909145355\n",
      "Replaced token 2900 with corr 0.2898256480693817 with new token with corr 0.2898256480693817\n",
      "Replaced token 2901 with corr 0.10089803487062454 with new token with corr 0.1897086352109909\n",
      "Replaced token 2902 with corr 0.25884872674942017 with new token with corr 0.25884872674942017\n",
      "Replaced token 2903 with corr 0.24282129108905792 with new token with corr 0.24282130599021912\n",
      "Replaced token 2904 with corr 0.3164783716201782 with new token with corr 0.31647831201553345\n",
      "Replaced token 2905 with corr 0.26568174362182617 with new token with corr 0.2656817138195038\n",
      "Replaced token 2906 with corr 0.2285589724779129 with new token with corr 0.22855901718139648\n",
      "Replaced token 2907 with corr 0.3090537488460541 with new token with corr 0.3090537488460541\n",
      "Replaced token 2908 with corr 0.34442922472953796 with new token with corr 0.3444291949272156\n",
      "Replaced token 2909 with corr 0.2795051336288452 with new token with corr 0.2795051336288452\n",
      "Replaced token 2910 with corr 0.29954278469085693 with new token with corr 0.29954278469085693\n",
      "Replaced token 2911 with corr 0.1145368367433548 with new token with corr 0.22872769832611084\n",
      "Replaced token 2912 with corr 0.27101242542266846 with new token with corr 0.27101239562034607\n",
      "Replaced token 2913 with corr 0.327333927154541 with new token with corr 0.32733389735221863\n",
      "Replaced token 2914 with corr 0.08962295949459076 with new token with corr 0.2755124270915985\n",
      "Replaced token 2915 with corr 0.30346038937568665 with new token with corr 0.30346041917800903\n",
      "Replaced token 2916 with corr 0.35747575759887695 with new token with corr 0.35747575759887695\n",
      "Replaced token 2917 with corr 0.296988844871521 with new token with corr 0.296988844871521\n",
      "Replaced token 2918 with corr 0.259734183549881 with new token with corr 0.259734183549881\n",
      "Replaced token 2919 with corr 0.29218679666519165 with new token with corr 0.29218679666519165\n",
      "Replaced token 2920 with corr 0.3563610315322876 with new token with corr 0.3563610017299652\n",
      "Replaced token 2921 with corr 0.2519075870513916 with new token with corr 0.2519075870513916\n",
      "Replaced token 2922 with corr 0.2916238009929657 with new token with corr 0.2916238009929657\n",
      "Replaced token 2923 with corr 0.24916958808898926 with new token with corr 0.24916960299015045\n",
      "Replaced token 2924 with corr 0.25099965929985046 with new token with corr 0.25099965929985046\n",
      "Replaced token 2925 with corr 0.3491073548793793 with new token with corr 0.3491073548793793\n",
      "Replaced token 2926 with corr 0.0813339427113533 with new token with corr 0.1766229122877121\n",
      "Replaced token 2927 with corr 0.27954116463661194 with new token with corr 0.2795411944389343\n",
      "Replaced token 2928 with corr 0.3766881823539734 with new token with corr 0.3766882121562958\n",
      "Replaced token 2929 with corr 0.23667219281196594 with new token with corr 0.23667219281196594\n",
      "Replaced token 2930 with corr 0.3087972402572632 with new token with corr 0.3087972402572632\n",
      "Replaced token 2931 with corr 0.10793379694223404 with new token with corr 0.3027452528476715\n",
      "Replaced token 2932 with corr 0.12502598762512207 with new token with corr 0.1574915200471878\n",
      "Replaced token 2933 with corr 0.2849438190460205 with new token with corr 0.2849437892436981\n",
      "Replaced token 2934 with corr 0.31736308336257935 with new token with corr 0.31736308336257935\n",
      "Replaced token 2935 with corr 0.2991573214530945 with new token with corr 0.29915735125541687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 2936 with corr 0.23710085451602936 with new token with corr 0.23710085451602936\n",
      "Replaced token 2937 with corr 0.27495405077934265 with new token with corr 0.27495402097702026\n",
      "Replaced token 2938 with corr 0.3096819818019867 with new token with corr 0.3096819818019867\n",
      "Replaced token 2939 with corr 0.3300201892852783 with new token with corr 0.3300202190876007\n",
      "Replaced token 2940 with corr 0.2858734726905823 with new token with corr 0.2858734726905823\n",
      "Replaced token 2941 with corr 0.32987192273139954 with new token with corr 0.32987192273139954\n",
      "Replaced token 2942 with corr 0.1250670999288559 with new token with corr 0.1625632345676422\n",
      "Replaced token 2943 with corr 0.12474377453327179 with new token with corr 0.2676112949848175\n",
      "Replaced token 2944 with corr 0.3048621714115143 with new token with corr 0.3048621714115143\n",
      "Replaced token 2945 with corr 0.2683846950531006 with new token with corr 0.2683846950531006\n",
      "Replaced token 2946 with corr 0.29472604393959045 with new token with corr 0.29472604393959045\n",
      "Replaced token 2947 with corr 0.3283272385597229 with new token with corr 0.3283272385597229\n",
      "Replaced token 2948 with corr 0.3104345500469208 with new token with corr 0.3104345500469208\n",
      "Replaced token 2949 with corr 0.27767401933670044 with new token with corr 0.2776740491390228\n",
      "Replaced token 2950 with corr 0.34119388461112976 with new token with corr 0.34119391441345215\n",
      "Replaced token 2951 with corr 0.2833544611930847 with new token with corr 0.2833544909954071\n",
      "Replaced token 2952 with corr 0.24196849763393402 with new token with corr 0.24196849763393402\n",
      "Replaced token 2953 with corr 0.2843092679977417 with new token with corr 0.2843092679977417\n",
      "Replaced token 2954 with corr 0.1689448356628418 with new token with corr 0.1689448356628418\n",
      "Replaced token 2955 with corr 0.3129800856113434 with new token with corr 0.3129800856113434\n",
      "Replaced token 2956 with corr 0.27514368295669556 with new token with corr 0.27514368295669556\n",
      "Replaced token 2957 with corr 0.3698638379573822 with new token with corr 0.3698638677597046\n",
      "Replaced token 2958 with corr 0.29062825441360474 with new token with corr 0.29062825441360474\n",
      "Replaced token 2959 with corr 0.3310646712779999 with new token with corr 0.3310646712779999\n",
      "Replaced token 2960 with corr 0.2776823937892914 with new token with corr 0.27768242359161377\n",
      "Replaced token 2961 with corr 0.30943095684051514 with new token with corr 0.30943095684051514\n",
      "Replaced token 2962 with corr 0.08167469501495361 with new token with corr 0.15196111798286438\n",
      "Replaced token 2963 with corr 0.30250924825668335 with new token with corr 0.30250924825668335\n",
      "Replaced token 2964 with corr 0.270112544298172 with new token with corr 0.2701125741004944\n",
      "Replaced token 2965 with corr 0.29687026143074036 with new token with corr 0.29687026143074036\n",
      "Replaced token 2966 with corr 0.2869407534599304 with new token with corr 0.2869407534599304\n",
      "Replaced token 2967 with corr 0.2672543227672577 with new token with corr 0.2672543227672577\n",
      "Replaced token 2968 with corr 0.25345471501350403 with new token with corr 0.25345471501350403\n",
      "Replaced token 2969 with corr 0.3877059817314148 with new token with corr 0.3877059519290924\n",
      "Replaced token 2970 with corr 0.2982275187969208 with new token with corr 0.2982275187969208\n",
      "Replaced token 2971 with corr 0.34566861391067505 with new token with corr 0.34566864371299744\n",
      "Replaced token 2972 with corr 0.26005709171295166 with new token with corr 0.2600570619106293\n",
      "Replaced token 2973 with corr 0.2971177101135254 with new token with corr 0.297117680311203\n",
      "Replaced token 2974 with corr 0.29304805397987366 with new token with corr 0.29304805397987366\n",
      "Replaced token 2975 with corr 0.2805350720882416 with new token with corr 0.2805350422859192\n",
      "Replaced token 2976 with corr 0.10337535291910172 with new token with corr 0.1584203541278839\n",
      "Replaced token 2977 with corr 0.11099407821893692 with new token with corr 0.14886930584907532\n",
      "Replaced token 2978 with corr 0.3511083722114563 with new token with corr 0.3511084020137787\n",
      "Replaced token 2979 with corr 0.34007322788238525 with new token with corr 0.34007319808006287\n",
      "Replaced token 2980 with corr 0.2454444319009781 with new token with corr 0.24544444680213928\n",
      "Replaced token 2981 with corr 0.3330356776714325 with new token with corr 0.3330356776714325\n",
      "Replaced token 2982 with corr 0.23054486513137817 with new token with corr 0.23054486513137817\n",
      "Replaced token 2983 with corr 0.3034144341945648 with new token with corr 0.3034144341945648\n",
      "Replaced token 2984 with corr 0.2724500596523285 with new token with corr 0.2724500894546509\n",
      "Replaced token 2985 with corr 0.2961947023868561 with new token with corr 0.2961947023868561\n",
      "Replaced token 2986 with corr 0.3326423764228821 with new token with corr 0.3326423466205597\n",
      "Replaced token 2987 with corr 0.28480035066604614 with new token with corr 0.28480038046836853\n",
      "Replaced token 2988 with corr 0.30023837089538574 with new token with corr 0.30023837089538574\n",
      "Replaced token 2989 with corr 0.3244364857673645 with new token with corr 0.3244364857673645\n",
      "Replaced token 2990 with corr 0.3479374051094055 with new token with corr 0.3479374051094055\n",
      "Replaced token 2991 with corr 0.3307269215583801 with new token with corr 0.3307269513607025\n",
      "Replaced token 2992 with corr 0.30573374032974243 with new token with corr 0.30573374032974243\n",
      "Replaced token 2993 with corr 0.34381458163261414 with new token with corr 0.3438146114349365\n",
      "Replaced token 2994 with corr 0.2958308458328247 with new token with corr 0.2958308458328247\n",
      "Replaced token 2995 with corr 0.28919607400894165 with new token with corr 0.28919604420661926\n",
      "Replaced token 2996 with corr 0.3117140531539917 with new token with corr 0.3117140233516693\n",
      "Replaced token 2997 with corr 0.2718154788017273 with new token with corr 0.2718155086040497\n",
      "Replaced token 2998 with corr 0.3307749629020691 with new token with corr 0.3307749330997467\n",
      "Replaced token 2999 with corr 0.2853197157382965 with new token with corr 0.2853197157382965\n",
      "Replaced token 3000 with corr 0.21487168967723846 with new token with corr 0.21487168967723846\n",
      "Replaced token 3001 with corr 0.2549532651901245 with new token with corr 0.2549532949924469\n",
      "Replaced token 3002 with corr 0.18597263097763062 with new token with corr 0.18597261607646942\n",
      "Replaced token 3003 with corr 0.2789969742298126 with new token with corr 0.2789969742298126\n",
      "Replaced token 3004 with corr 0.34002000093460083 with new token with corr 0.34002000093460083\n",
      "Replaced token 3005 with corr 0.2886573076248169 with new token with corr 0.2886573076248169\n",
      "Replaced token 3006 with corr 0.2906310260295868 with new token with corr 0.2906309962272644\n",
      "Replaced token 3007 with corr 0.24815182387828827 with new token with corr 0.24815180897712708\n",
      "Replaced token 3008 with corr 0.2820442318916321 with new token with corr 0.2820442318916321\n",
      "Replaced token 3009 with corr 0.29477500915527344 with new token with corr 0.2947750389575958\n",
      "Replaced token 3010 with corr 0.11868207156658173 with new token with corr 0.14755398035049438\n",
      "Replaced token 3011 with corr 0.2520068883895874 with new token with corr 0.2520069181919098\n",
      "Replaced token 3012 with corr 0.3445465862751007 with new token with corr 0.3445465862751007\n",
      "Replaced token 3013 with corr 0.2870844304561615 with new token with corr 0.2870844602584839\n",
      "Replaced token 3014 with corr 0.30479276180267334 with new token with corr 0.30479273200035095\n",
      "Replaced token 3015 with corr 0.3186180889606476 with new token with corr 0.3186180889606476\n",
      "Replaced token 3016 with corr 0.2754878103733063 with new token with corr 0.2754878103733063\n",
      "Replaced token 3017 with corr 0.16304586827754974 with new token with corr 0.16304586827754974\n",
      "Replaced token 3018 with corr 0.3059351146221161 with new token with corr 0.3059351146221161\n",
      "Replaced token 3019 with corr 0.29364579916000366 with new token with corr 0.2936457395553589\n",
      "Replaced token 3020 with corr 0.36311015486717224 with new token with corr 0.36311018466949463\n",
      "Replaced token 3021 with corr 0.3374064564704895 with new token with corr 0.3374064564704895\n",
      "Replaced token 3022 with corr 0.23606713116168976 with new token with corr 0.23606711626052856\n",
      "Replaced token 3023 with corr 0.10768715292215347 with new token with corr 0.14940567314624786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3024 with corr 0.29437822103500366 with new token with corr 0.2943781912326813\n",
      "Replaced token 3025 with corr 0.24959178268909454 with new token with corr 0.24959179759025574\n",
      "Replaced token 3026 with corr 0.31492072343826294 with new token with corr 0.31492069363594055\n",
      "Replaced token 3027 with corr 0.11195295304059982 with new token with corr 0.2836076021194458\n",
      "Replaced token 3028 with corr 0.2808561325073242 with new token with corr 0.2808561623096466\n",
      "Replaced token 3029 with corr 0.2707647979259491 with new token with corr 0.2707647681236267\n",
      "Replaced token 3030 with corr 0.09112260490655899 with new token with corr 0.21726897358894348\n",
      "Replaced token 3031 with corr 0.1106770858168602 with new token with corr 0.1531311273574829\n",
      "Replaced token 3032 with corr 0.31789588928222656 with new token with corr 0.31789588928222656\n",
      "Replaced token 3033 with corr 0.3275725841522217 with new token with corr 0.32757261395454407\n",
      "Replaced token 3034 with corr 0.4182170629501343 with new token with corr 0.41821709275245667\n",
      "Replaced token 3035 with corr 0.23624597489833832 with new token with corr 0.23624597489833832\n",
      "Replaced token 3036 with corr 0.31206944584846497 with new token with corr 0.31206944584846497\n",
      "Replaced token 3037 with corr 0.3439180850982666 with new token with corr 0.3439180850982666\n",
      "Replaced token 3038 with corr 0.2502279579639435 with new token with corr 0.2502279281616211\n",
      "Replaced token 3039 with corr 0.27650755643844604 with new token with corr 0.27650755643844604\n",
      "Replaced token 3040 with corr 0.28191205859184265 with new token with corr 0.28191208839416504\n",
      "Replaced token 3041 with corr 0.3068418502807617 with new token with corr 0.3068418800830841\n",
      "Replaced token 3042 with corr 0.24207259714603424 with new token with corr 0.24207261204719543\n",
      "Replaced token 3043 with corr 0.23321692645549774 with new token with corr 0.23321694135665894\n",
      "Replaced token 3044 with corr 0.23700664937496185 with new token with corr 0.23700666427612305\n",
      "Replaced token 3045 with corr 0.23867835104465485 with new token with corr 0.23867838084697723\n",
      "Replaced token 3046 with corr 0.28706252574920654 with new token with corr 0.28706249594688416\n",
      "Replaced token 3047 with corr 0.3081338405609131 with new token with corr 0.3081338405609131\n",
      "Replaced token 3048 with corr 0.2929076850414276 with new token with corr 0.29290771484375\n",
      "Replaced token 3049 with corr 0.3181764483451843 with new token with corr 0.31817641854286194\n",
      "Replaced token 3050 with corr 0.2967861592769623 with new token with corr 0.29678618907928467\n",
      "Replaced token 3051 with corr 0.2199171632528305 with new token with corr 0.2199171632528305\n",
      "Replaced token 3052 with corr 0.33219289779663086 with new token with corr 0.33219289779663086\n",
      "Replaced token 3053 with corr 0.30898818373680115 with new token with corr 0.30898818373680115\n",
      "Replaced token 3054 with corr 0.1288672685623169 with new token with corr 0.23834443092346191\n",
      "Replaced token 3055 with corr 0.22233976423740387 with new token with corr 0.22233976423740387\n",
      "Replaced token 3056 with corr 0.17507396638393402 with new token with corr 0.17507395148277283\n",
      "Replaced token 3057 with corr 0.3907829225063324 with new token with corr 0.3907829523086548\n",
      "Replaced token 3058 with corr 0.37363094091415405 with new token with corr 0.37363094091415405\n",
      "Replaced token 3059 with corr 0.21145398914813995 with new token with corr 0.21145397424697876\n",
      "Replaced token 3060 with corr 0.3333773910999298 with new token with corr 0.3333773910999298\n",
      "Replaced token 3061 with corr 0.2352861911058426 with new token with corr 0.23528620600700378\n",
      "Replaced token 3062 with corr 0.30178752541542053 with new token with corr 0.30178752541542053\n",
      "Replaced token 3063 with corr 0.3040354549884796 with new token with corr 0.3040354549884796\n",
      "Replaced token 3064 with corr 0.37461230158805847 with new token with corr 0.37461233139038086\n",
      "Replaced token 3065 with corr 0.33548790216445923 with new token with corr 0.33548790216445923\n",
      "Replaced token 3066 with corr 0.32375794649124146 with new token with corr 0.32375794649124146\n",
      "Replaced token 3067 with corr 0.30812907218933105 with new token with corr 0.30812910199165344\n",
      "Replaced token 3068 with corr 0.234377920627594 with new token with corr 0.2343779355287552\n",
      "Replaced token 3069 with corr 0.23138783872127533 with new token with corr 0.23138782382011414\n",
      "Replaced token 3070 with corr 0.2654120624065399 with new token with corr 0.2654120624065399\n",
      "Replaced token 3071 with corr 0.15201009809970856 with new token with corr 0.15590743720531464\n",
      "Replaced token 3072 with corr 0.26388198137283325 with new token with corr 0.26388201117515564\n",
      "Replaced token 3073 with corr 0.27733683586120605 with new token with corr 0.27733680605888367\n",
      "Replaced token 3074 with corr 0.26661771535873413 with new token with corr 0.26661771535873413\n",
      "Replaced token 3075 with corr 0.2823447585105896 with new token with corr 0.282344788312912\n",
      "Replaced token 3076 with corr 0.2647377550601959 with new token with corr 0.2647377550601959\n",
      "Replaced token 3077 with corr 0.2772602140903473 with new token with corr 0.2772602140903473\n",
      "Replaced token 3078 with corr 0.29426464438438416 with new token with corr 0.29426467418670654\n",
      "Replaced token 3079 with corr 0.2445032149553299 with new token with corr 0.2445032149553299\n",
      "Replaced token 3080 with corr 0.32566526532173157 with new token with corr 0.32566529512405396\n",
      "Replaced token 3081 with corr 0.32514744997024536 with new token with corr 0.325147420167923\n",
      "Replaced token 3082 with corr 0.2627272307872772 with new token with corr 0.2627272605895996\n",
      "Replaced token 3083 with corr 0.2666110694408417 with new token with corr 0.2666110694408417\n",
      "Replaced token 3084 with corr 0.3045254349708557 with new token with corr 0.3045254051685333\n",
      "Replaced token 3085 with corr 0.28806379437446594 with new token with corr 0.28806379437446594\n",
      "Replaced token 3086 with corr 0.24133707582950592 with new token with corr 0.24133706092834473\n",
      "Replaced token 3087 with corr 0.25576937198638916 with new token with corr 0.25576940178871155\n",
      "Replaced token 3088 with corr 0.2911570072174072 with new token with corr 0.2911570072174072\n",
      "Replaced token 3089 with corr 0.2710430920124054 with new token with corr 0.2710430920124054\n",
      "Replaced token 3090 with corr 0.27473559975624084 with new token with corr 0.27473559975624084\n",
      "Replaced token 3091 with corr 0.3050699830055237 with new token with corr 0.3050699532032013\n",
      "Replaced token 3092 with corr 0.259738028049469 with new token with corr 0.2597380578517914\n",
      "Replaced token 3093 with corr 0.1469605416059494 with new token with corr 0.15437667071819305\n",
      "Replaced token 3094 with corr 0.10854519158601761 with new token with corr 0.30788329243659973\n",
      "Replaced token 3095 with corr 0.33825966715812683 with new token with corr 0.33825966715812683\n",
      "Replaced token 3096 with corr 0.329983651638031 with new token with corr 0.32998359203338623\n",
      "Replaced token 3097 with corr 0.2511182725429535 with new token with corr 0.2511182725429535\n",
      "Replaced token 3098 with corr 0.2759745419025421 with new token with corr 0.2759745419025421\n",
      "Replaced token 3099 with corr 0.3271556794643402 with new token with corr 0.3271557092666626\n",
      "Replaced token 3100 with corr 0.36967575550079346 with new token with corr 0.36967578530311584\n",
      "Replaced token 3101 with corr 0.31623518466949463 with new token with corr 0.31623518466949463\n",
      "Replaced token 3102 with corr 0.257233589887619 with new token with corr 0.25723356008529663\n",
      "Replaced token 3103 with corr 0.2643526494503021 with new token with corr 0.2643526494503021\n",
      "Replaced token 3104 with corr 0.23625992238521576 with new token with corr 0.23625995218753815\n",
      "Replaced token 3105 with corr 0.23645085096359253 with new token with corr 0.23645083606243134\n",
      "Replaced token 3106 with corr 0.2993021011352539 with new token with corr 0.2993021011352539\n",
      "Replaced token 3107 with corr 0.2648746073246002 with new token with corr 0.2648746073246002\n",
      "Replaced token 3108 with corr 0.29073476791381836 with new token with corr 0.29073476791381836\n",
      "Replaced token 3109 with corr 0.10213868319988251 with new token with corr 0.25648751854896545\n",
      "Replaced token 3110 with corr 0.25401708483695984 with new token with corr 0.25401708483695984\n",
      "Replaced token 3111 with corr 0.26566454768180847 with new token with corr 0.26566454768180847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3112 with corr 0.27349796891212463 with new token with corr 0.27349793910980225\n",
      "Replaced token 3113 with corr 0.3272770941257477 with new token with corr 0.32727712392807007\n",
      "Replaced token 3114 with corr 0.27382317185401917 with new token with corr 0.27382317185401917\n",
      "Replaced token 3115 with corr 0.28083154559135437 with new token with corr 0.28083157539367676\n",
      "Replaced token 3116 with corr 0.2517532706260681 with new token with corr 0.2517533004283905\n",
      "Replaced token 3117 with corr 0.325269490480423 with new token with corr 0.325269490480423\n",
      "Replaced token 3118 with corr 0.37553170323371887 with new token with corr 0.3755316734313965\n",
      "Replaced token 3119 with corr 0.22620822489261627 with new token with corr 0.22620820999145508\n",
      "Replaced token 3120 with corr 0.2085699439048767 with new token with corr 0.2085699439048767\n",
      "Replaced token 3121 with corr 0.282205194234848 with new token with corr 0.28220516443252563\n",
      "Replaced token 3122 with corr 0.2896576523780823 with new token with corr 0.2896576523780823\n",
      "Replaced token 3123 with corr 0.26595795154571533 with new token with corr 0.26595792174339294\n",
      "Replaced token 3124 with corr 0.3495568335056305 with new token with corr 0.3495568633079529\n",
      "Replaced token 3125 with corr 0.29221898317337036 with new token with corr 0.29221898317337036\n",
      "Replaced token 3126 with corr 0.2457440197467804 with new token with corr 0.2457440048456192\n",
      "Replaced token 3127 with corr 0.0960758626461029 with new token with corr 0.15783217549324036\n",
      "Replaced token 3128 with corr 0.08161012083292007 with new token with corr 0.2301304042339325\n",
      "Replaced token 3129 with corr 0.29283106327056885 with new token with corr 0.29283109307289124\n",
      "Replaced token 3130 with corr 0.29544126987457275 with new token with corr 0.29544129967689514\n",
      "Replaced token 3131 with corr 0.2885768413543701 with new token with corr 0.2885768711566925\n",
      "Replaced token 3132 with corr 0.3120284974575043 with new token with corr 0.3120284676551819\n",
      "Replaced token 3133 with corr 0.16447652876377106 with new token with corr 0.16447654366493225\n",
      "Replaced token 3134 with corr 0.27460968494415283 with new token with corr 0.27460968494415283\n",
      "Replaced token 3135 with corr 0.2741852402687073 with new token with corr 0.2741852402687073\n",
      "Replaced token 3136 with corr 0.26002201437950134 with new token with corr 0.26002201437950134\n",
      "Replaced token 3137 with corr 0.240180104970932 with new token with corr 0.24018007516860962\n",
      "Replaced token 3138 with corr 0.3414745628833771 with new token with corr 0.3414745628833771\n",
      "Replaced token 3139 with corr 0.2561131417751312 with new token with corr 0.2561131417751312\n",
      "Replaced token 3140 with corr 0.23581522703170776 with new token with corr 0.23581522703170776\n",
      "Replaced token 3141 with corr 0.20907486975193024 with new token with corr 0.20907486975193024\n",
      "Replaced token 3142 with corr 0.2947503626346588 with new token with corr 0.2947503626346588\n",
      "Replaced token 3143 with corr 0.08852166682481766 with new token with corr 0.19981727004051208\n",
      "Replaced token 3144 with corr 0.24447542428970337 with new token with corr 0.24447540938854218\n",
      "Replaced token 3145 with corr 0.27173852920532227 with new token with corr 0.2717384994029999\n",
      "Replaced token 3146 with corr 0.25524207949638367 with new token with corr 0.25524207949638367\n",
      "Replaced token 3147 with corr 0.3049796521663666 with new token with corr 0.3049796223640442\n",
      "Replaced token 3148 with corr 0.29916274547576904 with new token with corr 0.29916277527809143\n",
      "Replaced token 3149 with corr 0.29765620827674866 with new token with corr 0.29765620827674866\n",
      "Replaced token 3150 with corr 0.2926345467567444 with new token with corr 0.2926345765590668\n",
      "Replaced token 3151 with corr 0.2599993348121643 with new token with corr 0.2599993050098419\n",
      "Replaced token 3152 with corr 0.3552083969116211 with new token with corr 0.3552083969116211\n",
      "Replaced token 3153 with corr 0.30235573649406433 with new token with corr 0.30235573649406433\n",
      "Replaced token 3154 with corr 0.19718770682811737 with new token with corr 0.19718770682811737\n",
      "Replaced token 3155 with corr 0.26042112708091736 with new token with corr 0.26042115688323975\n",
      "Replaced token 3156 with corr 0.2809746265411377 with new token with corr 0.2809746265411377\n",
      "Replaced token 3157 with corr 0.2588382661342621 with new token with corr 0.2588382661342621\n",
      "Replaced token 3158 with corr 0.28486308455467224 with new token with corr 0.28486308455467224\n",
      "Replaced token 3159 with corr 0.3234153687953949 with new token with corr 0.3234153687953949\n",
      "Replaced token 3160 with corr 0.30907654762268066 with new token with corr 0.3090765178203583\n",
      "Replaced token 3161 with corr 0.2862318754196167 with new token with corr 0.2862319052219391\n",
      "Replaced token 3162 with corr 0.3153914511203766 with new token with corr 0.3153914511203766\n",
      "Replaced token 3163 with corr 0.3213709592819214 with new token with corr 0.3213709592819214\n",
      "Replaced token 3164 with corr 0.23847374320030212 with new token with corr 0.23847375810146332\n",
      "Replaced token 3165 with corr 0.2175707221031189 with new token with corr 0.2175707072019577\n",
      "Replaced token 3166 with corr 0.09498576074838638 with new token with corr 0.24592570960521698\n",
      "Replaced token 3167 with corr 0.2365710437297821 with new token with corr 0.2365710586309433\n",
      "Replaced token 3168 with corr 0.30335816740989685 with new token with corr 0.30335819721221924\n",
      "Replaced token 3169 with corr 0.28934669494628906 with new token with corr 0.28934669494628906\n",
      "Replaced token 3170 with corr 0.3097341060638428 with new token with corr 0.3097340762615204\n",
      "Replaced token 3171 with corr 0.22573663294315338 with new token with corr 0.22573663294315338\n",
      "Replaced token 3172 with corr 0.24573630094528198 with new token with corr 0.24573631584644318\n",
      "Replaced token 3173 with corr 0.3006598949432373 with new token with corr 0.3006598949432373\n",
      "Replaced token 3174 with corr 0.3108856678009033 with new token with corr 0.3108856976032257\n",
      "Replaced token 3175 with corr 0.14499571919441223 with new token with corr 0.2901389002799988\n",
      "Replaced token 3176 with corr 0.27366510033607483 with new token with corr 0.27366507053375244\n",
      "Replaced token 3177 with corr 0.3565112352371216 with new token with corr 0.3565112352371216\n",
      "Replaced token 3178 with corr 0.29372432827949524 with new token with corr 0.29372432827949524\n",
      "Replaced token 3179 with corr 0.2831222414970398 with new token with corr 0.2831222712993622\n",
      "Replaced token 3180 with corr 0.3295915126800537 with new token with corr 0.3295915424823761\n",
      "Replaced token 3181 with corr 0.29014885425567627 with new token with corr 0.29014885425567627\n",
      "Replaced token 3182 with corr 0.26823312044143677 with new token with corr 0.26823312044143677\n",
      "Replaced token 3183 with corr 0.3748120367527008 with new token with corr 0.3748120069503784\n",
      "Replaced token 3184 with corr 0.2985673248767853 with new token with corr 0.2985673248767853\n",
      "Replaced token 3185 with corr 0.23156166076660156 with new token with corr 0.23156166076660156\n",
      "Replaced token 3186 with corr 0.3196883499622345 with new token with corr 0.3196883499622345\n",
      "Replaced token 3187 with corr 0.2760879695415497 with new token with corr 0.2760879695415497\n",
      "Replaced token 3188 with corr 0.3055450916290283 with new token with corr 0.3055450916290283\n",
      "Replaced token 3189 with corr 0.29650354385375977 with new token with corr 0.29650357365608215\n",
      "Replaced token 3190 with corr 0.3065164387226105 with new token with corr 0.3065164387226105\n",
      "Replaced token 3191 with corr 0.3160277307033539 with new token with corr 0.3160277307033539\n",
      "Replaced token 3192 with corr 0.3444533050060272 with new token with corr 0.3444533348083496\n",
      "Replaced token 3193 with corr 0.2908287048339844 with new token with corr 0.2908287048339844\n",
      "Replaced token 3194 with corr 0.453325480222702 with new token with corr 0.4533255100250244\n",
      "Replaced token 3195 with corr 0.2173149585723877 with new token with corr 0.2173149585723877\n",
      "Replaced token 3196 with corr 0.24810419976711273 with new token with corr 0.24810419976711273\n",
      "Replaced token 3197 with corr 0.243911013007164 with new token with corr 0.243911013007164\n",
      "Replaced token 3198 with corr 0.26917630434036255 with new token with corr 0.26917627453804016\n",
      "Replaced token 3199 with corr 0.3511580526828766 with new token with corr 0.3511580526828766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3200 with corr 0.35557079315185547 with new token with corr 0.35557079315185547\n",
      "Replaced token 3201 with corr 0.2779083549976349 with new token with corr 0.2779083847999573\n",
      "Replaced token 3202 with corr 0.3136618137359619 with new token with corr 0.3136618435382843\n",
      "Replaced token 3203 with corr 0.29559752345085144 with new token with corr 0.29559752345085144\n",
      "Replaced token 3204 with corr 0.1083015725016594 with new token with corr 0.20106463134288788\n",
      "Replaced token 3205 with corr 0.2595655620098114 with new token with corr 0.2595655620098114\n",
      "Replaced token 3206 with corr 0.2629847526550293 with new token with corr 0.2629847526550293\n",
      "Replaced token 3207 with corr 0.2465239316225052 with new token with corr 0.2465239316225052\n",
      "Replaced token 3208 with corr 0.26102933287620544 with new token with corr 0.26102933287620544\n",
      "Replaced token 3209 with corr 0.24372412264347076 with new token with corr 0.24372415244579315\n",
      "Replaced token 3210 with corr 0.30520591139793396 with new token with corr 0.30520591139793396\n",
      "Replaced token 3211 with corr 0.1092938631772995 with new token with corr 0.22648459672927856\n",
      "Replaced token 3212 with corr 0.23105508089065552 with new token with corr 0.23105508089065552\n",
      "Replaced token 3213 with corr 0.09117642790079117 with new token with corr 0.16049659252166748\n",
      "Replaced token 3214 with corr 0.28603681921958923 with new token with corr 0.28603678941726685\n",
      "Replaced token 3215 with corr 0.27146634459495544 with new token with corr 0.27146634459495544\n",
      "Replaced token 3216 with corr 0.28376346826553345 with new token with corr 0.28376349806785583\n",
      "Replaced token 3217 with corr 0.3282027542591095 with new token with corr 0.3282027840614319\n",
      "Replaced token 3218 with corr 0.3005363345146179 with new token with corr 0.3005363345146179\n",
      "Replaced token 3219 with corr 0.23004469275474548 with new token with corr 0.2300446778535843\n",
      "Replaced token 3220 with corr 0.25070518255233765 with new token with corr 0.25070518255233765\n",
      "Replaced token 3221 with corr 0.07762452960014343 with new token with corr 0.2182246446609497\n",
      "Replaced token 3222 with corr 0.3071686923503876 with new token with corr 0.3071686625480652\n",
      "Replaced token 3223 with corr 0.09327423572540283 with new token with corr 0.2611684203147888\n",
      "Replaced token 3224 with corr 0.11905615776777267 with new token with corr 0.16442018747329712\n",
      "Replaced token 3225 with corr 0.26221826672554016 with new token with corr 0.26221826672554016\n",
      "Replaced token 3226 with corr 0.3848671317100525 with new token with corr 0.3848671615123749\n",
      "Replaced token 3227 with corr 0.24920257925987244 with new token with corr 0.24920259416103363\n",
      "Replaced token 3228 with corr 0.2860143482685089 with new token with corr 0.2860143482685089\n",
      "Replaced token 3229 with corr 0.27864402532577515 with new token with corr 0.27864399552345276\n",
      "Replaced token 3230 with corr 0.11070850491523743 with new token with corr 0.14476200938224792\n",
      "Replaced token 3231 with corr 0.2636707127094269 with new token with corr 0.2636707127094269\n",
      "Replaced token 3232 with corr 0.29628419876098633 with new token with corr 0.29628416895866394\n",
      "Replaced token 3233 with corr 0.2598402798175812 with new token with corr 0.2598402798175812\n",
      "Replaced token 3234 with corr 0.30233001708984375 with new token with corr 0.30232998728752136\n",
      "Replaced token 3235 with corr 0.29370754957199097 with new token with corr 0.29370754957199097\n",
      "Replaced token 3236 with corr 0.2789425551891327 with new token with corr 0.2789425551891327\n",
      "Replaced token 3237 with corr 0.2993912100791931 with new token with corr 0.2993911802768707\n",
      "Replaced token 3238 with corr 0.3232467472553253 with new token with corr 0.3232467472553253\n",
      "Replaced token 3239 with corr 0.301766037940979 with new token with corr 0.30176597833633423\n",
      "Replaced token 3240 with corr 0.2630290687084198 with new token with corr 0.2630290985107422\n",
      "Replaced token 3241 with corr 0.2160891443490982 with new token with corr 0.2160891443490982\n",
      "Replaced token 3242 with corr 0.28592005372047424 with new token with corr 0.28592005372047424\n",
      "Replaced token 3243 with corr 0.21711134910583496 with new token with corr 0.21711134910583496\n",
      "Replaced token 3244 with corr 0.25187742710113525 with new token with corr 0.25187745690345764\n",
      "Replaced token 3245 with corr 0.2872714698314667 with new token with corr 0.2872714698314667\n",
      "Replaced token 3246 with corr 0.2663094997406006 with new token with corr 0.2663094699382782\n",
      "Replaced token 3247 with corr 0.28579631447792053 with new token with corr 0.2857963442802429\n",
      "Replaced token 3248 with corr 0.3099329471588135 with new token with corr 0.3099329471588135\n",
      "Replaced token 3249 with corr 0.2848811149597168 with new token with corr 0.2848811149597168\n",
      "Replaced token 3250 with corr 0.3415716886520386 with new token with corr 0.3415716886520386\n",
      "Replaced token 3251 with corr 0.2379777580499649 with new token with corr 0.2379777580499649\n",
      "Replaced token 3252 with corr 0.2223692089319229 with new token with corr 0.2223692238330841\n",
      "Replaced token 3253 with corr 0.33372440934181213 with new token with corr 0.33372440934181213\n",
      "Replaced token 3254 with corr 0.26653262972831726 with new token with corr 0.26653265953063965\n",
      "Replaced token 3255 with corr 0.30542802810668945 with new token with corr 0.30542802810668945\n",
      "Replaced token 3256 with corr 0.28583747148513794 with new token with corr 0.2858375012874603\n",
      "Replaced token 3257 with corr 0.3315267860889435 with new token with corr 0.3315267860889435\n",
      "Replaced token 3258 with corr 0.3360157907009125 with new token with corr 0.3360157907009125\n",
      "Replaced token 3259 with corr 0.3140585422515869 with new token with corr 0.3140585422515869\n",
      "Replaced token 3260 with corr 0.2908836603164673 with new token with corr 0.2908836603164673\n",
      "Replaced token 3261 with corr 0.29043564200401306 with new token with corr 0.29043567180633545\n",
      "Replaced token 3262 with corr 0.29636842012405396 with new token with corr 0.29636839032173157\n",
      "Replaced token 3263 with corr 0.22814206779003143 with new token with corr 0.22814208269119263\n",
      "Replaced token 3264 with corr 0.3187439739704132 with new token with corr 0.3187439441680908\n",
      "Replaced token 3265 with corr 0.19253109395503998 with new token with corr 0.19253110885620117\n",
      "Replaced token 3266 with corr 0.38574984669685364 with new token with corr 0.3857499063014984\n",
      "Replaced token 3267 with corr 0.27784493565559387 with new token with corr 0.27784496545791626\n",
      "Replaced token 3268 with corr 0.28589147329330444 with new token with corr 0.28589150309562683\n",
      "Replaced token 3269 with corr 0.29249459505081177 with new token with corr 0.2924945652484894\n",
      "Replaced token 3270 with corr 0.3711445927619934 with new token with corr 0.3711445927619934\n",
      "Replaced token 3271 with corr 0.21919046342372894 with new token with corr 0.21919047832489014\n",
      "Replaced token 3272 with corr 0.304792582988739 with new token with corr 0.3047925531864166\n",
      "Replaced token 3273 with corr 0.27557334303855896 with new token with corr 0.27557334303855896\n",
      "Replaced token 3274 with corr 0.31342247128486633 with new token with corr 0.31342247128486633\n",
      "Replaced token 3275 with corr 0.18228386342525482 with new token with corr 0.18228386342525482\n",
      "Replaced token 3276 with corr 0.2546376883983612 with new token with corr 0.2546376883983612\n",
      "Replaced token 3277 with corr 0.3158162832260132 with new token with corr 0.31581631302833557\n",
      "Replaced token 3278 with corr 0.3118370771408081 with new token with corr 0.3118370473384857\n",
      "Replaced token 3279 with corr 0.24274340271949768 with new token with corr 0.24274341762065887\n",
      "Replaced token 3280 with corr 0.2889942228794098 with new token with corr 0.2889941930770874\n",
      "Replaced token 3281 with corr 0.2711394429206848 with new token with corr 0.2711394429206848\n",
      "Replaced token 3282 with corr 0.2506932020187378 with new token with corr 0.2506932020187378\n",
      "Replaced token 3283 with corr 0.27722787857055664 with new token with corr 0.27722787857055664\n",
      "Replaced token 3284 with corr 0.29006218910217285 with new token with corr 0.29006218910217285\n",
      "Replaced token 3285 with corr 0.24757516384124756 with new token with corr 0.24757516384124756\n",
      "Replaced token 3286 with corr 0.26548072695732117 with new token with corr 0.26548072695732117\n",
      "Replaced token 3287 with corr 0.27534645795822144 with new token with corr 0.27534645795822144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3288 with corr 0.22772473096847534 with new token with corr 0.22772474586963654\n",
      "Replaced token 3289 with corr 0.2852020561695099 with new token with corr 0.2852020561695099\n",
      "Replaced token 3290 with corr 0.3536558747291565 with new token with corr 0.3536558747291565\n",
      "Replaced token 3291 with corr 0.18335793912410736 with new token with corr 0.18335793912410736\n",
      "Replaced token 3292 with corr 0.2679148018360138 with new token with corr 0.2679148018360138\n",
      "Replaced token 3293 with corr 0.32561662793159485 with new token with corr 0.32561659812927246\n",
      "Replaced token 3294 with corr 0.2518559396266937 with new token with corr 0.2518559396266937\n",
      "Replaced token 3295 with corr 0.31833773851394653 with new token with corr 0.3183377683162689\n",
      "Replaced token 3296 with corr 0.2566039562225342 with new token with corr 0.2566039562225342\n",
      "Replaced token 3297 with corr 0.3216404616832733 with new token with corr 0.3216404616832733\n",
      "Replaced token 3298 with corr 0.30224525928497314 with new token with corr 0.30224522948265076\n",
      "Replaced token 3299 with corr 0.3242455720901489 with new token with corr 0.3242456018924713\n",
      "Replaced token 3300 with corr 0.25323137640953064 with new token with corr 0.253231406211853\n",
      "Replaced token 3301 with corr 0.24892164766788483 with new token with corr 0.24892166256904602\n",
      "Replaced token 3302 with corr 0.24301142990589142 with new token with corr 0.24301142990589142\n",
      "Replaced token 3303 with corr 0.26866012811660767 with new token with corr 0.2686600983142853\n",
      "Replaced token 3304 with corr 0.2988011837005615 with new token with corr 0.2988011837005615\n",
      "Replaced token 3305 with corr 0.34027954936027527 with new token with corr 0.34027954936027527\n",
      "Replaced token 3306 with corr 0.2621079087257385 with new token with corr 0.2621079087257385\n",
      "Replaced token 3307 with corr 0.35990941524505615 with new token with corr 0.35990941524505615\n",
      "Replaced token 3308 with corr 0.10283837467432022 with new token with corr 0.23205004632472992\n",
      "Replaced token 3309 with corr 0.2998174726963043 with new token with corr 0.2998174726963043\n",
      "Replaced token 3310 with corr 0.29347941279411316 with new token with corr 0.29347947239875793\n",
      "Replaced token 3311 with corr 0.30663591623306274 with new token with corr 0.30663585662841797\n",
      "Replaced token 3312 with corr 0.34176966547966003 with new token with corr 0.34176963567733765\n",
      "Replaced token 3313 with corr 0.27363121509552 with new token with corr 0.27363121509552\n",
      "Replaced token 3314 with corr 0.24191544950008392 with new token with corr 0.24191543459892273\n",
      "Replaced token 3315 with corr 0.2544754147529602 with new token with corr 0.2544754445552826\n",
      "Replaced token 3316 with corr 0.2754204571247101 with new token with corr 0.2754204571247101\n",
      "Replaced token 3317 with corr 0.2404063642024994 with new token with corr 0.2404063642024994\n",
      "Replaced token 3318 with corr 0.2266005575656891 with new token with corr 0.2266005426645279\n",
      "Replaced token 3319 with corr 0.2615332305431366 with new token with corr 0.2615332007408142\n",
      "Replaced token 3320 with corr 0.2303869128227234 with new token with corr 0.2303869128227234\n",
      "Replaced token 3321 with corr 0.26070916652679443 with new token with corr 0.26070913672447205\n",
      "Replaced token 3322 with corr 0.2707408368587494 with new token with corr 0.270740807056427\n",
      "Replaced token 3323 with corr 0.23797406256198883 with new token with corr 0.23797406256198883\n",
      "Replaced token 3324 with corr 0.2964463233947754 with new token with corr 0.2964463233947754\n",
      "Replaced token 3325 with corr 0.23811496794223785 with new token with corr 0.23811496794223785\n",
      "Replaced token 3326 with corr 0.2679224908351898 with new token with corr 0.2679225504398346\n",
      "Replaced token 3327 with corr 0.2994460463523865 with new token with corr 0.2994460463523865\n",
      "Replaced token 3328 with corr 0.28086209297180176 with new token with corr 0.28086209297180176\n",
      "Replaced token 3329 with corr 0.1003747284412384 with new token with corr 0.14953385293483734\n",
      "Replaced token 3330 with corr 0.2846640646457672 with new token with corr 0.2846640646457672\n",
      "Replaced token 3331 with corr 0.32396233081817627 with new token with corr 0.32396233081817627\n",
      "Replaced token 3332 with corr 0.3463469445705414 with new token with corr 0.34634697437286377\n",
      "Replaced token 3333 with corr 0.28507664799690247 with new token with corr 0.28507664799690247\n",
      "Replaced token 3334 with corr 0.2138420045375824 with new token with corr 0.2138420194387436\n",
      "Replaced token 3335 with corr 0.08474868535995483 with new token with corr 0.260865181684494\n",
      "Replaced token 3336 with corr 0.2776681184768677 with new token with corr 0.2776680886745453\n",
      "Replaced token 3337 with corr 0.2940506041049957 with new token with corr 0.2940506041049957\n",
      "Replaced token 3338 with corr 0.27137839794158936 with new token with corr 0.27137836813926697\n",
      "Replaced token 3339 with corr 0.2362114042043686 with new token with corr 0.2362114042043686\n",
      "Replaced token 3340 with corr 0.08995696157217026 with new token with corr 0.29117822647094727\n",
      "Replaced token 3341 with corr 0.3530758321285248 with new token with corr 0.3530758023262024\n",
      "Replaced token 3342 with corr 0.2705787420272827 with new token with corr 0.2705787420272827\n",
      "Replaced token 3343 with corr 0.105535127222538 with new token with corr 0.14037670195102692\n",
      "Replaced token 3344 with corr 0.07471393793821335 with new token with corr 0.20954430103302002\n",
      "Replaced token 3345 with corr 0.29006427526474 with new token with corr 0.2900643050670624\n",
      "Replaced token 3346 with corr 0.32132142782211304 with new token with corr 0.32132139801979065\n",
      "Replaced token 3347 with corr 0.28736552596092224 with new token with corr 0.28736552596092224\n",
      "Replaced token 3348 with corr 0.3210318982601166 with new token with corr 0.3210318982601166\n",
      "Replaced token 3349 with corr 0.3259076774120331 with new token with corr 0.3259076774120331\n",
      "Replaced token 3350 with corr 0.29346543550491333 with new token with corr 0.2934654653072357\n",
      "Replaced token 3351 with corr 0.4293423295021057 with new token with corr 0.4293423593044281\n",
      "Replaced token 3352 with corr 0.30051085352897644 with new token with corr 0.30051082372665405\n",
      "Replaced token 3353 with corr 0.27797389030456543 with new token with corr 0.27797389030456543\n",
      "Replaced token 3354 with corr 0.2855277359485626 with new token with corr 0.28552770614624023\n",
      "Replaced token 3355 with corr 0.3176450729370117 with new token with corr 0.3176450729370117\n",
      "Replaced token 3356 with corr 0.29481756687164307 with new token with corr 0.29481759667396545\n",
      "Replaced token 3357 with corr 0.29271432757377625 with new token with corr 0.29271435737609863\n",
      "Replaced token 3358 with corr 0.20528152585029602 with new token with corr 0.20528154075145721\n",
      "Replaced token 3359 with corr 0.2660179138183594 with new token with corr 0.2660179138183594\n",
      "Replaced token 3360 with corr 0.2765789330005646 with new token with corr 0.27657899260520935\n",
      "Replaced token 3361 with corr 0.22673194110393524 with new token with corr 0.22673191130161285\n",
      "Replaced token 3362 with corr 0.30010804533958435 with new token with corr 0.30010804533958435\n",
      "Replaced token 3363 with corr 0.3272864520549774 with new token with corr 0.3272864520549774\n",
      "Replaced token 3364 with corr 0.1469879299402237 with new token with corr 0.1714986264705658\n",
      "Replaced token 3365 with corr 0.34081918001174927 with new token with corr 0.34081918001174927\n",
      "Replaced token 3366 with corr 0.230152890086174 with new token with corr 0.23015286028385162\n",
      "Replaced token 3367 with corr 0.24154038727283478 with new token with corr 0.24154038727283478\n",
      "Replaced token 3368 with corr 0.24219107627868652 with new token with corr 0.24219107627868652\n",
      "Replaced token 3369 with corr 0.2808833718299866 with new token with corr 0.28088340163230896\n",
      "Replaced token 3370 with corr 0.10360986739397049 with new token with corr 0.14797066152095795\n",
      "Replaced token 3371 with corr 0.3029536306858063 with new token with corr 0.3029536306858063\n",
      "Replaced token 3372 with corr 0.3633565604686737 with new token with corr 0.3633565604686737\n",
      "Replaced token 3373 with corr 0.26872190833091736 with new token with corr 0.26872190833091736\n",
      "Replaced token 3374 with corr 0.2916395664215088 with new token with corr 0.2916395366191864\n",
      "Replaced token 3375 with corr 0.30004778504371643 with new token with corr 0.30004775524139404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3376 with corr 0.24009664356708527 with new token with corr 0.24009664356708527\n",
      "Replaced token 3377 with corr 0.23907187581062317 with new token with corr 0.23907187581062317\n",
      "Replaced token 3378 with corr 0.27450308203697205 with new token with corr 0.27450308203697205\n",
      "Replaced token 3379 with corr 0.3026961386203766 with new token with corr 0.3026961386203766\n",
      "Replaced token 3380 with corr 0.3340757489204407 with new token with corr 0.3340757489204407\n",
      "Replaced token 3381 with corr 0.26085951924324036 with new token with corr 0.26085954904556274\n",
      "Replaced token 3382 with corr 0.2722454071044922 with new token with corr 0.2722454071044922\n",
      "Replaced token 3383 with corr 0.2644803524017334 with new token with corr 0.264480322599411\n",
      "Replaced token 3384 with corr 0.2882263660430908 with new token with corr 0.28822633624076843\n",
      "Replaced token 3385 with corr 0.39391183853149414 with new token with corr 0.39391180872917175\n",
      "Replaced token 3386 with corr 0.2921977639198303 with new token with corr 0.2921977937221527\n",
      "Replaced token 3387 with corr 0.29029181599617004 with new token with corr 0.29029178619384766\n",
      "Replaced token 3388 with corr 0.3408615291118622 with new token with corr 0.34086155891418457\n",
      "Replaced token 3389 with corr 0.2891591787338257 with new token with corr 0.2891591787338257\n",
      "Replaced token 3390 with corr 0.3051556348800659 with new token with corr 0.30515560507774353\n",
      "Replaced token 3391 with corr 0.3117619752883911 with new token with corr 0.3117619454860687\n",
      "Replaced token 3392 with corr 0.2846381664276123 with new token with corr 0.2846381664276123\n",
      "Replaced token 3393 with corr 0.29986274242401123 with new token with corr 0.29986274242401123\n",
      "Replaced token 3394 with corr 0.29086482524871826 with new token with corr 0.29086482524871826\n",
      "Replaced token 3395 with corr 0.34285715222358704 with new token with corr 0.3428571820259094\n",
      "Replaced token 3396 with corr 0.3330402076244354 with new token with corr 0.3330402076244354\n",
      "Replaced token 3397 with corr 0.2946403920650482 with new token with corr 0.29464036226272583\n",
      "Replaced token 3398 with corr 0.22107401490211487 with new token with corr 0.22107401490211487\n",
      "Replaced token 3399 with corr 0.2872544825077057 with new token with corr 0.2872544527053833\n",
      "Replaced token 3400 with corr 0.2829861640930176 with new token with corr 0.28298619389533997\n",
      "Replaced token 3401 with corr 0.2590102255344391 with new token with corr 0.2590102255344391\n",
      "Replaced token 3402 with corr 0.09207748621702194 with new token with corr 0.20862500369548798\n",
      "Replaced token 3403 with corr 0.25511434674263 with new token with corr 0.25511434674263\n",
      "Replaced token 3404 with corr 0.29843035340309143 with new token with corr 0.29843035340309143\n",
      "Replaced token 3405 with corr 0.2675924003124237 with new token with corr 0.2675923705101013\n",
      "Replaced token 3406 with corr 0.2703394591808319 with new token with corr 0.2703394889831543\n",
      "Replaced token 3407 with corr 0.2691522538661957 with new token with corr 0.26915228366851807\n",
      "Replaced token 3408 with corr 0.2811221778392792 with new token with corr 0.2811221778392792\n",
      "Replaced token 3409 with corr 0.3225317895412445 with new token with corr 0.3225317895412445\n",
      "Replaced token 3410 with corr 0.25574547052383423 with new token with corr 0.25574547052383423\n",
      "Replaced token 3411 with corr 0.2059486359357834 with new token with corr 0.20594865083694458\n",
      "Replaced token 3412 with corr 0.3105338513851166 with new token with corr 0.3105338513851166\n",
      "Replaced token 3413 with corr 0.07762213796377182 with new token with corr 0.1717095524072647\n",
      "Replaced token 3414 with corr 0.2475113868713379 with new token with corr 0.2475113868713379\n",
      "Replaced token 3415 with corr 0.11113911122083664 with new token with corr 0.23568634688854218\n",
      "Replaced token 3416 with corr 0.2489355355501175 with new token with corr 0.2489355355501175\n",
      "Replaced token 3417 with corr 0.2756810784339905 with new token with corr 0.2756810784339905\n",
      "Replaced token 3418 with corr 0.2162538468837738 with new token with corr 0.21625381708145142\n",
      "Replaced token 3419 with corr 0.29395318031311035 with new token with corr 0.29395321011543274\n",
      "Replaced token 3420 with corr 0.21882833540439606 with new token with corr 0.21882833540439606\n",
      "Replaced token 3421 with corr 0.2670280933380127 with new token with corr 0.2670280933380127\n",
      "Replaced token 3422 with corr 0.3100345730781555 with new token with corr 0.3100345730781555\n",
      "Replaced token 3423 with corr 0.27556470036506653 with new token with corr 0.2755647301673889\n",
      "Replaced token 3424 with corr 0.2699124813079834 with new token with corr 0.2699124813079834\n",
      "Replaced token 3425 with corr 0.35973069071769714 with new token with corr 0.35973072052001953\n",
      "Replaced token 3426 with corr 0.3357439935207367 with new token with corr 0.3357439637184143\n",
      "Replaced token 3427 with corr 0.3255400061607361 with new token with corr 0.32554003596305847\n",
      "Replaced token 3428 with corr 0.35814815759658813 with new token with corr 0.35814815759658813\n",
      "Replaced token 3429 with corr 0.18302571773529053 with new token with corr 0.18302571773529053\n",
      "Replaced token 3430 with corr 0.29197078943252563 with new token with corr 0.29197075963020325\n",
      "Replaced token 3431 with corr 0.3253590762615204 with new token with corr 0.3253591060638428\n",
      "Replaced token 3432 with corr 0.3882083296775818 with new token with corr 0.3882082998752594\n",
      "Replaced token 3433 with corr 0.27222105860710144 with new token with corr 0.27222105860710144\n",
      "Replaced token 3434 with corr 0.2848924696445465 with new token with corr 0.2848924696445465\n",
      "Replaced token 3435 with corr 0.32152652740478516 with new token with corr 0.32152652740478516\n",
      "Replaced token 3436 with corr 0.317508727312088 with new token with corr 0.3175086975097656\n",
      "Replaced token 3437 with corr 0.32581305503845215 with new token with corr 0.32581302523612976\n",
      "Replaced token 3438 with corr 0.2319849580526352 with new token with corr 0.23198498785495758\n",
      "Replaced token 3439 with corr 0.3096863925457001 with new token with corr 0.30968642234802246\n",
      "Replaced token 3440 with corr 0.3165583312511444 with new token with corr 0.31655827164649963\n",
      "Replaced token 3441 with corr 0.25462016463279724 with new token with corr 0.25462016463279724\n",
      "Replaced token 3442 with corr 0.35051384568214417 with new token with corr 0.35051384568214417\n",
      "Replaced token 3443 with corr 0.22571587562561035 with new token with corr 0.22571586072444916\n",
      "Replaced token 3444 with corr 0.34402745962142944 with new token with corr 0.34402745962142944\n",
      "Replaced token 3445 with corr 0.22462625801563263 with new token with corr 0.22462625801563263\n",
      "Replaced token 3446 with corr 0.2503245770931244 with new token with corr 0.2503246068954468\n",
      "Replaced token 3447 with corr 0.33154502511024475 with new token with corr 0.33154502511024475\n",
      "Replaced token 3448 with corr 0.2622354328632355 with new token with corr 0.2622354328632355\n",
      "Replaced token 3449 with corr 0.3332619071006775 with new token with corr 0.3332619071006775\n",
      "Replaced token 3450 with corr 0.3124159574508667 with new token with corr 0.3124159574508667\n",
      "Replaced token 3451 with corr 0.09928575158119202 with new token with corr 0.2579036355018616\n",
      "Replaced token 3452 with corr 0.17020653188228607 with new token with corr 0.17020654678344727\n",
      "Replaced token 3453 with corr 0.25642889738082886 with new token with corr 0.25642886757850647\n",
      "Replaced token 3454 with corr 0.2331475466489792 with new token with corr 0.2331475466489792\n",
      "Replaced token 3455 with corr 0.2758495509624481 with new token with corr 0.2758495509624481\n",
      "Replaced token 3456 with corr 0.3685474693775177 with new token with corr 0.3685474693775177\n",
      "Replaced token 3457 with corr 0.29282039403915405 with new token with corr 0.29282036423683167\n",
      "Replaced token 3458 with corr 0.29741957783699036 with new token with corr 0.29741957783699036\n",
      "Replaced token 3459 with corr 0.30984213948249817 with new token with corr 0.30984216928482056\n",
      "Replaced token 3460 with corr 0.31040042638778687 with new token with corr 0.31040048599243164\n",
      "Replaced token 3461 with corr 0.26256731152534485 with new token with corr 0.26256728172302246\n",
      "Replaced token 3462 with corr 0.2972395420074463 with new token with corr 0.2972395122051239\n",
      "Replaced token 3463 with corr 0.24996405839920044 with new token with corr 0.24996405839920044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3464 with corr 0.1866806149482727 with new token with corr 0.1866806298494339\n",
      "Replaced token 3465 with corr 0.3103006184101105 with new token with corr 0.3103006184101105\n",
      "Replaced token 3466 with corr 0.290622740983963 with new token with corr 0.2906227111816406\n",
      "Replaced token 3467 with corr 0.32174962759017944 with new token with corr 0.32174959778785706\n",
      "Replaced token 3468 with corr 0.3440774083137512 with new token with corr 0.3440774381160736\n",
      "Replaced token 3469 with corr 0.297251433134079 with new token with corr 0.297251433134079\n",
      "Replaced token 3470 with corr 0.22689151763916016 with new token with corr 0.22689150273799896\n",
      "Replaced token 3471 with corr 0.11550285667181015 with new token with corr 0.14842289686203003\n",
      "Replaced token 3472 with corr 0.2940524220466614 with new token with corr 0.2940524220466614\n",
      "Replaced token 3473 with corr 0.27944424748420715 with new token with corr 0.27944427728652954\n",
      "Replaced token 3474 with corr 0.24759021401405334 with new token with corr 0.24759018421173096\n",
      "Replaced token 3475 with corr 0.3194417357444763 with new token with corr 0.3194417357444763\n",
      "Replaced token 3476 with corr 0.2809142768383026 with new token with corr 0.2809142768383026\n",
      "Replaced token 3477 with corr 0.317972332239151 with new token with corr 0.317972332239151\n",
      "Replaced token 3478 with corr 0.2800275385379791 with new token with corr 0.2800275385379791\n",
      "Replaced token 3479 with corr 0.09774256497621536 with new token with corr 0.18581438064575195\n",
      "Replaced token 3480 with corr 0.11261890828609467 with new token with corr 0.23385603725910187\n",
      "Replaced token 3481 with corr 0.33475708961486816 with new token with corr 0.33475711941719055\n",
      "Replaced token 3482 with corr 0.3755998909473419 with new token with corr 0.3755999207496643\n",
      "Replaced token 3483 with corr 0.2870369255542755 with new token with corr 0.2870369255542755\n",
      "Replaced token 3484 with corr 0.2753017544746399 with new token with corr 0.2753017544746399\n",
      "Replaced token 3485 with corr 0.27529609203338623 with new token with corr 0.2752961218357086\n",
      "Replaced token 3486 with corr 0.094296395778656 with new token with corr 0.26696982979774475\n",
      "Replaced token 3487 with corr 0.33781591057777405 with new token with corr 0.33781591057777405\n",
      "Replaced token 3488 with corr 0.2981841266155243 with new token with corr 0.2981841266155243\n",
      "Replaced token 3489 with corr 0.29424381256103516 with new token with corr 0.29424381256103516\n",
      "Replaced token 3490 with corr 0.33829620480537415 with new token with corr 0.33829623460769653\n",
      "Replaced token 3491 with corr 0.3370090425014496 with new token with corr 0.337009072303772\n",
      "Replaced token 3492 with corr 0.24010100960731506 with new token with corr 0.24010099470615387\n",
      "Replaced token 3493 with corr 0.29688748717308044 with new token with corr 0.29688748717308044\n",
      "Replaced token 3494 with corr 0.23054486513137817 with new token with corr 0.23054486513137817\n",
      "Replaced token 3495 with corr 0.31919530034065247 with new token with corr 0.31919533014297485\n",
      "Replaced token 3496 with corr 0.3248361051082611 with new token with corr 0.3248361349105835\n",
      "Replaced token 3497 with corr 0.3029785454273224 with new token with corr 0.3029785454273224\n",
      "Replaced token 3498 with corr 0.3629446029663086 with new token with corr 0.3629446029663086\n",
      "Replaced token 3499 with corr 0.25960686802864075 with new token with corr 0.25960686802864075\n",
      "Replaced token 3500 with corr 0.34244292974472046 with new token with corr 0.34244295954704285\n",
      "Replaced token 3501 with corr 0.30752602219581604 with new token with corr 0.3075260818004608\n",
      "Replaced token 3502 with corr 0.3117193579673767 with new token with corr 0.3117193579673767\n",
      "Replaced token 3503 with corr 0.2514297068119049 with new token with corr 0.2514297366142273\n",
      "Replaced token 3504 with corr 0.10243967920541763 with new token with corr 0.21259687840938568\n",
      "Replaced token 3505 with corr 0.2946949601173401 with new token with corr 0.2946949601173401\n",
      "Replaced token 3506 with corr 0.3300517797470093 with new token with corr 0.3300517201423645\n",
      "Replaced token 3507 with corr 0.3535926938056946 with new token with corr 0.3535926640033722\n",
      "Replaced token 3508 with corr 0.11241219192743301 with new token with corr 0.3117140233516693\n",
      "Replaced token 3509 with corr 0.2770094871520996 with new token with corr 0.2770094871520996\n",
      "Replaced token 3510 with corr 0.34594470262527466 with new token with corr 0.34594470262527466\n",
      "Replaced token 3511 with corr 0.3336726129055023 with new token with corr 0.3336726129055023\n",
      "Replaced token 3512 with corr 0.2211863249540329 with new token with corr 0.2211863398551941\n",
      "Replaced token 3513 with corr 0.2549532651901245 with new token with corr 0.2549532949924469\n",
      "Replaced token 3514 with corr 0.25273397564888 with new token with corr 0.25273397564888\n",
      "Replaced token 3515 with corr 0.30516645312309265 with new token with corr 0.30516648292541504\n",
      "Replaced token 3516 with corr 0.26712939143180847 with new token with corr 0.26712939143180847\n",
      "Replaced token 3517 with corr 0.3119608759880066 with new token with corr 0.3119608759880066\n",
      "Replaced token 3518 with corr 0.2906310260295868 with new token with corr 0.2906309962272644\n",
      "Replaced token 3519 with corr 0.24301661550998688 with new token with corr 0.24301664531230927\n",
      "Replaced token 3520 with corr 0.29137465357780457 with new token with corr 0.2913746237754822\n",
      "Replaced token 3521 with corr 0.33951765298843384 with new token with corr 0.33951765298843384\n",
      "Replaced token 3522 with corr 0.11608175188302994 with new token with corr 0.2361796647310257\n",
      "Replaced token 3523 with corr 0.3219805061817169 with new token with corr 0.3219805061817169\n",
      "Replaced token 3524 with corr 0.31571459770202637 with new token with corr 0.31571462750434875\n",
      "Replaced token 3525 with corr 0.26265132427215576 with new token with corr 0.26265132427215576\n",
      "Replaced token 3526 with corr 0.3059469163417816 with new token with corr 0.30594688653945923\n",
      "Replaced token 3527 with corr 0.2661696672439575 with new token with corr 0.26616963744163513\n",
      "Replaced token 3528 with corr 0.30951792001724243 with new token with corr 0.30951789021492004\n",
      "Replaced token 3529 with corr 0.28984105587005615 with new token with corr 0.28984102606773376\n",
      "Replaced token 3530 with corr 0.2778851389884949 with new token with corr 0.2778851389884949\n",
      "Replaced token 3531 with corr 0.3150264024734497 with new token with corr 0.3150264024734497\n",
      "Replaced token 3532 with corr 0.36311015486717224 with new token with corr 0.36311018466949463\n",
      "Replaced token 3533 with corr 0.3277008831501007 with new token with corr 0.3277009129524231\n",
      "Replaced token 3534 with corr 0.333200603723526 with new token with corr 0.3332006335258484\n",
      "Replaced token 3535 with corr 0.2822628319263458 with new token with corr 0.2822628319263458\n",
      "Replaced token 3536 with corr 0.23524269461631775 with new token with corr 0.23524269461631775\n",
      "Replaced token 3537 with corr 0.1282229721546173 with new token with corr 0.25225773453712463\n",
      "Replaced token 3538 with corr 0.3343486487865448 with new token with corr 0.3343486487865448\n",
      "Replaced token 3539 with corr 0.3241089880466461 with new token with corr 0.3241089880466461\n",
      "Replaced token 3540 with corr 0.0735185369849205 with new token with corr 0.18384917080402374\n",
      "Replaced token 3541 with corr 0.34818896651268005 with new token with corr 0.34818893671035767\n",
      "Replaced token 3542 with corr 0.271989107131958 with new token with corr 0.271989107131958\n",
      "Replaced token 3543 with corr 0.3055879771709442 with new token with corr 0.3055880069732666\n",
      "Replaced token 3544 with corr 0.30127912759780884 with new token with corr 0.30127909779548645\n",
      "Replaced token 3545 with corr 0.2988933026790619 with new token with corr 0.2988932728767395\n",
      "Replaced token 3546 with corr 0.22234666347503662 with new token with corr 0.22234666347503662\n",
      "Replaced token 3547 with corr 0.12320207059383392 with new token with corr 0.2969287633895874\n",
      "Replaced token 3548 with corr 0.30665236711502075 with new token with corr 0.30665236711502075\n",
      "Replaced token 3549 with corr 0.214874267578125 with new token with corr 0.214874267578125\n",
      "Replaced token 3550 with corr 0.18737910687923431 with new token with corr 0.18737909197807312\n",
      "Replaced token 3551 with corr 0.24486090242862701 with new token with corr 0.24486090242862701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3552 with corr 0.2552683353424072 with new token with corr 0.2552683353424072\n",
      "Replaced token 3553 with corr 0.3383708596229553 with new token with corr 0.3383708596229553\n",
      "Replaced token 3554 with corr 0.11856120079755783 with new token with corr 0.20777767896652222\n",
      "Replaced token 3555 with corr 0.2724015414714813 with new token with corr 0.2724015712738037\n",
      "Replaced token 3556 with corr 0.31979644298553467 with new token with corr 0.31979647278785706\n",
      "Replaced token 3557 with corr 0.274533748626709 with new token with corr 0.274533748626709\n",
      "Replaced token 3558 with corr 0.26805955171585083 with new token with corr 0.26805952191352844\n",
      "Replaced token 3559 with corr 0.28880438208580017 with new token with corr 0.28880441188812256\n",
      "Replaced token 3560 with corr 0.2541344463825226 with new token with corr 0.2541344463825226\n",
      "Replaced token 3561 with corr 0.30769065022468567 with new token with corr 0.3076906204223633\n",
      "Replaced token 3562 with corr 0.30466076731681824 with new token with corr 0.3046607971191406\n",
      "Replaced token 3563 with corr 0.2201850712299347 with new token with corr 0.2201850563287735\n",
      "Replaced token 3564 with corr 0.36595234274864197 with new token with corr 0.36595237255096436\n",
      "Replaced token 3565 with corr 0.07344812899827957 with new token with corr 0.14897918701171875\n",
      "Replaced token 3566 with corr 0.3263932764530182 with new token with corr 0.3263933062553406\n",
      "Replaced token 3567 with corr 0.2530454695224762 with new token with corr 0.2530454993247986\n",
      "Replaced token 3568 with corr 0.3110349774360657 with new token with corr 0.3110349476337433\n",
      "Replaced token 3569 with corr 0.3907829225063324 with new token with corr 0.3907829523086548\n",
      "Replaced token 3570 with corr 0.370435893535614 with new token with corr 0.370435893535614\n",
      "Replaced token 3571 with corr 0.23816721141338348 with new token with corr 0.2381671965122223\n",
      "Replaced token 3572 with corr 0.289568692445755 with new token with corr 0.2895687222480774\n",
      "Replaced token 3573 with corr 0.0852590948343277 with new token with corr 0.22231847047805786\n",
      "Replaced token 3574 with corr 0.2984023988246918 with new token with corr 0.2984023690223694\n",
      "Replaced token 3575 with corr 0.2611331343650818 with new token with corr 0.2611331641674042\n",
      "Replaced token 3576 with corr 0.26425936818122864 with new token with corr 0.26425936818122864\n",
      "Replaced token 3577 with corr 0.31720468401908875 with new token with corr 0.31720468401908875\n",
      "Replaced token 3578 with corr 0.3398708999156952 with new token with corr 0.3398709297180176\n",
      "Replaced token 3579 with corr 0.30557534098625183 with new token with corr 0.3055753707885742\n",
      "Replaced token 3580 with corr 0.25222206115722656 with new token with corr 0.25222206115722656\n",
      "Replaced token 3581 with corr 0.2280559539794922 with new token with corr 0.2280559241771698\n",
      "Replaced token 3582 with corr 0.2059638351202011 with new token with corr 0.20596382021903992\n",
      "Replaced token 3583 with corr 0.07468339055776596 with new token with corr 0.15685757994651794\n",
      "Replaced token 3584 with corr 0.27081048488616943 with new token with corr 0.2708105146884918\n",
      "Replaced token 3585 with corr 0.27245181798934937 with new token with corr 0.272451788187027\n",
      "Replaced token 3586 with corr 0.20032626390457153 with new token with corr 0.20032627880573273\n",
      "Replaced token 3587 with corr 0.32366257905960083 with new token with corr 0.3236626088619232\n",
      "Replaced token 3588 with corr 0.2586875855922699 with new token with corr 0.2586875855922699\n",
      "Replaced token 3589 with corr 0.3073035776615143 with new token with corr 0.3073035776615143\n",
      "Replaced token 3590 with corr 0.3175654709339142 with new token with corr 0.3175654411315918\n",
      "Replaced token 3591 with corr 0.3026507794857025 with new token with corr 0.3026507794857025\n",
      "Replaced token 3592 with corr 0.30893826484680176 with new token with corr 0.30893829464912415\n",
      "Replaced token 3593 with corr 0.12260448932647705 with new token with corr 0.15267544984817505\n",
      "Replaced token 3594 with corr 0.26568639278411865 with new token with corr 0.26568639278411865\n",
      "Replaced token 3595 with corr 0.18890498578548431 with new token with corr 0.1889050006866455\n",
      "Replaced token 3596 with corr 0.2794085144996643 with new token with corr 0.2794085144996643\n",
      "Replaced token 3597 with corr 0.2716728746891022 with new token with corr 0.27167290449142456\n",
      "Replaced token 3598 with corr 0.2338637411594391 with new token with corr 0.2338637411594391\n",
      "Replaced token 3599 with corr 0.21700537204742432 with new token with corr 0.21700535714626312\n",
      "Replaced token 3600 with corr 0.3088518977165222 with new token with corr 0.3088519275188446\n",
      "Replaced token 3601 with corr 0.35594505071640015 with new token with corr 0.35594505071640015\n",
      "Replaced token 3602 with corr 0.23261140286922455 with new token with corr 0.23261140286922455\n",
      "Replaced token 3603 with corr 0.23389464616775513 with new token with corr 0.23389461636543274\n",
      "Replaced token 3604 with corr 0.33159151673316956 with new token with corr 0.33159151673316956\n",
      "Replaced token 3605 with corr 0.15743738412857056 with new token with corr 0.24347980320453644\n",
      "Replaced token 3606 with corr 0.2864311635494232 with new token with corr 0.2864311933517456\n",
      "Replaced token 3607 with corr 0.3578156530857086 with new token with corr 0.3578156530857086\n",
      "Replaced token 3608 with corr 0.3225267231464386 with new token with corr 0.322526752948761\n",
      "Replaced token 3609 with corr 0.22058506309986115 with new token with corr 0.22058507800102234\n",
      "Replaced token 3610 with corr 0.27439144253730774 with new token with corr 0.27439144253730774\n",
      "Replaced token 3611 with corr 0.1045120358467102 with new token with corr 0.2583322823047638\n",
      "Replaced token 3612 with corr 0.3297247290611267 with new token with corr 0.3297247290611267\n",
      "Replaced token 3613 with corr 0.30641666054725647 with new token with corr 0.30641666054725647\n",
      "Replaced token 3614 with corr 0.27643829584121704 with new token with corr 0.27643826603889465\n",
      "Replaced token 3615 with corr 0.2643526494503021 with new token with corr 0.2643526494503021\n",
      "Replaced token 3616 with corr 0.2585375905036926 with new token with corr 0.25853756070137024\n",
      "Replaced token 3617 with corr 0.11635561287403107 with new token with corr 0.21962647140026093\n",
      "Replaced token 3618 with corr 0.2910197377204895 with new token with corr 0.2910197377204895\n",
      "Replaced token 3619 with corr 0.3241090476512909 with new token with corr 0.3241089880466461\n",
      "Replaced token 3620 with corr 0.26052218675613403 with new token with corr 0.26052218675613403\n",
      "Replaced token 3621 with corr 0.2704753279685974 with new token with corr 0.2704753279685974\n",
      "Replaced token 3622 with corr 0.11626020818948746 with new token with corr 0.15774716436862946\n",
      "Replaced token 3623 with corr 0.09608295559883118 with new token with corr 0.20783036947250366\n",
      "Replaced token 3624 with corr 0.23590433597564697 with new token with corr 0.23590433597564697\n",
      "Replaced token 3625 with corr 0.32891666889190674 with new token with corr 0.32891666889190674\n",
      "Replaced token 3626 with corr 0.2333221286535263 with new token with corr 0.2333221286535263\n",
      "Replaced token 3627 with corr 0.286204993724823 with new token with corr 0.2862050235271454\n",
      "Replaced token 3628 with corr 0.2884170413017273 with new token with corr 0.2884170413017273\n",
      "Replaced token 3629 with corr 0.1657281070947647 with new token with corr 0.16572809219360352\n",
      "Replaced token 3630 with corr 0.39254724979400635 with new token with corr 0.39254721999168396\n",
      "Replaced token 3631 with corr 0.07907850295305252 with new token with corr 0.1806187927722931\n",
      "Replaced token 3632 with corr 0.26622113585472107 with new token with corr 0.2662211060523987\n",
      "Replaced token 3633 with corr 0.3002917170524597 with new token with corr 0.3002917170524597\n",
      "Replaced token 3634 with corr 0.23803220689296722 with new token with corr 0.23803220689296722\n",
      "Replaced token 3635 with corr 0.32747897505760193 with new token with corr 0.32747897505760193\n",
      "Replaced token 3636 with corr 0.353609561920166 with new token with corr 0.353609561920166\n",
      "Replaced token 3637 with corr 0.2446422129869461 with new token with corr 0.2446422129869461\n",
      "Replaced token 3638 with corr 0.07013028860092163 with new token with corr 0.1800089031457901\n",
      "Replaced token 3639 with corr 0.2772209346294403 with new token with corr 0.2772209346294403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3640 with corr 0.25649890303611755 with new token with corr 0.25649893283843994\n",
      "Replaced token 3641 with corr 0.29841580986976624 with new token with corr 0.29841580986976624\n",
      "Replaced token 3642 with corr 0.23931364715099335 with new token with corr 0.23931364715099335\n",
      "Replaced token 3643 with corr 0.30218759179115295 with new token with corr 0.30218759179115295\n",
      "Replaced token 3644 with corr 0.2729215919971466 with new token with corr 0.2729215919971466\n",
      "Replaced token 3645 with corr 0.23913806676864624 with new token with corr 0.23913806676864624\n",
      "Replaced token 3646 with corr 0.22957363724708557 with new token with corr 0.22957363724708557\n",
      "Replaced token 3647 with corr 0.3002971410751343 with new token with corr 0.3002971410751343\n",
      "Replaced token 3648 with corr 0.27515286207199097 with new token with corr 0.27515289187431335\n",
      "Replaced token 3649 with corr 0.22985851764678955 with new token with corr 0.22985853254795074\n",
      "Replaced token 3650 with corr 0.31610578298568726 with new token with corr 0.31610578298568726\n",
      "Replaced token 3651 with corr 0.2735236883163452 with new token with corr 0.2735236585140228\n",
      "Replaced token 3652 with corr 0.2325960099697113 with new token with corr 0.2325959950685501\n",
      "Replaced token 3653 with corr 0.24473237991333008 with new token with corr 0.24473236501216888\n",
      "Replaced token 3654 with corr 0.32611241936683655 with new token with corr 0.32611241936683655\n",
      "Replaced token 3655 with corr 0.26242825388908386 with new token with corr 0.26242825388908386\n",
      "Replaced token 3656 with corr 0.20722565054893494 with new token with corr 0.20722565054893494\n",
      "Replaced token 3657 with corr 0.3064219057559967 with new token with corr 0.3064218759536743\n",
      "Replaced token 3658 with corr 0.29331332445144653 with new token with corr 0.29331332445144653\n",
      "Replaced token 3659 with corr 0.24567550420761108 with new token with corr 0.2456754893064499\n",
      "Replaced token 3660 with corr 0.25533172488212585 with new token with corr 0.25533169507980347\n",
      "Replaced token 3661 with corr 0.2960047125816345 with new token with corr 0.2960047125816345\n",
      "Replaced token 3662 with corr 0.2992486357688904 with new token with corr 0.29924866557121277\n",
      "Replaced token 3663 with corr 0.25996384024620056 with new token with corr 0.25996384024620056\n",
      "Replaced token 3664 with corr 0.3112480044364929 with new token with corr 0.31124797463417053\n",
      "Replaced token 3665 with corr 0.27602916955947876 with new token with corr 0.27602916955947876\n",
      "Replaced token 3666 with corr 0.22114485502243042 with new token with corr 0.22114485502243042\n",
      "Replaced token 3667 with corr 0.10379547625780106 with new token with corr 0.2801976799964905\n",
      "Replaced token 3668 with corr 0.2786698639392853 with new token with corr 0.2786698639392853\n",
      "Replaced token 3669 with corr 0.07176963239908218 with new token with corr 0.2982428967952728\n",
      "Replaced token 3670 with corr 0.06947410106658936 with new token with corr 0.32409781217575073\n",
      "Replaced token 3671 with corr 0.226419597864151 with new token with corr 0.2264195829629898\n",
      "Replaced token 3672 with corr 0.2630872428417206 with new token with corr 0.2630872428417206\n",
      "Replaced token 3673 with corr 0.11199440062046051 with new token with corr 0.21503151953220367\n",
      "Replaced token 3674 with corr 0.1082954853773117 with new token with corr 0.34233036637306213\n",
      "Replaced token 3675 with corr 0.2199246734380722 with new token with corr 0.2199247032403946\n",
      "Replaced token 3676 with corr 0.32447126507759094 with new token with corr 0.32447126507759094\n",
      "Replaced token 3677 with corr 0.22673791646957397 with new token with corr 0.22673793137073517\n",
      "Replaced token 3678 with corr 0.2712607681751251 with new token with corr 0.2712607979774475\n",
      "Replaced token 3679 with corr 0.08759612590074539 with new token with corr 0.23954784870147705\n",
      "Replaced token 3680 with corr 0.22838318347930908 with new token with corr 0.22838319838047028\n",
      "Replaced token 3681 with corr 0.28014352917671204 with new token with corr 0.28014352917671204\n",
      "Replaced token 3682 with corr 0.2366478443145752 with new token with corr 0.236647829413414\n",
      "Replaced token 3683 with corr 0.213851198554039 with new token with corr 0.2138512134552002\n",
      "Replaced token 3684 with corr 0.23062434792518616 with new token with corr 0.23062431812286377\n",
      "Replaced token 3685 with corr 0.31199219822883606 with new token with corr 0.31199222803115845\n",
      "Replaced token 3686 with corr 0.31702056527137756 with new token with corr 0.31702056527137756\n",
      "Replaced token 3687 with corr 0.2618323266506195 with new token with corr 0.2618323564529419\n",
      "Replaced token 3688 with corr 0.32953110337257385 with new token with corr 0.32953110337257385\n",
      "Replaced token 3689 with corr 0.2326207458972931 with new token with corr 0.2326207309961319\n",
      "Replaced token 3690 with corr 0.2446184754371643 with new token with corr 0.2446184605360031\n",
      "Replaced token 3691 with corr 0.24806536734104156 with new token with corr 0.24806536734104156\n",
      "Replaced token 3692 with corr 0.2816567122936249 with new token with corr 0.2816567122936249\n",
      "Replaced token 3693 with corr 0.22506947815418243 with new token with corr 0.22506946325302124\n",
      "Replaced token 3694 with corr 0.2308536320924759 with new token with corr 0.2308536171913147\n",
      "Replaced token 3695 with corr 0.29364311695098877 with new token with corr 0.29364311695098877\n",
      "Replaced token 3696 with corr 0.2961324453353882 with new token with corr 0.2961324155330658\n",
      "Replaced token 3697 with corr 0.2705630958080292 with new token with corr 0.2705630362033844\n",
      "Replaced token 3698 with corr 0.29189616441726685 with new token with corr 0.29189619421958923\n",
      "Replaced token 3699 with corr 0.3371712267398834 with new token with corr 0.3371712565422058\n",
      "Replaced token 3700 with corr 0.30257919430732727 with new token with corr 0.30257922410964966\n",
      "Replaced token 3701 with corr 0.13045057654380798 with new token with corr 0.25759297609329224\n",
      "Replaced token 3702 with corr 0.2519649565219879 with new token with corr 0.2519649267196655\n",
      "Replaced token 3703 with corr 0.2802749574184418 with new token with corr 0.2802749574184418\n",
      "Replaced token 3704 with corr 0.2994263768196106 with new token with corr 0.2994263470172882\n",
      "Replaced token 3705 with corr 0.25746533274650574 with new token with corr 0.25746533274650574\n",
      "Replaced token 3706 with corr 0.3148330748081207 with new token with corr 0.3148330748081207\n",
      "Replaced token 3707 with corr 0.21608887612819672 with new token with corr 0.21608887612819672\n",
      "Replaced token 3708 with corr 0.13221634924411774 with new token with corr 0.26396578550338745\n",
      "Replaced token 3709 with corr 0.2462778389453888 with new token with corr 0.2462778389453888\n",
      "Replaced token 3710 with corr 0.18549737334251404 with new token with corr 0.18549735844135284\n",
      "Replaced token 3711 with corr 0.2758602797985077 with new token with corr 0.2758602797985077\n",
      "Replaced token 3712 with corr 0.3150036036968231 with new token with corr 0.3150036334991455\n",
      "Replaced token 3713 with corr 0.0684177502989769 with new token with corr 0.2262493073940277\n",
      "Replaced token 3714 with corr 0.28491851687431335 with new token with corr 0.28491854667663574\n",
      "Replaced token 3715 with corr 0.29559752345085144 with new token with corr 0.29559752345085144\n",
      "Replaced token 3716 with corr 0.27783656120300293 with new token with corr 0.27783653140068054\n",
      "Replaced token 3717 with corr 0.24160708487033844 with new token with corr 0.24160709977149963\n",
      "Replaced token 3718 with corr 0.2629847526550293 with new token with corr 0.2629847526550293\n",
      "Replaced token 3719 with corr 0.22166118025779724 with new token with corr 0.22166116535663605\n",
      "Replaced token 3720 with corr 0.25002408027648926 with new token with corr 0.25002408027648926\n",
      "Replaced token 3721 with corr 0.3010711371898651 with new token with corr 0.3010711371898651\n",
      "Replaced token 3722 with corr 0.28074005246162415 with new token with corr 0.28074008226394653\n",
      "Replaced token 3723 with corr 0.17644144594669342 with new token with corr 0.17644146084785461\n",
      "Replaced token 3724 with corr 0.2803407609462738 with new token with corr 0.2803407609462738\n",
      "Replaced token 3725 with corr 0.31802019476890564 with new token with corr 0.31802019476890564\n",
      "Replaced token 3726 with corr 0.28484246134757996 with new token with corr 0.28484249114990234\n",
      "Replaced token 3727 with corr 0.12891528010368347 with new token with corr 0.24917134642601013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3728 with corr 0.34511834383010864 with new token with corr 0.34511837363243103\n",
      "Replaced token 3729 with corr 0.2955830991268158 with new token with corr 0.2955830991268158\n",
      "Replaced token 3730 with corr 0.2819732427597046 with new token with corr 0.2819732129573822\n",
      "Replaced token 3731 with corr 0.22080348432064056 with new token with corr 0.22080348432064056\n",
      "Replaced token 3732 with corr 0.28329312801361084 with new token with corr 0.28329309821128845\n",
      "Replaced token 3733 with corr 0.29225462675094604 with new token with corr 0.29225459694862366\n",
      "Replaced token 3734 with corr 0.2669542133808136 with new token with corr 0.2669542133808136\n",
      "Replaced token 3735 with corr 0.11797637492418289 with new token with corr 0.2217080146074295\n",
      "Replaced token 3736 with corr 0.09470909088850021 with new token with corr 0.21329985558986664\n",
      "Replaced token 3737 with corr 0.1390988528728485 with new token with corr 0.2615695893764496\n",
      "Replaced token 3738 with corr 0.368228554725647 with new token with corr 0.36822858452796936\n",
      "Replaced token 3739 with corr 0.20858289301395416 with new token with corr 0.20858289301395416\n",
      "Replaced token 3740 with corr 0.23580828309059143 with new token with corr 0.23580826818943024\n",
      "Replaced token 3741 with corr 0.31349262595176697 with new token with corr 0.31349265575408936\n",
      "Replaced token 3742 with corr 0.28972327709198 with new token with corr 0.2897232472896576\n",
      "Replaced token 3743 with corr 0.2731115221977234 with new token with corr 0.2731115221977234\n",
      "Replaced token 3744 with corr 0.0792054533958435 with new token with corr 0.2511129677295685\n",
      "Replaced token 3745 with corr 0.27606096863746643 with new token with corr 0.2760609984397888\n",
      "Replaced token 3746 with corr 0.3110803961753845 with new token with corr 0.3110804259777069\n",
      "Replaced token 3747 with corr 0.24628590047359467 with new token with corr 0.24628590047359467\n",
      "Replaced token 3748 with corr 0.2887590527534485 with new token with corr 0.2887590527534485\n",
      "Replaced token 3749 with corr 0.3582928776741028 with new token with corr 0.35829293727874756\n",
      "Replaced token 3750 with corr 0.3187626898288727 with new token with corr 0.3187626898288727\n",
      "Replaced token 3751 with corr 0.08053730428218842 with new token with corr 0.14904911816120148\n",
      "Replaced token 3752 with corr 0.2975614666938782 with new token with corr 0.2975614666938782\n",
      "Replaced token 3753 with corr 0.25094637274742126 with new token with corr 0.25094640254974365\n",
      "Replaced token 3754 with corr 0.3110351860523224 with new token with corr 0.3110351860523224\n",
      "Replaced token 3755 with corr 0.3201279044151306 with new token with corr 0.3201278746128082\n",
      "Replaced token 3756 with corr 0.2998099625110626 with new token with corr 0.299809992313385\n",
      "Replaced token 3757 with corr 0.30794578790664673 with new token with corr 0.3079458177089691\n",
      "Replaced token 3758 with corr 0.27789556980133057 with new token with corr 0.27789556980133057\n",
      "Replaced token 3759 with corr 0.23770661652088165 with new token with corr 0.23770663142204285\n",
      "Replaced token 3760 with corr 0.12319856882095337 with new token with corr 0.16508053243160248\n",
      "Replaced token 3761 with corr 0.28879666328430176 with new token with corr 0.28879666328430176\n",
      "Replaced token 3762 with corr 0.3305313289165497 with new token with corr 0.3305313289165497\n",
      "Replaced token 3763 with corr 0.24828191101551056 with new token with corr 0.24828191101551056\n",
      "Replaced token 3764 with corr 0.2679699957370758 with new token with corr 0.2679699957370758\n",
      "Replaced token 3765 with corr 0.3070681393146515 with new token with corr 0.3070681393146515\n",
      "Replaced token 3766 with corr 0.24656303226947784 with new token with corr 0.24656301736831665\n",
      "Replaced token 3767 with corr 0.2815326750278473 with new token with corr 0.2815326750278473\n",
      "Replaced token 3768 with corr 0.2139132022857666 with new token with corr 0.2139132022857666\n",
      "Replaced token 3769 with corr 0.34856221079826355 with new token with corr 0.34856221079826355\n",
      "Replaced token 3770 with corr 0.28675761818885803 with new token with corr 0.28675761818885803\n",
      "Replaced token 3771 with corr 0.2672482430934906 with new token with corr 0.2672482430934906\n",
      "Replaced token 3772 with corr 0.2474512904882431 with new token with corr 0.2474512755870819\n",
      "Replaced token 3773 with corr 0.21879947185516357 with new token with corr 0.21879947185516357\n",
      "Replaced token 3774 with corr 0.3242877125740051 with new token with corr 0.32428768277168274\n",
      "Replaced token 3775 with corr 0.2854037284851074 with new token with corr 0.2854037284851074\n",
      "Replaced token 3776 with corr 0.30753010511398315 with new token with corr 0.30753010511398315\n",
      "Replaced token 3777 with corr 0.1903855949640274 with new token with corr 0.1903855949640274\n",
      "Replaced token 3778 with corr 0.3226352035999298 with new token with corr 0.3226352334022522\n",
      "Replaced token 3779 with corr 0.307891309261322 with new token with corr 0.307891309261322\n",
      "Replaced token 3780 with corr 0.2632019817829132 with new token with corr 0.2632019817829132\n",
      "Replaced token 3781 with corr 0.31788691878318787 with new token with corr 0.31788694858551025\n",
      "Replaced token 3782 with corr 0.3114471435546875 with new token with corr 0.3114471435546875\n",
      "Replaced token 3783 with corr 0.30310800671577454 with new token with corr 0.3031080365180969\n",
      "Replaced token 3784 with corr 0.2694707214832306 with new token with corr 0.2694706618785858\n",
      "Replaced token 3785 with corr 0.08235035091638565 with new token with corr 0.19586622714996338\n",
      "Replaced token 3786 with corr 0.2739614248275757 with new token with corr 0.2739614248275757\n",
      "Replaced token 3787 with corr 0.4095652997493744 with new token with corr 0.4095652997493744\n",
      "Replaced token 3788 with corr 0.23559962213039398 with new token with corr 0.23559962213039398\n",
      "Replaced token 3789 with corr 0.29493406414985657 with new token with corr 0.29493406414985657\n",
      "Replaced token 3790 with corr 0.3001329302787781 with new token with corr 0.3001329302787781\n",
      "Replaced token 3791 with corr 0.29710525274276733 with new token with corr 0.29710522294044495\n",
      "Replaced token 3792 with corr 0.27805209159851074 with new token with corr 0.27805209159851074\n",
      "Replaced token 3793 with corr 0.2971053421497345 with new token with corr 0.2971053421497345\n",
      "Replaced token 3794 with corr 0.0956580862402916 with new token with corr 0.2699718177318573\n",
      "Replaced token 3795 with corr 0.26944440603256226 with new token with corr 0.26944437623023987\n",
      "Replaced token 3796 with corr 0.2717667520046234 with new token with corr 0.2717667520046234\n",
      "Replaced token 3797 with corr 0.21852342784404755 with new token with corr 0.21852342784404755\n",
      "Replaced token 3798 with corr 0.2373615801334381 with new token with corr 0.2373615801334381\n",
      "Replaced token 3799 with corr 0.2556630074977875 with new token with corr 0.2556630074977875\n",
      "Replaced token 3800 with corr 0.3078761100769043 with new token with corr 0.3078761100769043\n",
      "Replaced token 3801 with corr 0.2853325605392456 with new token with corr 0.2853325307369232\n",
      "Replaced token 3802 with corr 0.43958860635757446 with new token with corr 0.4395885467529297\n",
      "Replaced token 3803 with corr 0.24838827550411224 with new token with corr 0.24838824570178986\n",
      "Replaced token 3804 with corr 0.26129668951034546 with new token with corr 0.26129665970802307\n",
      "Replaced token 3805 with corr 0.24906659126281738 with new token with corr 0.249066561460495\n",
      "Replaced token 3806 with corr 0.10203952342271805 with new token with corr 0.1528431475162506\n",
      "Replaced token 3807 with corr 0.2185843586921692 with new token with corr 0.21858437359333038\n",
      "Replaced token 3808 with corr 0.24602186679840088 with new token with corr 0.24602185189723969\n",
      "Replaced token 3809 with corr 0.30630284547805786 with new token with corr 0.30630284547805786\n",
      "Replaced token 3810 with corr 0.29574814438819885 with new token with corr 0.29574817419052124\n",
      "Replaced token 3811 with corr 0.26074203848838806 with new token with corr 0.26074206829071045\n",
      "Replaced token 3812 with corr 0.2420000284910202 with new token with corr 0.2420000284910202\n",
      "Replaced token 3813 with corr 0.2026224136352539 with new token with corr 0.2026224285364151\n",
      "Replaced token 3814 with corr 0.27058207988739014 with new token with corr 0.27058207988739014\n",
      "Replaced token 3815 with corr 0.3096253573894501 with new token with corr 0.3096253275871277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3816 with corr 0.2988011837005615 with new token with corr 0.2988011837005615\n",
      "Replaced token 3817 with corr 0.19687430560588837 with new token with corr 0.19687432050704956\n",
      "Replaced token 3818 with corr 0.1288331151008606 with new token with corr 0.23295429348945618\n",
      "Replaced token 3819 with corr 0.2907969057559967 with new token with corr 0.2907968759536743\n",
      "Replaced token 3820 with corr 0.27051809430122375 with new token with corr 0.27051809430122375\n",
      "Replaced token 3821 with corr 0.28557437658309937 with new token with corr 0.28557437658309937\n",
      "Replaced token 3822 with corr 0.16054946184158325 with new token with corr 0.16640932857990265\n",
      "Replaced token 3823 with corr 0.22404614090919495 with new token with corr 0.22404614090919495\n",
      "Replaced token 3824 with corr 0.2825174331665039 with new token with corr 0.2825174033641815\n",
      "Replaced token 3825 with corr 0.246450275182724 with new token with corr 0.2464502453804016\n",
      "Replaced token 3826 with corr 0.2959827780723572 with new token with corr 0.2959827780723572\n",
      "Replaced token 3827 with corr 0.1984330117702484 with new token with corr 0.1984330117702484\n",
      "Replaced token 3828 with corr 0.2577812373638153 with new token with corr 0.2577812373638153\n",
      "Replaced token 3829 with corr 0.26362213492393494 with new token with corr 0.26362213492393494\n",
      "Replaced token 3830 with corr 0.3231769800186157 with new token with corr 0.3231769800186157\n",
      "Replaced token 3831 with corr 0.26849350333213806 with new token with corr 0.26849350333213806\n",
      "Replaced token 3832 with corr 0.21325305104255676 with new token with corr 0.21325305104255676\n",
      "Replaced token 3833 with corr 0.23532634973526 with new token with corr 0.23532634973526\n",
      "Replaced token 3834 with corr 0.2890876233577728 with new token with corr 0.2890876233577728\n",
      "Replaced token 3835 with corr 0.5092566609382629 with new token with corr 0.5092566013336182\n",
      "Replaced token 3836 with corr 0.3122139573097229 with new token with corr 0.3122139871120453\n",
      "Replaced token 3837 with corr 0.29100674390792847 with new token with corr 0.29100674390792847\n",
      "Replaced token 3838 with corr 0.2553596496582031 with new token with corr 0.2553596496582031\n",
      "Replaced token 3839 with corr 0.31149816513061523 with new token with corr 0.3114981949329376\n",
      "Replaced token 3840 with corr 0.21330760419368744 with new token with corr 0.21330760419368744\n",
      "Replaced token 3841 with corr 0.09109344333410263 with new token with corr 0.1467636376619339\n",
      "Replaced token 3842 with corr 0.26292476058006287 with new token with corr 0.26292476058006287\n",
      "Replaced token 3843 with corr 0.09166190773248672 with new token with corr 0.2591124176979065\n",
      "Replaced token 3844 with corr 0.3268719017505646 with new token with corr 0.3268718719482422\n",
      "Replaced token 3845 with corr 0.2430620789527893 with new token with corr 0.2430620789527893\n",
      "Replaced token 3846 with corr 0.2248118370771408 with new token with corr 0.2248118370771408\n",
      "Replaced token 3847 with corr 0.3221197724342346 with new token with corr 0.3221197724342346\n",
      "Replaced token 3848 with corr 0.2597770392894745 with new token with corr 0.2597770094871521\n",
      "Replaced token 3849 with corr 0.10936854779720306 with new token with corr 0.26489901542663574\n",
      "Replaced token 3850 with corr 0.1962175965309143 with new token with corr 0.1962176114320755\n",
      "Replaced token 3851 with corr 0.10035465657711029 with new token with corr 0.22951041162014008\n",
      "Replaced token 3852 with corr 0.2805832028388977 with new token with corr 0.2805832028388977\n",
      "Replaced token 3853 with corr 0.2772916257381439 with new token with corr 0.2772916257381439\n",
      "Replaced token 3854 with corr 0.27932995557785034 with new token with corr 0.27932995557785034\n",
      "Replaced token 3855 with corr 0.3065687119960785 with new token with corr 0.3065687417984009\n",
      "Replaced token 3856 with corr 0.2677139341831207 with new token with corr 0.2677139341831207\n",
      "Replaced token 3857 with corr 0.3042986989021301 with new token with corr 0.3042986989021301\n",
      "Replaced token 3858 with corr 0.294644832611084 with new token with corr 0.2946448028087616\n",
      "Replaced token 3859 with corr 0.2793242037296295 with new token with corr 0.2793242335319519\n",
      "Replaced token 3860 with corr 0.27274197340011597 with new token with corr 0.27274197340011597\n",
      "Replaced token 3861 with corr 0.3154200613498688 with new token with corr 0.3154200613498688\n",
      "Replaced token 3862 with corr 0.31614261865615845 with new token with corr 0.31614261865615845\n",
      "Replaced token 3863 with corr 0.32300710678100586 with new token with corr 0.32300710678100586\n",
      "Replaced token 3864 with corr 0.30917036533355713 with new token with corr 0.30917036533355713\n",
      "Replaced token 3865 with corr 0.28816232085227966 with new token with corr 0.28816235065460205\n",
      "Replaced token 3866 with corr 0.32542359828948975 with new token with corr 0.32542356848716736\n",
      "Replaced token 3867 with corr 0.2714402377605438 with new token with corr 0.2714402675628662\n",
      "Replaced token 3868 with corr 0.25201112031936646 with new token with corr 0.25201112031936646\n",
      "Replaced token 3869 with corr 0.2761283218860626 with new token with corr 0.27612829208374023\n",
      "Replaced token 3870 with corr 0.21733233332633972 with new token with corr 0.21733231842517853\n",
      "Replaced token 3871 with corr 0.11843269318342209 with new token with corr 0.2503451406955719\n",
      "Replaced token 3872 with corr 0.11060427874326706 with new token with corr 0.2391880452632904\n",
      "Replaced token 3873 with corr 0.27534016966819763 with new token with corr 0.27534013986587524\n",
      "Replaced token 3874 with corr 0.24032051861286163 with new token with corr 0.24032051861286163\n",
      "Replaced token 3875 with corr 0.09328150004148483 with new token with corr 0.15586718916893005\n",
      "Replaced token 3876 with corr 0.17983394861221313 with new token with corr 0.17983394861221313\n",
      "Replaced token 3877 with corr 0.30351904034614563 with new token with corr 0.30351904034614563\n",
      "Replaced token 3878 with corr 0.24014481902122498 with new token with corr 0.24014483392238617\n",
      "Replaced token 3879 with corr 0.32275980710983276 with new token with corr 0.32275983691215515\n",
      "Replaced token 3880 with corr 0.24861006438732147 with new token with corr 0.24861006438732147\n",
      "Replaced token 3881 with corr 0.2822769284248352 with new token with corr 0.2822769582271576\n",
      "Replaced token 3882 with corr 0.21127139031887054 with new token with corr 0.21127142012119293\n",
      "Replaced token 3883 with corr 0.33793577551841736 with new token with corr 0.33793574571609497\n",
      "Replaced token 3884 with corr 0.330648273229599 with new token with corr 0.330648273229599\n",
      "Replaced token 3885 with corr 0.0908476859331131 with new token with corr 0.2347525656223297\n",
      "Replaced token 3886 with corr 0.3676784932613373 with new token with corr 0.36767852306365967\n",
      "Replaced token 3887 with corr 0.30608242750167847 with new token with corr 0.30608242750167847\n",
      "Replaced token 3888 with corr 0.2542556822299957 with new token with corr 0.2542556822299957\n",
      "Replaced token 3889 with corr 0.25365981459617615 with new token with corr 0.25365981459617615\n",
      "Replaced token 3890 with corr 0.26276254653930664 with new token with corr 0.26276254653930664\n",
      "Replaced token 3891 with corr 0.24789093434810638 with new token with corr 0.24789093434810638\n",
      "Replaced token 3892 with corr 0.2986719608306885 with new token with corr 0.2986719608306885\n",
      "Replaced token 3893 with corr 0.3771909475326538 with new token with corr 0.3771909177303314\n",
      "Replaced token 3894 with corr 0.2583465874195099 with new token with corr 0.2583466172218323\n",
      "Replaced token 3895 with corr 0.2644803524017334 with new token with corr 0.264480322599411\n",
      "Replaced token 3896 with corr 0.27649036049842834 with new token with corr 0.27649039030075073\n",
      "Replaced token 3897 with corr 0.3125394880771637 with new token with corr 0.3125394582748413\n",
      "Replaced token 3898 with corr 0.3082246780395508 with new token with corr 0.3082246780395508\n",
      "Replaced token 3899 with corr 0.2005397379398346 with new token with corr 0.2005397379398346\n",
      "Replaced token 3900 with corr 0.3319718837738037 with new token with corr 0.3319718837738037\n",
      "Replaced token 3901 with corr 0.3046897053718567 with new token with corr 0.3046897351741791\n",
      "Replaced token 3902 with corr 0.23514105379581451 with new token with corr 0.23514103889465332\n",
      "Replaced token 3903 with corr 0.37119060754776 with new token with corr 0.37119060754776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3904 with corr 0.25841519236564636 with new token with corr 0.25841519236564636\n",
      "Replaced token 3905 with corr 0.32950228452682495 with new token with corr 0.32950225472450256\n",
      "Replaced token 3906 with corr 0.2750011086463928 with new token with corr 0.2750011086463928\n",
      "Replaced token 3907 with corr 0.2930745780467987 with new token with corr 0.2930745780467987\n",
      "Replaced token 3908 with corr 0.33435431122779846 with new token with corr 0.33435431122779846\n",
      "Replaced token 3909 with corr 0.3485250174999237 with new token with corr 0.3485250174999237\n",
      "Replaced token 3910 with corr 0.2652069330215454 with new token with corr 0.2652069330215454\n",
      "Replaced token 3911 with corr 0.2971383035182953 with new token with corr 0.2971383333206177\n",
      "Replaced token 3912 with corr 0.28748977184295654 with new token with corr 0.28748977184295654\n",
      "Replaced token 3913 with corr 0.3032384514808655 with new token with corr 0.3032384514808655\n",
      "Replaced token 3914 with corr 0.08463185280561447 with new token with corr 0.15947912633419037\n",
      "Replaced token 3915 with corr 0.22286134958267212 with new token with corr 0.22286134958267212\n",
      "Replaced token 3916 with corr 0.34370148181915283 with new token with corr 0.34370148181915283\n",
      "Replaced token 3917 with corr 0.260009229183197 with new token with corr 0.2600092589855194\n",
      "Replaced token 3918 with corr 0.23259237408638 with new token with corr 0.23259237408638\n",
      "Replaced token 3919 with corr 0.2223779410123825 with new token with corr 0.2223779559135437\n",
      "Replaced token 3920 with corr 0.25065675377845764 with new token with corr 0.25065672397613525\n",
      "Replaced token 3921 with corr 0.2764006555080414 with new token with corr 0.2764006555080414\n",
      "Replaced token 3922 with corr 0.24416691064834595 with new token with corr 0.24416689574718475\n",
      "Replaced token 3923 with corr 0.09905815124511719 with new token with corr 0.14535480737686157\n",
      "Replaced token 3924 with corr 0.2891409397125244 with new token with corr 0.2891409397125244\n",
      "Replaced token 3925 with corr 0.2452179193496704 with new token with corr 0.24521788954734802\n",
      "Replaced token 3926 with corr 0.12426407635211945 with new token with corr 0.23572112619876862\n",
      "Replaced token 3927 with corr 0.2609591484069824 with new token with corr 0.26095911860466003\n",
      "Replaced token 3928 with corr 0.09814780950546265 with new token with corr 0.2512640953063965\n",
      "Replaced token 3929 with corr 0.3507377505302429 with new token with corr 0.3507377505302429\n",
      "Replaced token 3930 with corr 0.3347782492637634 with new token with corr 0.3347782492637634\n",
      "Replaced token 3931 with corr 0.26177969574928284 with new token with corr 0.26177969574928284\n",
      "Replaced token 3932 with corr 0.26943454146385193 with new token with corr 0.26943454146385193\n",
      "Replaced token 3933 with corr 0.10581307113170624 with new token with corr 0.2439889907836914\n",
      "Replaced token 3934 with corr 0.2730863690376282 with new token with corr 0.27308639883995056\n",
      "Replaced token 3935 with corr 0.2595382630825043 with new token with corr 0.2595382630825043\n",
      "Replaced token 3936 with corr 0.2868734896183014 with new token with corr 0.286873459815979\n",
      "Replaced token 3937 with corr 0.2949063181877136 with new token with corr 0.2949063181877136\n",
      "Replaced token 3938 with corr 0.2755124270915985 with new token with corr 0.2755124270915985\n",
      "Replaced token 3939 with corr 0.3400017321109772 with new token with corr 0.34000176191329956\n",
      "Replaced token 3940 with corr 0.31847232580184937 with new token with corr 0.31847235560417175\n",
      "Replaced token 3941 with corr 0.31247350573539734 with new token with corr 0.31247350573539734\n",
      "Replaced token 3942 with corr 0.29712042212486267 with new token with corr 0.2971203923225403\n",
      "Replaced token 3943 with corr 0.22393035888671875 with new token with corr 0.22393038868904114\n",
      "Replaced token 3944 with corr 0.31020528078079224 with new token with corr 0.31020528078079224\n",
      "Replaced token 3945 with corr 0.2895403802394867 with new token with corr 0.2895403504371643\n",
      "Replaced token 3946 with corr 0.11236857622861862 with new token with corr 0.18822109699249268\n",
      "Replaced token 3947 with corr 0.22461912035942078 with new token with corr 0.22461912035942078\n",
      "Replaced token 3948 with corr 0.10665471851825714 with new token with corr 0.25099965929985046\n",
      "Replaced token 3949 with corr 0.2986234128475189 with new token with corr 0.29862338304519653\n",
      "Replaced token 3950 with corr 0.2475002110004425 with new token with corr 0.2475001960992813\n",
      "Replaced token 3951 with corr 0.2649001479148865 with new token with corr 0.2649001479148865\n",
      "Replaced token 3952 with corr 0.25153911113739014 with new token with corr 0.2515391409397125\n",
      "Replaced token 3953 with corr 0.3010352551937103 with new token with corr 0.3010352551937103\n",
      "Replaced token 3954 with corr 0.33422359824180603 with new token with corr 0.33422359824180603\n",
      "Replaced token 3955 with corr 0.25693565607070923 with new token with corr 0.25693565607070923\n",
      "Replaced token 3956 with corr 0.31554344296455383 with new token with corr 0.31554344296455383\n",
      "Replaced token 3957 with corr 0.11053760349750519 with new token with corr 0.1511632204055786\n",
      "Replaced token 3958 with corr 0.24246099591255188 with new token with corr 0.2424609512090683\n",
      "Replaced token 3959 with corr 0.18422938883304596 with new token with corr 0.18422937393188477\n",
      "Replaced token 3960 with corr 0.08955783396959305 with new token with corr 0.23699374496936798\n",
      "Replaced token 3961 with corr 0.22510389983654022 with new token with corr 0.22510388493537903\n",
      "Replaced token 3962 with corr 0.3211369812488556 with new token with corr 0.3211369812488556\n",
      "Replaced token 3963 with corr 0.2612976133823395 with new token with corr 0.26129764318466187\n",
      "Replaced token 3964 with corr 0.1662689745426178 with new token with corr 0.1662689745426178\n",
      "Replaced token 3965 with corr 0.31291139125823975 with new token with corr 0.31291139125823975\n",
      "Replaced token 3966 with corr 0.27225229144096375 with new token with corr 0.27225232124328613\n",
      "Replaced token 3967 with corr 0.26212045550346375 with new token with corr 0.26212048530578613\n",
      "Replaced token 3968 with corr 0.34499433636665344 with new token with corr 0.34499433636665344\n",
      "Replaced token 3969 with corr 0.27426648139953613 with new token with corr 0.27426645159721375\n",
      "Replaced token 3970 with corr 0.2727270722389221 with new token with corr 0.2727270722389221\n",
      "Replaced token 3971 with corr 0.24225299060344696 with new token with corr 0.24225299060344696\n",
      "Replaced token 3972 with corr 0.3360772430896759 with new token with corr 0.3360772430896759\n",
      "Replaced token 3973 with corr 0.21642853319644928 with new token with corr 0.21642853319644928\n",
      "Replaced token 3974 with corr 0.2794153690338135 with new token with corr 0.27941539883613586\n",
      "Replaced token 3975 with corr 0.22887475788593292 with new token with corr 0.2288747876882553\n",
      "Replaced token 3976 with corr 0.24324804544448853 with new token with corr 0.24324804544448853\n",
      "Replaced token 3977 with corr 0.1248236894607544 with new token with corr 0.22677119076251984\n",
      "Replaced token 3978 with corr 0.268280953168869 with new token with corr 0.2682809829711914\n",
      "Replaced token 3979 with corr 0.09531667828559875 with new token with corr 0.2902751863002777\n",
      "Replaced token 3980 with corr 0.2682100236415863 with new token with corr 0.2682100236415863\n",
      "Replaced token 3981 with corr 0.3395916819572449 with new token with corr 0.3395916819572449\n",
      "Replaced token 3982 with corr 0.22842425107955933 with new token with corr 0.22842423617839813\n",
      "Replaced token 3983 with corr 0.24391137063503265 with new token with corr 0.24391135573387146\n",
      "Replaced token 3984 with corr 0.2501336932182312 with new token with corr 0.2501336932182312\n",
      "Replaced token 3985 with corr 0.24149920046329498 with new token with corr 0.24149921536445618\n",
      "Replaced token 3986 with corr 0.26511910557746887 with new token with corr 0.2651190757751465\n",
      "Replaced token 3987 with corr 0.09578265994787216 with new token with corr 0.18374766409397125\n",
      "Replaced token 3988 with corr 0.2642907202243805 with new token with corr 0.2642907202243805\n",
      "Replaced token 3989 with corr 0.31613925099372864 with new token with corr 0.31613922119140625\n",
      "Replaced token 3990 with corr 0.24267177283763885 with new token with corr 0.24267175793647766\n",
      "Replaced token 3991 with corr 0.15551899373531342 with new token with corr 0.1657889187335968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 3992 with corr 0.20836299657821655 with new token with corr 0.20836301147937775\n",
      "Replaced token 3993 with corr 0.2797645926475525 with new token with corr 0.2797646224498749\n",
      "Replaced token 3994 with corr 0.24389046430587769 with new token with corr 0.24389047920703888\n",
      "Replaced token 3995 with corr 0.2726772427558899 with new token with corr 0.2726772427558899\n",
      "Replaced token 3996 with corr 0.2776162028312683 with new token with corr 0.2776161730289459\n",
      "Replaced token 3997 with corr 0.28997802734375 with new token with corr 0.2899779975414276\n",
      "Replaced token 3998 with corr 0.24073143303394318 with new token with corr 0.24073141813278198\n",
      "Replaced token 3999 with corr 0.25683411955833435 with new token with corr 0.25683411955833435\n",
      "Replaced token 4000 with corr 0.33340635895729065 with new token with corr 0.33340638875961304\n",
      "Replaced token 4001 with corr 0.3169530928134918 with new token with corr 0.3169530928134918\n",
      "Replaced token 4002 with corr 0.3041837811470032 with new token with corr 0.3041837811470032\n",
      "Replaced token 4003 with corr 0.2632756531238556 with new token with corr 0.2632756233215332\n",
      "Replaced token 4004 with corr 0.22926998138427734 with new token with corr 0.22926999628543854\n",
      "Replaced token 4005 with corr 0.27747201919555664 with new token with corr 0.27747195959091187\n",
      "Replaced token 4006 with corr 0.2674817442893982 with new token with corr 0.2674817442893982\n",
      "Replaced token 4007 with corr 0.10252664983272552 with new token with corr 0.25471606850624084\n",
      "Replaced token 4008 with corr 0.32342472672462463 with new token with corr 0.32342472672462463\n",
      "Replaced token 4009 with corr 0.30346181988716125 with new token with corr 0.30346179008483887\n",
      "Replaced token 4010 with corr 0.14443473517894745 with new token with corr 0.1491142064332962\n",
      "Replaced token 4011 with corr 0.2663796842098236 with new token with corr 0.266379714012146\n",
      "Replaced token 4012 with corr 0.2918701767921448 with new token with corr 0.2918701469898224\n",
      "Replaced token 4013 with corr 0.33399727940559387 with new token with corr 0.33399730920791626\n",
      "Replaced token 4014 with corr 0.31646063923835754 with new token with corr 0.31646063923835754\n",
      "Replaced token 4015 with corr 0.2998608946800232 with new token with corr 0.2998608648777008\n",
      "Replaced token 4016 with corr 0.35037368535995483 with new token with corr 0.35037368535995483\n",
      "Replaced token 4017 with corr 0.24711020290851593 with new token with corr 0.24711018800735474\n",
      "Replaced token 4018 with corr 0.30157405138015747 with new token with corr 0.30157405138015747\n",
      "Replaced token 4019 with corr 0.2829786241054535 with new token with corr 0.2829786241054535\n",
      "Replaced token 4020 with corr 0.33109697699546814 with new token with corr 0.33109697699546814\n",
      "Replaced token 4021 with corr 0.26877596974372864 with new token with corr 0.26877596974372864\n",
      "Replaced token 4022 with corr 0.10040204226970673 with new token with corr 0.21668174862861633\n",
      "Replaced token 4023 with corr 0.0731392577290535 with new token with corr 0.1712467074394226\n",
      "Replaced token 4024 with corr 0.11364530771970749 with new token with corr 0.14999864995479584\n",
      "Replaced token 4025 with corr 0.3377477526664734 with new token with corr 0.3377477526664734\n",
      "Replaced token 4026 with corr 0.2604151666164398 with new token with corr 0.26041513681411743\n",
      "Replaced token 4027 with corr 0.28356730937957764 with new token with corr 0.28356730937957764\n",
      "Replaced token 4028 with corr 0.32219424843788147 with new token with corr 0.32219427824020386\n",
      "Replaced token 4029 with corr 0.2838289737701416 with new token with corr 0.283829003572464\n",
      "Replaced token 4030 with corr 0.27508533000946045 with new token with corr 0.27508533000946045\n",
      "Replaced token 4031 with corr 0.30292320251464844 with new token with corr 0.30292320251464844\n",
      "Replaced token 4032 with corr 0.10857785493135452 with new token with corr 0.20799802243709564\n",
      "Replaced token 4033 with corr 0.23130391538143158 with new token with corr 0.23130391538143158\n",
      "Replaced token 4034 with corr 0.28143811225891113 with new token with corr 0.28143811225891113\n",
      "Replaced token 4035 with corr 0.2612789571285248 with new token with corr 0.2612789571285248\n",
      "Replaced token 4036 with corr 0.282816618680954 with new token with corr 0.2828165888786316\n",
      "Replaced token 4037 with corr 0.27323469519615173 with new token with corr 0.27323469519615173\n",
      "Replaced token 4038 with corr 0.29659608006477356 with new token with corr 0.29659608006477356\n",
      "Replaced token 4039 with corr 0.27123868465423584 with new token with corr 0.27123868465423584\n",
      "Replaced token 4040 with corr 0.260603129863739 with new token with corr 0.2606031596660614\n",
      "Replaced token 4041 with corr 0.10823719203472137 with new token with corr 0.2075950801372528\n",
      "Replaced token 4042 with corr 0.2349410206079483 with new token with corr 0.2349410057067871\n",
      "Replaced token 4043 with corr 0.35291749238967896 with new token with corr 0.35291749238967896\n",
      "Replaced token 4044 with corr 0.32441645860671997 with new token with corr 0.32441645860671997\n",
      "Replaced token 4045 with corr 0.32512569427490234 with new token with corr 0.32512569427490234\n",
      "Replaced token 4046 with corr 0.28353050351142883 with new token with corr 0.28353050351142883\n",
      "Replaced token 4047 with corr 0.22975614666938782 with new token with corr 0.22975613176822662\n",
      "Replaced token 4048 with corr 0.2773479223251343 with new token with corr 0.27734795212745667\n",
      "Replaced token 4049 with corr 0.2333863228559494 with new token with corr 0.2333863228559494\n",
      "Replaced token 4050 with corr 0.3014644980430603 with new token with corr 0.3014644980430603\n",
      "Replaced token 4051 with corr 0.29839691519737244 with new token with corr 0.29839691519737244\n",
      "Replaced token 4052 with corr 0.36423370242118835 with new token with corr 0.36423370242118835\n",
      "Replaced token 4053 with corr 0.2501380443572998 with new token with corr 0.2501380443572998\n",
      "Replaced token 4054 with corr 0.26145413517951965 with new token with corr 0.26145413517951965\n",
      "Replaced token 4055 with corr 0.2600758671760559 with new token with corr 0.2600758671760559\n",
      "Replaced token 4056 with corr 0.2557351887226105 with new token with corr 0.2557351887226105\n",
      "Replaced token 4057 with corr 0.29834404587745667 with new token with corr 0.29834404587745667\n",
      "Replaced token 4058 with corr 0.20751427114009857 with new token with corr 0.20751428604125977\n",
      "Replaced token 4059 with corr 0.25268328189849854 with new token with corr 0.25268328189849854\n",
      "Replaced token 4060 with corr 0.3118493854999542 with new token with corr 0.31184935569763184\n",
      "Replaced token 4061 with corr 0.33531761169433594 with new token with corr 0.33531761169433594\n",
      "Replaced token 4062 with corr 0.2207612246274948 with new token with corr 0.2207612246274948\n",
      "Replaced token 4063 with corr 0.2786915898323059 with new token with corr 0.2786916196346283\n",
      "Replaced token 4064 with corr 0.25259047746658325 with new token with corr 0.25259050726890564\n",
      "Replaced token 4065 with corr 0.24302248656749725 with new token with corr 0.24302245676517487\n",
      "Replaced token 4066 with corr 0.30042365193367004 with new token with corr 0.30042365193367004\n",
      "Replaced token 4067 with corr 0.24304574728012085 with new token with corr 0.24304574728012085\n",
      "Replaced token 4068 with corr 0.2895646393299103 with new token with corr 0.2895646393299103\n",
      "Replaced token 4069 with corr 0.3482958972454071 with new token with corr 0.3482958972454071\n",
      "Replaced token 4070 with corr 0.2126791775226593 with new token with corr 0.2126791775226593\n",
      "Replaced token 4071 with corr 0.33771631121635437 with new token with corr 0.33771631121635437\n",
      "Replaced token 4072 with corr 0.2954484224319458 with new token with corr 0.2954484820365906\n",
      "Replaced token 4073 with corr 0.30574721097946167 with new token with corr 0.30574721097946167\n",
      "Replaced token 4074 with corr 0.31151995062828064 with new token with corr 0.31151992082595825\n",
      "Replaced token 4075 with corr 0.2532825767993927 with new token with corr 0.2532825767993927\n",
      "Replaced token 4076 with corr 0.30222004652023315 with new token with corr 0.30222004652023315\n",
      "Replaced token 4077 with corr 0.3161959648132324 with new token with corr 0.3161959648132324\n",
      "Replaced token 4078 with corr 0.2784736156463623 with new token with corr 0.2784735858440399\n",
      "Replaced token 4079 with corr 0.27073898911476135 with new token with corr 0.27073898911476135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced token 4080 with corr 0.27061501145362854 with new token with corr 0.27061501145362854\n",
      "Replaced token 4081 with corr 0.09662853181362152 with new token with corr 0.19235314428806305\n",
      "Replaced token 4082 with corr 0.358834832906723 with new token with corr 0.3588348627090454\n",
      "Replaced token 4083 with corr 0.3017421364784241 with new token with corr 0.3017421066761017\n",
      "Replaced token 4084 with corr 0.2358466535806656 with new token with corr 0.2358466237783432\n",
      "Replaced token 4085 with corr 0.28542622923851013 with new token with corr 0.28542619943618774\n",
      "Replaced token 4086 with corr 0.32203593850135803 with new token with corr 0.32203593850135803\n",
      "Replaced token 4087 with corr 0.2609933912754059 with new token with corr 0.26099342107772827\n",
      "Replaced token 4088 with corr 0.3617456257343292 with new token with corr 0.3617456257343292\n",
      "Replaced token 4089 with corr 0.29691386222839355 with new token with corr 0.29691386222839355\n",
      "Replaced token 4090 with corr 0.298216313123703 with new token with corr 0.298216313123703\n",
      "Replaced token 4091 with corr 0.2694332003593445 with new token with corr 0.2694332003593445\n",
      "Replaced token 4092 with corr 0.2948596477508545 with new token with corr 0.2948596477508545\n",
      "Replaced token 4093 with corr 0.270882248878479 with new token with corr 0.2708822190761566\n",
      "Replaced token 4094 with corr 0.28278452157974243 with new token with corr 0.28278452157974243\n",
      "Replaced token 4095 with corr 0.0721680223941803 with new token with corr 0.14965713024139404\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.9009 | S-BLEU: 0.76 | FMSE: 2.7284e-03 | \n",
      " G-BLEU: 0.73 | ROUGE1: 0.89| ROUGE2: 0.77 | ROUGE-L: 0.87| Token Acc: 92.48% | Label Acc: 92.48%\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "for sentence_alg in [\"dynamic-threshold\"]:\n",
    "    for embedding_weight in [0, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5, 0.75, 0.95, 1.0, 10]:\n",
    "        attacker.cfg.sentence_algorithm=sentence_alg\n",
    "        attacker.cfg.embedding_token_weight = embedding_weight\n",
    "        print(f\"Evaluating {sentence_alg} with {embedding_weight}\")\n",
    "        try:\n",
    "            reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                          server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "            metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                                server.model, cfg_case=cfg.case, setup=setup)\n",
    "            results[f\"{sentence_alg}-{embedding_weight}\"] = metrics[\"accuracy\"]\n",
    "        except:\n",
    "            results[f\"{sentence_alg}-{embedding_weight}\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b03f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dynamic-threshold-0': 0.865234375,\n",
       " 'dynamic-threshold-0.0001': 0.865234375,\n",
       " 'dynamic-threshold-0.001': 0.865234375,\n",
       " 'dynamic-threshold-0.01': 0.865234375,\n",
       " 'dynamic-threshold-0.1': 0.865234375,\n",
       " 'dynamic-threshold-0.2': 0.865234375,\n",
       " 'dynamic-threshold-0.5': 0.891845703125,\n",
       " 'dynamic-threshold-0.75': 0.904541015625,\n",
       " 'dynamic-threshold-0.95': 0.90234375,\n",
       " 'dynamic-threshold-1.0': 0.90087890625,\n",
       " 'dynamic-threshold-10': 0.90087890625}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fefdce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker.cfg.sentence_algorithm=\"dynamic-threshold\"\n",
    "attacker.cfg.embedding_token_weight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf6f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.6856348514556885, feature std is 863.3228149414062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 395 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [205, 5, 182, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.476519227027893, feature std is 72.77660369873047.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 696 embeddings with positional data from imprinted layer.\n",
      "Assigned [176, 159, 12, 90, 63, 89, 67, 40] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0056887464597821236, feature std is 0.7724676728248596.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3674 embeddings with positional data from imprinted layer.\n",
      "Assigned [361, 512, 512, 512, 512, 512, 334, 419] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0225 | S-BLEU: 0.01 | FMSE: 3.0903e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.22% | Label Acc: 98.22%\n",
      "Checking 8-10-10.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004818500892724842, feature std is 0.07909378409385681.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3827 embeddings with positional data from imprinted layer.\n",
      "Assigned [457, 512, 503, 370, 465, 512, 496, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0681 | S-BLEU: 0.09 | FMSE: 8.6089e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.41| ROUGE2: 0.05 | ROUGE-L: 0.17| Token Acc: 92.11% | Label Acc: 92.11%\n",
      "Checking 8-10-10.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00030287253321148455, feature std is 0.008350723423063755.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3872 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 319, 481, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0640 | S-BLEU: 0.10 | FMSE: 1.1046e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.39| ROUGE2: 0.04 | ROUGE-L: 0.16| Token Acc: 86.43% | Label Acc: 86.43%\n",
      "Checking 8-10-10.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.5238248276291415e-05, feature std is 0.0009017959819175303.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 475, 311, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0530 | S-BLEU: 0.05 | FMSE: 1.1542e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.33| ROUGE2: 0.02 | ROUGE-L: 0.13| Token Acc: 75.00% | Label Acc: 75.00%\n",
      "Checking 8-10-10.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -82.6476821899414, feature std is 1011.3864135742188.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 340 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [26, 309, 1, 1, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.8525782823562622, feature std is 99.70964813232422.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 595 embeddings with positional data from imprinted layer.\n",
      "Assigned [121, 112, 76, 64, 81, 32, 72, 37] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.009841729886829853, feature std is 1.0646510124206543.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3441 embeddings with positional data from imprinted layer.\n",
      "Assigned [443, 476, 512, 512, 269, 512, 512, 205] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0222 | S-BLEU: 0.01 | FMSE: 3.1872e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.29% | Label Acc: 98.29%\n",
      "Checking 8-10-10.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001057264395058155, feature std is 0.1005808562040329.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3701 embeddings with positional data from imprinted layer.\n",
      "Assigned [332, 512, 512, 512, 459, 512, 350, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0588 | S-BLEU: 0.05 | FMSE: 1.0330e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.37| ROUGE2: 0.03 | ROUGE-L: 0.14| Token Acc: 84.72% | Label Acc: 84.72%\n",
      "Checking 8-10-10.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004966752021573484, feature std is 0.009933419525623322.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 291, 512, 512, 512, 474] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0779 | S-BLEU: 0.09 | FMSE: 1.1204e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.03 | ROUGE-L: 0.13| Token Acc: 71.24% | Label Acc: 71.24%\n",
      "Checking 8-10-10.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.0238974027743097e-05, feature std is 0.0009594925795681775.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3806 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 388, 346, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0542 | S-BLEU: 0.08 | FMSE: 1.2470e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 69.78% | Label Acc: 69.78%\n",
      "Checking 8-10-10.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 55.25940704345703, feature std is 1064.3199462890625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 360 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [4, 351, 1, 1, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.8897814750671387, feature std is 104.6097183227539.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 587 embeddings with positional data from imprinted layer.\n",
      "Assigned [60, 62, 6, 119, 62, 13, 29, 236] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03813847899436951, feature std is 1.0271813869476318.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3368 embeddings with positional data from imprinted layer.\n",
      "Assigned [398, 393, 279, 512, 512, 512, 338, 424] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0205 | S-BLEU: 0.01 | FMSE: 3.1874e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.05% | Label Acc: 98.05%\n",
      "Checking 8-10-10.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005196623504161835, feature std is 0.09509656578302383.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3692 embeddings with positional data from imprinted layer.\n",
      "Assigned [314, 415, 512, 512, 512, 403, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1025 | S-BLEU: 0.09 | FMSE: 1.1019e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.39| ROUGE2: 0.05 | ROUGE-L: 0.18| Token Acc: 84.16% | Label Acc: 84.16%\n",
      "Checking 8-10-10.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004362373729236424, feature std is 0.010654449462890625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [276, 512, 512, 383, 512, 512, 512, 506] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0833 | S-BLEU: 0.09 | FMSE: 1.1769e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.04 | ROUGE-L: 0.13| Token Acc: 69.85% | Label Acc: 69.85%\n",
      "Checking 8-10-10.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.662089562159963e-05, feature std is 0.0009862948209047318.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 420, 504, 240, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0525 | S-BLEU: 0.06 | FMSE: 1.1781e-02 | \n",
      " G-BLEU: 0.07 | ROUGE1: 0.28| ROUGE2: 0.01 | ROUGE-L: 0.10| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-10-10.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 12.902698516845703, feature std is 1035.377197265625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 380 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [370, 5, 1, 1, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.258580207824707, feature std is 93.77592468261719.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 515 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [319, 171, 13, 2, 1, 2, 7] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.05610837787389755, feature std is 1.0418756008148193.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3403 embeddings with positional data from imprinted layer.\n",
      "Assigned [311, 512, 341, 421, 512, 512, 282, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0208 | S-BLEU: 0.01 | FMSE: 3.4849e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.32% | Label Acc: 98.32%\n",
      "Checking 8-10-10.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002885809517465532, feature std is 0.10272639244794846.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3697 embeddings with positional data from imprinted layer.\n",
      "Assigned [402, 512, 512, 512, 459, 512, 276, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0554 | S-BLEU: 0.08 | FMSE: 1.1757e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.03 | ROUGE-L: 0.15| Token Acc: 85.23% | Label Acc: 85.23%\n",
      "Checking 8-10-10.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00012838961265515536, feature std is 0.010365383699536324.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 273, 445, 512, 459, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0825 | S-BLEU: 0.10 | FMSE: 1.1648e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.04 | ROUGE-L: 0.12| Token Acc: 69.73% | Label Acc: 69.73%\n",
      "Checking 8-10-10.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.0519015631871298e-05, feature std is 0.0010135264601558447.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3717 embeddings with positional data from imprinted layer.\n",
      "Assigned [342, 303, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0776 | S-BLEU: 0.08 | FMSE: 1.1899e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.03 | ROUGE-L: 0.12| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-10-10.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 82.490234375, feature std is 981.16455078125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 297 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [231, 55, 5, 2, 2, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.547217845916748, feature std is 101.40660095214844.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 444 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 4 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [9, 158, 132, 127, 3, 15] breached embeddings to each sentence.\n",
      "Checking 8-10-10.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.010108720511198044, feature std is 1.015777587890625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3426 embeddings with positional data from imprinted layer.\n",
      "Assigned [229, 512, 458, 512, 291, 400, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0220 | S-BLEU: 0.01 | FMSE: 3.2169e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.17% | Label Acc: 98.17%\n",
      "Checking 8-10-10.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0018293325556442142, feature std is 0.0986996740102768.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3668 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 253, 445, 410, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0923 | S-BLEU: 0.09 | FMSE: 1.0370e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.38| ROUGE2: 0.04 | ROUGE-L: 0.16| Token Acc: 84.77% | Label Acc: 84.77%\n",
      "Checking 8-10-10.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00048072892241179943, feature std is 0.009591761976480484.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [448, 512, 216, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0515 | S-BLEU: 0.05 | FMSE: 1.1691e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.30| ROUGE2: 0.01 | ROUGE-L: 0.10| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-10-10.0-0.001-0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.5828245523152873e-05, feature std is 0.0009991528932005167.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3745 embeddings with positional data from imprinted layer.\n",
      "Assigned [447, 512, 512, 448, 512, 512, 512, 290] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0979 | S-BLEU: 0.08 | FMSE: 1.1623e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.04 | ROUGE-L: 0.13| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-10-100.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 18.728778839111328, feature std is 405.34832763671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 416 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [129, 223, 3, 1, 2, 6, 52] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0011822439264506102, feature std is 38.55458068847656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1315 embeddings with positional data from imprinted layer.\n",
      "Assigned [155, 325, 100, 35, 200, 242, 59, 199] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.007154518738389015, feature std is 0.40393921732902527.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3777 embeddings with positional data from imprinted layer.\n",
      "Assigned [468, 485, 512, 512, 474, 512, 488, 326] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0259 | S-BLEU: 0.01 | FMSE: 1.6393e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.46% | Label Acc: 99.46%\n",
      "Checking 8-10-100.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00026379257906228304, feature std is 0.04241005703806877.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [500, 512, 512, 512, 512, 286, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0100 | S-BLEU: 0.01 | FMSE: 2.5255e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.27% | Label Acc: 99.27%\n",
      "Checking 8-10-100.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.000434194429544732, feature std is 0.0052170041017234325.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3859 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 359, 512, 512, 512, 428, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0491 | S-BLEU: 0.01 | FMSE: 4.5288e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.19% | Label Acc: 98.19%\n",
      "Checking 8-10-100.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.385774471098557e-05, feature std is 0.00043565340456552804.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 409, 512, 471, 493, 476, 493, 492] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0352 | S-BLEU: 0.01 | FMSE: 2.6957e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.71% | Label Acc: 99.71%\n",
      "Checking 8-10-100.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.3066511154174805, feature std is 981.3033447265625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 342 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [13, 327, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.385367393493652, feature std is 97.56915283203125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 544 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.5285703258766843.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n",
      "Assigned [8, 11, 313, 41, 11, 125, 35] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0009015895775519311, feature std is 0.9833663702011108.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3573 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 270, 512, 512, 231] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0703 | S-BLEU: 0.01 | FMSE: 2.3615e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.22% | Label Acc: 98.22%\n",
      "Checking 8-10-100.0-1-0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002520221984013915, feature std is 0.09458769112825394.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3808 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 505, 512, 512, 395, 348] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5632 | S-BLEU: 0.38 | FMSE: 3.9935e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.63| ROUGE2: 0.36 | ROUGE-L: 0.55| Token Acc: 87.01% | Label Acc: 87.01%\n",
      "Checking 8-10-100.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.51748845889233e-05, feature std is 0.009828838519752026.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 438, 512, 512, 512, 399, 512, 454] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2449 | S-BLEU: 0.24 | FMSE: 1.0170e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.43| ROUGE2: 0.16 | ROUGE-L: 0.27| Token Acc: 77.56% | Label Acc: 77.56%\n",
      "Checking 8-10-100.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.7035042371135205e-05, feature std is 0.0009709566948004067.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3872 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 461, 452, 512, 502, 454, 467, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6318 | S-BLEU: 0.41 | FMSE: 5.2578e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.64| ROUGE2: 0.41 | ROUGE-L: 0.60| Token Acc: 77.51% | Label Acc: 77.51%\n",
      "Checking 8-10-100.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.385066032409668, feature std is 973.9762573242188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 318 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [300, 1, 1, 9, 2, 5] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.946971893310547, feature std is 101.03131103515625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 540 embeddings with positional data from imprinted layer.\n",
      "Assigned [322, 104, 55, 7, 25, 8, 11, 8] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.04366965591907501, feature std is 1.028171181678772.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3426 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 171, 450, 500, 512, 257, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0327 | S-BLEU: 0.01 | FMSE: 2.8088e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 97.92% | Label Acc: 97.92%\n",
      "Checking 8-10-100.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0006982635823078454, feature std is 0.10041279345750809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3708 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 274, 512, 367, 507, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2524 | S-BLEU: 0.17 | FMSE: 8.2842e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.45| ROUGE2: 0.12 | ROUGE-L: 0.29| Token Acc: 85.47% | Label Acc: 85.47%\n",
      "Checking 8-10-100.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0009617038886062801, feature std is 0.010095004923641682.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3791 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 364, 512, 512, 512, 355, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2439 | S-BLEU: 0.20 | FMSE: 9.7634e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.39| ROUGE2: 0.13 | ROUGE-L: 0.27| Token Acc: 69.95% | Label Acc: 69.95%\n",
      "Checking 8-10-100.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.373693471075967e-05, feature std is 0.0010286137694492936.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3769 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 358, 512, 374, 512, 477, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3706 | S-BLEU: 0.20 | FMSE: 9.1611e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.45| ROUGE2: 0.19 | ROUGE-L: 0.36| Token Acc: 68.24% | Label Acc: 68.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.0197434425354, feature std is 1041.1844482421875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 351 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [345, 2, 1, 2, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.969576597213745, feature std is 100.88838958740234.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 563 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.6488129468552288.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n",
      "Assigned [205, 52, 25, 186, 11, 3, 81] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.03889511898159981, feature std is 1.0076632499694824.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3426 embeddings with positional data from imprinted layer.\n",
      "Assigned [239, 396, 505, 369, 512, 391, 512, 502] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0496 | S-BLEU: 0.02 | FMSE: 2.8367e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.10% | Label Acc: 98.10%\n",
      "Checking 8-10-100.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004904251545667648, feature std is 0.09729425609111786.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3705 embeddings with positional data from imprinted layer.\n",
      "Assigned [358, 512, 512, 512, 512, 512, 512, 275] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4023 | S-BLEU: 0.21 | FMSE: 6.4134e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.54| ROUGE2: 0.21 | ROUGE-L: 0.40| Token Acc: 83.86% | Label Acc: 83.86%\n",
      "Checking 8-10-100.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0002838447398971766, feature std is 0.010323808528482914.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3727 embeddings with positional data from imprinted layer.\n",
      "Assigned [409, 512, 246, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1843 | S-BLEU: 0.13 | FMSE: 1.0849e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.35| ROUGE2: 0.08 | ROUGE-L: 0.20| Token Acc: 69.65% | Label Acc: 69.65%\n",
      "Checking 8-10-100.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.668427431577584e-06, feature std is 0.0009982273913919926.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [457, 387, 512, 512, 512, 512, 512, 322] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4194 | S-BLEU: 0.22 | FMSE: 8.1299e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.49| ROUGE2: 0.22 | ROUGE-L: 0.41| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-10-100.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 10.663225173950195, feature std is 1028.057373046875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 366 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [175, 10, 176, 2, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.5898404121398926, feature std is 100.09239196777344.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 557 embeddings with positional data from imprinted layer.\n",
      "Assigned [11, 73, 19, 21, 241, 121, 63, 8] breached embeddings to each sentence.\n",
      "Checking 8-10-100.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0013402531621977687, feature std is 1.0746006965637207.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3455 embeddings with positional data from imprinted layer.\n",
      "Assigned [456, 335, 367, 512, 470, 291, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0369 | S-BLEU: 0.01 | FMSE: 2.6086e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.22% | Label Acc: 98.22%\n",
      "Checking 8-10-100.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004724744241684675, feature std is 0.0957295298576355.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3679 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 236, 512, 371, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3630 | S-BLEU: 0.20 | FMSE: 6.7376e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.50| ROUGE2: 0.18 | ROUGE-L: 0.36| Token Acc: 84.11% | Label Acc: 84.11%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00018616292800288647, feature std is 0.009852387942373753.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3743 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 267, 448, 512, 468, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2246 | S-BLEU: 0.17 | FMSE: 1.0266e-02 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.36| ROUGE2: 0.11 | ROUGE-L: 0.24| Token Acc: 69.41% | Label Acc: 69.41%\n",
      "Checking 8-10-100.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.9960079953307286e-05, feature std is 0.0009652537992224097.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3756 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 503, 512, 512, 512, 501, 512, 192] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1421 | S-BLEU: 0.11 | FMSE: 1.0735e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.07 | ROUGE-L: 0.18| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-10-1000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -27.789960861206055, feature std is 443.6424865722656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 338 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [315, 5, 4, 8, 6] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.9319016933441162, feature std is 38.1524772644043.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1278 embeddings with positional data from imprinted layer.\n",
      "Assigned [166, 97, 128, 365, 154, 151, 115, 102] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.02822721004486084, feature std is 0.4286496043205261.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3827 embeddings with positional data from imprinted layer.\n",
      "Assigned [482, 491, 512, 453, 472, 512, 444, 461] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0178 | S-BLEU: 0.01 | FMSE: 1.9486e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.27% | Label Acc: 99.27%\n",
      "Checking 8-10-1000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002077382057905197, feature std is 0.042476266622543335.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3860 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 475, 483, 478, 489, 485, 491, 483] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0359 | S-BLEU: 0.01 | FMSE: 2.6310e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.66% | Label Acc: 99.66%\n",
      "Checking 8-10-1000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -0.00010359322186559439, feature std is 0.004727126099169254.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3842 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 375, 512, 512, 512, 395, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0562 | S-BLEU: 0.01 | FMSE: 2.9158e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.61% | Label Acc: 98.61%\n",
      "Checking 8-10-1000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.0376752470619977e-05, feature std is 0.00042282367940060794.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3849 embeddings with positional data from imprinted layer.\n",
      "Assigned [477, 329, 512, 512, 512, 512, 512, 483] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0298 | S-BLEU: 0.01 | FMSE: 2.8215e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.76% | Label Acc: 99.76%\n",
      "Checking 8-10-1000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -36.49953842163086, feature std is 910.5357055664062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 377 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [1, 374, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.924662709236145, feature std is 96.43017578125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 551 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.5601182101986528.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [1, 16, 3, 409, 10, 109, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.06684448570013046, feature std is 0.9806112051010132.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3538 embeddings with positional data from imprinted layer.\n",
      "Assigned [496, 337, 335, 512, 512, 322, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0886 | S-BLEU: 0.02 | FMSE: 2.0401e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.29% | Label Acc: 98.29%\n",
      "Checking 8-10-1000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004209243692457676, feature std is 0.09663622826337814.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3790 embeddings with positional data from imprinted layer.\n",
      "Assigned [320, 413, 512, 512, 512, 512, 497, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4370 | S-BLEU: 0.28 | FMSE: 5.4525e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.54| ROUGE2: 0.22 | ROUGE-L: 0.42| Token Acc: 85.99% | Label Acc: 85.99%\n",
      "Checking 8-10-1000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00043490881216712296, feature std is 0.009644657373428345.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3834 embeddings with positional data from imprinted layer.\n",
      "Assigned [363, 512, 512, 457, 512, 512, 512, 454] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5330 | S-BLEU: 0.35 | FMSE: 6.6216e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.58| ROUGE2: 0.32 | ROUGE-L: 0.51| Token Acc: 77.93% | Label Acc: 77.93%\n",
      "Checking 8-10-1000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.624029704951681e-05, feature std is 0.0009742733091115952.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3876 embeddings with positional data from imprinted layer.\n",
      "Assigned [432, 512, 512, 372, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4114 | S-BLEU: 0.30 | FMSE: 7.6622e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.52| ROUGE2: 0.25 | ROUGE-L: 0.41| Token Acc: 77.25% | Label Acc: 77.25%\n",
      "Checking 8-10-1000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 20.351289749145508, feature std is 1011.9907836914062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 342 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [333, 2, 1, 1, 3, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.0605454444885254, feature std is 102.1506118774414.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 573 embeddings with positional data from imprinted layer.\n",
      "Assigned [67, 65, 15, 76, 33, 16, 132, 169] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.1012609452009201, feature std is 0.939498245716095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3431 embeddings with positional data from imprinted layer.\n",
      "Assigned [450, 190, 480, 512, 491, 512, 512, 284] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0374 | S-BLEU: 0.01 | FMSE: 3.0108e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.17| Token Acc: 98.19% | Label Acc: 98.19%\n",
      "Checking 8-10-1000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0014760122867301106, feature std is 0.09609720855951309.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3693 embeddings with positional data from imprinted layer.\n",
      "Assigned [463, 468, 451, 455, 475, 456, 466, 459] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6941 | S-BLEU: 0.39 | FMSE: 2.7554e-03 | \n",
      " G-BLEU: 0.38 | ROUGE1: 0.70| ROUGE2: 0.42 | ROUGE-L: 0.65| Token Acc: 84.35% | Label Acc: 84.35%\n",
      "Checking 8-10-1000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0001987023715628311, feature std is 0.010091045871376991.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3745 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 393, 455, 512, 376, 512, 473] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4729 | S-BLEU: 0.25 | FMSE: 7.5376e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.52| ROUGE2: 0.26 | ROUGE-L: 0.46| Token Acc: 70.04% | Label Acc: 70.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-1000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.0084246241603978e-05, feature std is 0.0009978176094591618.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3722 embeddings with positional data from imprinted layer.\n",
      "Assigned [340, 512, 512, 512, 310, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1831 | S-BLEU: 0.09 | FMSE: 9.8483e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.07 | ROUGE-L: 0.20| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-10-1000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -36.419185638427734, feature std is 944.9601440429688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 318 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [313, 5] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.8921299576759338, feature std is 102.94367218017578.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 485 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [334, 30, 107, 1, 2, 6, 4, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.018803538754582405, feature std is 1.0192949771881104.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3411 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 379, 384, 384, 471, 380, 389] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1626 | S-BLEU: 0.02 | FMSE: 1.3670e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.49| ROUGE2: 0.03 | ROUGE-L: 0.20| Token Acc: 98.07% | Label Acc: 98.07%\n",
      "Checking 8-10-1000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0006631407304666936, feature std is 0.09998709708452225.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3692 embeddings with positional data from imprinted layer.\n",
      "Assigned [306, 512, 512, 512, 340, 486, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3694 | S-BLEU: 0.24 | FMSE: 7.0711e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.52| ROUGE2: 0.19 | ROUGE-L: 0.38| Token Acc: 85.30% | Label Acc: 85.30%\n",
      "Checking 8-10-1000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002570421784184873, feature std is 0.009775337763130665.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [462, 474, 512, 486, 317, 512, 451, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5464 | S-BLEU: 0.26 | FMSE: 7.1338e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.57| ROUGE2: 0.28 | ROUGE-L: 0.52| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-10-1000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.7188196327188052e-05, feature std is 0.0010221160482615232.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3738 embeddings with positional data from imprinted layer.\n",
      "Assigned [466, 463, 474, 449, 484, 466, 481, 455] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6235 | S-BLEU: 0.28 | FMSE: 6.7941e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.62| ROUGE2: 0.33 | ROUGE-L: 0.60| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-10-1000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -67.01876831054688, feature std is 1052.27880859375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 307 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [276, 27, 1, 1, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.141225814819336, feature std is 102.8351058959961.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 545 embeddings with positional data from imprinted layer.\n",
      "Assigned [237, 6, 195, 2, 69, 9, 10, 17] breached embeddings to each sentence.\n",
      "Checking 8-10-1000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006996709853410721, feature std is 0.9757128357887268.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3440 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 324, 512, 417, 139, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0835 | S-BLEU: 0.02 | FMSE: 2.3978e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.44% | Label Acc: 98.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-1000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005713474936783314, feature std is 0.09913530200719833.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3712 embeddings with positional data from imprinted layer.\n",
      "Assigned [356, 512, 299, 512, 512, 512, 497, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2830 | S-BLEU: 0.25 | FMSE: 7.3197e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.49| ROUGE2: 0.18 | ROUGE-L: 0.33| Token Acc: 84.79% | Label Acc: 84.79%\n",
      "Checking 8-10-1000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004677963734138757, feature std is 0.009801439009606838.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [418, 512, 458, 512, 512, 512, 306, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2463 | S-BLEU: 0.15 | FMSE: 1.0013e-02 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.38| ROUGE2: 0.11 | ROUGE-L: 0.25| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-10-1000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.5453994718845934e-05, feature std is 0.0010164884151890874.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3712 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 409, 231, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2473 | S-BLEU: 0.17 | FMSE: 9.6913e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.37| ROUGE2: 0.12 | ROUGE-L: 0.26| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-10-10000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.683356285095215, feature std is 465.3494567871094.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 493 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [3, 484, 3, 1, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.66202974319458, feature std is 33.7848014831543.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1596 embeddings with positional data from imprinted layer.\n",
      "Assigned [166, 82, 75, 180, 170, 174, 264, 485] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.008974401280283928, feature std is 0.40367013216018677.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3756 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 428, 425, 512, 436, 419] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0195 | S-BLEU: 0.01 | FMSE: 1.9561e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.05% | Label Acc: 99.05%\n",
      "Checking 8-10-10000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0011219242587685585, feature std is 0.03651484474539757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3847 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 263, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0117 | S-BLEU: 0.01 | FMSE: 3.8601e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.42| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 92.41% | Label Acc: 92.41%\n",
      "Checking 8-10-10000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.4340147976763546e-05, feature std is 0.005103743635118008.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 489, 512, 512, 484, 378, 494, 477] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1409 | S-BLEU: 0.02 | FMSE: 2.8745e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 99.07% | Label Acc: 99.07%\n",
      "Checking 8-10-10000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.481119347270578e-05, feature std is 0.00038271304219961166.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3876 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 404, 512, 512, 512, 400, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0352 | S-BLEU: 0.01 | FMSE: 2.3194e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.32% | Label Acc: 99.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 11.114197731018066, feature std is 943.0997924804688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 335 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [158, 97, 77, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.6379029750823975, feature std is 96.87378692626953.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 577 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 5 seeds searching on threshold 0.40343081488340526.\n",
      "Filling with 3 random seeds...These sentences will be scrambled.\n",
      "Assigned [206, 191, 28, 78, 71, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.01768830418586731, feature std is 1.020896553993225.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3523 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 506, 419, 512, 38, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1086 | S-BLEU: 0.03 | FMSE: 1.7605e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.07% | Label Acc: 98.07%\n",
      "Checking 8-10-10000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.006575368344783783, feature std is 0.09193696081638336.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3834 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 497, 476, 512, 481, 512, 359, 485] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7102 | S-BLEU: 0.43 | FMSE: 1.9303e-03 | \n",
      " G-BLEU: 0.40 | ROUGE1: 0.70| ROUGE2: 0.44 | ROUGE-L: 0.66| Token Acc: 86.65% | Label Acc: 86.65%\n",
      "Checking 8-10-10000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00015246639668475837, feature std is 0.009513135999441147.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3832 embeddings with positional data from imprinted layer.\n",
      "Assigned [437, 512, 512, 512, 512, 512, 512, 323] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3025 | S-BLEU: 0.21 | FMSE: 8.7516e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.15 | ROUGE-L: 0.32| Token Acc: 77.05% | Label Acc: 77.05%\n",
      "Checking 8-10-10000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.623655255883932e-05, feature std is 0.0010066344402730465.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3902 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 348, 512, 512, 512, 512, 482] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4600 | S-BLEU: 0.27 | FMSE: 7.5994e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.52| ROUGE2: 0.25 | ROUGE-L: 0.44| Token Acc: 74.93% | Label Acc: 74.93%\n",
      "Checking 8-10-10000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 39.9868278503418, feature std is 1005.3001098632812.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 342 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [3, 336, 2, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.4566543102264404, feature std is 101.52745819091797.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 519 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 3 seeds searching on threshold 0.12708189775845913.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [163, 14, 262, 25, 1, 7, 2, 45] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.021410394459962845, feature std is 1.0342819690704346.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3404 embeddings with positional data from imprinted layer.\n",
      "Assigned [397, 390, 512, 297, 512, 512, 272, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0791 | S-BLEU: 0.01 | FMSE: 2.0796e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 97.97% | Label Acc: 97.97%\n",
      "Checking 8-10-10000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002581222215667367, feature std is 0.09677711874246597.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3689 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 442, 330, 357, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1392 | S-BLEU: 0.11 | FMSE: 9.4646e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.40| ROUGE2: 0.05 | ROUGE-L: 0.19| Token Acc: 84.13% | Label Acc: 84.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.000133503635879606, feature std is 0.009908579289913177.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3738 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 264, 402, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3594 | S-BLEU: 0.19 | FMSE: 8.9372e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.45| ROUGE2: 0.17 | ROUGE-L: 0.35| Token Acc: 70.02% | Label Acc: 70.02%\n",
      "Checking 8-10-10000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.102436484274222e-06, feature std is 0.0010061394423246384.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3761 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 428, 357, 512, 416] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1848 | S-BLEU: 0.12 | FMSE: 1.0368e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.35| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-10-10000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -58.755027770996094, feature std is 1020.590576171875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 355 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [160, 57, 129, 7, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.659661769866943, feature std is 101.70232391357422.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 580 embeddings with positional data from imprinted layer.\n",
      "Assigned [80, 73, 111, 144, 76, 18, 62, 16] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0076113673858344555, feature std is 1.0139013528823853.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3413 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 268, 512, 512, 512, 233, 352] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0417 | S-BLEU: 0.01 | FMSE: 3.0601e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.17| Token Acc: 98.00% | Label Acc: 98.00%\n",
      "Checking 8-10-10000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0006861182046122849, feature std is 0.104185089468956.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3676 embeddings with positional data from imprinted layer.\n",
      "Assigned [463, 468, 478, 479, 447, 445, 449, 447] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6838 | S-BLEU: 0.39 | FMSE: 2.6783e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.69| ROUGE2: 0.41 | ROUGE-L: 0.63| Token Acc: 85.38% | Label Acc: 85.38%\n",
      "Checking 8-10-10000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is 0.0008560598944313824, feature std is 0.010136180557310581.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3733 embeddings with positional data from imprinted layer.\n",
      "Assigned [421, 512, 253, 499, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2781 | S-BLEU: 0.16 | FMSE: 9.8120e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.40| ROUGE2: 0.13 | ROUGE-L: 0.28| Token Acc: 69.70% | Label Acc: 69.70%\n",
      "Checking 8-10-10000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.6510711652226746e-05, feature std is 0.0009836131939664483.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [470, 463, 459, 456, 461, 475, 482, 462] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6226 | S-BLEU: 0.29 | FMSE: 6.4703e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.62| ROUGE2: 0.33 | ROUGE-L: 0.60| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-10-10000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -49.286399841308594, feature std is 1020.3067626953125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 289 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [286, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.2566118240356445, feature std is 100.57672882080078.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 657 embeddings with positional data from imprinted layer.\n",
      "Assigned [75, 166, 77, 19, 81, 80, 80, 79] breached embeddings to each sentence.\n",
      "Checking 8-10-10000.0-0.001-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.028172286227345467, feature std is 1.0444642305374146.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3434 embeddings with positional data from imprinted layer.\n",
      "Assigned [411, 246, 512, 460, 406, 430, 512, 457] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0693 | S-BLEU: 0.01 | FMSE: 2.3002e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.29% | Label Acc: 98.29%\n",
      "Checking 8-10-10000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0035897516645491123, feature std is 0.10231009870767593.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3661 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 414, 512, 314, 373, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3079 | S-BLEU: 0.21 | FMSE: 8.1868e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.48| ROUGE2: 0.17 | ROUGE-L: 0.33| Token Acc: 84.59% | Label Acc: 84.59%\n",
      "Checking 8-10-10000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.834903276991099e-05, feature std is 0.010143502615392208.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 493, 512, 512, 251, 512, 512, 476] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5796 | S-BLEU: 0.26 | FMSE: 6.3848e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.59| ROUGE2: 0.29 | ROUGE-L: 0.55| Token Acc: 69.48% | Label Acc: 69.48%\n",
      "Checking 8-10-10000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.665374606498517e-06, feature std is 0.0009379886905662715.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3735 embeddings with positional data from imprinted layer.\n",
      "Assigned [409, 512, 463, 303, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5537 | S-BLEU: 0.23 | FMSE: 7.3998e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.56| ROUGE2: 0.26 | ROUGE-L: 0.52| Token Acc: 68.41% | Label Acc: 68.41%\n",
      "Checking 8-10-100000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 16.31300926208496, feature std is 439.2449951171875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 450 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [32, 413, 4, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.889987587928772, feature std is 29.5778751373291.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1645 embeddings with positional data from imprinted layer.\n",
      "Assigned [159, 112, 107, 169, 248, 512, 152, 186] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005970407277345657, feature std is 0.3203309178352356.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3838 embeddings with positional data from imprinted layer.\n",
      "Assigned [254, 512, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0105 | S-BLEU: 0.01 | FMSE: 1.5447e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.42| ROUGE2: 0.02 | ROUGE-L: 0.14| Token Acc: 90.75% | Label Acc: 90.75%\n",
      "Checking 8-10-100000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0026062396354973316, feature std is 0.04683889448642731.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3884 embeddings with positional data from imprinted layer.\n",
      "Assigned [509, 512, 512, 512, 303, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0332 | S-BLEU: 0.01 | FMSE: 2.6887e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 96.36% | Label Acc: 96.36%\n",
      "Checking 8-10-100000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00014303222997114062, feature std is 0.003875132417306304.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3840 embeddings with positional data from imprinted layer.\n",
      "Assigned [492, 471, 478, 475, 488, 486, 512, 438] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0342 | S-BLEU: 0.01 | FMSE: 2.5400e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.76% | Label Acc: 99.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.8151716732245404e-06, feature std is 0.00043269438901916146.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3846 embeddings with positional data from imprinted layer.\n",
      "Assigned [415, 512, 512, 512, 512, 512, 512, 359] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0247 | S-BLEU: 0.01 | FMSE: 4.5575e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.46% | Label Acc: 97.46%\n",
      "Checking 8-10-100000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -48.79014587402344, feature std is 957.4832153320312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 370 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [4, 366] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.415886402130127, feature std is 90.54666900634766.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 687 embeddings with positional data from imprinted layer.\n",
      "Assigned [224, 39, 142, 57, 44, 89, 27, 65] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.019162872806191444, feature std is 0.9857392907142639.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3480 embeddings with positional data from imprinted layer.\n",
      "Assigned [436, 319, 512, 512, 239, 512, 512, 438] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1348 | S-BLEU: 0.02 | FMSE: 1.6067e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.51% | Label Acc: 98.51%\n",
      "Checking 8-10-100000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.007386285811662674, feature std is 0.09510251134634018.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3809 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 357, 512, 380, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3252 | S-BLEU: 0.21 | FMSE: 7.0722e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.50| ROUGE2: 0.17 | ROUGE-L: 0.35| Token Acc: 86.89% | Label Acc: 86.89%\n",
      "Checking 8-10-100000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00046508150990121067, feature std is 0.009489546529948711.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3838 embeddings with positional data from imprinted layer.\n",
      "Assigned [416, 494, 475, 512, 476, 512, 479, 474] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6973 | S-BLEU: 0.40 | FMSE: 4.8237e-03 | \n",
      " G-BLEU: 0.38 | ROUGE1: 0.69| ROUGE2: 0.42 | ROUGE-L: 0.66| Token Acc: 78.91% | Label Acc: 78.91%\n",
      "Checking 8-10-100000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.379367939895019e-05, feature std is 0.0009194609010592103.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3842 embeddings with positional data from imprinted layer.\n",
      "Assigned [381, 509, 392, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1523 | S-BLEU: 0.14 | FMSE: 1.0607e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.35| ROUGE2: 0.08 | ROUGE-L: 0.19| Token Acc: 74.73% | Label Acc: 74.73%\n",
      "Checking 8-10-100000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 55.53002166748047, feature std is 1045.6524658203125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 368 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [367, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.5544736385345459, feature std is 94.79810333251953.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 594 embeddings with positional data from imprinted layer.\n",
      "Assigned [40, 8, 10, 58, 40, 1, 429, 8] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.08078158646821976, feature std is 1.018194317817688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3464 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 378, 315, 425, 512, 512, 512, 298] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0862 | S-BLEU: 0.02 | FMSE: 2.1563e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.14% | Label Acc: 98.14%\n",
      "Checking 8-10-100000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.003476479323580861, feature std is 0.10173854231834412.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3714 embeddings with positional data from imprinted layer.\n",
      "Assigned [468, 462, 401, 458, 469, 462, 482, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6882 | S-BLEU: 0.38 | FMSE: 2.4362e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.69| ROUGE2: 0.41 | ROUGE-L: 0.65| Token Acc: 85.21% | Label Acc: 85.21%\n",
      "Checking 8-10-100000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0003223215462639928, feature std is 0.009963376447558403.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3768 embeddings with positional data from imprinted layer.\n",
      "Assigned [429, 512, 512, 512, 512, 512, 512, 267] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3542 | S-BLEU: 0.18 | FMSE: 8.7466e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.16 | ROUGE-L: 0.34| Token Acc: 70.04% | Label Acc: 70.04%\n",
      "Checking 8-10-100000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.2571219233213924e-05, feature std is 0.0010009066900238395.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3744 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 467, 512, 311, 512, 478, 483, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5938 | S-BLEU: 0.27 | FMSE: 7.0117e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.60| ROUGE2: 0.29 | ROUGE-L: 0.56| Token Acc: 68.43% | Label Acc: 68.43%\n",
      "Checking 8-10-100000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 20.120603561401367, feature std is 1008.936767578125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 313 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [311, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.009518623352051, feature std is 99.56982421875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 558 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 6 seeds searching on threshold 0.22395669554756203.\n",
      "Filling with 2 random seeds...These sentences will be scrambled.\n",
      "Assigned [81, 223, 196, 16, 27, 10, 2, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.07835259288549423, feature std is 0.9498040676116943.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3488 embeddings with positional data from imprinted layer.\n",
      "Assigned [482, 407, 75, 512, 512, 476, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1360 | S-BLEU: 0.02 | FMSE: 1.5584e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.48| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.24% | Label Acc: 98.24%\n",
      "Checking 8-10-100000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.001534283859655261, feature std is 0.10116793215274811.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3668 embeddings with positional data from imprinted layer.\n",
      "Assigned [457, 512, 461, 469, 443, 466, 394, 466] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6719 | S-BLEU: 0.37 | FMSE: 2.7590e-03 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.68| ROUGE2: 0.39 | ROUGE-L: 0.63| Token Acc: 84.47% | Label Acc: 84.47%\n",
      "Checking 8-10-100000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00039766207919456065, feature std is 0.010004865005612373.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3741 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 282, 387, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3098 | S-BLEU: 0.18 | FMSE: 9.2187e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.41| ROUGE2: 0.14 | ROUGE-L: 0.31| Token Acc: 69.75% | Label Acc: 69.75%\n",
      "Checking 8-10-100000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.9490376871544868e-05, feature std is 0.0010212910128757358.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 263, 407] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1926 | S-BLEU: 0.11 | FMSE: 1.0779e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.34| ROUGE2: 0.07 | ROUGE-L: 0.20| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-10-100000.0-0.001-1000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 33.976234436035156, feature std is 987.0653686523438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 335 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 4 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [20, 55, 131, 123, 2, 1, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.693549156188965, feature std is 102.62694549560547.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 606 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.5136466878515196.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n",
      "Assigned [3, 74, 5, 461, 18, 27, 18] breached embeddings to each sentence.\n",
      "Checking 8-10-100000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.008270862512290478, feature std is 0.9829713106155396.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3419 embeddings with positional data from imprinted layer.\n",
      "Assigned [499, 512, 512, 507, 468, 297, 287, 337] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0784 | S-BLEU: 0.01 | FMSE: 2.2610e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.27% | Label Acc: 98.27%\n",
      "Checking 8-10-100000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.003849092870950699, feature std is 0.0996154248714447.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3668 embeddings with positional data from imprinted layer.\n",
      "Assigned [480, 512, 512, 512, 512, 116, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2144 | S-BLEU: 0.12 | FMSE: 9.4269e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.42| ROUGE2: 0.09 | ROUGE-L: 0.24| Token Acc: 84.94% | Label Acc: 84.94%\n",
      "Checking 8-10-100000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0002721449709497392, feature std is 0.010106171481311321.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3730 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 481, 458, 252, 512, 491, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5403 | S-BLEU: 0.25 | FMSE: 7.6980e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.57| ROUGE2: 0.27 | ROUGE-L: 0.52| Token Acc: 69.58% | Label Acc: 69.58%\n",
      "Checking 8-10-100000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.106893240736099e-06, feature std is 0.0009445947944186628.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3734 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 329, 512, 512, 333, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3442 | S-BLEU: 0.19 | FMSE: 9.1865e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.43| ROUGE2: 0.18 | ROUGE-L: 0.34| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-10-1000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -14.357922554016113, feature std is 403.36248779296875.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 418 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [233, 58, 123, 2, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.40155291557312, feature std is 38.4654426574707.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1254 embeddings with positional data from imprinted layer.\n",
      "Assigned [108, 84, 134, 38, 183, 326, 291, 90] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.008672330528497696, feature std is 0.391753226518631.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3773 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 437, 512, 308, 512, 512, 512, 468] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0137 | S-BLEU: 0.01 | FMSE: 3.3615e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 95.61% | Label Acc: 95.61%\n",
      "Checking 8-10-1000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001017787610180676, feature std is 0.04052559286355972.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3844 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 260, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0161 | S-BLEU: 0.01 | FMSE: 2.6197e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.40| ROUGE2: 0.02 | ROUGE-L: 0.14| Token Acc: 90.45% | Label Acc: 90.45%\n",
      "Checking 8-10-1000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00019468240498099476, feature std is 0.004211017861962318.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3846 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 390, 512, 384, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0515 | S-BLEU: 0.01 | FMSE: 2.7101e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.83% | Label Acc: 98.83%\n",
      "Checking 8-10-1000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.7436988148110686e-07, feature std is 0.0003675609186757356.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3804 embeddings with positional data from imprinted layer.\n",
      "Assigned [363, 512, 512, 512, 369, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0176 | S-BLEU: 0.01 | FMSE: 1.7463e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.88% | Label Acc: 98.88%\n",
      "Checking 8-10-1000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -81.85330963134766, feature std is 896.426513671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 326 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [320, 3, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.245474815368652, feature std is 98.08665466308594.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 574 embeddings with positional data from imprinted layer.\n",
      "Assigned [72, 11, 107, 14, 69, 143, 12, 146] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.019071077927947044, feature std is 0.9552203416824341.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3557 embeddings with positional data from imprinted layer.\n",
      "Assigned [448, 446, 418, 456, 452, 388, 512, 437] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1707 | S-BLEU: 0.02 | FMSE: 1.2822e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.50| ROUGE2: 0.04 | ROUGE-L: 0.21| Token Acc: 98.05% | Label Acc: 98.05%\n",
      "Checking 8-10-1000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0021943640895187855, feature std is 0.09757747501134872.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3828 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 512, 512, 481, 461, 359, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5359 | S-BLEU: 0.33 | FMSE: 3.8870e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.60| ROUGE2: 0.31 | ROUGE-L: 0.51| Token Acc: 85.89% | Label Acc: 85.89%\n",
      "Checking 8-10-1000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.000712802866473794, feature std is 0.009939719922840595.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3860 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [512, 436, 495, 482, 489, 477, 478, 491] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6946 | S-BLEU: 0.39 | FMSE: 5.2967e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.69| ROUGE2: 0.42 | ROUGE-L: 0.66| Token Acc: 76.76% | Label Acc: 76.76%\n",
      "Checking 8-10-1000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.2599700716673397e-06, feature std is 0.0009202485671266913.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3849 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 442, 335, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2927 | S-BLEU: 0.22 | FMSE: 8.7264e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.31| Token Acc: 80.03% | Label Acc: 80.03%\n",
      "Checking 8-10-1000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -38.92132568359375, feature std is 1017.7968139648438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 369 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [349, 7, 9, 1, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.1097263097763062, feature std is 96.07815551757812.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 568 embeddings with positional data from imprinted layer.\n",
      "Assigned [31, 9, 35, 180, 63, 10, 40, 200] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.034012239426374435, feature std is 1.029130458831787.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3492 embeddings with positional data from imprinted layer.\n",
      "Assigned [421, 512, 512, 512, 406, 114, 503, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1047 | S-BLEU: 0.01 | FMSE: 1.9469e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.41% | Label Acc: 98.41%\n",
      "Checking 8-10-1000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0018417369574308395, feature std is 0.09621550142765045.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3668 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 466, 332, 310] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3574 | S-BLEU: 0.23 | FMSE: 6.7929e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.51| ROUGE2: 0.21 | ROUGE-L: 0.38| Token Acc: 84.38% | Label Acc: 84.38%\n",
      "Checking 8-10-1000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0005946544115431607, feature std is 0.010152921080589294.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3718 embeddings with positional data from imprinted layer.\n",
      "Assigned [454, 512, 512, 512, 364, 340, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3374 | S-BLEU: 0.18 | FMSE: 8.8684e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.16 | ROUGE-L: 0.34| Token Acc: 69.78% | Label Acc: 69.78%\n",
      "Checking 8-10-1000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.5957879087363835e-06, feature std is 0.0010195558425039053.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3776 embeddings with positional data from imprinted layer.\n",
      "Assigned [240, 512, 464, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2109 | S-BLEU: 0.17 | FMSE: 1.0214e-02 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.35| ROUGE2: 0.10 | ROUGE-L: 0.23| Token Acc: 68.48% | Label Acc: 68.48%\n",
      "Checking 8-10-1000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 45.71831130981445, feature std is 1011.6705322265625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 344 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [338, 1, 3, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.8325397968292236, feature std is 99.30783081054688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 570 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.5706548543262664.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n",
      "Assigned [7, 1, 1, 235, 284, 40, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.013460309244692326, feature std is 1.0123947858810425.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3495 embeddings with positional data from imprinted layer.\n",
      "Assigned [445, 512, 155, 423, 512, 512, 512, 424] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1279 | S-BLEU: 0.03 | FMSE: 1.7188e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.29% | Label Acc: 98.29%\n",
      "Checking 8-10-1000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.003619804512709379, feature std is 0.10505828261375427.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3684 embeddings with positional data from imprinted layer.\n",
      "Assigned [480, 512, 467, 241, 481, 512, 479, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5840 | S-BLEU: 0.31 | FMSE: 3.7526e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.63| ROUGE2: 0.31 | ROUGE-L: 0.55| Token Acc: 85.42% | Label Acc: 85.42%\n",
      "Checking 8-10-1000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002815115440171212, feature std is 0.009998507797718048.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 402, 512, 337, 512, 512, 425] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1663 | S-BLEU: 0.12 | FMSE: 1.0618e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.34| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 69.68% | Label Acc: 69.68%\n",
      "Checking 8-10-1000000.0-0.01-0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.0633429560111836e-05, feature std is 0.0009652601438574493.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3746 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 407, 372, 512, 512, 407, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1548 | S-BLEU: 0.13 | FMSE: 1.0477e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.32| ROUGE2: 0.07 | ROUGE-L: 0.18| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-10-1000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -17.41602325439453, feature std is 955.2451782226562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 337 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [271, 58, 1, 3, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.5934604406356812, feature std is 103.28353118896484.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 562 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 6 seeds searching on threshold 0.40136227959271475.\n",
      "Filling with 2 random seeds...These sentences will be scrambled.\n",
      "Assigned [8, 85, 19, 291, 95, 64] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0808352380990982, feature std is 1.0053104162216187.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3419 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 281, 512, 512, 512, 332, 246, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1018 | S-BLEU: 0.01 | FMSE: 2.1349e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.04 | ROUGE-L: 0.19| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-10-1000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0004925605026073754, feature std is 0.10082396119832993.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3696 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 387, 512, 345, 445, 512, 471] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4390 | S-BLEU: 0.30 | FMSE: 5.7027e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.56| ROUGE2: 0.27 | ROUGE-L: 0.45| Token Acc: 85.16% | Label Acc: 85.16%\n",
      "Checking 8-10-1000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.344368011923507e-05, feature std is 0.010246751829981804.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3702 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 170, 512, 460, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4504 | S-BLEU: 0.20 | FMSE: 7.8892e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.19 | ROUGE-L: 0.43| Token Acc: 69.78% | Label Acc: 69.78%\n",
      "Checking 8-10-1000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.3781216694042087e-05, feature std is 0.000998357660137117.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3753 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 368, 313, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3022 | S-BLEU: 0.16 | FMSE: 9.4203e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.40| ROUGE2: 0.13 | ROUGE-L: 0.30| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-10-10000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.8760266304016113, feature std is 467.0770568847656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 409 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [2, 381, 21, 5] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.0235230922698975, feature std is 38.85918426513672.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1255 embeddings with positional data from imprinted layer.\n",
      "Assigned [33, 328, 124, 84, 55, 108, 444, 79] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.01695159263908863, feature std is 0.38266125321388245.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 391, 512, 512, 421, 465, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0125 | S-BLEU: 0.01 | FMSE: 1.6702e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 96.44% | Label Acc: 96.44%\n",
      "Checking 8-10-10000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0007085662800818682, feature std is 0.042459238320589066.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3854 embeddings with positional data from imprinted layer.\n",
      "Assigned [399, 512, 512, 383, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0376 | S-BLEU: 0.01 | FMSE: 3.8811e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 96.88% | Label Acc: 96.88%\n",
      "Checking 8-10-10000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.315531648695469e-05, feature std is 0.0028376439586281776.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [465, 476, 512, 512, 512, 457, 512, 391] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0149 | S-BLEU: 0.01 | FMSE: 1.1299e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.71% | Label Acc: 99.71%\n",
      "Checking 8-10-10000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.1459610504971351e-05, feature std is 0.000490301288664341.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3848 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 264, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0613 | S-BLEU: 0.07 | FMSE: 5.2101e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.41| ROUGE2: 0.04 | ROUGE-L: 0.17| Token Acc: 89.40% | Label Acc: 89.40%\n",
      "Checking 8-10-10000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -43.68032455444336, feature std is 964.1926879882812.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 320 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [78, 22, 211, 8, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.711421012878418, feature std is 96.56019592285156.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 572 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 5 seeds searching on threshold 0.4197242688570183.\n",
      "Filling with 3 random seeds...These sentences will be scrambled.\n",
      "Assigned [155, 100, 44, 95, 170, 8] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.030034277588129044, feature std is 0.974355161190033.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3483 embeddings with positional data from imprinted layer.\n",
      "Assigned [460, 507, 512, 464, 321, 401, 509, 309] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0532 | S-BLEU: 0.01 | FMSE: 2.6818e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-10-10000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001730899210087955, feature std is 0.09638914465904236.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [338, 512, 491, 512, 496, 490, 512, 486] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6545 | S-BLEU: 0.36 | FMSE: 2.5812e-03 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.66| ROUGE2: 0.37 | ROUGE-L: 0.61| Token Acc: 86.30% | Label Acc: 86.30%\n",
      "Checking 8-10-10000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.503934077452868e-05, feature std is 0.009394719265401363.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3861 embeddings with positional data from imprinted layer.\n",
      "Assigned [317, 512, 512, 512, 512, 472, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0947 | S-BLEU: 0.13 | FMSE: 1.1389e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.35| ROUGE2: 0.05 | ROUGE-L: 0.15| Token Acc: 74.85% | Label Acc: 74.85%\n",
      "Checking 8-10-10000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.0325764378649183e-05, feature std is 0.0009559346362948418.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3847 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 477, 490, 487, 479, 479, 481, 478] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7007 | S-BLEU: 0.39 | FMSE: 5.2090e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.69| ROUGE2: 0.42 | ROUGE-L: 0.67| Token Acc: 76.66% | Label Acc: 76.66%\n",
      "Checking 8-10-10000000.0-0.1-1000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 50.13210678100586, feature std is 1021.6661987304688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 324 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 4 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [1, 88, 213, 13, 7, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.7224354147911072, feature std is 106.40939331054688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 561 embeddings with positional data from imprinted layer.\n",
      "Assigned [122, 137, 13, 9, 131, 68, 9, 72] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.030732205137610435, feature std is 1.029693603515625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3406 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 281, 366, 512, 512, 457, 254, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0627 | S-BLEU: 0.02 | FMSE: 2.5684e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.05% | Label Acc: 98.05%\n",
      "Checking 8-10-10000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001191736781038344, feature std is 0.10068753361701965.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3732 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 285, 375, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3108 | S-BLEU: 0.16 | FMSE: 7.2753e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.49| ROUGE2: 0.14 | ROUGE-L: 0.31| Token Acc: 85.01% | Label Acc: 85.01%\n",
      "Checking 8-10-10000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.3163007679395378e-05, feature std is 0.00971035286784172.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3738 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 154, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4028 | S-BLEU: 0.17 | FMSE: 8.2898e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.46| ROUGE2: 0.15 | ROUGE-L: 0.38| Token Acc: 69.82% | Label Acc: 69.82%\n",
      "Checking 8-10-10000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.175686171947746e-06, feature std is 0.0009944535559043288.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 152, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4875 | S-BLEU: 0.21 | FMSE: 8.2408e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.53| ROUGE2: 0.23 | ROUGE-L: 0.47| Token Acc: 68.48% | Label Acc: 68.48%\n",
      "Checking 8-10-10000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -32.71446990966797, feature std is 1027.6971435546875.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 317 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [314, 1, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.6780455112457275, feature std is 102.39966583251953.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 567 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 6 seeds searching on threshold 0.4566629015813898.\n",
      "Filling with 2 random seeds...These sentences will be scrambled.\n",
      "Assigned [21, 454, 36, 12, 13, 21, 2, 8] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03214636817574501, feature std is 1.0171090364456177.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3415 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 322, 332, 512, 214, 499] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0720 | S-BLEU: 0.02 | FMSE: 2.1600e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.05% | Label Acc: 98.05%\n",
      "Checking 8-10-10000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002076833276078105, feature std is 0.10487261414527893.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3668 embeddings with positional data from imprinted layer.\n",
      "Assigned [84, 512, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1716 | S-BLEU: 0.10 | FMSE: 9.9700e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.41| ROUGE2: 0.06 | ROUGE-L: 0.22| Token Acc: 85.74% | Label Acc: 85.74%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00022467438247986138, feature std is 0.010129445232450962.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 155, 512, 512, 512, 512, 498] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1770 | S-BLEU: 0.16 | FMSE: 1.0224e-02 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.34| ROUGE2: 0.09 | ROUGE-L: 0.20| Token Acc: 69.82% | Label Acc: 69.82%\n",
      "Checking 8-10-10000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00011108931357739493, feature std is 0.001018583308905363.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3713 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 367, 512, 512, 274] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1716 | S-BLEU: 0.10 | FMSE: 1.1018e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.07 | ROUGE-L: 0.18| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-10-10000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 9.421690940856934, feature std is 994.5491943359375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 337 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [333, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.2036869525909424, feature std is 99.21521759033203.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 583 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 6 seeds searching on threshold 0.5102668203005599.\n",
      "Filling with 2 random seeds...These sentences will be scrambled.\n",
      "Assigned [329, 144, 33, 45, 23, 5, 2, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0413338728249073, feature std is 0.9845791459083557.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3427 embeddings with positional data from imprinted layer.\n",
      "Assigned [26, 512, 458, 464, 512, 431, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1384 | S-BLEU: 0.03 | FMSE: 1.7680e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.20| Token Acc: 98.17% | Label Acc: 98.17%\n",
      "Checking 8-10-10000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.004398498218506575, feature std is 0.09950146079063416.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3687 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 482, 512, 407, 512, 512, 512, 238] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1892 | S-BLEU: 0.14 | FMSE: 9.6220e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.42| ROUGE2: 0.10 | ROUGE-L: 0.24| Token Acc: 84.50% | Label Acc: 84.50%\n",
      "Checking 8-10-10000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0007116015767678618, feature std is 0.009753790684044361.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3734 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 486, 360, 512, 328, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3440 | S-BLEU: 0.20 | FMSE: 9.1742e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.44| ROUGE2: 0.18 | ROUGE-L: 0.34| Token Acc: 69.60% | Label Acc: 69.60%\n",
      "Checking 8-10-10000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.0781669162679464e-05, feature std is 0.000972110778093338.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3749 embeddings with positional data from imprinted layer.\n",
      "Assigned [303, 512, 466, 479, 478, 512, 487, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5833 | S-BLEU: 0.25 | FMSE: 7.3494e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.59| ROUGE2: 0.29 | ROUGE-L: 0.56| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-10-100000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 18.92091178894043, feature std is 376.48626708984375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 491 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [484, 1, 1, 5] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.1250132322311401, feature std is 43.71835708618164.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1184 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [255, 162, 88, 126, 146, 232, 70, 105] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00487132603302598, feature std is 0.3066379427909851.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3796 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 334, 390, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0129 | S-BLEU: 0.01 | FMSE: 2.1391e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 96.90% | Label Acc: 96.90%\n",
      "Checking 8-10-100000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0016304218443110585, feature std is 0.03942373767495155.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3849 embeddings with positional data from imprinted layer.\n",
      "Assigned [451, 496, 489, 483, 512, 474, 466, 478] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0486 | S-BLEU: 0.01 | FMSE: 2.5385e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.76% | Label Acc: 99.76%\n",
      "Checking 8-10-100000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00025441974867135286, feature std is 0.00412073265761137.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3833 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 477, 512, 512, 512, 395, 401, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0227 | S-BLEU: 0.01 | FMSE: 1.9815e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 98.75% | Label Acc: 98.75%\n",
      "Checking 8-10-100000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.381342129519908e-06, feature std is 0.0004211486375425011.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3827 embeddings with positional data from imprinted layer.\n",
      "Assigned [256, 512, 512, 512, 499, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0327 | S-BLEU: 0.03 | FMSE: 2.8074e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.10% | Label Acc: 98.10%\n",
      "Checking 8-10-100000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.076623439788818, feature std is 983.6615600585938.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 385 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [2, 383] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.6117118000984192, feature std is 96.32140350341797.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 611 embeddings with positional data from imprinted layer.\n",
      "Assigned [76, 79, 27, 143, 12, 66, 74, 134] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.017285149544477463, feature std is 0.9610427021980286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3554 embeddings with positional data from imprinted layer.\n",
      "Assigned [483, 452, 512, 512, 446, 199, 512, 438] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1484 | S-BLEU: 0.03 | FMSE: 1.3420e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.39% | Label Acc: 98.39%\n",
      "Checking 8-10-100000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0018415837548673153, feature std is 0.10192186385393143.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3800 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 464, 463, 481, 484, 475, 491, 463] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7178 | S-BLEU: 0.45 | FMSE: 1.5399e-03 | \n",
      " G-BLEU: 0.42 | ROUGE1: 0.71| ROUGE2: 0.46 | ROUGE-L: 0.67| Token Acc: 87.82% | Label Acc: 87.82%\n",
      "Checking 8-10-100000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002099985722452402, feature std is 0.009402474388480186.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3854 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 365, 512, 512, 512, 417, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4258 | S-BLEU: 0.31 | FMSE: 7.1954e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.54| ROUGE2: 0.26 | ROUGE-L: 0.42| Token Acc: 81.91% | Label Acc: 81.91%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.377902587293647e-05, feature std is 0.0009357866947539151.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3818 embeddings with positional data from imprinted layer.\n",
      "Assigned [477, 476, 495, 512, 364, 512, 512, 470] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6848 | S-BLEU: 0.39 | FMSE: 5.2439e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.68| ROUGE2: 0.41 | ROUGE-L: 0.65| Token Acc: 77.61% | Label Acc: 77.61%\n",
      "Checking 8-10-100000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 18.620866775512695, feature std is 1057.6826171875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 316 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [2, 314] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.6900062561035156, feature std is 101.74575805664062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 516 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [464, 41, 8, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.018888792023062706, feature std is 1.0464415550231934.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3414 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 471, 512, 512, 512, 459, 411, 25] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1226 | S-BLEU: 0.01 | FMSE: 1.5676e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.27% | Label Acc: 98.27%\n",
      "Checking 8-10-100000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0037034270353615284, feature std is 0.09792685508728027.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3730 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 339, 319] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2883 | S-BLEU: 0.18 | FMSE: 7.5228e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.46| ROUGE2: 0.15 | ROUGE-L: 0.31| Token Acc: 84.72% | Label Acc: 84.72%\n",
      "Checking 8-10-100000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0005173019017092884, feature std is 0.009903148747980595.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3763 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 237, 512, 454, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5166 | S-BLEU: 0.24 | FMSE: 7.0616e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.56| ROUGE2: 0.26 | ROUGE-L: 0.49| Token Acc: 70.00% | Label Acc: 70.00%\n",
      "Checking 8-10-100000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.061467188876122e-05, feature std is 0.0010359141742810607.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3747 embeddings with positional data from imprinted layer.\n",
      "Assigned [481, 512, 460, 471, 357, 512, 464, 490] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5935 | S-BLEU: 0.25 | FMSE: 7.2834e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.60| ROUGE2: 0.29 | ROUGE-L: 0.57| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-10-100000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 61.592872619628906, feature std is 1005.8161010742188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 353 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [306, 42, 1, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.30501505732536316, feature std is 99.11516571044922.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 590 embeddings with positional data from imprinted layer.\n",
      "Assigned [66, 48, 73, 54, 15, 245, 66, 23] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.01088719442486763, feature std is 0.9738777279853821.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3395 embeddings with positional data from imprinted layer.\n",
      "Assigned [403, 19, 476, 512, 449, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0789 | S-BLEU: 0.02 | FMSE: 2.8585e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.22% | Label Acc: 98.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.010537463240325451, feature std is 0.09973853826522827.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3690 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 456, 457, 512, 459, 315, 512, 467] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6519 | S-BLEU: 0.36 | FMSE: 3.2798e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.68| ROUGE2: 0.37 | ROUGE-L: 0.61| Token Acc: 84.74% | Label Acc: 84.74%\n",
      "Checking 8-10-100000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.685338641749695e-05, feature std is 0.010014201514422894.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3746 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 512, 162] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1353 | S-BLEU: 0.13 | FMSE: 1.2101e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.32| ROUGE2: 0.05 | ROUGE-L: 0.16| Token Acc: 69.82% | Label Acc: 69.82%\n",
      "Checking 8-10-100000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.6432909584837034e-05, feature std is 0.0010195005452260375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 465, 416, 512, 296, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2837 | S-BLEU: 0.15 | FMSE: 9.5725e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.40| ROUGE2: 0.12 | ROUGE-L: 0.28| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-10-100000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 17.824583053588867, feature std is 974.0957641601562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 346 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [245, 50, 37, 4, 8, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.3593765497207642, feature std is 103.92732238769531.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 589 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 6 seeds searching on threshold 0.845189651788766.\n",
      "Filling with 2 random seeds...These sentences will be scrambled.\n",
      "Assigned [20, 1, 385, 127, 7, 49] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.01912560686469078, feature std is 1.04863703250885.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3411 embeddings with positional data from imprinted layer.\n",
      "Assigned [440, 377, 109, 512, 437, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1169 | S-BLEU: 0.01 | FMSE: 1.5852e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.24% | Label Acc: 98.24%\n",
      "Checking 8-10-100000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0025323517620563507, feature std is 0.09620937705039978.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3684 embeddings with positional data from imprinted layer.\n",
      "Assigned [458, 512, 369, 512, 465, 383, 473, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1858 | S-BLEU: 0.13 | FMSE: 8.8947e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.42| ROUGE2: 0.08 | ROUGE-L: 0.24| Token Acc: 84.47% | Label Acc: 84.47%\n",
      "Checking 8-10-100000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00047780704335309565, feature std is 0.009748237207531929.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3732 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 413, 512, 407, 512, 352, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1272 | S-BLEU: 0.08 | FMSE: 1.1461e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.32| ROUGE2: 0.05 | ROUGE-L: 0.16| Token Acc: 69.36% | Label Acc: 69.36%\n",
      "Checking 8-10-100000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.5787852438224945e-06, feature std is 0.0009608031250536442.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3741 embeddings with positional data from imprinted layer.\n",
      "Assigned [175, 512, 512, 494, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.1731 | S-BLEU: 0.11 | FMSE: 1.1262e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.08 | ROUGE-L: 0.19| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-10-1000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -12.952146530151367, feature std is 421.8226318359375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 424 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [272, 8, 133, 2, 9] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.242646217346191, feature std is 41.54597473144531.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1172 embeddings with positional data from imprinted layer.\n",
      "Assigned [62, 160, 106, 165, 178, 170, 123, 208] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.012156611308455467, feature std is 0.3774074614048004.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3817 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 423, 466, 509, 512, 512, 371] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0117 | S-BLEU: 0.01 | FMSE: 1.7297e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 94.60% | Label Acc: 94.60%\n",
      "Checking 8-10-1000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0017747959354892373, feature std is 0.031609732657670975.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3868 embeddings with positional data from imprinted layer.\n",
      "Assigned [488, 387, 495, 478, 484, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0293 | S-BLEU: 0.01 | FMSE: 1.4261e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.17| Token Acc: 99.83% | Label Acc: 99.83%\n",
      "Checking 8-10-1000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.31358226807788e-05, feature std is 0.0034159724600613117.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3836 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 433, 512, 512, 512, 512, 512, 331] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0161 | S-BLEU: 0.01 | FMSE: 1.6340e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.75% | Label Acc: 98.75%\n",
      "Checking 8-10-1000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.367799182451563e-07, feature std is 0.0005134092061780393.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3859 embeddings with positional data from imprinted layer.\n",
      "Assigned [482, 512, 512, 512, 492, 473, 480, 396] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1533 | S-BLEU: 0.02 | FMSE: 3.1171e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 99.07% | Label Acc: 99.07%\n",
      "Checking 8-10-1000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 68.82720947265625, feature std is 930.7456665039062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 345 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [337, 3, 2, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.967742919921875, feature std is 92.68055725097656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 568 embeddings with positional data from imprinted layer.\n",
      "Assigned [67, 79, 87, 64, 128, 56, 20, 67] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.01423949096351862, feature std is 0.9580105543136597.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3522 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 447, 479, 512, 36] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1516 | S-BLEU: 0.02 | FMSE: 1.4298e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.07% | Label Acc: 98.07%\n",
      "Checking 8-10-1000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006054359953850508, feature std is 0.10104847699403763.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3797 embeddings with positional data from imprinted layer.\n",
      "Assigned [484, 469, 462, 467, 512, 512, 485, 406] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7036 | S-BLEU: 0.42 | FMSE: 1.9821e-03 | \n",
      " G-BLEU: 0.40 | ROUGE1: 0.71| ROUGE2: 0.44 | ROUGE-L: 0.66| Token Acc: 87.89% | Label Acc: 87.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-1000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.068149716360494e-05, feature std is 0.010055238381028175.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3857 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 469, 512, 502, 326, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4302 | S-BLEU: 0.31 | FMSE: 6.5243e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.50| ROUGE2: 0.26 | ROUGE-L: 0.41| Token Acc: 75.49% | Label Acc: 75.49%\n",
      "Checking 8-10-1000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.0047823858913034e-05, feature std is 0.0009795048972591758.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3853 embeddings with positional data from imprinted layer.\n",
      "Assigned [486, 512, 481, 485, 484, 449, 470, 486] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6875 | S-BLEU: 0.39 | FMSE: 5.2194e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.68| ROUGE2: 0.42 | ROUGE-L: 0.65| Token Acc: 76.98% | Label Acc: 76.98%\n",
      "Checking 8-10-1000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 58.433841705322266, feature std is 1011.9857788085938.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 341 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [202, 134, 2, 2, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.246355652809143, feature std is 98.0194091796875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 585 embeddings with positional data from imprinted layer.\n",
      "Assigned [32, 283, 20, 180, 22, 13, 4, 31] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0025789495557546616, feature std is 1.0148720741271973.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3456 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 293, 512, 512, 276, 512, 327, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0396 | S-BLEU: 0.01 | FMSE: 2.9866e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.97% | Label Acc: 97.97%\n",
      "Checking 8-10-1000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005212572403252125, feature std is 0.10087314993143082.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3691 embeddings with positional data from imprinted layer.\n",
      "Assigned [453, 460, 512, 465, 512, 464, 512, 313] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6499 | S-BLEU: 0.38 | FMSE: 3.0595e-03 | \n",
      " G-BLEU: 0.36 | ROUGE1: 0.68| ROUGE2: 0.39 | ROUGE-L: 0.61| Token Acc: 85.01% | Label Acc: 85.01%\n",
      "Checking 8-10-1000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is 9.27414366742596e-05, feature std is 0.010093473829329014.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3729 embeddings with positional data from imprinted layer.\n",
      "Assigned [468, 462, 455, 459, 488, 512, 512, 373] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6152 | S-BLEU: 0.29 | FMSE: 6.5752e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.62| ROUGE2: 0.32 | ROUGE-L: 0.59| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 8-10-1000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.55250303982757e-05, feature std is 0.0009870168287307024.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3769 embeddings with positional data from imprinted layer.\n",
      "Assigned [463, 512, 475, 512, 482, 301, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5591 | S-BLEU: 0.23 | FMSE: 6.5762e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.56| ROUGE2: 0.26 | ROUGE-L: 0.52| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-10-1000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.505767822265625, feature std is 953.867431640625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 315 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [280, 3, 3, 25, 1, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.434527635574341, feature std is 99.81494140625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 597 embeddings with positional data from imprinted layer.\n",
      "Assigned [35, 257, 2, 24, 12, 193, 28, 46] breached embeddings to each sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-1000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.029342828318476677, feature std is 0.9667354226112366.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3398 embeddings with positional data from imprinted layer.\n",
      "Assigned [442, 233, 512, 420, 512, 439, 407, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1577 | S-BLEU: 0.01 | FMSE: 1.7583e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.32% | Label Acc: 98.32%\n",
      "Checking 8-10-1000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005264753941446543, feature std is 0.10334580391645432.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3676 embeddings with positional data from imprinted layer.\n",
      "Assigned [511, 255, 512, 350, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2373 | S-BLEU: 0.18 | FMSE: 8.4040e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.47| ROUGE2: 0.13 | ROUGE-L: 0.28| Token Acc: 85.28% | Label Acc: 85.28%\n",
      "Checking 8-10-1000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0009192011202685535, feature std is 0.010015970095992088.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3727 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 380, 512, 436, 512, 512, 351] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3389 | S-BLEU: 0.20 | FMSE: 9.1864e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.18 | ROUGE-L: 0.34| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 8-10-1000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.159739197959425e-06, feature std is 0.0010222732089459896.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3723 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 409, 512, 512, 512, 382, 372] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4355 | S-BLEU: 0.22 | FMSE: 8.0095e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.22 | ROUGE-L: 0.43| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-10-1000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -70.61322021484375, feature std is 1047.0836181640625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 344 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [6, 220, 114, 2, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.3057584762573242, feature std is 97.66804504394531.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 637 embeddings with positional data from imprinted layer.\n",
      "Assigned [281, 229, 9, 13, 5, 42, 17, 41] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -0.026484744623303413, feature std is 0.9434108138084412.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3508 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 455, 446, 106, 512, 512, 453] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1414 | S-BLEU: 0.03 | FMSE: 1.7139e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 97.88% | Label Acc: 97.88%\n",
      "Checking 8-10-1000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0025669436436146498, feature std is 0.09839162230491638.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3697 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 499, 373, 265] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2424 | S-BLEU: 0.17 | FMSE: 8.9244e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.45| ROUGE2: 0.12 | ROUGE-L: 0.27| Token Acc: 84.84% | Label Acc: 84.84%\n",
      "Checking 8-10-1000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004367999208625406, feature std is 0.010015273466706276.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3718 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 405, 512, 512, 438, 420, 512, 407] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.4673 | S-BLEU: 0.21 | FMSE: 8.0829e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.51| ROUGE2: 0.22 | ROUGE-L: 0.45| Token Acc: 69.58% | Label Acc: 69.58%\n",
      "Checking 8-10-1000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.454964462434873e-05, feature std is 0.0009996944572776556.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3730 embeddings with positional data from imprinted layer.\n",
      "Assigned [390, 512, 404, 512, 512, 512, 376, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4465 | S-BLEU: 0.20 | FMSE: 7.9504e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.50| ROUGE2: 0.21 | ROUGE-L: 0.43| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-10-10000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 11.785018920898438, feature std is 411.0277099609375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 403 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [328, 4, 62, 1, 7, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.4893035888671875, feature std is 40.460235595703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1404 embeddings with positional data from imprinted layer.\n",
      "Assigned [195, 165, 102, 192, 142, 169, 155, 284] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006698031909763813, feature std is 0.35083749890327454.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3808 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 353, 450, 512, 512, 512, 512, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0205 | S-BLEU: 0.01 | FMSE: 1.2908e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.37% | Label Acc: 99.37%\n",
      "Checking 8-10-10000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00015680768410675228, feature std is 0.054291948676109314.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3861 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 351, 484, 512, 493, 512, 485] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1257 | S-BLEU: 0.01 | FMSE: 2.8164e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 99.22% | Label Acc: 99.22%\n",
      "Checking 8-10-10000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.000124162485008128, feature std is 0.003976414445787668.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3876 embeddings with positional data from imprinted layer.\n",
      "Assigned [488, 479, 481, 481, 481, 492, 490, 484] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0457 | S-BLEU: 0.01 | FMSE: 2.0117e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.80% | Label Acc: 99.80%\n",
      "Checking 8-10-10000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.54243036074331e-06, feature std is 0.000353520066710189.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3846 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 262, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0310 | S-BLEU: 0.03 | FMSE: 4.1879e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.80% | Label Acc: 97.80%\n",
      "Checking 8-10-10000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.7854236364364624, feature std is 850.7259521484375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 355 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [346, 4, 2, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.762448787689209, feature std is 93.66793823242188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 626 embeddings with positional data from imprinted layer.\n",
      "Assigned [258, 14, 59, 103, 39, 27, 33, 93] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03469781205058098, feature std is 0.9811044335365295.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3517 embeddings with positional data from imprinted layer.\n",
      "Assigned [278, 512, 512, 506, 305, 512, 380, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0894 | S-BLEU: 0.01 | FMSE: 2.2802e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 97.95% | Label Acc: 97.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002140110358595848, feature std is 0.09178430587053299.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3794 embeddings with positional data from imprinted layer.\n",
      "Assigned [467, 512, 512, 310, 512, 512, 457, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6633 | S-BLEU: 0.38 | FMSE: 2.7306e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.70| ROUGE2: 0.40 | ROUGE-L: 0.63| Token Acc: 88.67% | Label Acc: 88.67%\n",
      "Checking 8-10-10000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00040260498644784093, feature std is 0.010035311803221703.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3860 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 442, 512, 348, 512, 512, 510] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2363 | S-BLEU: 0.21 | FMSE: 9.8572e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.40| ROUGE2: 0.12 | ROUGE-L: 0.25| Token Acc: 75.00% | Label Acc: 75.00%\n",
      "Checking 8-10-10000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.4064848073758185e-05, feature std is 0.0009681606316007674.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3855 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 486, 478, 489, 479, 488, 478, 478] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6887 | S-BLEU: 0.39 | FMSE: 5.6235e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.68| ROUGE2: 0.42 | ROUGE-L: 0.66| Token Acc: 75.17% | Label Acc: 75.17%\n",
      "Checking 8-10-10000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 23.660860061645508, feature std is 994.3692626953125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 371 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [370, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.044378757476807, feature std is 98.60499572753906.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 571 embeddings with positional data from imprinted layer.\n",
      "Assigned [3, 453, 61, 13, 6, 13, 10, 12] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.06562836468219757, feature std is 1.0281444787979126.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3462 embeddings with positional data from imprinted layer.\n",
      "Assigned [459, 512, 512, 512, 512, 512, 46, 397] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0649 | S-BLEU: 0.01 | FMSE: 2.6137e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.19% | Label Acc: 98.19%\n",
      "Checking 8-10-10000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005968712270259857, feature std is 0.09783574193716049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3713 embeddings with positional data from imprinted layer.\n",
      "Assigned [459, 512, 439, 424, 425, 430, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5496 | S-BLEU: 0.32 | FMSE: 4.3301e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.62| ROUGE2: 0.31 | ROUGE-L: 0.52| Token Acc: 84.94% | Label Acc: 84.94%\n",
      "Checking 8-10-10000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0006933126715011895, feature std is 0.010263824835419655.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [463, 458, 475, 512, 512, 512, 478, 314] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5869 | S-BLEU: 0.26 | FMSE: 6.6710e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.59| ROUGE2: 0.29 | ROUGE-L: 0.56| Token Acc: 69.85% | Label Acc: 69.85%\n",
      "Checking 8-10-10000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.105984433204867e-06, feature std is 0.001044697593897581.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3764 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 502, 512, 235, 512, 512, 512, 467] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1887 | S-BLEU: 0.11 | FMSE: 1.0422e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.34| ROUGE2: 0.07 | ROUGE-L: 0.20| Token Acc: 68.24% | Label Acc: 68.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 20.540008544921875, feature std is 995.6757202148438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 360 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [349, 1, 8, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.84256649017334, feature std is 96.15010833740234.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 527 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 3 seeds searching on threshold 0.2555196196696955.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [84, 48, 372, 5, 14, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03986399620771408, feature std is 0.9997714161872864.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3418 embeddings with positional data from imprinted layer.\n",
      "Assigned [442, 512, 512, 296, 421, 397, 441, 397] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1580 | S-BLEU: 0.02 | FMSE: 1.2703e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.21| Token Acc: 98.14% | Label Acc: 98.14%\n",
      "Checking 8-10-10000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004672597162425518, feature std is 0.09935060888528824.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3699 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 324, 512, 512, 512, 303, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2837 | S-BLEU: 0.19 | FMSE: 8.0002e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.47| ROUGE2: 0.15 | ROUGE-L: 0.31| Token Acc: 85.11% | Label Acc: 85.11%\n",
      "Checking 8-10-10000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0004490542924031615, feature std is 0.010086510330438614.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3743 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 462, 466, 512, 358, 473, 483, 477] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6040 | S-BLEU: 0.27 | FMSE: 6.8526e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 69.60% | Label Acc: 69.60%\n",
      "Checking 8-10-10000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.879975025076419e-05, feature std is 0.0010258457623422146.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3735 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 455, 512, 470, 470, 339, 465] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5891 | S-BLEU: 0.25 | FMSE: 7.0418e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.29 | ROUGE-L: 0.56| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-10-10000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.6698930263519287, feature std is 1022.5175170898438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 320 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [15, 3, 298, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.61237621307373, feature std is 101.22581481933594.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 566 embeddings with positional data from imprinted layer.\n",
      "Assigned [72, 121, 84, 135, 16, 23, 53, 62] breached embeddings to each sentence.\n",
      "Checking 8-10-10000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.029262378811836243, feature std is 1.0017651319503784.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3372 embeddings with positional data from imprinted layer.\n",
      "Assigned [429, 413, 426, 414, 435, 417, 423, 415] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1531 | S-BLEU: 0.02 | FMSE: 1.2858e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.50| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.34% | Label Acc: 98.34%\n",
      "Checking 8-10-10000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.001037888927385211, feature std is 0.10174141079187393.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3681 embeddings with positional data from imprinted layer.\n",
      "Assigned [467, 456, 367, 512, 512, 418, 512, 437] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6099 | S-BLEU: 0.34 | FMSE: 3.7739e-03 | \n",
      " G-BLEU: 0.33 | ROUGE1: 0.65| ROUGE2: 0.35 | ROUGE-L: 0.57| Token Acc: 85.13% | Label Acc: 85.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-10000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00035187372122891247, feature std is 0.01058671623468399.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3719 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 402, 405, 512, 465, 512, 399] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4587 | S-BLEU: 0.23 | FMSE: 8.2148e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.51| ROUGE2: 0.24 | ROUGE-L: 0.44| Token Acc: 69.97% | Label Acc: 69.97%\n",
      "Checking 8-10-10000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00012858310947194695, feature std is 0.0010435027070343494.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3722 embeddings with positional data from imprinted layer.\n",
      "Assigned [451, 512, 512, 224, 512, 512, 500, 499] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1714 | S-BLEU: 0.12 | FMSE: 1.0244e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-10-100000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 22.197860717773438, feature std is 308.1791687011719.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 515 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [60, 210, 231, 13, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.204306960105896, feature std is 38.57719802856445.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1260 embeddings with positional data from imprinted layer.\n",
      "Assigned [151, 41, 374, 125, 141, 121, 134, 173] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.009771539829671383, feature std is 0.3671257197856903.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3825 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 241, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0144 | S-BLEU: 0.01 | FMSE: 1.5531e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.39% | Label Acc: 99.39%\n",
      "Checking 8-10-100000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0006905648624524474, feature std is 0.03548106923699379.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 464, 315, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0190 | S-BLEU: 0.01 | FMSE: 1.9423e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.68% | Label Acc: 97.68%\n",
      "Checking 8-10-100000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -0.00016965242684818804, feature std is 0.0032306774519383907.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3861 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 369, 512, 420, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0186 | S-BLEU: 0.01 | FMSE: 1.4528e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.15| Token Acc: 96.46% | Label Acc: 96.46%\n",
      "Checking 8-10-100000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.922283263411373e-05, feature std is 0.0005090840859338641.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3880 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 487, 477, 471, 512, 512, 489, 420] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0933 | S-BLEU: 0.02 | FMSE: 3.1110e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.93% | Label Acc: 98.93%\n",
      "Checking 8-10-100000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 43.750465393066406, feature std is 879.715576171875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 370 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [369, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.03548264876008034, feature std is 97.64907836914062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 624 embeddings with positional data from imprinted layer.\n",
      "Assigned [29, 150, 66, 71, 19, 84, 73, 132] breached embeddings to each sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.053781844675540924, feature std is 0.9723894596099854.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3516 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 409, 317, 512, 512, 512, 230, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0486 | S-BLEU: 0.01 | FMSE: 2.7301e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.17% | Label Acc: 98.17%\n",
      "Checking 8-10-100000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0021892643999308348, feature std is 0.09483817219734192.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3793 embeddings with positional data from imprinted layer.\n",
      "Assigned [427, 512, 406, 465, 512, 512, 453, 506] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5649 | S-BLEU: 0.33 | FMSE: 3.4715e-03 | \n",
      " G-BLEU: 0.31 | ROUGE1: 0.63| ROUGE2: 0.33 | ROUGE-L: 0.54| Token Acc: 87.30% | Label Acc: 87.30%\n",
      "Checking 8-10-100000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0002035696234088391, feature std is 0.009564262814819813.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3833 embeddings with positional data from imprinted layer.\n",
      "Assigned [397, 512, 512, 457, 512, 512, 495, 436] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3965 | S-BLEU: 0.26 | FMSE: 7.6523e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.52| ROUGE2: 0.23 | ROUGE-L: 0.39| Token Acc: 79.08% | Label Acc: 79.08%\n",
      "Checking 8-10-100000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.959185611776775e-06, feature std is 0.0010372069664299488.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3846 embeddings with positional data from imprinted layer.\n",
      "Assigned [435, 512, 512, 512, 512, 512, 339, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1792 | S-BLEU: 0.16 | FMSE: 9.3728e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.36| ROUGE2: 0.10 | ROUGE-L: 0.21| Token Acc: 73.32% | Label Acc: 73.32%\n",
      "Checking 8-10-100000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.639516830444336, feature std is 979.6123657226562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 281 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [231, 7, 1, 2, 2, 38] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.171836853027344, feature std is 97.53477478027344.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 617 embeddings with positional data from imprinted layer.\n",
      "Assigned [137, 21, 21, 18, 31, 128, 51, 210] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -0.007709226571023464, feature std is 1.0009480714797974.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3422 embeddings with positional data from imprinted layer.\n",
      "Assigned [411, 512, 512, 420, 498, 512, 512, 45] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1387 | S-BLEU: 0.02 | FMSE: 1.5111e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.20| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-10-100000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0031540694180876017, feature std is 0.09967920929193497.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 443, 222, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5669 | S-BLEU: 0.33 | FMSE: 4.2637e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.62| ROUGE2: 0.32 | ROUGE-L: 0.53| Token Acc: 84.89% | Label Acc: 84.89%\n",
      "Checking 8-10-100000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00041039296775124967, feature std is 0.01014633383601904.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3764 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 278, 512, 512, 512, 512, 414] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.1855 | S-BLEU: 0.15 | FMSE: 1.0321e-02 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.35| ROUGE2: 0.09 | ROUGE-L: 0.21| Token Acc: 69.92% | Label Acc: 69.92%\n",
      "Checking 8-10-100000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.8999256755923852e-05, feature std is 0.0009770778706297278.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3799 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 215, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2180 | S-BLEU: 0.17 | FMSE: 1.0624e-02 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.36| ROUGE2: 0.11 | ROUGE-L: 0.23| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-10-100000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 83.67552185058594, feature std is 970.6148071289062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 360 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [358, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.8889155983924866, feature std is 102.14368438720703.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 509 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [495, 5, 7, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.01841820403933525, feature std is 0.9726930856704712.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3456 embeddings with positional data from imprinted layer.\n",
      "Assigned [295, 512, 512, 512, 315, 512, 512, 286] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0586 | S-BLEU: 0.02 | FMSE: 3.0421e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.36% | Label Acc: 98.36%\n",
      "Checking 8-10-100000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0004861388879362494, feature std is 0.09814738482236862.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3704 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 332, 512, 512, 300, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2188 | S-BLEU: 0.17 | FMSE: 9.8954e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.45| ROUGE2: 0.11 | ROUGE-L: 0.26| Token Acc: 85.25% | Label Acc: 85.25%\n",
      "Checking 8-10-100000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00011203317990293726, feature std is 0.009776151739060879.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3709 embeddings with positional data from imprinted layer.\n",
      "Assigned [234, 512, 512, 512, 434, 481, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2944 | S-BLEU: 0.19 | FMSE: 9.4566e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.42| ROUGE2: 0.15 | ROUGE-L: 0.30| Token Acc: 69.53% | Label Acc: 69.53%\n",
      "Checking 8-10-100000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.615995799715165e-05, feature std is 0.0010157161159440875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3747 embeddings with positional data from imprinted layer.\n",
      "Assigned [482, 352, 468, 479, 512, 485, 457, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6069 | S-BLEU: 0.26 | FMSE: 7.1000e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.60| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-10-100000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -31.812862396240234, feature std is 1017.6958618164062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 391 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [2, 381, 4, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.388815879821777, feature std is 103.38764190673828.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 561 embeddings with positional data from imprinted layer.\n",
      "Assigned [40, 3, 1, 5, 51, 13, 447, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-100000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.002782573224976659, feature std is 0.9978715181350708.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3415 embeddings with positional data from imprinted layer.\n",
      "Assigned [398, 406, 178, 417, 512, 512, 480, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1328 | S-BLEU: 0.01 | FMSE: 1.6077e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.20| Token Acc: 98.49% | Label Acc: 98.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-10-100000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0025878583546727896, feature std is 0.10274431109428406.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3701 embeddings with positional data from imprinted layer.\n",
      "Assigned [488, 512, 512, 512, 512, 511, 328, 326] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2593 | S-BLEU: 0.19 | FMSE: 8.5685e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.46| ROUGE2: 0.13 | ROUGE-L: 0.29| Token Acc: 85.30% | Label Acc: 85.30%\n",
      "Checking 8-10-100000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00047927722334861755, feature std is 0.009763878770172596.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3715 embeddings with positional data from imprinted layer.\n",
      "Assigned [500, 332, 512, 409, 512, 458, 512, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3276 | S-BLEU: 0.20 | FMSE: 8.7681e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.32| Token Acc: 69.43% | Label Acc: 69.43%\n",
      "Checking 8-10-100000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 9.679418144514784e-05, feature std is 0.0010367941576987505.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [394, 415, 512, 512, 383, 512, 497, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4399 | S-BLEU: 0.22 | FMSE: 8.3741e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.21 | ROUGE-L: 0.42| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-10-1000000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 21.486963272094727, feature std is 418.5111389160156.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 473 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 1 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 7 random seeds...These sentences will be scrambled.\n",
      "Assigned [449, 2, 2, 18, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.1713056564331055, feature std is 35.95854949951172.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1381 embeddings with positional data from imprinted layer.\n",
      "Assigned [408, 109, 98, 145, 190, 269, 40, 122] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.018126199021935463, feature std is 0.2714405655860901.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [483, 477, 484, 512, 488, 465, 458, 470] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0125 | S-BLEU: 0.00 | FMSE: 1.1484e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.85% | Label Acc: 99.85%\n",
      "Checking 8-10-1000000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -0.001731476979330182, feature std is 0.038995176553726196.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3880 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 306, 512, 512, 512, 512, 502] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0112 | S-BLEU: 0.01 | FMSE: 3.2258e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.61% | Label Acc: 97.61%\n",
      "Checking 8-10-1000000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.374309254577383e-05, feature std is 0.003865125821903348.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3868 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 284, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0168 | S-BLEU: 0.01 | FMSE: 5.4712e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 95.19% | Label Acc: 95.19%\n",
      "Checking 8-10-1000000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.463096385938115e-06, feature std is 0.00037612710730172694.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3865 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 281, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0164 | S-BLEU: 0.01 | FMSE: 2.3833e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.42| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 94.02% | Label Acc: 94.02%\n",
      "Checking 8-10-1000000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -90.82783508300781, feature std is 1014.0231323242188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 367 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [360, 3, 1, 1, 2] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.44830584526062, feature std is 99.77032470703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 640 embeddings with positional data from imprinted layer.\n",
      "Assigned [147, 21, 384, 40, 13, 7, 23, 5] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.011812588199973106, feature std is 0.9575349688529968.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3497 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 269, 502, 512, 471, 207, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0764 | S-BLEU: 0.02 | FMSE: 2.2312e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.04 | ROUGE-L: 0.17| Token Acc: 98.36% | Label Acc: 98.36%\n",
      "Checking 8-10-1000000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001419286010786891, feature std is 0.09632480144500732.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3808 embeddings with positional data from imprinted layer.\n",
      "Assigned [394, 426, 466, 512, 512, 512, 474, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2947 | S-BLEU: 0.19 | FMSE: 7.7323e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.47| ROUGE2: 0.14 | ROUGE-L: 0.30| Token Acc: 85.94% | Label Acc: 85.94%\n",
      "Checking 8-10-1000000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00028668451705016196, feature std is 0.009744132868945599.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3874 embeddings with positional data from imprinted layer.\n",
      "Assigned [290, 512, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3059 | S-BLEU: 0.24 | FMSE: 8.4815e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.45| ROUGE2: 0.16 | ROUGE-L: 0.31| Token Acc: 77.47% | Label Acc: 77.47%\n",
      "Checking 8-10-1000000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.007585175713757e-06, feature std is 0.0009411072242073715.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3850 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 445, 442, 471, 512, 512, 444] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6157 | S-BLEU: 0.38 | FMSE: 6.0016e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.64| ROUGE2: 0.37 | ROUGE-L: 0.60| Token Acc: 77.25% | Label Acc: 77.25%\n",
      "Checking 8-10-1000000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -29.492919921875, feature std is 985.6646118164062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 321 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [277, 38, 1, 2, 2, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.699625492095947, feature std is 99.13782501220703.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 508 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [497, 1, 4, 1, 5] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.10166424512863159, feature std is 1.029346227645874.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3410 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 382, 342, 335, 425, 512, 512, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1406 | S-BLEU: 0.02 | FMSE: 1.4525e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.12% | Label Acc: 98.12%\n",
      "Checking 8-10-1000000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0054755667224526405, feature std is 0.10243354737758636.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3687 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 442, 512, 385, 512, 474, 405, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.6499 | S-BLEU: 0.35 | FMSE: 3.0760e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.68| ROUGE2: 0.38 | ROUGE-L: 0.62| Token Acc: 85.77% | Label Acc: 85.77%\n",
      "Checking 8-10-1000000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0001970876328414306, feature std is 0.009247335605323315.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3744 embeddings with positional data from imprinted layer.\n",
      "Assigned [465, 512, 246, 512, 512, 512, 473, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5835 | S-BLEU: 0.26 | FMSE: 6.7651e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.59| ROUGE2: 0.29 | ROUGE-L: 0.55| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 8-10-1000000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.306587940547615e-05, feature std is 0.001017642905935645.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3819 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 450, 512, 503, 512, 316, 512, 502] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5320 | S-BLEU: 0.23 | FMSE: 7.6246e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.55| ROUGE2: 0.26 | ROUGE-L: 0.51| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-10-1000000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -82.34208679199219, feature std is 1066.656494140625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 373 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [9, 328, 34, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.668825149536133, feature std is 96.66059112548828.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 616 embeddings with positional data from imprinted layer.\n",
      "Assigned [70, 66, 68, 76, 63, 125, 74, 74] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.04311354458332062, feature std is 1.0965856313705444.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3419 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 63, 512, 331, 512, 465, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0325 | S-BLEU: 0.01 | FMSE: 2.5392e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-10-1000000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005426712799817324, feature std is 0.099024198949337.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3675 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 416, 468, 511, 232] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2485 | S-BLEU: 0.17 | FMSE: 7.5970e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.45| ROUGE2: 0.12 | ROUGE-L: 0.28| Token Acc: 84.96% | Label Acc: 84.96%\n",
      "Checking 8-10-1000000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00034312985371798277, feature std is 0.01002822071313858.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3740 embeddings with positional data from imprinted layer.\n",
      "Assigned [453, 484, 473, 469, 325, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6060 | S-BLEU: 0.27 | FMSE: 6.4285e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 69.70% | Label Acc: 69.70%\n",
      "Checking 8-10-1000000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.2662636183667928e-05, feature std is 0.0010196075309067965.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3743 embeddings with positional data from imprinted layer.\n",
      "Assigned [366, 474, 512, 512, 512, 512, 343, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3948 | S-BLEU: 0.22 | FMSE: 8.5056e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.46| ROUGE2: 0.20 | ROUGE-L: 0.38| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-10-1000000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 73.92100524902344, feature std is 978.2031860351562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 348 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [52, 58, 226, 5, 3, 4] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.5978918075561523, feature std is 93.1019515991211.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 557 embeddings with positional data from imprinted layer.\n",
      "Assigned [193, 134, 12, 187, 10, 8, 10, 3] breached embeddings to each sentence.\n",
      "Checking 8-10-1000000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.07222062349319458, feature std is 0.9781036972999573.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3501 embeddings with positional data from imprinted layer.\n",
      "Assigned [377, 338, 512, 364, 512, 374, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0850 | S-BLEU: 0.01 | FMSE: 2.5589e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.12% | Label Acc: 98.12%\n",
      "Checking 8-10-1000000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.01037650741636753, feature std is 0.09636273235082626.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3678 embeddings with positional data from imprinted layer.\n",
      "Assigned [405, 393, 512, 388, 512, 512, 444, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5342 | S-BLEU: 0.33 | FMSE: 4.8474e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.60| ROUGE2: 0.32 | ROUGE-L: 0.52| Token Acc: 84.77% | Label Acc: 84.77%\n",
      "Checking 8-10-1000000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0001715187099762261, feature std is 0.009983150288462639.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3696 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/dl/lib/python3.9/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/jonas/miniconda3/envs/dl/lib/python3.9/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError from correlation matrix [[0.99999989 0.99999989 0.99999989 ... 0.99670269 0.99670269 0.99670269]\n",
      " [0.99841794 0.99841794 0.99841794 ... 0.99732197 0.99732197 0.99732197]\n",
      " [0.66794301 0.66794301 0.66794301 ... 0.62673755 0.62673755 0.62673755]\n",
      " ...\n",
      " [0.10872969 0.10872969 0.10872969 ... 0.05890015 0.05890015 0.05890015]\n",
      " [0.99531958 0.99531958 0.99531958 ... 0.99807852 0.99807852 0.99807852]\n",
      " [0.9984178  0.9984178  0.9984178  ... 0.99732545 0.99732545 0.99732545]]\n",
      "Returning trivial order...\n",
      "Checking 8-10-1000000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.547878441167995e-05, feature std is 0.0009908899664878845.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3716 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 349, 512, 512, 512, 512, 511, 296] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2539 | S-BLEU: 0.14 | FMSE: 9.4509e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.38| ROUGE2: 0.11 | ROUGE-L: 0.26| Token Acc: 68.04% | Label Acc: 68.04%\n",
      "Checking 8-1-10.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.5256547927856445, feature std is 817.0218505859375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 658 embeddings with positional data from imprinted layer.\n",
      "Assigned [100, 101, 52, 21, 37, 120, 157, 70] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.6990456581115723, feature std is 84.7550277709961.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1915 embeddings with positional data from imprinted layer.\n",
      "Assigned [206, 251, 168, 354, 173, 266, 252, 245] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.09009017795324326, feature std is 0.6955609321594238.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3821 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 421, 328, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0647 | S-BLEU: 0.08 | FMSE: 6.2028e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.43| ROUGE2: 0.05 | ROUGE-L: 0.18| Token Acc: 95.48% | Label Acc: 95.48%\n",
      "Checking 8-1-10.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0020422458183020353, feature std is 0.09561196714639664.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3864 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 509, 512, 512, 345, 450, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0752 | S-BLEU: 0.08 | FMSE: 1.1536e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.34| ROUGE2: 0.04 | ROUGE-L: 0.15| Token Acc: 78.42% | Label Acc: 78.42%\n",
      "Checking 8-1-10.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.906174480216578e-05, feature std is 0.008492529392242432.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3850 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 471, 512, 512, 307] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1116 | S-BLEU: 0.12 | FMSE: 9.4975e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.41| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 89.53% | Label Acc: 89.53%\n",
      "Checking 8-1-10.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.1102516661339905e-06, feature std is 0.0008831737213768065.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3875 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 315, 512, 488, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0854 | S-BLEU: 0.10 | FMSE: 9.6782e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.39| ROUGE2: 0.05 | ROUGE-L: 0.18| Token Acc: 88.23% | Label Acc: 88.23%\n",
      "Checking 8-1-10.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 33.363040924072266, feature std is 1001.4547729492188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 616 embeddings with positional data from imprinted layer.\n",
      "Assigned [122, 57, 55, 99, 106, 20, 52, 105] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.859772682189941, feature std is 98.83269500732422.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1619 embeddings with positional data from imprinted layer.\n",
      "Assigned [138, 133, 118, 242, 452, 200, 74, 262] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.000418488634750247, feature std is 0.9717655777931213.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3765 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 425, 512, 437, 343, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0759 | S-BLEU: 0.07 | FMSE: 1.2599e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.38| ROUGE2: 0.04 | ROUGE-L: 0.16| Token Acc: 84.77% | Label Acc: 84.77%\n",
      "Checking 8-1-10.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0017386357067152858, feature std is 0.09858107566833496.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3762 embeddings with positional data from imprinted layer.\n",
      "Assigned [371, 493, 512, 512, 512, 512, 512, 338] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0559 | S-BLEU: 0.08 | FMSE: 1.1812e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 69.53% | Label Acc: 69.53%\n",
      "Checking 8-1-10.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00013859338650945574, feature std is 0.009863079525530338.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3815 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 231, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0706 | S-BLEU: 0.10 | FMSE: 1.2555e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.04 | ROUGE-L: 0.13| Token Acc: 69.02% | Label Acc: 69.02%\n",
      "Checking 8-1-10.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.642677858006209e-05, feature std is 0.0009583214414305985.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3770 embeddings with positional data from imprinted layer.\n",
      "Assigned [312, 494, 512, 512, 512, 404, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0532 | S-BLEU: 0.06 | FMSE: 1.1672e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 68.46% | Label Acc: 68.46%\n",
      "Checking 8-1-10.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 44.67500686645508, feature std is 1036.3310546875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 565 embeddings with positional data from imprinted layer.\n",
      "Assigned [73, 51, 111, 44, 86, 19, 61, 120] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.3347628116607666, feature std is 99.0713119506836.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1662 embeddings with positional data from imprinted layer.\n",
      "Assigned [208, 392, 277, 170, 121, 82, 298, 114] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.019782962277531624, feature std is 1.0348944664001465.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3671 embeddings with positional data from imprinted layer.\n",
      "Assigned [406, 512, 327, 512, 512, 470, 512, 420] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0735 | S-BLEU: 0.05 | FMSE: 1.0920e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 85.45% | Label Acc: 85.45%\n",
      "Checking 8-1-10.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004936005920171738, feature std is 0.09982727468013763.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3711 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 274, 512, 512, 512, 512, 365, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0498 | S-BLEU: 0.05 | FMSE: 1.1684e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 69.46% | Label Acc: 69.46%\n",
      "Checking 8-1-10.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00022187663125805557, feature std is 0.010400966741144657.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3739 embeddings with positional data from imprinted layer.\n",
      "Assigned [198, 512, 497, 512, 512, 512, 484, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0808 | S-BLEU: 0.07 | FMSE: 1.1268e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.03 | ROUGE-L: 0.12| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-10.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.233416282455437e-05, feature std is 0.0009776926599442959.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 287, 369, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1135 | S-BLEU: 0.09 | FMSE: 1.1515e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.30| ROUGE2: 0.04 | ROUGE-L: 0.14| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-1-10.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -43.20638656616211, feature std is 1024.14501953125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 525 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [101, 404, 14, 1, 1, 2, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.401538610458374, feature std is 97.12006378173828.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1754 embeddings with positional data from imprinted layer.\n",
      "Assigned [220, 94, 370, 106, 190, 216, 337, 221] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.015447105281054974, feature std is 1.029360294342041.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3708 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 432, 497, 419, 512, 512, 512, 312] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0471 | S-BLEU: 0.06 | FMSE: 1.1383e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.02 | ROUGE-L: 0.14| Token Acc: 84.84% | Label Acc: 84.84%\n",
      "Checking 8-1-10.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005159591790288687, feature std is 0.10246890038251877.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3717 embeddings with positional data from imprinted layer.\n",
      "Assigned [444, 512, 512, 400, 512, 512, 512, 313] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0483 | S-BLEU: 0.05 | FMSE: 1.3534e-02 | \n",
      " G-BLEU: 0.07 | ROUGE1: 0.29| ROUGE2: 0.01 | ROUGE-L: 0.10| Token Acc: 69.65% | Label Acc: 69.65%\n",
      "Checking 8-1-10.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0007582504767924547, feature std is 0.010347474366426468.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3740 embeddings with positional data from imprinted layer.\n",
      "Assigned [411, 512, 468, 333, 512, 512, 480, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0642 | S-BLEU: 0.06 | FMSE: 1.1889e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-1-10.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.992212679004297e-05, feature std is 0.0009613377624191344.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3759 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 477, 325, 512, 512, 397] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0701 | S-BLEU: 0.06 | FMSE: 1.1050e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.03 | ROUGE-L: 0.11| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-1-10.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 66.04708099365234, feature std is 1003.0796508789062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 582 embeddings with positional data from imprinted layer.\n",
      "Assigned [89, 115, 18, 4, 39, 159, 31, 127] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.3826258182525635, feature std is 100.37770080566406.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1721 embeddings with positional data from imprinted layer.\n",
      "Assigned [257, 199, 117, 241, 177, 432, 131, 167] breached embeddings to each sentence.\n",
      "Checking 8-1-10.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.062029365450143814, feature std is 0.9922301769256592.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3739 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 430, 512, 237, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0393 | S-BLEU: 0.06 | FMSE: 1.1532e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.02 | ROUGE-L: 0.14| Token Acc: 85.06% | Label Acc: 85.06%\n",
      "Checking 8-1-10.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.011881480924785137, feature std is 0.0991925522685051.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 344, 512, 512, 310, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0591 | S-BLEU: 0.06 | FMSE: 1.1625e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 69.60% | Label Acc: 69.60%\n",
      "Checking 8-1-10.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -5.829673682455905e-05, feature std is 0.010235846042633057.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3727 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/dl/lib/python3.9/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/jonas/miniconda3/envs/dl/lib/python3.9/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError from correlation matrix [[0.6944765  0.6944765  0.6944765  ... 0.92889333 0.92889333 0.92889333]\n",
      " [0.49117066 0.49117066 0.49117066 ... 0.81872193 0.81872193 0.81872193]\n",
      " [0.62350813 0.62350813 0.62350813 ... 0.88969297 0.88969297 0.88969297]\n",
      " ...\n",
      " [0.44277549 0.44277549 0.44277549 ... 0.24439944 0.24439944 0.24439944]\n",
      " [0.38082334 0.38082334 0.38082334 ... 0.16447886 0.16447886 0.16447886]\n",
      " [0.3853086  0.3853086  0.3853086  ... 0.14945576 0.14945576 0.14945576]]\n",
      "Returning trivial order...\n",
      "Checking 8-1-10.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.8120746467029676e-05, feature std is 0.0010420699836686254.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3729 embeddings with positional data from imprinted layer.\n",
      "Assigned [399, 512, 512, 512, 512, 348, 422, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1040 | S-BLEU: 0.09 | FMSE: 1.2025e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.29| ROUGE2: 0.04 | ROUGE-L: 0.13| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-100.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.9081945419311523, feature std is 372.2099914550781.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1374 embeddings with positional data from imprinted layer.\n",
      "Assigned [54, 108, 289, 245, 365, 117, 79, 117] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.9583543539047241, feature std is 37.39516830444336.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3306 embeddings with positional data from imprinted layer.\n",
      "Assigned [458, 512, 400, 347, 421, 447, 209, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0120 | S-BLEU: 0.01 | FMSE: 5.7454e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.56% | Label Acc: 97.56%\n",
      "Checking 8-1-100.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.004243630915880203, feature std is 0.40319710969924927.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3841 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 269, 512, 500, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0146 | S-BLEU: 0.01 | FMSE: 3.1578e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 96.88% | Label Acc: 96.88%\n",
      "Checking 8-1-100.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0017258087173104286, feature std is 0.028676718473434448.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3873 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 469, 512, 512, 512, 467, 465, 424] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0146 | S-BLEU: 0.01 | FMSE: 1.2004e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.73% | Label Acc: 99.73%\n",
      "Checking 8-1-100.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00017100080731324852, feature std is 0.004003377631306648.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3815 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 363, 380, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0215 | S-BLEU: 0.01 | FMSE: 3.3222e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 97.73% | Label Acc: 97.73%\n",
      "Checking 8-1-100.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.6842498047917616e-06, feature std is 0.00037122913636267185.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3832 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 385, 512, 375, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0115 | S-BLEU: 0.01 | FMSE: 2.1724e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.32% | Label Acc: 98.32%\n",
      "Checking 8-1-100.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -66.27352142333984, feature std is 994.7740478515625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 541 embeddings with positional data from imprinted layer.\n",
      "Assigned [127, 7, 72, 9, 65, 171, 7, 83] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.943397521972656, feature std is 102.13654327392578.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1852 embeddings with positional data from imprinted layer.\n",
      "Assigned [229, 377, 441, 90, 208, 219, 138, 150] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.04132440313696861, feature std is 0.9568241238594055.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3828 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 249, 507, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1943 | S-BLEU: 0.17 | FMSE: 7.9637e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.43| ROUGE2: 0.11 | ROUGE-L: 0.25| Token Acc: 86.65% | Label Acc: 86.65%\n",
      "Checking 8-1-100.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.566907025742694e-06, feature std is 0.09571303427219391.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3859 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 481, 466, 491, 512, 479, 437, 481] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7063 | S-BLEU: 0.42 | FMSE: 5.2717e-03 | \n",
      " G-BLEU: 0.40 | ROUGE1: 0.70| ROUGE2: 0.44 | ROUGE-L: 0.67| Token Acc: 77.83% | Label Acc: 77.83%\n",
      "Checking 8-1-100.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0005796594195999205, feature std is 0.009916994720697403.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3854 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 512, 270] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2473 | S-BLEU: 0.21 | FMSE: 1.0245e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.40| ROUGE2: 0.13 | ROUGE-L: 0.26| Token Acc: 74.73% | Label Acc: 74.73%\n",
      "Checking 8-1-100.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.02596220333362e-05, feature std is 0.001006196835078299.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3858 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 510, 512, 512, 512, 276] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2966 | S-BLEU: 0.23 | FMSE: 9.8336e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.16 | ROUGE-L: 0.30| Token Acc: 74.73% | Label Acc: 74.73%\n",
      "Checking 8-1-100.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -14.070314407348633, feature std is 1054.0447998046875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 476 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [107, 174, 184, 1, 1, 2, 6, 1] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.88811206817627, feature std is 101.69164276123047.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1823 embeddings with positional data from imprinted layer.\n",
      "Assigned [150, 127, 142, 82, 293, 347, 503, 179] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00980315450578928, feature std is 1.0101624727249146.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3721 embeddings with positional data from imprinted layer.\n",
      "Assigned [462, 326, 512, 411, 474, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.5571 | S-BLEU: 0.34 | FMSE: 3.9736e-03 | \n",
      " G-BLEU: 0.31 | ROUGE1: 0.61| ROUGE2: 0.33 | ROUGE-L: 0.54| Token Acc: 84.96% | Label Acc: 84.96%\n",
      "Checking 8-1-100.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006824518088251352, feature std is 0.10071288049221039.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 379, 347, 512, 456] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1646 | S-BLEU: 0.13 | FMSE: 1.0889e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 69.70% | Label Acc: 69.70%\n",
      "Checking 8-1-100.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00017883596592582762, feature std is 0.010645191185176373.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3716 embeddings with positional data from imprinted layer.\n",
      "Assigned [458, 512, 512, 462, 311, 512, 458, 491] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5637 | S-BLEU: 0.24 | FMSE: 7.0457e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.58| ROUGE2: 0.28 | ROUGE-L: 0.54| Token Acc: 68.55% | Label Acc: 68.55%\n",
      "Checking 8-1-100.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.564224814705085e-05, feature std is 0.0009532428230158985.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3752 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 439, 241] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3662 | S-BLEU: 0.21 | FMSE: 9.1298e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.45| ROUGE2: 0.19 | ROUGE-L: 0.37| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-1-100.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 17.79705810546875, feature std is 968.6857299804688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 637 embeddings with positional data from imprinted layer.\n",
      "Assigned [30, 40, 78, 18, 247, 75, 145, 4] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.724308013916016, feature std is 98.56466674804688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1751 embeddings with positional data from imprinted layer.\n",
      "Assigned [110, 218, 376, 217, 59, 151, 108, 512] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.009594832547008991, feature std is 0.9899924397468567.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3688 embeddings with positional data from imprinted layer.\n",
      "Assigned [450, 512, 457, 471, 512, 270, 504, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5933 | S-BLEU: 0.32 | FMSE: 4.3767e-03 | \n",
      " G-BLEU: 0.31 | ROUGE1: 0.62| ROUGE2: 0.32 | ROUGE-L: 0.55| Token Acc: 85.03% | Label Acc: 85.03%\n",
      "Checking 8-1-100.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0018450289499014616, feature std is 0.09800700843334198.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 422, 512, 242, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1514 | S-BLEU: 0.14 | FMSE: 1.0870e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.33| ROUGE2: 0.07 | ROUGE-L: 0.18| Token Acc: 69.41% | Label Acc: 69.41%\n",
      "Checking 8-1-100.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0003113200655207038, feature std is 0.00972219742834568.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3730 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 241, 512, 512, 512, 512, 417] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2688 | S-BLEU: 0.16 | FMSE: 9.6112e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.39| ROUGE2: 0.14 | ROUGE-L: 0.27| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-1-100.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.4892960684373975e-05, feature std is 0.0009835916571319103.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3734 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 352, 512, 310] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3274 | S-BLEU: 0.19 | FMSE: 8.6753e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.33| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-1-100.0-0.001-1000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 15.65113639831543, feature std is 1098.73681640625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 517 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 3 seeds searching on threshold 0.05805308579302104.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [310, 173, 27, 1, 2, 4] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.6616803407669067, feature std is 101.23271179199219.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1685 embeddings with positional data from imprinted layer.\n",
      "Assigned [210, 109, 324, 234, 95, 169, 232, 312] breached embeddings to each sentence.\n",
      "Checking 8-1-100.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.041317857801914215, feature std is 1.0276799201965332.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3683 embeddings with positional data from imprinted layer.\n",
      "Assigned [426, 396, 512, 407, 406, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4985 | S-BLEU: 0.30 | FMSE: 4.8397e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.58| ROUGE2: 0.29 | ROUGE-L: 0.48| Token Acc: 84.99% | Label Acc: 84.99%\n",
      "Checking 8-1-100.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0023277124855667353, feature std is 0.10207492113113403.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3732 embeddings with positional data from imprinted layer.\n",
      "Assigned [419, 246, 512, 512, 512, 512, 507, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2583 | S-BLEU: 0.20 | FMSE: 9.8122e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.38| ROUGE2: 0.13 | ROUGE-L: 0.26| Token Acc: 69.38% | Label Acc: 69.38%\n",
      "Checking 8-1-100.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0005005677812732756, feature std is 0.009259307757019997.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3750 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 327, 512, 385, 512, 478] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3811 | S-BLEU: 0.21 | FMSE: 9.2045e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.46| ROUGE2: 0.19 | ROUGE-L: 0.37| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-1-100.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.679153739241883e-05, feature std is 0.00093559839297086.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3718 embeddings with positional data from imprinted layer.\n",
      "Assigned [465, 482, 462, 463, 457, 470, 458, 461] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6206 | S-BLEU: 0.28 | FMSE: 6.7811e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.62| ROUGE2: 0.32 | ROUGE-L: 0.59| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-1-1000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 20.371959686279297, feature std is 424.4107971191406.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1132 embeddings with positional data from imprinted layer.\n",
      "Assigned [247, 47, 158, 123, 166, 56, 33, 302] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.625763416290283, feature std is 40.936519622802734.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3247 embeddings with positional data from imprinted layer.\n",
      "Assigned [397, 390, 391, 268, 381, 512, 512, 396] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0112 | S-BLEU: 0.01 | FMSE: 1.7609e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.22% | Label Acc: 97.22%\n",
      "Checking 8-1-1000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.028095213696360588, feature std is 0.38310977816581726.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3838 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 507, 512, 259] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0176 | S-BLEU: 0.01 | FMSE: 3.4524e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 98.00% | Label Acc: 98.00%\n",
      "Checking 8-1-1000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0013471522834151983, feature std is 0.041112080216407776.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3886 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 333, 512, 512, 512, 512, 481] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0569 | S-BLEU: 0.01 | FMSE: 2.6384e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.68% | Label Acc: 99.68%\n",
      "Checking 8-1-1000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0001347370707662776, feature std is 0.0039729829877614975.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [397, 512, 512, 368, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0234 | S-BLEU: 0.01 | FMSE: 2.6749e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.95% | Label Acc: 97.95%\n",
      "Checking 8-1-1000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 9.569718713464681e-06, feature std is 0.0002859699015971273.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3853 embeddings with positional data from imprinted layer.\n",
      "Assigned [492, 490, 512, 512, 424, 417, 494, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0266 | S-BLEU: 0.01 | FMSE: 1.6488e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.10% | Label Acc: 99.10%\n",
      "Checking 8-1-1000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 25.83818817138672, feature std is 1000.0645141601562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 629 embeddings with positional data from imprinted layer.\n",
      "Assigned [77, 77, 91, 83, 15, 135, 79, 72] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.093932151794434, feature std is 96.77766418457031.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1700 embeddings with positional data from imprinted layer.\n",
      "Assigned [132, 238, 302, 100, 206, 478, 79, 165] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.06286568194627762, feature std is 0.9602745175361633.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3790 embeddings with positional data from imprinted layer.\n",
      "Assigned [473, 475, 477, 479, 466, 482, 476, 462] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7261 | S-BLEU: 0.45 | FMSE: 2.2746e-03 | \n",
      " G-BLEU: 0.42 | ROUGE1: 0.73| ROUGE2: 0.47 | ROUGE-L: 0.68| Token Acc: 86.62% | Label Acc: 86.62%\n",
      "Checking 8-1-1000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.4454515369143337e-05, feature std is 0.09924613684415817.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3838 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 434, 332, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3530 | S-BLEU: 0.27 | FMSE: 7.9609e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.47| ROUGE2: 0.21 | ROUGE-L: 0.35| Token Acc: 75.68% | Label Acc: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-1-1000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.000565744994673878, feature std is 0.009810064919292927.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3890 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 306, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2021 | S-BLEU: 0.18 | FMSE: 9.4137e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.40| ROUGE2: 0.11 | ROUGE-L: 0.24| Token Acc: 76.25% | Label Acc: 76.25%\n",
      "Checking 8-1-1000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00011549724149517715, feature std is 0.0009744992712512612.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3873 embeddings with positional data from imprinted layer.\n",
      "Assigned [413, 484, 512, 493, 512, 512, 490, 457] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6936 | S-BLEU: 0.40 | FMSE: 5.3462e-03 | \n",
      " G-BLEU: 0.38 | ROUGE1: 0.69| ROUGE2: 0.42 | ROUGE-L: 0.66| Token Acc: 76.76% | Label Acc: 76.76%\n",
      "Checking 8-1-1000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 32.30388259887695, feature std is 980.643798828125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 606 embeddings with positional data from imprinted layer.\n",
      "Assigned [43, 31, 9, 51, 390, 4, 35, 43] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 11.727518081665039, feature std is 104.41690826416016.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1683 embeddings with positional data from imprinted layer.\n",
      "Assigned [139, 150, 25, 153, 300, 512, 299, 105] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.021803049370646477, feature std is 1.0709336996078491.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3705 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 454, 508, 512, 512, 326, 369, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1487 | S-BLEU: 0.13 | FMSE: 1.0457e-02 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.41| ROUGE2: 0.08 | ROUGE-L: 0.21| Token Acc: 85.64% | Label Acc: 85.64%\n",
      "Checking 8-1-1000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.009966899640858173, feature std is 0.09989207983016968.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3744 embeddings with positional data from imprinted layer.\n",
      "Assigned [209, 463, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5811 | S-BLEU: 0.26 | FMSE: 6.7985e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.60| ROUGE2: 0.30 | ROUGE-L: 0.56| Token Acc: 69.63% | Label Acc: 69.63%\n",
      "Checking 8-1-1000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0005124986637383699, feature std is 0.00960335973650217.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3765 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [512, 295, 466, 472, 512, 484, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5767 | S-BLEU: 0.24 | FMSE: 7.3260e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.28 | ROUGE-L: 0.55| Token Acc: 68.46% | Label Acc: 68.46%\n",
      "Checking 8-1-1000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.0733862836787011e-05, feature std is 0.0009603833896107972.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3759 embeddings with positional data from imprinted layer.\n",
      "Assigned [319, 512, 512, 512, 368, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3579 | S-BLEU: 0.15 | FMSE: 8.3143e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.44| ROUGE2: 0.15 | ROUGE-L: 0.34| Token Acc: 68.46% | Label Acc: 68.46%\n",
      "Checking 8-1-1000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -41.30768966674805, feature std is 990.4685668945312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 548 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 4 seeds searching on threshold 0.18825374411492857.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [67, 223, 136, 97, 9, 1, 1, 14] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.540087938308716, feature std is 102.13387298583984.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1669 embeddings with positional data from imprinted layer.\n",
      "Assigned [212, 53, 191, 166, 192, 395, 60, 400] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.02501070313155651, feature std is 1.040098786354065.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3694 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 452, 464, 413, 512, 443, 460, 481] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6868 | S-BLEU: 0.38 | FMSE: 2.5929e-03 | \n",
      " G-BLEU: 0.36 | ROUGE1: 0.69| ROUGE2: 0.40 | ROUGE-L: 0.64| Token Acc: 85.30% | Label Acc: 85.30%\n",
      "Checking 8-1-1000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006209994666278362, feature std is 0.0980478972196579.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3731 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 461, 433, 512, 398, 476, 427, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5864 | S-BLEU: 0.27 | FMSE: 6.9218e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.59| ROUGE2: 0.30 | ROUGE-L: 0.56| Token Acc: 69.38% | Label Acc: 69.38%\n",
      "Checking 8-1-1000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00017619019490666687, feature std is 0.010078886523842812.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [458, 512, 455, 388, 462, 425, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5686 | S-BLEU: 0.25 | FMSE: 7.8989e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.29 | ROUGE-L: 0.54| Token Acc: 68.33% | Label Acc: 68.33%\n",
      "Checking 8-1-1000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.536932050948963e-05, feature std is 0.0009646954713389277.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3735 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 468, 512, 400, 487, 470, 466, 463] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6040 | S-BLEU: 0.27 | FMSE: 6.6575e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.60| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-1-1000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.9825873374938965, feature std is 949.9829711914062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 649 embeddings with positional data from imprinted layer.\n",
      "Assigned [75, 70, 110, 60, 139, 80, 99, 16] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.396995782852173, feature std is 95.77668762207031.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1765 embeddings with positional data from imprinted layer.\n",
      "Assigned [438, 344, 285, 146, 72, 320, 54, 106] breached embeddings to each sentence.\n",
      "Checking 8-1-1000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.1212003156542778, feature std is 0.9919437170028687.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3687 embeddings with positional data from imprinted layer.\n",
      "Assigned [433, 479, 512, 299, 512, 454, 486, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5032 | S-BLEU: 0.30 | FMSE: 4.7213e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.59| ROUGE2: 0.29 | ROUGE-L: 0.49| Token Acc: 85.06% | Label Acc: 85.06%\n",
      "Checking 8-1-1000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.002104330575093627, feature std is 0.10151803493499756.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3741 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 473, 512, 512, 196, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5430 | S-BLEU: 0.24 | FMSE: 7.3990e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.56| ROUGE2: 0.26 | ROUGE-L: 0.52| Token Acc: 69.58% | Label Acc: 69.58%\n",
      "Checking 8-1-1000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0005173293175175786, feature std is 0.010002699680626392.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [456, 512, 512, 512, 512, 393, 512, 319] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2473 | S-BLEU: 0.16 | FMSE: 9.4533e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.38| ROUGE2: 0.11 | ROUGE-L: 0.25| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-1000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.970844075724017e-06, feature std is 0.0010080705396831036.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 464, 309, 458, 500, 475, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5234 | S-BLEU: 0.24 | FMSE: 7.8141e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.55| ROUGE2: 0.26 | ROUGE-L: 0.50| Token Acc: 67.94% | Label Acc: 67.94%\n",
      "Checking 8-1-10000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.385100841522217, feature std is 537.0265502929688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1035 embeddings with positional data from imprinted layer.\n",
      "Assigned [46, 223, 231, 51, 121, 131, 133, 99] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.30764949321746826, feature std is 37.81216812133789.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3331 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 213, 401, 512, 157, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0127 | S-BLEU: 0.01 | FMSE: 1.3186e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.49% | Label Acc: 97.49%\n",
      "Checking 8-1-10000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.009421154856681824, feature std is 0.3998373746871948.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3859 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 492, 484, 385, 512, 512, 472, 490] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0322 | S-BLEU: 0.02 | FMSE: 2.4259e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.76% | Label Acc: 99.76%\n",
      "Checking 8-1-10000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0008591455407440662, feature std is 0.04595718905329704.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3874 embeddings with positional data from imprinted layer.\n",
      "Assigned [478, 506, 457, 512, 419, 512, 478, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0623 | S-BLEU: 0.01 | FMSE: 2.3605e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 99.76% | Label Acc: 99.76%\n",
      "Checking 8-1-10000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00019254586368333548, feature std is 0.0038963896222412586.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3840 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 483, 482, 471, 388, 480, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0562 | S-BLEU: 0.01 | FMSE: 2.1528e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.80% | Label Acc: 99.80%\n",
      "Checking 8-1-10000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.511598025506828e-06, feature std is 0.00033305241959169507.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3881 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 512, 297] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0132 | S-BLEU: 0.01 | FMSE: 2.3077e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 96.70% | Label Acc: 96.70%\n",
      "Checking 8-1-10000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 17.210886001586914, feature std is 973.9088134765625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 586 embeddings with positional data from imprinted layer.\n",
      "Assigned [124, 31, 75, 67, 68, 71, 73, 77] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.1846184730529785, feature std is 97.12327575683594.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1840 embeddings with positional data from imprinted layer.\n",
      "Assigned [163, 272, 383, 145, 152, 247, 417, 61] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.019199896603822708, feature std is 0.9637530446052551.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3816 embeddings with positional data from imprinted layer.\n",
      "Assigned [471, 498, 462, 467, 484, 482, 486, 466] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7356 | S-BLEU: 0.46 | FMSE: 1.6322e-03 | \n",
      " G-BLEU: 0.43 | ROUGE1: 0.73| ROUGE2: 0.48 | ROUGE-L: 0.69| Token Acc: 87.92% | Label Acc: 87.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-1-10000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0014175733085721731, feature std is 0.09415009617805481.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3817 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 396, 512, 377, 484] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2788 | S-BLEU: 0.22 | FMSE: 8.3787e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.43| ROUGE2: 0.15 | ROUGE-L: 0.28| Token Acc: 75.83% | Label Acc: 75.83%\n",
      "Checking 8-1-10000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0002724911901168525, feature std is 0.010078986175358295.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3856 embeddings with positional data from imprinted layer.\n",
      "Assigned [304, 512, 512, 480, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5500 | S-BLEU: 0.33 | FMSE: 6.1378e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.60| ROUGE2: 0.34 | ROUGE-L: 0.53| Token Acc: 76.17% | Label Acc: 76.17%\n",
      "Checking 8-1-10000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.589051993913017e-05, feature std is 0.0009435960673727095.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3859 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 384, 512, 512, 403, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4675 | S-BLEU: 0.30 | FMSE: 6.5750e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.56| ROUGE2: 0.27 | ROUGE-L: 0.46| Token Acc: 81.52% | Label Acc: 81.52%\n",
      "Checking 8-1-10000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -16.357126235961914, feature std is 1028.9188232421875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 577 embeddings with positional data from imprinted layer.\n",
      "Assigned [2, 41, 154, 21, 328, 1, 15, 15] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.5697168111801147, feature std is 104.4455337524414.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1646 embeddings with positional data from imprinted layer.\n",
      "Assigned [22, 216, 145, 140, 294, 119, 428, 282] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.1319357454776764, feature std is 1.0562615394592285.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3713 embeddings with positional data from imprinted layer.\n",
      "Assigned [359, 512, 512, 512, 512, 489, 512, 305] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3521 | S-BLEU: 0.25 | FMSE: 7.2258e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.51| ROUGE2: 0.20 | ROUGE-L: 0.37| Token Acc: 85.38% | Label Acc: 85.38%\n",
      "Checking 8-1-10000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0055022165179252625, feature std is 0.09716550260782242.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3766 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 236, 458, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2393 | S-BLEU: 0.19 | FMSE: 1.0319e-02 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.38| ROUGE2: 0.13 | ROUGE-L: 0.25| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 8-1-10000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.092031278763898e-05, feature std is 0.010379362851381302.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3758 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 174, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2065 | S-BLEU: 0.13 | FMSE: 1.0195e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.35| ROUGE2: 0.08 | ROUGE-L: 0.22| Token Acc: 68.41% | Label Acc: 68.41%\n",
      "Checking 8-1-10000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.909202546812594e-05, feature std is 0.0009926805505529046.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 245, 512, 512, 512, 512, 512, 425] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2070 | S-BLEU: 0.12 | FMSE: 1.1204e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.35| ROUGE2: 0.08 | ROUGE-L: 0.21| Token Acc: 68.41% | Label Acc: 68.41%\n",
      "Checking 8-1-10000.0-0.01-1000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 104.97265625, feature std is 992.4177856445312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 606 embeddings with positional data from imprinted layer.\n",
      "Assigned [21, 68, 72, 207, 70, 23, 20, 125] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.057523462921381, feature std is 102.88074493408203.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1703 embeddings with positional data from imprinted layer.\n",
      "Assigned [216, 45, 384, 187, 198, 373, 221, 79] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.03647500276565552, feature std is 1.0211050510406494.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3653 embeddings with positional data from imprinted layer.\n",
      "Assigned [477, 270, 435, 512, 512, 512, 423, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4214 | S-BLEU: 0.21 | FMSE: 6.6891e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.53| ROUGE2: 0.20 | ROUGE-L: 0.40| Token Acc: 85.18% | Label Acc: 85.18%\n",
      "Checking 8-1-10000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.007459332700818777, feature std is 0.10196423530578613.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3717 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 407, 381, 512, 512, 369] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4194 | S-BLEU: 0.19 | FMSE: 8.3322e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.20 | ROUGE-L: 0.42| Token Acc: 69.53% | Label Acc: 69.53%\n",
      "Checking 8-1-10000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00020172903896309435, feature std is 0.01062280498445034.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3733 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 359, 333, 481, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2837 | S-BLEU: 0.18 | FMSE: 9.8466e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.39| ROUGE2: 0.14 | ROUGE-L: 0.30| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-10000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.1020794520154595e-05, feature std is 0.0010543731041252613.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 458, 512, 512, 512, 512, 194, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5081 | S-BLEU: 0.23 | FMSE: 7.6613e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.54| ROUGE2: 0.25 | ROUGE-L: 0.49| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-10000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 43.52577590942383, feature std is 941.1704711914062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 548 embeddings with positional data from imprinted layer.\n",
      "Assigned [7, 23, 4, 403, 73, 7, 27, 4] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.194580078125, feature std is 101.4311752319336.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1753 embeddings with positional data from imprinted layer.\n",
      "Assigned [188, 192, 239, 52, 214, 217, 415, 236] breached embeddings to each sentence.\n",
      "Checking 8-1-10000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00872427225112915, feature std is 0.9838994145393372.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3691 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 266, 512, 512, 512, 512, 512, 353] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2327 | S-BLEU: 0.17 | FMSE: 8.9906e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.45| ROUGE2: 0.11 | ROUGE-L: 0.27| Token Acc: 84.84% | Label Acc: 84.84%\n",
      "Checking 8-1-10000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0004942326340824366, feature std is 0.09806270152330399.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3732 embeddings with positional data from imprinted layer.\n",
      "Assigned [454, 467, 421, 476, 512, 460, 471, 471] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6257 | S-BLEU: 0.28 | FMSE: 6.3399e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.63| ROUGE2: 0.33 | ROUGE-L: 0.60| Token Acc: 69.41% | Label Acc: 69.41%\n",
      "Checking 8-1-10000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00017275485151913017, feature std is 0.010036041960120201.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3749 embeddings with positional data from imprinted layer.\n",
      "Assigned [472, 469, 467, 465, 468, 461, 479, 468] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6235 | S-BLEU: 0.27 | FMSE: 6.9145e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.62| ROUGE2: 0.32 | ROUGE-L: 0.60| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-10000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.052322270174045e-05, feature std is 0.0010033169528469443.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 455, 253, 490, 479] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5425 | S-BLEU: 0.24 | FMSE: 7.4795e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.56| ROUGE2: 0.27 | ROUGE-L: 0.52| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-100000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -12.620197296142578, feature std is 328.33087158203125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1465 embeddings with positional data from imprinted layer.\n",
      "Assigned [44, 196, 299, 158, 53, 156, 390, 169] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.260246992111206, feature std is 37.52933120727539.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3356 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 466, 512, 413, 52, 437, 452] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0127 | S-BLEU: 0.01 | FMSE: 4.8372e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 96.41% | Label Acc: 96.41%\n",
      "Checking 8-1-100000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0023855026811361313, feature std is 0.3737662136554718.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3843 embeddings with positional data from imprinted layer.\n",
      "Assigned [488, 512, 512, 512, 467, 512, 328, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0159 | S-BLEU: 0.01 | FMSE: 3.1175e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 95.04% | Label Acc: 95.04%\n",
      "Checking 8-1-100000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00026586969033814967, feature std is 0.04449877887964249.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3860 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 482, 351, 483, 512, 512, 512, 496] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0601 | S-BLEU: 0.01 | FMSE: 3.0494e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 99.39% | Label Acc: 99.39%\n",
      "Checking 8-1-100000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.16063698544167e-06, feature std is 0.004002735950052738.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3837 embeddings with positional data from imprinted layer.\n",
      "Assigned [396, 512, 512, 512, 369, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0430 | S-BLEU: 0.01 | FMSE: 2.2291e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.78% | Label Acc: 98.78%\n",
      "Checking 8-1-100000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.4127057258738205e-05, feature std is 0.00036416156217455864.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3843 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 362, 409, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0259 | S-BLEU: 0.01 | FMSE: 1.9672e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 96.12% | Label Acc: 96.12%\n",
      "Checking 8-1-100000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -17.470848083496094, feature std is 1014.9168090820312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 585 embeddings with positional data from imprinted layer.\n",
      "Assigned [22, 91, 14, 69, 334, 6, 31, 18] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.938501358032227, feature std is 96.63740539550781.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1823 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [226, 155, 369, 179, 224, 173, 257, 240] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.04560482129454613, feature std is 0.9466612339019775.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3821 embeddings with positional data from imprinted layer.\n",
      "Assigned [480, 482, 503, 465, 512, 485, 512, 382] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6997 | S-BLEU: 0.42 | FMSE: 2.1510e-03 | \n",
      " G-BLEU: 0.40 | ROUGE1: 0.70| ROUGE2: 0.43 | ROUGE-L: 0.66| Token Acc: 87.45% | Label Acc: 87.45%\n",
      "Checking 8-1-100000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0010385167552158237, feature std is 0.09682992845773697.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3864 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 484, 478, 485, 484, 479, 454, 488] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6968 | S-BLEU: 0.39 | FMSE: 5.1881e-03 | \n",
      " G-BLEU: 0.38 | ROUGE1: 0.69| ROUGE2: 0.42 | ROUGE-L: 0.66| Token Acc: 76.34% | Label Acc: 76.34%\n",
      "Checking 8-1-100000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.9943948397412896e-05, feature std is 0.009272048249840736.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3842 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 258, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2302 | S-BLEU: 0.19 | FMSE: 9.5815e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.40| ROUGE2: 0.11 | ROUGE-L: 0.24| Token Acc: 75.56% | Label Acc: 75.56%\n",
      "Checking 8-1-100000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.745267945807427e-05, feature std is 0.001006383216008544.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3836 embeddings with positional data from imprinted layer.\n",
      "Assigned [478, 512, 512, 347, 483, 512, 512, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6626 | S-BLEU: 0.35 | FMSE: 6.0874e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.39 | ROUGE-L: 0.63| Token Acc: 75.22% | Label Acc: 75.22%\n",
      "Checking 8-1-100000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -25.302831649780273, feature std is 1053.49365234375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 514 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 3 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [282, 163, 30, 1, 26, 12] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.373853921890259, feature std is 96.3754653930664.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1725 embeddings with positional data from imprinted layer.\n",
      "Assigned [243, 230, 172, 190, 63, 415, 216, 196] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is 0.04043072834610939, feature std is 0.9729183912277222.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3701 embeddings with positional data from imprinted layer.\n",
      "Assigned [472, 435, 450, 476, 495, 467, 465, 441] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7056 | S-BLEU: 0.42 | FMSE: 2.6463e-03 | \n",
      " G-BLEU: 0.40 | ROUGE1: 0.70| ROUGE2: 0.44 | ROUGE-L: 0.66| Token Acc: 85.01% | Label Acc: 85.01%\n",
      "Checking 8-1-100000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0010018957545980811, feature std is 0.10037174820899963.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3748 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 368, 512, 512, 512, 512, 308, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5220 | S-BLEU: 0.20 | FMSE: 7.2676e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.54| ROUGE2: 0.23 | ROUGE-L: 0.49| Token Acc: 69.73% | Label Acc: 69.73%\n",
      "Checking 8-1-100000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0007636724621988833, feature std is 0.009892868809401989.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3759 embeddings with positional data from imprinted layer.\n",
      "Assigned [257, 512, 512, 512, 459, 512, 512, 483] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.5730 | S-BLEU: 0.23 | FMSE: 8.1031e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.58| ROUGE2: 0.27 | ROUGE-L: 0.54| Token Acc: 68.58% | Label Acc: 68.58%\n",
      "Checking 8-1-100000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.5196193241281435e-05, feature std is 0.0010261563584208488.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3767 embeddings with positional data from imprinted layer.\n",
      "Assigned [281, 512, 512, 444, 512, 512, 512, 482] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2158 | S-BLEU: 0.13 | FMSE: 1.0581e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.35| ROUGE2: 0.08 | ROUGE-L: 0.22| Token Acc: 68.38% | Label Acc: 68.38%\n",
      "Checking 8-1-100000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 41.67228317260742, feature std is 1011.2832641601562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 559 embeddings with positional data from imprinted layer.\n",
      "Assigned [386, 2, 2, 102, 12, 43, 3, 9] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.390475273132324, feature std is 103.46786499023438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1628 embeddings with positional data from imprinted layer.\n",
      "Assigned [208, 227, 356, 65, 206, 189, 308, 69] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0012587025994434953, feature std is 0.9925635457038879.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3673 embeddings with positional data from imprinted layer.\n",
      "Assigned [387, 512, 512, 383, 512, 512, 343, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2925 | S-BLEU: 0.15 | FMSE: 8.1641e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.47| ROUGE2: 0.11 | ROUGE-L: 0.29| Token Acc: 84.59% | Label Acc: 84.59%\n",
      "Checking 8-1-100000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002081075916066766, feature std is 0.09990715235471725.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3746 embeddings with positional data from imprinted layer.\n",
      "Assigned [360, 512, 512, 512, 512, 372, 454, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3601 | S-BLEU: 0.18 | FMSE: 9.3728e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.45| ROUGE2: 0.16 | ROUGE-L: 0.35| Token Acc: 69.46% | Label Acc: 69.46%\n",
      "Checking 8-1-100000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0005383429815992713, feature std is 0.009459092281758785.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3745 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 161, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4272 | S-BLEU: 0.18 | FMSE: 8.3895e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.18 | ROUGE-L: 0.40| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-100000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.8941343013430014e-05, feature std is 0.0010457473108544946.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 421, 512, 439, 512, 421, 512, 408] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5088 | S-BLEU: 0.23 | FMSE: 8.1009e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.53| ROUGE2: 0.24 | ROUGE-L: 0.49| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-1-100000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -70.6921157836914, feature std is 1031.4814453125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 495 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 2 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 6 random seeds...These sentences will be scrambled.\n",
      "Assigned [3, 490, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.813439846038818, feature std is 96.45256805419922.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49889, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1748 embeddings with positional data from imprinted layer.\n",
      "Assigned [326, 129, 174, 118, 512, 103, 221, 165] breached embeddings to each sentence.\n",
      "Checking 8-1-100000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.062225326895713806, feature std is 1.0348334312438965.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3684 embeddings with positional data from imprinted layer.\n",
      "Assigned [462, 462, 448, 472, 479, 460, 448, 453] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6924 | S-BLEU: 0.39 | FMSE: 2.6338e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.70| ROUGE2: 0.42 | ROUGE-L: 0.65| Token Acc: 85.50% | Label Acc: 85.50%\n",
      "Checking 8-1-100000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004853889811784029, feature std is 0.09612813591957092.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3712 embeddings with positional data from imprinted layer.\n",
      "Assigned [425, 512, 431, 512, 512, 296, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4316 | S-BLEU: 0.21 | FMSE: 8.4204e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.21 | ROUGE-L: 0.42| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-1-100000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0002116654213750735, feature std is 0.010328385978937149.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3747 embeddings with positional data from imprinted layer.\n",
      "Assigned [427, 512, 421, 339, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4819 | S-BLEU: 0.21 | FMSE: 7.7211e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.52| ROUGE2: 0.22 | ROUGE-L: 0.45| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-100000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.8050934158964083e-05, feature std is 0.0009561222977936268.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3750 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 395, 512, 417, 512, 478, 418, 506] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5178 | S-BLEU: 0.23 | FMSE: 7.5820e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.55| ROUGE2: 0.26 | ROUGE-L: 0.50| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-1-1000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -14.49982738494873, feature std is 424.4407653808594.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1216 embeddings with positional data from imprinted layer.\n",
      "Assigned [279, 217, 141, 192, 113, 133, 69, 72] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.05984273552894592, feature std is 33.48591232299805.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3457 embeddings with positional data from imprinted layer.\n",
      "Assigned [286, 252, 512, 512, 512, 359, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0081 | S-BLEU: 0.01 | FMSE: 5.7695e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.17| Token Acc: 98.51% | Label Acc: 98.51%\n",
      "Checking 8-1-1000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.015642685815691948, feature std is 0.41790613532066345.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3835 embeddings with positional data from imprinted layer.\n",
      "Assigned [407, 512, 512, 512, 512, 512, 512, 356] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0256 | S-BLEU: 0.01 | FMSE: 2.1453e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.80% | Label Acc: 98.80%\n",
      "Checking 8-1-1000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002419557888060808, feature std is 0.0478147454559803.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3872 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 373, 512, 427, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0635 | S-BLEU: 0.02 | FMSE: 5.2014e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 97.19% | Label Acc: 97.19%\n",
      "Checking 8-1-1000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0001835414586821571, feature std is 0.005050471518188715.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3864 embeddings with positional data from imprinted layer.\n",
      "Assigned [455, 490, 395, 476, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0747 | S-BLEU: 0.01 | FMSE: 4.1975e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.90% | Label Acc: 98.90%\n",
      "Checking 8-1-1000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.526501521060709e-05, feature std is 0.00035995812504552305.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3821 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 428, 512, 321, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0220 | S-BLEU: 0.01 | FMSE: 1.6339e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.41% | Label Acc: 99.41%\n",
      "Checking 8-1-1000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -46.41451644897461, feature std is 993.3853149414062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 577 embeddings with positional data from imprinted layer.\n",
      "Assigned [37, 77, 13, 152, 5, 14, 56, 223] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.940302848815918, feature std is 97.45970916748047.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49889, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1702 embeddings with positional data from imprinted layer.\n",
      "Assigned [134, 373, 176, 311, 96, 286, 137, 189] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.027176273986697197, feature std is 0.9947325587272644.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3823 embeddings with positional data from imprinted layer.\n",
      "Assigned [464, 477, 371, 512, 494, 512, 512, 481] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6909 | S-BLEU: 0.41 | FMSE: 2.1847e-03 | \n",
      " G-BLEU: 0.39 | ROUGE1: 0.70| ROUGE2: 0.43 | ROUGE-L: 0.65| Token Acc: 86.23% | Label Acc: 86.23%\n",
      "Checking 8-1-1000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002528663957491517, feature std is 0.09651026129722595.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3839 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 392, 512, 512, 375, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4580 | S-BLEU: 0.35 | FMSE: 6.8981e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.55| ROUGE2: 0.30 | ROUGE-L: 0.47| Token Acc: 80.03% | Label Acc: 80.03%\n",
      "Checking 8-1-1000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0006724752602167428, feature std is 0.009327050298452377.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3826 embeddings with positional data from imprinted layer.\n",
      "Assigned [506, 512, 512, 248, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3020 | S-BLEU: 0.26 | FMSE: 8.8623e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.44| ROUGE2: 0.19 | ROUGE-L: 0.33| Token Acc: 75.20% | Label Acc: 75.20%\n",
      "Checking 8-1-1000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.2332245205470826e-05, feature std is 0.0009553133277222514.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3870 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 472, 326, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6726 | S-BLEU: 0.39 | FMSE: 5.2261e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.67| ROUGE2: 0.41 | ROUGE-L: 0.64| Token Acc: 78.49% | Label Acc: 78.49%\n",
      "Checking 8-1-1000000.0-0.1-1000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 13.87608528137207, feature std is 1011.9076538085938.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 576 embeddings with positional data from imprinted layer.\n",
      "Assigned [59, 8, 374, 11, 9, 81, 25, 9] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.637719631195068, feature std is 96.06396484375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1697 embeddings with positional data from imprinted layer.\n",
      "Assigned [198, 158, 205, 164, 437, 212, 89, 234] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005656099878251553, feature std is 1.0009084939956665.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3733 embeddings with positional data from imprinted layer.\n",
      "Assigned [444, 476, 469, 465, 512, 512, 441, 414] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6853 | S-BLEU: 0.41 | FMSE: 2.7136e-03 | \n",
      " G-BLEU: 0.38 | ROUGE1: 0.70| ROUGE2: 0.42 | ROUGE-L: 0.64| Token Acc: 85.40% | Label Acc: 85.40%\n",
      "Checking 8-1-1000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002333752578124404, feature std is 0.0997965931892395.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3764 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 246, 512, 511, 447] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2334 | S-BLEU: 0.13 | FMSE: 1.0133e-02 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.38| ROUGE2: 0.09 | ROUGE-L: 0.24| Token Acc: 69.87% | Label Acc: 69.87%\n",
      "Checking 8-1-1000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00010512837616261095, feature std is 0.010449793189764023.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3752 embeddings with positional data from imprinted layer.\n",
      "Assigned [470, 472, 501, 463, 422, 512, 460, 452] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6172 | S-BLEU: 0.28 | FMSE: 6.8008e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.61| ROUGE2: 0.32 | ROUGE-L: 0.59| Token Acc: 68.48% | Label Acc: 68.48%\n",
      "Checking 8-1-1000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.0691610340436455e-06, feature std is 0.0009710484882816672.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3761 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 310, 512, 379, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2537 | S-BLEU: 0.16 | FMSE: 1.0441e-02 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.38| ROUGE2: 0.11 | ROUGE-L: 0.25| Token Acc: 68.43% | Label Acc: 68.43%\n",
      "Checking 8-1-1000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -25.03723907470703, feature std is 1065.201904296875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 536 embeddings with positional data from imprinted layer.\n",
      "Assigned [262, 3, 5, 5, 13, 3, 10, 235] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.073070764541626, feature std is 95.82687377929688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1689 embeddings with positional data from imprinted layer.\n",
      "Assigned [188, 177, 247, 190, 165, 164, 367, 191] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.04356340691447258, feature std is 1.029435396194458.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3698 embeddings with positional data from imprinted layer.\n",
      "Assigned [468, 512, 477, 340, 512, 443, 461, 485] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6506 | S-BLEU: 0.35 | FMSE: 3.1183e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.67| ROUGE2: 0.37 | ROUGE-L: 0.61| Token Acc: 85.11% | Label Acc: 85.11%\n",
      "Checking 8-1-1000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.001749072689563036, feature std is 0.09960766136646271.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3750 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 510, 512, 512, 408, 314, 512, 470] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4971 | S-BLEU: 0.26 | FMSE: 7.3726e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.53| ROUGE2: 0.26 | ROUGE-L: 0.47| Token Acc: 69.70% | Label Acc: 69.70%\n",
      "Checking 8-1-1000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00014948498574085534, feature std is 0.009968026541173458.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3715 embeddings with positional data from imprinted layer.\n",
      "Assigned [274, 512, 512, 512, 512, 470, 451, 472] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5139 | S-BLEU: 0.23 | FMSE: 8.1885e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.54| ROUGE2: 0.25 | ROUGE-L: 0.49| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-1-1000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.159239273983985e-05, feature std is 0.0010031559504568577.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 236, 512, 417, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2751 | S-BLEU: 0.18 | FMSE: 9.9164e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.40| ROUGE2: 0.13 | ROUGE-L: 0.29| Token Acc: 68.31% | Label Acc: 68.31%\n",
      "Checking 8-1-1000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 25.464563369750977, feature std is 1004.1242065429688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 620 embeddings with positional data from imprinted layer.\n",
      "Assigned [189, 40, 177, 6, 23, 26, 137, 22] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.6277732849121094, feature std is 99.90361022949219.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1706 embeddings with positional data from imprinted layer.\n",
      "Assigned [135, 135, 450, 114, 191, 234, 138, 309] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000.0-0.001-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.05640973895788193, feature std is 1.0446423292160034.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3673 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 318, 330, 465, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5330 | S-BLEU: 0.30 | FMSE: 4.2994e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.52| Token Acc: 85.08% | Label Acc: 85.08%\n",
      "Checking 8-1-1000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001504464540630579, feature std is 0.1013408675789833.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 395, 512, 512, 512, 269] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2607 | S-BLEU: 0.16 | FMSE: 9.5408e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.39| ROUGE2: 0.12 | ROUGE-L: 0.26| Token Acc: 69.70% | Label Acc: 69.70%\n",
      "Checking 8-1-1000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00029952998738735914, feature std is 0.00994068942964077.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3716 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 469, 175, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2336 | S-BLEU: 0.14 | FMSE: 9.2085e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.37| ROUGE2: 0.11 | ROUGE-L: 0.24| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-1-1000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.774846406187862e-05, feature std is 0.0009906591149047017.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3722 embeddings with positional data from imprinted layer.\n",
      "Assigned [473, 466, 464, 465, 462, 457, 474, 461] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6157 | S-BLEU: 0.26 | FMSE: 7.1103e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.62| ROUGE2: 0.31 | ROUGE-L: 0.59| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-1-10000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -19.48281478881836, feature std is 464.1778564453125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1089 embeddings with positional data from imprinted layer.\n",
      "Assigned [198, 50, 132, 130, 80, 251, 130, 118] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.489813804626465, feature std is 45.89456558227539.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3100 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 427, 419, 512, 512, 478, 22, 218] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0134 | S-BLEU: 0.01 | FMSE: 5.0027e-04 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 93.36% | Label Acc: 93.36%\n",
      "Checking 8-1-10000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.02628999389708042, feature std is 0.4756111800670624.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3871 embeddings with positional data from imprinted layer.\n",
      "Assigned [486, 512, 449, 496, 478, 495, 479, 476] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1003 | S-BLEU: 0.02 | FMSE: 2.8691e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 99.17% | Label Acc: 99.17%\n",
      "Checking 8-1-10000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0012198648182675242, feature std is 0.037981968373060226.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3845 embeddings with positional data from imprinted layer.\n",
      "Assigned [427, 346, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0149 | S-BLEU: 0.02 | FMSE: 2.5691e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 98.17% | Label Acc: 98.17%\n",
      "Checking 8-1-10000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.693223597016186e-05, feature std is 0.0042653572745621204.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3846 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 305, 512, 469] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0317 | S-BLEU: 0.01 | FMSE: 2.4617e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.15% | Label Acc: 99.15%\n",
      "Checking 8-1-10000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.5070805829964229e-06, feature std is 0.0005238702869974077.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3873 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 289, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0413 | S-BLEU: 0.01 | FMSE: 5.5022e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 96.85% | Label Acc: 96.85%\n",
      "Checking 8-1-10000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -53.4858283996582, feature std is 931.2462768554688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 553 embeddings with positional data from imprinted layer.\n",
      "Assigned [12, 174, 6, 45, 150, 11, 11, 144] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.60203218460083, feature std is 92.16880798339844.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1810 embeddings with positional data from imprinted layer.\n",
      "Assigned [226, 123, 278, 80, 332, 148, 512, 111] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.015323199331760406, feature std is 0.9936424493789673.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3783 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 478, 476, 512, 269] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5105 | S-BLEU: 0.28 | FMSE: 4.1168e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.26 | ROUGE-L: 0.47| Token Acc: 86.57% | Label Acc: 86.57%\n",
      "Checking 8-1-10000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0032009470742195845, feature std is 0.09750454872846603.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3869 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 472, 486, 351, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2026 | S-BLEU: 0.17 | FMSE: 9.0763e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.39| ROUGE2: 0.10 | ROUGE-L: 0.23| Token Acc: 76.10% | Label Acc: 76.10%\n",
      "Checking 8-1-10000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002750549465417862, feature std is 0.009757112711668015.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [360, 512, 512, 512, 512, 512, 512, 419] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.2561 | S-BLEU: 0.25 | FMSE: 9.1523e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.41| ROUGE2: 0.14 | ROUGE-L: 0.28| Token Acc: 74.44% | Label Acc: 74.44%\n",
      "Checking 8-1-10000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00010601123358355835, feature std is 0.0009132749983109534.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3859 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 482, 512, 512, 512, 512, 305] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2390 | S-BLEU: 0.25 | FMSE: 9.7363e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.41| ROUGE2: 0.15 | ROUGE-L: 0.26| Token Acc: 74.80% | Label Acc: 74.80%\n",
      "Checking 8-1-10000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 13.18236255645752, feature std is 986.9989624023438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 531 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 4 seeds searching on threshold 0.5318241301673536.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [1, 481, 17, 30, 2] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.0331475734710693, feature std is 102.15380096435547.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1802 embeddings with positional data from imprinted layer.\n",
      "Assigned [330, 175, 222, 257, 221, 267, 277, 53] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.04797477647662163, feature std is 1.003005862236023.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3702 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 354, 512, 512, 410, 378, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3730 | S-BLEU: 0.23 | FMSE: 7.1847e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.51| ROUGE2: 0.21 | ROUGE-L: 0.38| Token Acc: 85.13% | Label Acc: 85.13%\n",
      "Checking 8-1-10000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.013134495355188847, feature std is 0.10518995672464371.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3767 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 476, 474, 476, 459, 482, 376] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6152 | S-BLEU: 0.28 | FMSE: 6.5936e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.62| ROUGE2: 0.33 | ROUGE-L: 0.59| Token Acc: 69.82% | Label Acc: 69.82%\n",
      "Checking 8-1-10000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00026819645427167416, feature std is 0.010316398926079273.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3775 embeddings with positional data from imprinted layer.\n",
      "Assigned [444, 452, 512, 428, 433, 512, 482, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5476 | S-BLEU: 0.25 | FMSE: 8.0156e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.56| ROUGE2: 0.27 | ROUGE-L: 0.52| Token Acc: 68.73% | Label Acc: 68.73%\n",
      "Checking 8-1-10000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.350119631155394e-06, feature std is 0.0009917557472363114.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3739 embeddings with positional data from imprinted layer.\n",
      "Assigned [470, 445, 472, 471, 483, 470, 461, 467] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6116 | S-BLEU: 0.27 | FMSE: 6.8348e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.59| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-10000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 60.010684967041016, feature std is 1013.0233764648438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 617 embeddings with positional data from imprinted layer.\n",
      "Assigned [139, 143, 69, 75, 146, 19, 5, 21] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.243320941925049, feature std is 104.3479995727539.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1813 embeddings with positional data from imprinted layer.\n",
      "Assigned [330, 250, 210, 165, 242, 128, 234, 254] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0174759142100811, feature std is 1.002561330795288.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3688 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 264, 488, 376] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2615 | S-BLEU: 0.16 | FMSE: 8.9426e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.46| ROUGE2: 0.12 | ROUGE-L: 0.29| Token Acc: 85.06% | Label Acc: 85.06%\n",
      "Checking 8-1-10000000.0-0.01-0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.007555402349680662, feature std is 0.10102305561304092.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3741 embeddings with positional data from imprinted layer.\n",
      "Assigned [488, 512, 512, 512, 512, 512, 209, 484] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5110 | S-BLEU: 0.23 | FMSE: 7.0659e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.54| ROUGE2: 0.24 | ROUGE-L: 0.48| Token Acc: 69.60% | Label Acc: 69.60%\n",
      "Checking 8-1-10000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00039524229941889644, feature std is 0.010709930211305618.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 475, 467, 466, 476, 465, 389, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6057 | S-BLEU: 0.26 | FMSE: 6.5381e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.61| ROUGE2: 0.30 | ROUGE-L: 0.58| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-10000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.239501767093316e-05, feature std is 0.0010107068810611963.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3738 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 238, 512, 512, 455, 512, 512, 485] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5110 | S-BLEU: 0.21 | FMSE: 7.2509e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.54| ROUGE2: 0.23 | ROUGE-L: 0.49| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-1-10000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 46.44718551635742, feature std is 1038.6387939453125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 602 embeddings with positional data from imprinted layer.\n",
      "Assigned [9, 4, 273, 15, 231, 45, 5, 20] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.610264778137207, feature std is 105.71107482910156.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1609 embeddings with positional data from imprinted layer.\n",
      "Assigned [141, 133, 112, 98, 33, 442, 378, 272] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.012020560912787914, feature std is 0.9519121050834656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3697 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 323, 512, 302, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4421 | S-BLEU: 0.28 | FMSE: 6.2820e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.55| ROUGE2: 0.24 | ROUGE-L: 0.43| Token Acc: 83.67% | Label Acc: 83.67%\n",
      "Checking 8-1-10000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0009089110535569489, feature std is 0.10477026551961899.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [467, 466, 461, 512, 487, 309, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6011 | S-BLEU: 0.27 | FMSE: 7.2010e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.57| Token Acc: 69.70% | Label Acc: 69.70%\n",
      "Checking 8-1-10000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.598626638762653e-05, feature std is 0.009957362897694111.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3739 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 353, 500, 512, 482, 356] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3523 | S-BLEU: 0.20 | FMSE: 9.8755e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.35| Token Acc: 68.31% | Label Acc: 68.31%\n",
      "Checking 8-1-10000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.0433529395377263e-05, feature std is 0.0009852770017459989.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3714 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 465, 512, 479, 463, 300, 471, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5110 | S-BLEU: 0.24 | FMSE: 7.1121e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.54| ROUGE2: 0.25 | ROUGE-L: 0.49| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-100000000.0-10-1000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -27.344322204589844, feature std is 448.5941162109375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1127 embeddings with positional data from imprinted layer.\n",
      "Assigned [152, 139, 172, 127, 124, 59, 143, 211] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.2026360034942627, feature std is 35.97743606567383.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3366 embeddings with positional data from imprinted layer.\n",
      "Assigned [375, 495, 420, 512, 446, 94, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0166 | S-BLEU: 0.01 | FMSE: 6.7841e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.34% | Label Acc: 98.34%\n",
      "Checking 8-1-100000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00808075163513422, feature std is 0.3716832101345062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3852 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 327, 453, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0144 | S-BLEU: 0.01 | FMSE: 1.6819e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 95.78% | Label Acc: 95.78%\n",
      "Checking 8-1-100000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0005029970780014992, feature std is 0.038536399602890015.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3870 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 418, 500, 512, 512, 415, 489] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0212 | S-BLEU: 0.01 | FMSE: 1.9662e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.46% | Label Acc: 99.46%\n",
      "Checking 8-1-100000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.304980681510642e-05, feature std is 0.003345709526911378.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3848 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 321, 512, 512, 455, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0127 | S-BLEU: 0.01 | FMSE: 2.7169e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.95% | Label Acc: 98.95%\n",
      "Checking 8-1-100000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.2668201634369325e-05, feature std is 0.0003797937242779881.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3850 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 466, 312, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0139 | S-BLEU: 0.01 | FMSE: 1.8902e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.68% | Label Acc: 97.68%\n",
      "Checking 8-1-100000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.709724426269531, feature std is 993.052490234375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 584 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.4841593329319648.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n",
      "Assigned [38, 14, 92, 3, 52, 108, 276, 1] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.190873861312866, feature std is 95.83869934082031.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1825 embeddings with positional data from imprinted layer.\n",
      "Assigned [302, 67, 118, 512, 156, 316, 180, 174] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00464656762778759, feature std is 0.985399067401886.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3797 embeddings with positional data from imprinted layer.\n",
      "Assigned [467, 416, 512, 433, 459, 512, 486, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6113 | S-BLEU: 0.37 | FMSE: 3.1016e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.65| ROUGE2: 0.37 | ROUGE-L: 0.58| Token Acc: 86.08% | Label Acc: 86.08%\n",
      "Checking 8-1-100000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0016721085412427783, feature std is 0.09921444207429886.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3845 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 296, 512, 477] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6548 | S-BLEU: 0.36 | FMSE: 5.4485e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.62| Token Acc: 77.15% | Label Acc: 77.15%\n",
      "Checking 8-1-100000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0004925209213979542, feature std is 0.0098421610891819.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3879 embeddings with positional data from imprinted layer.\n",
      "Assigned [415, 495, 496, 494, 512, 512, 481, 474] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6877 | S-BLEU: 0.39 | FMSE: 5.8918e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.68| ROUGE2: 0.42 | ROUGE-L: 0.66| Token Acc: 75.61% | Label Acc: 75.61%\n",
      "Checking 8-1-100000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.9420934879453853e-05, feature std is 0.0009577974560670555.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3896 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 484, 497, 470, 512, 463, 479, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7158 | S-BLEU: 0.45 | FMSE: 4.7042e-03 | \n",
      " G-BLEU: 0.42 | ROUGE1: 0.71| ROUGE2: 0.48 | ROUGE-L: 0.69| Token Acc: 80.10% | Label Acc: 80.10%\n",
      "Checking 8-1-100000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 25.74309539794922, feature std is 936.4657592773438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 580 embeddings with positional data from imprinted layer.\n",
      "Assigned [66, 12, 67, 131, 27, 71, 133, 73] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.219417095184326, feature std is 97.98467254638672.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1856 embeddings with positional data from imprinted layer.\n",
      "Assigned [136, 208, 290, 229, 487, 168, 83, 255] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.004882728680968285, feature std is 1.0129646062850952.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3674 embeddings with positional data from imprinted layer.\n",
      "Assigned [468, 168, 512, 478, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6118 | S-BLEU: 0.33 | FMSE: 3.6761e-03 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.65| ROUGE2: 0.35 | ROUGE-L: 0.58| Token Acc: 84.86% | Label Acc: 84.86%\n",
      "Checking 8-1-100000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.006433846428990364, feature std is 0.10203695297241211.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3757 embeddings with positional data from imprinted layer.\n",
      "Assigned [482, 468, 456, 474, 469, 462, 473, 473] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6426 | S-BLEU: 0.31 | FMSE: 6.4109e-03 | \n",
      " G-BLEU: 0.31 | ROUGE1: 0.64| ROUGE2: 0.35 | ROUGE-L: 0.61| Token Acc: 69.73% | Label Acc: 69.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-1-100000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002589582290966064, feature std is 0.009894225746393204.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3762 embeddings with positional data from imprinted layer.\n",
      "Assigned [475, 512, 512, 481, 512, 512, 246, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5310 | S-BLEU: 0.23 | FMSE: 7.5631e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.56| ROUGE2: 0.25 | ROUGE-L: 0.50| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-1-100000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.5547917175572366e-05, feature std is 0.0009841942228376865.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 458, 425, 512, 299] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4502 | S-BLEU: 0.20 | FMSE: 8.4378e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.21 | ROUGE-L: 0.44| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-1-100000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 57.119972229003906, feature std is 998.1768188476562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 583 embeddings with positional data from imprinted layer.\n",
      "Assigned [147, 45, 35, 264, 45, 8, 6, 33] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.3784698247909546, feature std is 101.31613159179688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1743 embeddings with positional data from imprinted layer.\n",
      "Assigned [200, 183, 202, 148, 165, 198, 183, 464] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.025467973202466965, feature std is 0.9848804473876953.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3684 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 490, 380, 512, 254, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2561 | S-BLEU: 0.18 | FMSE: 8.4882e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.46| ROUGE2: 0.12 | ROUGE-L: 0.28| Token Acc: 85.13% | Label Acc: 85.13%\n",
      "Checking 8-1-100000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001459574792534113, feature std is 0.10278547555208206.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3748 embeddings with positional data from imprinted layer.\n",
      "Assigned [352, 512, 512, 441, 395, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3833 | S-BLEU: 0.20 | FMSE: 8.1924e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.47| ROUGE2: 0.19 | ROUGE-L: 0.38| Token Acc: 69.68% | Label Acc: 69.68%\n",
      "Checking 8-1-100000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.647917275084183e-05, feature std is 0.010177675634622574.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3734 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [512, 479, 459, 435, 446, 512, 379, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5632 | S-BLEU: 0.24 | FMSE: 6.9509e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.57| ROUGE2: 0.27 | ROUGE-L: 0.53| Token Acc: 68.33% | Label Acc: 68.33%\n",
      "Checking 8-1-100000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.4728492462600116e-06, feature std is 0.0009883715538308024.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [445, 477, 459, 477, 453, 465, 480, 469] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6140 | S-BLEU: 0.27 | FMSE: 7.5023e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-1-100000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 25.209400177001953, feature std is 962.5810546875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 572 embeddings with positional data from imprinted layer.\n",
      "Assigned [25, 116, 43, 90, 24, 33, 15, 226] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.9532413482666016, feature std is 97.49069213867188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1759 embeddings with positional data from imprinted layer.\n",
      "Assigned [359, 166, 309, 292, 138, 114, 177, 204] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.022662552073597908, feature std is 0.992882251739502.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3667 embeddings with positional data from imprinted layer.\n",
      "Assigned [232, 512, 363, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3010 | S-BLEU: 0.19 | FMSE: 8.2604e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.47| ROUGE2: 0.15 | ROUGE-L: 0.31| Token Acc: 84.79% | Label Acc: 84.79%\n",
      "Checking 8-1-100000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.002034729113802314, feature std is 0.10011937469244003.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3748 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 208, 512, 468, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5100 | S-BLEU: 0.23 | FMSE: 7.6274e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.56| ROUGE2: 0.25 | ROUGE-L: 0.49| Token Acc: 69.65% | Label Acc: 69.65%\n",
      "Checking 8-1-100000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0003230762667953968, feature std is 0.010270897299051285.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 198, 512, 512, 484, 482, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1780 | S-BLEU: 0.11 | FMSE: 1.0426e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.35| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-1-100000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.833527342882007e-05, feature std is 0.0010010985424742103.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [335, 512, 512, 441, 512, 512, 392, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2698 | S-BLEU: 0.14 | FMSE: 1.1192e-02 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.39| ROUGE2: 0.12 | ROUGE-L: 0.27| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-1000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.8310468196868896, feature std is 491.2339172363281.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1211 embeddings with positional data from imprinted layer.\n",
      "Assigned [162, 150, 153, 140, 63, 271, 136, 136] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.9287692904472351, feature std is 43.206092834472656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3140 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 275, 512, 476, 35, 497, 343, 490] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0146 | S-BLEU: 0.01 | FMSE: 5.8609e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 95.75% | Label Acc: 95.75%\n",
      "Checking 8-1-1000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006451586727052927, feature std is 0.3078616261482239.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3868 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 284, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0181 | S-BLEU: 0.01 | FMSE: 1.7306e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.15| Token Acc: 97.17% | Label Acc: 97.17%\n",
      "Checking 8-1-1000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.002091841073706746, feature std is 0.04222014918923378.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3841 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 351, 512, 512, 512, 418, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0129 | S-BLEU: 0.01 | FMSE: 2.6141e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.41% | Label Acc: 98.41%\n",
      "Checking 8-1-1000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00010685474990168586, feature std is 0.003920507151633501.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3852 embeddings with positional data from imprinted layer.\n",
      "Assigned [484, 488, 476, 482, 454, 478, 512, 478] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0386 | S-BLEU: 0.01 | FMSE: 1.9261e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.88% | Label Acc: 99.88%\n",
      "Checking 8-1-1000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.7315254808636382e-05, feature std is 0.0003784133295994252.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3856 embeddings with positional data from imprinted layer.\n",
      "Assigned [414, 512, 477, 440, 512, 512, 477, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0186 | S-BLEU: 0.01 | FMSE: 1.7640e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.78% | Label Acc: 99.78%\n",
      "Checking 8-1-1000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 10.023422241210938, feature std is 914.3851928710938.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 631 embeddings with positional data from imprinted layer.\n",
      "Assigned [18, 467, 14, 10, 45, 19, 27, 31] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 11.008020401000977, feature std is 97.91513061523438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1820 embeddings with positional data from imprinted layer.\n",
      "Assigned [424, 218, 47, 392, 226, 80, 223, 210] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.021494057029485703, feature std is 0.9716967940330505.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3813 embeddings with positional data from imprinted layer.\n",
      "Assigned [490, 512, 399, 472, 465, 512, 490, 473] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6917 | S-BLEU: 0.39 | FMSE: 2.2075e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.69| ROUGE2: 0.41 | ROUGE-L: 0.64| Token Acc: 85.74% | Label Acc: 85.74%\n",
      "Checking 8-1-1000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.018714357167482376, feature std is 0.09386671334505081.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3860 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 512, 512, 276] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5327 | S-BLEU: 0.34 | FMSE: 6.1936e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.58| ROUGE2: 0.32 | ROUGE-L: 0.51| Token Acc: 77.93% | Label Acc: 77.93%\n",
      "Checking 8-1-1000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00042549328645691276, feature std is 0.009685909375548363.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3807 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 434, 512, 406, 512, 407] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4751 | S-BLEU: 0.26 | FMSE: 7.1404e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.54| ROUGE2: 0.25 | ROUGE-L: 0.46| Token Acc: 74.46% | Label Acc: 74.46%\n",
      "Checking 8-1-1000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.5149860195815563e-06, feature std is 0.0009290429297834635.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3849 embeddings with positional data from imprinted layer.\n",
      "Assigned [499, 512, 512, 512, 512, 278, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2246 | S-BLEU: 0.23 | FMSE: 9.3816e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.39| ROUGE2: 0.14 | ROUGE-L: 0.25| Token Acc: 76.10% | Label Acc: 76.10%\n",
      "Checking 8-1-1000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.815584182739258, feature std is 1042.6767578125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 533 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 4 seeds searching on threshold 0.18261722820551574.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [143, 293, 18, 43, 21, 13, 2] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.42669838666915894, feature std is 94.99982452392578.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1802 embeddings with positional data from imprinted layer.\n",
      "Assigned [353, 278, 237, 225, 215, 41, 268, 185] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.009432471357285976, feature std is 1.0329266786575317.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3701 embeddings with positional data from imprinted layer.\n",
      "Assigned [162, 512, 467, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.5906 | S-BLEU: 0.32 | FMSE: 4.1326e-03 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.64| ROUGE2: 0.33 | ROUGE-L: 0.56| Token Acc: 85.42% | Label Acc: 85.42%\n",
      "Checking 8-1-1000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.003268727334216237, feature std is 0.09720835834741592.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3769 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 468, 476, 512, 445, 332] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5803 | S-BLEU: 0.27 | FMSE: 7.0867e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.59| ROUGE2: 0.30 | ROUGE-L: 0.55| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-1-1000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00041710870573297143, feature std is 0.010019204579293728.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3748 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 340, 512, 512, 512, 457, 475, 471] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5752 | S-BLEU: 0.24 | FMSE: 7.0431e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.58| ROUGE2: 0.27 | ROUGE-L: 0.55| Token Acc: 68.38% | Label Acc: 68.38%\n",
      "Checking 8-1-1000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.7648026187089272e-05, feature std is 0.000993823166936636.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3783 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 385, 512, 512, 406, 432, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3826 | S-BLEU: 0.18 | FMSE: 8.5320e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.46| ROUGE2: 0.17 | ROUGE-L: 0.37| Token Acc: 68.63% | Label Acc: 68.63%\n",
      "Checking 8-1-1000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -77.81001281738281, feature std is 985.5875854492188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 524 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 4 seeds searching on threshold 0.13009660209432394.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [130, 71, 216, 96, 9, 2] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.5654327869415283, feature std is 104.24325561523438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49889, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1609 embeddings with positional data from imprinted layer.\n",
      "Assigned [243, 120, 101, 162, 269, 258, 207, 249] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0063058617524802685, feature std is 1.0147182941436768.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3666 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 393, 283, 430, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1677 | S-BLEU: 0.10 | FMSE: 9.4957e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.42| ROUGE2: 0.06 | ROUGE-L: 0.22| Token Acc: 85.18% | Label Acc: 85.18%\n",
      "Checking 8-1-1000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004771245643496513, feature std is 0.10105260461568832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3735 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 397, 512, 512, 512, 266, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1804 | S-BLEU: 0.10 | FMSE: 1.0323e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.34| ROUGE2: 0.06 | ROUGE-L: 0.18| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-1-1000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0005721018533222377, feature std is 0.00976845994591713.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 357, 299, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2939 | S-BLEU: 0.18 | FMSE: 9.3047e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.40| ROUGE2: 0.15 | ROUGE-L: 0.29| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-1000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.3781738744000904e-05, feature std is 0.0010391913820058107.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3713 embeddings with positional data from imprinted layer.\n",
      "Assigned [448, 512, 449, 512, 512, 512, 463, 305] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5466 | S-BLEU: 0.22 | FMSE: 7.2703e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.56| ROUGE2: 0.25 | ROUGE-L: 0.52| Token Acc: 68.29% | Label Acc: 68.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-1-1000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -13.075296401977539, feature std is 969.7400512695312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 581 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 5 seeds searching on threshold 0.5136466878515196.\n",
      "Filling with 3 random seeds...These sentences will be scrambled.\n",
      "Assigned [18, 131, 17, 343, 67, 2, 3] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.38979843258857727, feature std is 99.49542236328125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1728 embeddings with positional data from imprinted layer.\n",
      "Assigned [498, 132, 331, 85, 226, 186, 170, 100] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.025892581790685654, feature std is 0.9541245698928833.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3729 embeddings with positional data from imprinted layer.\n",
      "Assigned [463, 512, 512, 464, 433, 512, 463, 370] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6638 | S-BLEU: 0.37 | FMSE: 3.5375e-03 | \n",
      " G-BLEU: 0.36 | ROUGE1: 0.68| ROUGE2: 0.39 | ROUGE-L: 0.62| Token Acc: 84.40% | Label Acc: 84.40%\n",
      "Checking 8-1-1000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004562622925732285, feature std is 0.10279519855976105.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3713 embeddings with positional data from imprinted layer.\n",
      "Assigned [465, 461, 483, 413, 454, 453, 512, 472] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6123 | S-BLEU: 0.27 | FMSE: 6.9751e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.61| ROUGE2: 0.32 | ROUGE-L: 0.58| Token Acc: 69.63% | Label Acc: 69.63%\n",
      "Checking 8-1-1000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002014745696214959, feature std is 0.009432682767510414.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [466, 454, 445, 451, 465, 461, 471, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5940 | S-BLEU: 0.26 | FMSE: 6.7062e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.60| ROUGE2: 0.30 | ROUGE-L: 0.57| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-1-1000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.73901566490531e-05, feature std is 0.0009832660434767604.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 467, 187, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2141 | S-BLEU: 0.10 | FMSE: 1.0347e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.36| ROUGE2: 0.08 | ROUGE-L: 0.22| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-1-10000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.769061088562012, feature std is 317.4524230957031.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1651 embeddings with positional data from imprinted layer.\n",
      "Assigned [206, 321, 209, 294, 179, 185, 177, 80] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.5206355452537537, feature std is 36.698570251464844.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3322 embeddings with positional data from imprinted layer.\n",
      "Assigned [462, 146, 393, 462, 395, 512, 440, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0110 | S-BLEU: 0.01 | FMSE: 4.7932e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.90% | Label Acc: 97.90%\n",
      "Checking 8-1-10000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.02704816684126854, feature std is 0.3671797513961792.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 284, 512, 495, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0146 | S-BLEU: 0.01 | FMSE: 1.5236e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.76% | Label Acc: 99.76%\n",
      "Checking 8-1-10000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0023066983558237553, feature std is 0.03654959052801132.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3854 embeddings with positional data from imprinted layer.\n",
      "Assigned [481, 486, 481, 481, 476, 485, 485, 479] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0466 | S-BLEU: 0.01 | FMSE: 1.6465e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.83% | Label Acc: 99.83%\n",
      "Checking 8-1-10000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.99660517461598e-06, feature std is 0.003254680661484599.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3886 embeddings with positional data from imprinted layer.\n",
      "Assigned [485, 493, 480, 487, 486, 484, 482, 489] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0220 | S-BLEU: 0.01 | FMSE: 1.6226e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.83% | Label Acc: 99.83%\n",
      "Checking 8-1-10000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.0909931006608531e-05, feature std is 0.00041360154864378273.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3842 embeddings with positional data from imprinted layer.\n",
      "Assigned [344, 512, 512, 479, 512, 489, 512, 482] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0652 | S-BLEU: 0.01 | FMSE: 2.4833e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.68% | Label Acc: 99.68%\n",
      "Checking 8-1-10000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 12.71252155303955, feature std is 982.079345703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 583 embeddings with positional data from imprinted layer.\n",
      "Assigned [89, 77, 14, 123, 70, 62, 72, 76] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.613245010375977, feature std is 96.31619262695312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1657 embeddings with positional data from imprinted layer.\n",
      "Assigned [40, 142, 58, 333, 221, 93, 328, 442] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.020775793120265007, feature std is 0.9720917344093323.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3809 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 277, 512, 512, 512, 460, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1848 | S-BLEU: 0.16 | FMSE: 8.4348e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.42| ROUGE2: 0.10 | ROUGE-L: 0.24| Token Acc: 85.77% | Label Acc: 85.77%\n",
      "Checking 8-1-10000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0011126286117359996, feature std is 0.09344322234392166.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3840 embeddings with positional data from imprinted layer.\n",
      "Assigned [297, 512, 512, 471, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2671 | S-BLEU: 0.24 | FMSE: 9.0525e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.41| ROUGE2: 0.15 | ROUGE-L: 0.27| Token Acc: 76.12% | Label Acc: 76.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-1-10000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.0159544621710666e-05, feature std is 0.009132178500294685.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3866 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 508, 449, 512, 349, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4878 | S-BLEU: 0.36 | FMSE: 5.8405e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.56| ROUGE2: 0.32 | ROUGE-L: 0.49| Token Acc: 79.44% | Label Acc: 79.44%\n",
      "Checking 8-1-10000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.028607872896828e-05, feature std is 0.0009558944730088115.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3848 embeddings with positional data from imprinted layer.\n",
      "Assigned [470, 512, 512, 425, 487, 487, 479, 476] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6885 | S-BLEU: 0.38 | FMSE: 5.4456e-03 | \n",
      " G-BLEU: 0.36 | ROUGE1: 0.67| ROUGE2: 0.41 | ROUGE-L: 0.65| Token Acc: 76.20% | Label Acc: 76.20%\n",
      "Checking 8-1-10000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.4435838460922241, feature std is 1022.61083984375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 549 embeddings with positional data from imprinted layer.\n",
      "Assigned [6, 201, 17, 272, 8, 43, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.768354415893555, feature std is 102.03679656982422.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1682 embeddings with positional data from imprinted layer.\n",
      "Assigned [174, 180, 28, 129, 252, 512, 130, 277] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.019916154444217682, feature std is 0.9502987861633301.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3682 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 442, 468, 512, 272, 452, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6353 | S-BLEU: 0.35 | FMSE: 3.0202e-03 | \n",
      " G-BLEU: 0.33 | ROUGE1: 0.66| ROUGE2: 0.36 | ROUGE-L: 0.59| Token Acc: 84.50% | Label Acc: 84.50%\n",
      "Checking 8-1-10000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.004982132464647293, feature std is 0.1008186787366867.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3756 embeddings with positional data from imprinted layer.\n",
      "Assigned [470, 418, 464, 512, 408, 512, 460, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2068 | S-BLEU: 0.11 | FMSE: 1.0587e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.36| ROUGE2: 0.07 | ROUGE-L: 0.21| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 8-1-10000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0007417515153065324, feature std is 0.00952169019728899.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3743 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [512, 512, 512, 458, 512, 213, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1416 | S-BLEU: 0.10 | FMSE: 1.1642e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.32| ROUGE2: 0.06 | ROUGE-L: 0.17| Token Acc: 68.43% | Label Acc: 68.43%\n",
      "Checking 8-1-10000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.478498133015819e-05, feature std is 0.0009894466493278742.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3768 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 469, 227, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4326 | S-BLEU: 0.23 | FMSE: 8.0608e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.48| ROUGE2: 0.23 | ROUGE-L: 0.42| Token Acc: 68.60% | Label Acc: 68.60%\n",
      "Checking 8-1-10000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 61.346595764160156, feature std is 1053.7347412109375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 534 embeddings with positional data from imprinted layer.\n",
      "Assigned [65, 10, 5, 2, 3, 435, 12, 2] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.5456897020339966, feature std is 97.05015563964844.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1714 embeddings with positional data from imprinted layer.\n",
      "Assigned [205, 214, 290, 342, 61, 23, 238, 341] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.03749798238277435, feature std is 0.9864721894264221.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3677 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 235, 512, 512, 512, 512, 512, 370] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1641 | S-BLEU: 0.13 | FMSE: 1.0748e-02 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.42| ROUGE2: 0.07 | ROUGE-L: 0.23| Token Acc: 84.96% | Label Acc: 84.96%\n",
      "Checking 8-1-10000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.008728920482099056, feature std is 0.1012606993317604.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3735 embeddings with positional data from imprinted layer.\n",
      "Assigned [466, 460, 471, 470, 464, 469, 464, 471] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6270 | S-BLEU: 0.28 | FMSE: 6.5778e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.63| ROUGE2: 0.32 | ROUGE-L: 0.60| Token Acc: 69.46% | Label Acc: 69.46%\n",
      "Checking 8-1-10000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.000638671510387212, feature std is 0.009801791980862617.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3732 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 461, 512, 199, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5559 | S-BLEU: 0.23 | FMSE: 7.2848e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.57| ROUGE2: 0.27 | ROUGE-L: 0.54| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-1-10000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.541603498684708e-05, feature std is 0.001003545825369656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [447, 465, 285, 512, 512, 483, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5352 | S-BLEU: 0.20 | FMSE: 7.5430e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.56| ROUGE2: 0.25 | ROUGE-L: 0.51| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-10000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.673074722290039, feature std is 979.2567749023438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 654 embeddings with positional data from imprinted layer.\n",
      "Assigned [29, 30, 206, 154, 23, 2, 85, 125] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.0195491313934326, feature std is 97.74332427978516.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1751 embeddings with positional data from imprinted layer.\n",
      "Assigned [414, 161, 289, 103, 202, 158, 188, 236] breached embeddings to each sentence.\n",
      "Checking 8-1-10000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.01807999238371849, feature std is 1.0511064529418945.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3673 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 451, 458, 512, 295, 512, 421, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5327 | S-BLEU: 0.27 | FMSE: 4.6551e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.60| ROUGE2: 0.27 | ROUGE-L: 0.50| Token Acc: 85.35% | Label Acc: 85.35%\n",
      "Checking 8-1-10000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0012511109234765172, feature std is 0.10037095099687576.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3739 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 351, 512, 512, 512, 365, 463] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2363 | S-BLEU: 0.15 | FMSE: 9.8889e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.39| ROUGE2: 0.12 | ROUGE-L: 0.25| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-1-10000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00024102522002067417, feature std is 0.010006045922636986.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3727 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 365, 491, 311, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3623 | S-BLEU: 0.18 | FMSE: 9.1743e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.35| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-10000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.443113695946522e-05, feature std is 0.0009950452949851751.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3718 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 472, 512, 458, 462, 370, 420] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5742 | S-BLEU: 0.24 | FMSE: 6.9124e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.28 | ROUGE-L: 0.54| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-1-100000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -19.74093246459961, feature std is 373.4742736816406.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1404 embeddings with positional data from imprinted layer.\n",
      "Assigned [197, 126, 313, 163, 99, 104, 255, 147] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.8126748204231262, feature std is 48.64129638671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49889, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 2887 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 472, 134, 234, 512, 402, 251, 370] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0164 | S-BLEU: 0.01 | FMSE: 5.6651e-04 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.47| ROUGE2: 0.02 | ROUGE-L: 0.17| Token Acc: 92.43% | Label Acc: 92.43%\n",
      "Checking 8-1-100000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005276881158351898, feature std is 0.37349605560302734.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [494, 512, 512, 512, 492, 512, 305, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0193 | S-BLEU: 0.01 | FMSE: 3.6238e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 95.61% | Label Acc: 95.61%\n",
      "Checking 8-1-100000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00023256021086126566, feature std is 0.03401068225502968.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3868 embeddings with positional data from imprinted layer.\n",
      "Assigned [458, 490, 459, 512, 512, 468, 512, 457] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0317 | S-BLEU: 0.01 | FMSE: 1.8009e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.63% | Label Acc: 99.63%\n",
      "Checking 8-1-100000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00016452885756734759, feature std is 0.00421625841408968.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3838 embeddings with positional data from imprinted layer.\n",
      "Assigned [314, 512, 512, 512, 512, 452, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0342 | S-BLEU: 0.03 | FMSE: 2.7062e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 96.26% | Label Acc: 96.26%\n",
      "Checking 8-1-100000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.041465606656857e-05, feature std is 0.0004199169052299112.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3847 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 449, 512, 512, 512, 326, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0208 | S-BLEU: 0.01 | FMSE: 2.6501e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.71% | Label Acc: 98.71%\n",
      "Checking 8-1-100000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 33.19965744018555, feature std is 939.024169921875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 607 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 6 seeds searching on threshold 0.40136227959271475.\n",
      "Filling with 2 random seeds...These sentences will be scrambled.\n",
      "Assigned [15, 35, 27, 285, 38, 179, 8, 20] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.9188315868377686, feature std is 96.8165283203125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1671 embeddings with positional data from imprinted layer.\n",
      "Assigned [154, 341, 212, 270, 264, 159, 219, 52] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.013508973643183708, feature std is 0.9584742784500122.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3810 embeddings with positional data from imprinted layer.\n",
      "Assigned [292, 512, 472, 512, 512, 512, 512, 486] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.6387 | S-BLEU: 0.36 | FMSE: 3.0360e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.36 | ROUGE-L: 0.59| Token Acc: 86.74% | Label Acc: 86.74%\n",
      "Checking 8-1-100000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005371094215661287, feature std is 0.09339936077594757.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3844 embeddings with positional data from imprinted layer.\n",
      "Assigned [398, 512, 512, 512, 374, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1748 | S-BLEU: 0.22 | FMSE: 9.4775e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.37| ROUGE2: 0.08 | ROUGE-L: 0.20| Token Acc: 76.20% | Label Acc: 76.20%\n",
      "Checking 8-1-100000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0008575411047786474, feature std is 0.009866042993962765.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3855 embeddings with positional data from imprinted layer.\n",
      "Assigned [307, 512, 512, 512, 512, 512, 512, 476] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2666 | S-BLEU: 0.21 | FMSE: 9.3291e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.42| ROUGE2: 0.14 | ROUGE-L: 0.28| Token Acc: 77.03% | Label Acc: 77.03%\n",
      "Checking 8-1-100000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.677509372821078e-05, feature std is 0.0009458765271119773.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3864 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 493, 512, 338, 473, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3589 | S-BLEU: 0.25 | FMSE: 7.9972e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.47| ROUGE2: 0.21 | ROUGE-L: 0.36| Token Acc: 77.12% | Label Acc: 77.12%\n",
      "Checking 8-1-100000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -34.77083969116211, feature std is 963.2403564453125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 578 embeddings with positional data from imprinted layer.\n",
      "Assigned [53, 3, 15, 1, 17, 238, 16, 235] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.540566921234131, feature std is 102.2669906616211.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1725 embeddings with positional data from imprinted layer.\n",
      "Assigned [264, 354, 20, 142, 154, 174, 208, 409] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.08785706013441086, feature std is 0.9843904376029968.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3721 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 282, 466, 512, 485, 512, 512, 473] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6313 | S-BLEU: 0.36 | FMSE: 3.2497e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.65| ROUGE2: 0.37 | ROUGE-L: 0.60| Token Acc: 84.72% | Label Acc: 84.72%\n",
      "Checking 8-1-100000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0005905755679123104, feature std is 0.10177869349718094.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 3732 embeddings with positional data from imprinted layer.\n",
      "Assigned [463, 468, 468, 467, 471, 465, 463, 467] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6321 | S-BLEU: 0.29 | FMSE: 6.6639e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.63| ROUGE2: 0.34 | ROUGE-L: 0.61| Token Acc: 69.85% | Label Acc: 69.85%\n",
      "Checking 8-1-100000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.291590009117499e-05, feature std is 0.009966051205992699.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [464, 465, 460, 446, 480, 512, 439, 459] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6118 | S-BLEU: 0.27 | FMSE: 6.6733e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 68.51% | Label Acc: 68.51%\n",
      "Checking 8-1-100000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.118379365536384e-06, feature std is 0.0009989559184759855.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3741 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 446, 512, 512, 512, 512, 379, 356] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1680 | S-BLEU: 0.12 | FMSE: 1.0739e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.32| ROUGE2: 0.06 | ROUGE-L: 0.18| Token Acc: 68.31% | Label Acc: 68.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-1-100000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -70.68280029296875, feature std is 1039.442138671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 497 embeddings with positional data from imprinted layer.\n",
      "Cannot separate 8 seeds by thresholding!\n",
      "Could assemble only 4 seeds searching on threshold 0.0009999999999998899.\n",
      "Filling with 4 random seeds...These sentences will be scrambled.\n",
      "Assigned [162, 98, 91, 128, 12, 3, 3] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.884734630584717, feature std is 105.21968078613281.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1634 embeddings with positional data from imprinted layer.\n",
      "Assigned [351, 109, 377, 242, 91, 184, 164, 116] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.000322052655974403, feature std is 0.9798969030380249.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3693 embeddings with positional data from imprinted layer.\n",
      "Assigned [468, 495, 455, 512, 459, 374, 467, 463] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6809 | S-BLEU: 0.39 | FMSE: 2.6652e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.68| ROUGE2: 0.41 | ROUGE-L: 0.64| Token Acc: 84.20% | Label Acc: 84.20%\n",
      "Checking 8-1-100000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.000865814508870244, feature std is 0.09749928116798401.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3743 embeddings with positional data from imprinted layer.\n",
      "Assigned [497, 512, 512, 512, 360, 512, 326, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3293 | S-BLEU: 0.20 | FMSE: 9.4085e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.16 | ROUGE-L: 0.33| Token Acc: 69.41% | Label Acc: 69.41%\n",
      "Checking 8-1-100000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0008096775854937732, feature std is 0.00992041639983654.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3731 embeddings with positional data from imprinted layer.\n",
      "Assigned [354, 512, 512, 371, 512, 446, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3870 | S-BLEU: 0.17 | FMSE: 9.2327e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.46| ROUGE2: 0.17 | ROUGE-L: 0.38| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-1-100000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.489614366320893e-05, feature std is 0.001019112067297101.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3718 embeddings with positional data from imprinted layer.\n",
      "Assigned [477, 512, 486, 512, 512, 253, 512, 454] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4417 | S-BLEU: 0.19 | FMSE: 8.5088e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.19 | ROUGE-L: 0.42| Token Acc: 68.12% | Label Acc: 68.12%\n",
      "Checking 8-1-100000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -103.29193115234375, feature std is 1000.79345703125.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 558 embeddings with positional data from imprinted layer.\n",
      "Assigned [15, 264, 11, 177, 5, 1, 14, 71] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.1776838302612305, feature std is 99.64784240722656.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1688 embeddings with positional data from imprinted layer.\n",
      "Assigned [309, 84, 281, 391, 174, 107, 152, 190] breached embeddings to each sentence.\n",
      "Checking 8-1-100000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005277843214571476, feature std is 1.019167423248291.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3678 embeddings with positional data from imprinted layer.\n",
      "Assigned [365, 512, 473, 512, 468, 441, 449, 458] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6521 | S-BLEU: 0.37 | FMSE: 3.0501e-03 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.67| ROUGE2: 0.38 | ROUGE-L: 0.61| Token Acc: 85.01% | Label Acc: 85.01%\n",
      "Checking 8-1-100000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.003017960349097848, feature std is 0.1008017435669899.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3704 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 374, 351, 428, 512, 503, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2471 | S-BLEU: 0.14 | FMSE: 9.3787e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.38| ROUGE2: 0.11 | ROUGE-L: 0.25| Token Acc: 69.60% | Label Acc: 69.60%\n",
      "Checking 8-1-100000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.000671256217174232, feature std is 0.009545543231070042.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3719 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 463, 512, 512, 389, 477, 512, 342] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5710 | S-BLEU: 0.23 | FMSE: 7.4510e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.58| ROUGE2: 0.27 | ROUGE-L: 0.54| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-1-100000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.6404716158576775e-06, feature std is 0.001039976836182177.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3716 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 467, 512, 512, 221, 468, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5659 | S-BLEU: 0.24 | FMSE: 7.6509e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.28 | ROUGE-L: 0.54| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-1-1000000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.0070900917053223, feature std is 360.45745849609375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1391 embeddings with positional data from imprinted layer.\n",
      "Assigned [93, 109, 48, 69, 395, 400, 214, 63] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.34962084889411926, feature std is 40.16999053955078.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3328 embeddings with positional data from imprinted layer.\n",
      "Assigned [436, 408, 434, 406, 406, 404, 442, 392] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0117 | S-BLEU: 0.01 | FMSE: 4.3448e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 96.73% | Label Acc: 96.73%\n",
      "Checking 8-1-1000000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00013816468708682805, feature std is 0.3414672315120697.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3868 embeddings with positional data from imprinted layer.\n",
      "Assigned [327, 512, 512, 512, 512, 473, 512, 508] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0127 | S-BLEU: 0.01 | FMSE: 3.0236e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.42| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 95.02% | Label Acc: 95.02%\n",
      "Checking 8-1-1000000000000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.3484462114283815e-05, feature std is 0.037459395825862885.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 485, 396, 410, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0173 | S-BLEU: 0.01 | FMSE: 2.1299e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-1-1000000000000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00010052808647742495, feature std is 0.0037930752150714397.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3864 embeddings with positional data from imprinted layer.\n",
      "Assigned [470, 512, 481, 363, 512, 512, 502, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0271 | S-BLEU: 0.01 | FMSE: 4.9509e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.54% | Label Acc: 98.54%\n",
      "Checking 8-1-1000000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.5037548109830823e-05, feature std is 0.00040041402098722756.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3814 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 409, 512, 333, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0317 | S-BLEU: 0.01 | FMSE: 2.2877e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.17% | Label Acc: 98.17%\n",
      "Checking 8-1-1000000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 50.688106536865234, feature std is 926.132080078125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 591 embeddings with positional data from imprinted layer.\n",
      "Assigned [70, 131, 66, 12, 15, 76, 140, 81] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.7113404870033264, feature std is 94.36975860595703.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1777 embeddings with positional data from imprinted layer.\n",
      "Assigned [358, 205, 252, 240, 167, 277, 115, 163] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.028774354606866837, feature std is 0.9924357533454895.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3800 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 299, 512, 481, 460, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6279 | S-BLEU: 0.37 | FMSE: 2.7267e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.65| ROUGE2: 0.36 | ROUGE-L: 0.58| Token Acc: 86.40% | Label Acc: 86.40%\n",
      "Checking 8-1-1000000000000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.002931339666247368, feature std is 0.09755022823810577.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3822 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 238, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2603 | S-BLEU: 0.20 | FMSE: 8.9283e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.42| ROUGE2: 0.13 | ROUGE-L: 0.28| Token Acc: 77.03% | Label Acc: 77.03%\n",
      "Checking 8-1-1000000000000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -2.512901119189337e-05, feature std is 0.0094710448756814.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3816 embeddings with positional data from imprinted layer.\n",
      "Assigned [406, 479, 512, 512, 444, 486, 512, 465] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6206 | S-BLEU: 0.41 | FMSE: 5.7885e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.65| ROUGE2: 0.40 | ROUGE-L: 0.60| Token Acc: 79.98% | Label Acc: 79.98%\n",
      "Checking 8-1-1000000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.4138404367258772e-05, feature std is 0.00099946279078722.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3849 embeddings with positional data from imprinted layer.\n",
      "Assigned [392, 512, 512, 385, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3167 | S-BLEU: 0.22 | FMSE: 8.0615e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.32| Token Acc: 76.22% | Label Acc: 76.22%\n",
      "Checking 8-1-1000000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 66.26701354980469, feature std is 1067.6051025390625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 571 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 7 seeds searching on threshold 0.6910828405855427.\n",
      "Filling with 1 random seeds...These sentences will be scrambled.\n",
      "Assigned [36, 87, 1, 133, 1, 1, 312] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.91563606262207, feature std is 101.13716125488281.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1742 embeddings with positional data from imprinted layer.\n",
      "Assigned [388, 165, 226, 207, 73, 215, 244, 224] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-0.1-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03139503300189972, feature std is 1.0154764652252197.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3708 embeddings with positional data from imprinted layer.\n",
      "Assigned [475, 512, 241, 487, 512, 512, 512, 457] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5393 | S-BLEU: 0.29 | FMSE: 4.3458e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.60| ROUGE2: 0.29 | ROUGE-L: 0.52| Token Acc: 84.86% | Label Acc: 84.86%\n",
      "Checking 8-1-1000000000000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0024627840612083673, feature std is 0.10353481024503708.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3738 embeddings with positional data from imprinted layer.\n",
      "Assigned [453, 470, 475, 464, 477, 467, 458, 474] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6289 | S-BLEU: 0.30 | FMSE: 7.0094e-03 | \n",
      " G-BLEU: 0.30 | ROUGE1: 0.62| ROUGE2: 0.34 | ROUGE-L: 0.60| Token Acc: 69.63% | Label Acc: 69.63%\n",
      "Checking 8-1-1000000000000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00016454934666398913, feature std is 0.010037591680884361.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3729 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 460, 474, 512, 483, 474, 302] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5737 | S-BLEU: 0.24 | FMSE: 7.5390e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.58| ROUGE2: 0.27 | ROUGE-L: 0.55| Token Acc: 68.33% | Label Acc: 68.33%\n",
      "Checking 8-1-1000000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.2817355279112235e-06, feature std is 0.0009879624703899026.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3760 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 438, 284, 512, 512, 478, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5464 | S-BLEU: 0.23 | FMSE: 8.0823e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.56| ROUGE2: 0.26 | ROUGE-L: 0.52| Token Acc: 68.55% | Label Acc: 68.55%\n",
      "Checking 8-1-1000000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 24.399484634399414, feature std is 1065.41650390625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 555 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 5 seeds searching on threshold 0.26065402885902045.\n",
      "Filling with 3 random seeds...These sentences will be scrambled.\n",
      "Assigned [323, 59, 42, 28, 91, 1, 8, 3] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.782612800598145, feature std is 95.96508026123047.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49889, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1698 embeddings with positional data from imprinted layer.\n",
      "Assigned [157, 200, 157, 174, 227, 275, 326, 182] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is 0.01233062893152237, feature std is 1.0281747579574585.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3673 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 411, 512, 512, 512, 345, 357] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4001 | S-BLEU: 0.25 | FMSE: 5.9709e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.53| ROUGE2: 0.22 | ROUGE-L: 0.40| Token Acc: 85.21% | Label Acc: 85.21%\n",
      "Checking 8-1-1000000000000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.001514403149485588, feature std is 0.10401242226362228.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3703 embeddings with positional data from imprinted layer.\n",
      "Assigned [461, 512, 460, 487, 466, 461, 463, 393] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6072 | S-BLEU: 0.26 | FMSE: 7.3552e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 8-1-1000000000000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00029911170713603497, feature std is 0.010369117371737957.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3711 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 410, 505, 380, 368, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.3733 | S-BLEU: 0.18 | FMSE: 8.3956e-03 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.17 | ROUGE-L: 0.37| Token Acc: 68.38% | Label Acc: 68.38%\n",
      "Checking 8-1-1000000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.869855133118108e-05, feature std is 0.0010176807409152389.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3719 embeddings with positional data from imprinted layer.\n",
      "Assigned [464, 512, 470, 316, 512, 478, 455, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5703 | S-BLEU: 0.23 | FMSE: 7.2317e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.57| ROUGE2: 0.26 | ROUGE-L: 0.54| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-1-1000000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -53.56763458251953, feature std is 1012.3485717773438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 518 embeddings with positional data from imprinted layer.\n",
      "Could assemble only 3 seeds searching on threshold 0.08692782219839013.\n",
      "Filling with 5 random seeds...These sentences will be scrambled.\n",
      "Assigned [65, 406, 36, 6, 3, 1, 1] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.518169641494751, feature std is 100.91404724121094.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1776 embeddings with positional data from imprinted layer.\n",
      "Assigned [120, 512, 248, 124, 428, 38, 91, 215] breached embeddings to each sentence.\n",
      "Checking 8-1-1000000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.029893090948462486, feature std is 1.0350741147994995.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3701 embeddings with positional data from imprinted layer.\n",
      "Assigned [461, 455, 462, 471, 466, 468, 460, 458] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7029 | S-BLEU: 0.40 | FMSE: 2.4709e-03 | \n",
      " G-BLEU: 0.39 | ROUGE1: 0.70| ROUGE2: 0.43 | ROUGE-L: 0.66| Token Acc: 85.08% | Label Acc: 85.08%\n",
      "Checking 8-1-1000000000000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004936255048960447, feature std is 0.10076188296079636.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3731 embeddings with positional data from imprinted layer.\n",
      "Assigned [451, 512, 512, 431, 512, 434, 433, 446] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4338 | S-BLEU: 0.21 | FMSE: 8.2443e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.49| ROUGE2: 0.20 | ROUGE-L: 0.41| Token Acc: 69.65% | Label Acc: 69.65%\n",
      "Checking 8-1-1000000000000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0002840975939761847, feature std is 0.010347542352974415.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3716 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 386, 404, 366, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4084 | S-BLEU: 0.19 | FMSE: 8.3824e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.47| ROUGE2: 0.20 | ROUGE-L: 0.40| Token Acc: 68.33% | Label Acc: 68.33%\n",
      "Checking 8-1-1000000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.127201332768891e-05, feature std is 0.0009587359963916242.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 374, 328, 512, 512, 474] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4185 | S-BLEU: 0.19 | FMSE: 8.5278e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.48| ROUGE2: 0.19 | ROUGE-L: 0.40| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-0.1-10.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.2501444816589355, feature std is 1011.479736328125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1736 embeddings with positional data from imprinted layer.\n",
      "Assigned [223, 84, 153, 150, 95, 208, 512, 311] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.9697611331939697, feature std is 101.0912094116211.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3527 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 255, 500, 512, 512, 512, 337, 387] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0193 | S-BLEU: 0.01 | FMSE: 3.0326e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.90% | Label Acc: 97.90%\n",
      "Checking 8-0.1-10.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0365263894200325, feature std is 0.9099733829498291.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3844 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 405, 367, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0781 | S-BLEU: 0.10 | FMSE: 1.0665e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.36| ROUGE2: 0.05 | ROUGE-L: 0.16| Token Acc: 79.96% | Label Acc: 79.96%\n",
      "Checking 8-0.1-10.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0027666217647492886, feature std is 0.08471039682626724.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3882 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 502, 512, 308] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1072 | S-BLEU: 0.14 | FMSE: 9.9265e-03 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.42| ROUGE2: 0.07 | ROUGE-L: 0.19| Token Acc: 88.28% | Label Acc: 88.28%\n",
      "Checking 8-0.1-10.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0003201144572813064, feature std is 0.008330567739903927.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3851 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 417, 505, 512, 512, 512, 369, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0498 | S-BLEU: 0.07 | FMSE: 9.8879e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.39| ROUGE2: 0.03 | ROUGE-L: 0.15| Token Acc: 87.70% | Label Acc: 87.70%\n",
      "Checking 8-0.1-10.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.070527888368815e-05, feature std is 0.000786628108471632.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3869 embeddings with positional data from imprinted layer.\n",
      "Assigned [426, 371, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0608 | S-BLEU: 0.08 | FMSE: 1.0215e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.40| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 89.75% | Label Acc: 89.75%\n",
      "Checking 8-0.1-10.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -31.585437774658203, feature std is 1063.5926513671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1520 embeddings with positional data from imprinted layer.\n",
      "Assigned [66, 74, 203, 214, 97, 316, 260, 290] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.1526451110839844, feature std is 101.25218200683594.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3442 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 384, 208, 512, 408, 512, 512, 394] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0281 | S-BLEU: 0.01 | FMSE: 2.8650e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.97% | Label Acc: 97.97%\n",
      "Checking 8-0.1-10.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004115041811019182, feature std is 1.0096535682678223.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3785 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [512, 512, 370, 343, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0513 | S-BLEU: 0.07 | FMSE: 1.2849e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.28| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 70.39% | Label Acc: 70.39%\n",
      "Checking 8-0.1-10.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.007592594251036644, feature std is 0.09725253283977509.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3828 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 396, 512, 512, 512, 360, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0459 | S-BLEU: 0.07 | FMSE: 1.1287e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 68.92% | Label Acc: 68.92%\n",
      "Checking 8-0.1-10.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00013877636229153723, feature std is 0.009927249513566494.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3819 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 235, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0718 | S-BLEU: 0.08 | FMSE: 1.0751e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.29| ROUGE2: 0.03 | ROUGE-L: 0.12| Token Acc: 69.26% | Label Acc: 69.26%\n",
      "Checking 8-0.1-10.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00015820760745555162, feature std is 0.0010647873859852552.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3790 embeddings with positional data from imprinted layer.\n",
      "Assigned [456, 472, 457, 512, 512, 512, 357, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1074 | S-BLEU: 0.12 | FMSE: 1.1678e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.30| ROUGE2: 0.06 | ROUGE-L: 0.14| Token Acc: 68.77% | Label Acc: 68.77%\n",
      "Checking 8-0.1-10.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -99.51048278808594, feature std is 985.416259765625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1677 embeddings with positional data from imprinted layer.\n",
      "Assigned [279, 249, 129, 209, 73, 184, 285, 269] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.501110076904297, feature std is 104.01595306396484.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3400 embeddings with positional data from imprinted layer.\n",
      "Assigned [355, 512, 512, 512, 512, 512, 303, 182] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0251 | S-BLEU: 0.01 | FMSE: 2.9576e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.05% | Label Acc: 98.05%\n",
      "Checking 8-0.1-10.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.11534241586923599, feature std is 1.0205214023590088.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 480, 353, 481, 512, 388, 512, 498] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1096 | S-BLEU: 0.08 | FMSE: 1.1151e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.31| ROUGE2: 0.04 | ROUGE-L: 0.14| Token Acc: 69.63% | Label Acc: 69.63%\n",
      "Checking 8-0.1-10.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0016235241200774908, feature std is 0.10074634104967117.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3733 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 425, 236, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1514 | S-BLEU: 0.14 | FMSE: 1.1805e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.08 | ROUGE-L: 0.18| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-0.1-10.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00012065843475284055, feature std is 0.009352981112897396.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3724 embeddings with positional data from imprinted layer.\n",
      "Assigned [246, 512, 512, 512, 512, 512, 512, 406] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0530 | S-BLEU: 0.05 | FMSE: 1.2003e-02 | \n",
      " G-BLEU: 0.07 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-0.1-10.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.849674835189944e-06, feature std is 0.0009471644298173487.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 406, 512, 512, 387, 512, 372] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0442 | S-BLEU: 0.05 | FMSE: 1.2466e-02 | \n",
      " G-BLEU: 0.07 | ROUGE1: 0.28| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-0.1-10.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 69.23847961425781, feature std is 991.1961059570312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1862 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 213, 421, 149, 139, 93, 212, 123] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.4001399874687195, feature std is 96.63292694091797.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3393 embeddings with positional data from imprinted layer.\n",
      "Assigned [397, 512, 486, 512, 187, 512, 275, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0212 | S-BLEU: 0.01 | FMSE: 3.4548e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 97.83% | Label Acc: 97.83%\n",
      "Checking 8-0.1-10.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.019670139998197556, feature std is 0.9982631206512451.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3735 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 276, 387, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0759 | S-BLEU: 0.09 | FMSE: 1.1287e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.03 | ROUGE-L: 0.11| Token Acc: 69.36% | Label Acc: 69.36%\n",
      "Checking 8-0.1-10.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.009875326417386532, feature std is 0.09837642312049866.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 415, 512, 351, 410, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0618 | S-BLEU: 0.07 | FMSE: 1.1804e-02 | \n",
      " G-BLEU: 0.07 | ROUGE1: 0.28| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-0.1-10.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004247092001605779, feature std is 0.00989148486405611.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 339, 512, 347, 496, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0757 | S-BLEU: 0.07 | FMSE: 1.2340e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.03 | ROUGE-L: 0.11| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-0.1-10.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.3308592062676325e-05, feature std is 0.0009909048676490784.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3727 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 407, 374, 512, 386] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0623 | S-BLEU: 0.06 | FMSE: 1.2222e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.29| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-0.1-10.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -66.78749084472656, feature std is 957.432861328125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1671 embeddings with positional data from imprinted layer.\n",
      "Assigned [107, 167, 132, 95, 512, 256, 143, 259] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.11439913511276245, feature std is 103.30363464355469.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3394 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 359, 401, 512, 379, 207, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0168 | S-BLEU: 0.01 | FMSE: 3.1794e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.07% | Label Acc: 98.07%\n",
      "Checking 8-0.1-10.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.06022251024842262, feature std is 0.9395942687988281.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3759 embeddings with positional data from imprinted layer.\n",
      "Assigned [327, 512, 512, 502, 512, 512, 370, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0554 | S-BLEU: 0.05 | FMSE: 1.2392e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.30| ROUGE2: 0.02 | ROUGE-L: 0.11| Token Acc: 69.65% | Label Acc: 69.65%\n",
      "Checking 8-0.1-10.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0064554717391729355, feature std is 0.09796592593193054.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3740 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 381, 475, 512, 512, 324] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0845 | S-BLEU: 0.07 | FMSE: 1.1455e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.28| ROUGE2: 0.02 | ROUGE-L: 0.12| Token Acc: 68.26% | Label Acc: 68.26%\n",
      "Checking 8-0.1-10.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00029463492683134973, feature std is 0.010087431408464909.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3731 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 267, 512, 512, 392, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0581 | S-BLEU: 0.07 | FMSE: 1.2419e-02 | \n",
      " G-BLEU: 0.08 | ROUGE1: 0.28| ROUGE2: 0.02 | ROUGE-L: 0.10| Token Acc: 68.12% | Label Acc: 68.12%\n",
      "Checking 8-0.1-10.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.37428669910878e-05, feature std is 0.0009888381464406848.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3706 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 320, 512, 512, 314, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1343 | S-BLEU: 0.12 | FMSE: 1.0811e-02 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.31| ROUGE2: 0.06 | ROUGE-L: 0.16| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-0.1-100.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -29.249971389770508, feature std is 322.6967468261719.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3404 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 462, 422, 413, 409, 436, 313, 437] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0166 | S-BLEU: 0.01 | FMSE: 6.1536e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.32% | Label Acc: 98.32%\n",
      "Checking 8-0.1-100.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.2533447742462158, feature std is 38.78813934326172.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3774 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 431, 342, 441, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0215 | S-BLEU: 0.01 | FMSE: 1.9154e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.39% | Label Acc: 99.39%\n",
      "Checking 8-0.1-100.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0010699717095121741, feature std is 0.40294161438941956.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3875 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 291, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0178 | S-BLEU: 0.01 | FMSE: 2.8119e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.03 | ROUGE-L: 0.15| Token Acc: 96.41% | Label Acc: 96.41%\n",
      "Checking 8-0.1-100.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0016790966037660837, feature std is 0.04577643796801567.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3895 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 447, 512, 512, 376, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0281 | S-BLEU: 0.01 | FMSE: 6.5314e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 96.26% | Label Acc: 96.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 8-0.1-100.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.15422720531933e-05, feature std is 0.004096148069947958.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3833 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 333, 500, 440] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0193 | S-BLEU: 0.01 | FMSE: 2.6632e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 95.65% | Label Acc: 95.65%\n",
      "Checking 8-0.1-100.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.480847433616873e-05, feature std is 0.0003861151053570211.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3862 embeddings with positional data from imprinted layer.\n",
      "Assigned [474, 493, 486, 484, 470, 485, 482, 488] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0239 | S-BLEU: 0.01 | FMSE: 2.1774e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.85% | Label Acc: 99.85%\n",
      "Checking 8-0.1-100.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 38.256717681884766, feature std is 976.20556640625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1850 embeddings with positional data from imprinted layer.\n",
      "Assigned [154, 242, 274, 263, 28, 256, 512, 121] breached embeddings to each sentence.\n",
      "Checking 8-0.1-100.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.2934763431549072, feature std is 91.48516845703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3569 embeddings with positional data from imprinted layer.\n",
      "Assigned [461, 512, 372, 512, 176, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0474 | S-BLEU: 0.01 | FMSE: 2.8635e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.19% | Label Acc: 98.19%\n",
      "Checking 8-0.1-100.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.09034032374620438, feature std is 0.9394063353538513.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3862 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 451, 441, 478, 444] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6663 | S-BLEU: 0.45 | FMSE: 4.3023e-03 | \n",
      " G-BLEU: 0.41 | ROUGE1: 0.69| ROUGE2: 0.45 | ROUGE-L: 0.64| Token Acc: 83.33% | Label Acc: 83.33%\n",
      "Checking 8-0.1-100.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0006168413674458861, feature std is 0.09313482791185379.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3849 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 265, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.2422 | S-BLEU: 0.20 | FMSE: 9.6250e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.42| ROUGE2: 0.14 | ROUGE-L: 0.27| Token Acc: 77.08% | Label Acc: 77.08%\n",
      "Checking 8-0.1-100.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00030105956830084324, feature std is 0.009999693371355534.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3855 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 457, 508, 512, 512, 512, 512, 330] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3621 | S-BLEU: 0.32 | FMSE: 7.8325e-03 | \n",
      " G-BLEU: 0.25 | ROUGE1: 0.46| ROUGE2: 0.24 | ROUGE-L: 0.36| Token Acc: 74.54% | Label Acc: 74.54%\n",
      "Checking 8-0.1-100.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.740044722799212e-05, feature std is 0.0009671835578046739.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3855 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 420, 512, 512, 363, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1338 | S-BLEU: 0.15 | FMSE: 1.0715e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.34| ROUGE2: 0.07 | ROUGE-L: 0.17| Token Acc: 73.93% | Label Acc: 73.93%\n",
      "Checking 8-0.1-100.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -41.81192398071289, feature std is 995.5432739257812.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1709 embeddings with positional data from imprinted layer.\n",
      "Assigned [128, 168, 262, 93, 198, 375, 327, 158] breached embeddings to each sentence.\n",
      "Checking 8-0.1-100.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.0208659172058105, feature std is 96.54033660888672.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3481 embeddings with positional data from imprinted layer.\n",
      "Assigned [434, 512, 505, 512, 502, 452, 359, 205] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0820 | S-BLEU: 0.02 | FMSE: 2.2147e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 98.22% | Label Acc: 98.22%\n",
      "Checking 8-0.1-100.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.054417189210653305, feature std is 0.9970241189002991.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3765 embeddings with positional data from imprinted layer.\n",
      "Assigned [451, 512, 283, 490, 493, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5867 | S-BLEU: 0.27 | FMSE: 7.1591e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.59| ROUGE2: 0.31 | ROUGE-L: 0.57| Token Acc: 70.09% | Label Acc: 70.09%\n",
      "Checking 8-0.1-100.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0023704676423221827, feature std is 0.09751264750957489.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3764 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 302, 512, 512, 390, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4148 | S-BLEU: 0.22 | FMSE: 7.7789e-03 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.49| ROUGE2: 0.21 | ROUGE-L: 0.40| Token Acc: 68.55% | Label Acc: 68.55%\n",
      "Checking 8-0.1-100.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0004122793034184724, feature std is 0.01054461020976305.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3776 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 463, 454, 512, 512, 341, 470] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1587 | S-BLEU: 0.13 | FMSE: 1.1024e-02 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.33| ROUGE2: 0.08 | ROUGE-L: 0.18| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-0.1-100.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.499236769741401e-05, feature std is 0.0010105423862114549.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3729 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 411, 310, 512, 512, 512, 512, 448] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3098 | S-BLEU: 0.18 | FMSE: 9.0389e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.42| ROUGE2: 0.15 | ROUGE-L: 0.31| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-0.1-100.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 28.15970230102539, feature std is 1014.0009765625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1683 embeddings with positional data from imprinted layer.\n",
      "Assigned [137, 70, 377, 192, 136, 305, 110, 356] breached embeddings to each sentence.\n",
      "Checking 8-0.1-100.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.098166823387146, feature std is 101.45006561279297.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3425 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 293, 500, 341, 512, 319, 512, 436] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0898 | S-BLEU: 0.01 | FMSE: 2.4020e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.24% | Label Acc: 98.24%\n",
      "Checking 8-0.1-100.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.06322689354419708, feature std is 1.0221953392028809.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 316, 512, 512, 495, 366, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3901 | S-BLEU: 0.24 | FMSE: 8.5164e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.47| ROUGE2: 0.21 | ROUGE-L: 0.38| Token Acc: 69.75% | Label Acc: 69.75%\n",
      "Checking 8-0.1-100.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0012233586749061942, feature std is 0.09820451587438583.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3726 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 372, 512, 512, 512, 282, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1631 | S-BLEU: 0.15 | FMSE: 1.0595e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.33| ROUGE2: 0.08 | ROUGE-L: 0.19| Token Acc: 68.36% | Label Acc: 68.36%\n",
      "Checking 8-0.1-100.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00011902857659151778, feature std is 0.009948689490556717.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3718 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 441, 512, 209, 508, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1831 | S-BLEU: 0.15 | FMSE: 1.1093e-02 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.33| ROUGE2: 0.08 | ROUGE-L: 0.20| Token Acc: 68.16% | Label Acc: 68.16%\n",
      "Checking 8-0.1-100.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.9503091607475653e-05, feature std is 0.0010460607009008527.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3743 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 435, 512, 512, 488, 512, 457, 315] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4458 | S-BLEU: 0.23 | FMSE: 8.0017e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.22 | ROUGE-L: 0.44| Token Acc: 68.14% | Label Acc: 68.14%\n",
      "Checking 8-0.1-100.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 54.03776168823242, feature std is 955.3932495117188.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1834 embeddings with positional data from imprinted layer.\n",
      "Assigned [214, 193, 371, 70, 258, 396, 268, 64] breached embeddings to each sentence.\n",
      "Checking 8-0.1-100.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.0561922788619995, feature std is 100.49141693115234.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3444 embeddings with positional data from imprinted layer.\n",
      "Assigned [421, 339, 417, 410, 413, 512, 420, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1506 | S-BLEU: 0.01 | FMSE: 1.4657e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.48| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.10% | Label Acc: 98.10%\n",
      "Checking 8-0.1-100.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.05390843376517296, feature std is 0.9846996665000916.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3738 embeddings with positional data from imprinted layer.\n",
      "Assigned [455, 469, 458, 469, 473, 472, 462, 480] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6362 | S-BLEU: 0.31 | FMSE: 6.6494e-03 | \n",
      " G-BLEU: 0.31 | ROUGE1: 0.63| ROUGE2: 0.35 | ROUGE-L: 0.61| Token Acc: 69.78% | Label Acc: 69.78%\n",
      "Checking 8-0.1-100.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00548099959269166, feature std is 0.09993552416563034.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3719 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 446, 466, 458, 474, 475, 474, 457] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6104 | S-BLEU: 0.26 | FMSE: 7.2449e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 68.38% | Label Acc: 68.38%\n",
      "Checking 8-0.1-100.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0012468654895201325, feature std is 0.009799075312912464.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3719 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 403, 512, 335, 512, 421] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1279 | S-BLEU: 0.10 | FMSE: 1.1515e-02 | \n",
      " G-BLEU: 0.09 | ROUGE1: 0.32| ROUGE2: 0.05 | ROUGE-L: 0.16| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-0.1-100.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.7579932318767533e-05, feature std is 0.001005997764877975.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3711 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 478, 512, 259, 512, 414, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2222 | S-BLEU: 0.15 | FMSE: 9.9642e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.36| ROUGE2: 0.10 | ROUGE-L: 0.24| Token Acc: 68.38% | Label Acc: 68.38%\n",
      "Checking 8-0.1-1000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.634716987609863, feature std is 350.35455322265625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3342 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 184, 499, 247, 364, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0142 | S-BLEU: 0.01 | FMSE: 5.4833e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.10% | Label Acc: 98.10%\n",
      "Checking 8-0.1-1000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.6823315620422363, feature std is 37.512901306152344.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3824 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 512, 493, 455, 512, 512, 512, 349] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0220 | S-BLEU: 0.01 | FMSE: 1.9466e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 99.29% | Label Acc: 99.29%\n",
      "Checking 8-0.1-1000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.010605222545564175, feature std is 0.36212390661239624.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3863 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 279, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.0386 | S-BLEU: 0.01 | FMSE: 4.0124e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.54% | Label Acc: 98.54%\n",
      "Checking 8-0.1-1000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.000804112118203193, feature std is 0.032368626445531845.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3845 embeddings with positional data from imprinted layer.\n",
      "Assigned [481, 322, 482, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0190 | S-BLEU: 0.01 | FMSE: 1.6658e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.17| Token Acc: 99.83% | Label Acc: 99.83%\n",
      "Checking 8-0.1-1000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.317874870845117e-05, feature std is 0.0034637751523405313.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3860 embeddings with positional data from imprinted layer.\n",
      "Assigned [452, 512, 408, 440, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0371 | S-BLEU: 0.01 | FMSE: 2.0215e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.44% | Label Acc: 99.44%\n",
      "Checking 8-0.1-1000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.0415171750064474e-06, feature std is 0.000282300723483786.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3836 embeddings with positional data from imprinted layer.\n",
      "Assigned [484, 480, 473, 483, 483, 472, 480, 481] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0259 | S-BLEU: 0.01 | FMSE: 1.3289e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 99.83% | Label Acc: 99.83%\n",
      "Checking 8-0.1-1000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -30.641172409057617, feature std is 967.7684936523438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1740 embeddings with positional data from imprinted layer.\n",
      "Assigned [399, 188, 180, 63, 240, 235, 202, 233] breached embeddings to each sentence.\n",
      "Checking 8-0.1-1000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.25025156140327454, feature std is 95.2967300415039.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3522 embeddings with positional data from imprinted layer.\n",
      "Assigned [297, 512, 469, 512, 512, 322, 512, 386] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0981 | S-BLEU: 0.02 | FMSE: 2.5170e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.41% | Label Acc: 98.41%\n",
      "Checking 8-0.1-1000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.02965201437473297, feature std is 0.9624236226081848.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3855 embeddings with positional data from imprinted layer.\n",
      "Assigned [469, 512, 512, 512, 314, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3564 | S-BLEU: 0.29 | FMSE: 7.9967e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.49| ROUGE2: 0.23 | ROUGE-L: 0.37| Token Acc: 77.95% | Label Acc: 77.95%\n",
      "Checking 8-0.1-1000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.001362121431156993, feature std is 0.09604977071285248.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3854 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 444, 512, 338, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3494 | S-BLEU: 0.29 | FMSE: 8.0301e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.47| ROUGE2: 0.22 | ROUGE-L: 0.36| Token Acc: 75.54% | Label Acc: 75.54%\n",
      "Checking 8-0.1-1000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00017455857596360147, feature std is 0.009721936658024788.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3840 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 473, 512, 473, 475, 409, 474, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7107 | S-BLEU: 0.44 | FMSE: 4.7004e-03 | \n",
      " G-BLEU: 0.41 | ROUGE1: 0.70| ROUGE2: 0.46 | ROUGE-L: 0.68| Token Acc: 80.10% | Label Acc: 80.10%\n",
      "Checking 8-0.1-1000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.246048335218802e-05, feature std is 0.0010115117765963078.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3835 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 251, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1899 | S-BLEU: 0.18 | FMSE: 1.0824e-02 | \n",
      " G-BLEU: 0.14 | ROUGE1: 0.37| ROUGE2: 0.11 | ROUGE-L: 0.22| Token Acc: 74.76% | Label Acc: 74.76%\n",
      "Checking 8-0.1-1000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -75.17935943603516, feature std is 979.5581665039062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1652 embeddings with positional data from imprinted layer.\n",
      "Assigned [287, 196, 180, 295, 122, 226, 152, 194] breached embeddings to each sentence.\n",
      "Checking 8-0.1-1000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 9.634843826293945, feature std is 103.02059936523438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3456 embeddings with positional data from imprinted layer.\n",
      "Assigned [432, 437, 452, 137, 462, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1379 | S-BLEU: 0.02 | FMSE: 1.4855e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.10% | Label Acc: 98.10%\n",
      "Checking 8-0.1-1000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.021392127498984337, feature std is 0.9757209420204163.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3769 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 336, 512, 512, 512, 512, 361, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2671 | S-BLEU: 0.15 | FMSE: 1.0540e-02 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.38| ROUGE2: 0.11 | ROUGE-L: 0.25| Token Acc: 69.56% | Label Acc: 69.56%\n",
      "Checking 8-0.1-1000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0018807030282914639, feature std is 0.10020218789577484.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3712 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 238, 512, 453, 512, 512, 512, 461] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2520 | S-BLEU: 0.17 | FMSE: 9.6610e-03 | \n",
      " G-BLEU: 0.15 | ROUGE1: 0.39| ROUGE2: 0.13 | ROUGE-L: 0.27| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-0.1-1000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.00014180492144078016, feature std is 0.010107330046594143.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3760 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 485, 412, 303] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3633 | S-BLEU: 0.21 | FMSE: 8.0442e-03 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.44| ROUGE2: 0.18 | ROUGE-L: 0.36| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-0.1-1000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.562858859775588e-05, feature std is 0.0010115151526406407.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3745 embeddings with positional data from imprinted layer.\n",
      "Assigned [448, 512, 251, 512, 512, 512, 486, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2117 | S-BLEU: 0.15 | FMSE: 1.0366e-02 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.36| ROUGE2: 0.09 | ROUGE-L: 0.22| Token Acc: 68.46% | Label Acc: 68.46%\n",
      "Checking 8-0.1-1000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 32.305274963378906, feature std is 1002.4638671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1724 embeddings with positional data from imprinted layer.\n",
      "Assigned [139, 233, 196, 204, 228, 305, 231, 188] breached embeddings to each sentence.\n",
      "Checking 8-0.1-1000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.0230265855789185, feature std is 101.46770477294922.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3482 embeddings with positional data from imprinted layer.\n",
      "Assigned [483, 512, 512, 381, 291, 512, 279, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0864 | S-BLEU: 0.01 | FMSE: 2.0547e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.29% | Label Acc: 98.29%\n",
      "Checking 8-0.1-1000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.04307645186781883, feature std is 0.9876986742019653.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3741 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 474, 512, 195, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.2803 | S-BLEU: 0.21 | FMSE: 9.3274e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.40| ROUGE2: 0.16 | ROUGE-L: 0.30| Token Acc: 69.51% | Label Acc: 69.51%\n",
      "Checking 8-0.1-1000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.005352628417313099, feature std is 0.10472841560840607.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [270, 512, 464, 482, 512, 512, 472, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5027 | S-BLEU: 0.20 | FMSE: 7.6782e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.53| ROUGE2: 0.22 | ROUGE-L: 0.48| Token Acc: 68.09% | Label Acc: 68.09%\n",
      "Checking 8-0.1-1000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -8.768477709963918e-05, feature std is 0.009637485258281231.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3713 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 450, 467, 236] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4783 | S-BLEU: 0.22 | FMSE: 8.4379e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.52| ROUGE2: 0.23 | ROUGE-L: 0.46| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-0.1-1000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.504109579604119e-05, feature std is 0.0009959014132618904.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3736 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 401, 424, 351] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4116 | S-BLEU: 0.21 | FMSE: 8.5170e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.48| ROUGE2: 0.21 | ROUGE-L: 0.41| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-0.1-1000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 36.84965896606445, feature std is 1067.0338134765625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1602 embeddings with positional data from imprinted layer.\n",
      "Assigned [435, 124, 241, 163, 245, 124, 160, 110] breached embeddings to each sentence.\n",
      "Checking 8-0.1-1000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.7251942157745361, feature std is 91.25839233398438.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3467 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 342, 512, 408, 472, 281, 428, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1206 | S-BLEU: 0.02 | FMSE: 2.1483e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.47| ROUGE2: 0.03 | ROUGE-L: 0.19| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-0.1-1000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.01706923544406891, feature std is 0.9984752535820007.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3725 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [462, 456, 426, 459, 480, 512, 475, 455] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6248 | S-BLEU: 0.29 | FMSE: 6.6769e-03 | \n",
      " G-BLEU: 0.29 | ROUGE1: 0.62| ROUGE2: 0.33 | ROUGE-L: 0.59| Token Acc: 69.46% | Label Acc: 69.46%\n",
      "Checking 8-0.1-1000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.006038838066160679, feature std is 0.10559947788715363.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3742 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 417, 262, 512, 512, 503] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4749 | S-BLEU: 0.23 | FMSE: 7.2796e-03 | \n",
      " G-BLEU: 0.23 | ROUGE1: 0.52| ROUGE2: 0.25 | ROUGE-L: 0.46| Token Acc: 68.29% | Label Acc: 68.29%\n",
      "Checking 8-0.1-1000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0007189072202891111, feature std is 0.009714380837976933.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3701 embeddings with positional data from imprinted layer.\n",
      "Assigned [466, 456, 466, 459, 467, 460, 461, 466] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6155 | S-BLEU: 0.26 | FMSE: 7.0418e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.32 | ROUGE-L: 0.59| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-0.1-1000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.072498970548622e-05, feature std is 0.0010538462083786726.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3737 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 442, 223, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4443 | S-BLEU: 0.21 | FMSE: 8.1295e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.21 | ROUGE-L: 0.42| Token Acc: 67.97% | Label Acc: 67.97%\n",
      "Checking 8-0.1-10000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.7627058029174805, feature std is 360.17303466796875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49889, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3444 embeddings with positional data from imprinted layer.\n",
      "Assigned [448, 105, 512, 415, 512, 512, 512, 428] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0115 | S-BLEU: 0.01 | FMSE: 5.4804e-04 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 98.02% | Label Acc: 98.02%\n",
      "Checking 8-0.1-10000.0-10-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.05533880740404129, feature std is 39.191280364990234.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3793 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 466, 421, 512, 346, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0159 | S-BLEU: 0.01 | FMSE: 1.9725e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 97.34% | Label Acc: 97.34%\n",
      "Checking 8-0.1-10000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.03731062263250351, feature std is 0.37545695900917053.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3857 embeddings with positional data from imprinted layer.\n",
      "Assigned [273, 512, 512, 512, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0239 | S-BLEU: 0.01 | FMSE: 4.2962e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.16| Token Acc: 92.31% | Label Acc: 92.31%\n",
      "Checking 8-0.1-10000.0-10-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0008510651532560587, feature std is 0.03847426548600197.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3827 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 424, 512, 512, 405, 438] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0203 | S-BLEU: 0.01 | FMSE: 3.0352e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.43| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 96.34% | Label Acc: 96.34%\n",
      "Checking 8-0.1-10000.0-10-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.8416217901394702e-05, feature std is 0.0035513387992978096.\n",
      "Computing user update in model mode: eval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3857 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 273, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0164 | S-BLEU: 0.01 | FMSE: 1.7337e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.44| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 96.29% | Label Acc: 96.29%\n",
      "Checking 8-0.1-10000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.415961590595543e-06, feature std is 0.000355745229171589.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3833 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 483, 512, 512, 512, 388, 402, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0132 | S-BLEU: 0.01 | FMSE: 2.6319e-03 | \n",
      " G-BLEU: 0.11 | ROUGE1: 0.42| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 94.48% | Label Acc: 94.48%\n",
      "Checking 8-0.1-10000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 8.259414672851562, feature std is 990.3448486328125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1832 embeddings with positional data from imprinted layer.\n",
      "Assigned [38, 469, 110, 202, 226, 180, 219, 388] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10000.0-1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.40922626852989197, feature std is 95.27250671386719.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3597 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 270, 512, 512, 512, 322, 512, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0415 | S-BLEU: 0.01 | FMSE: 2.8230e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.16| Token Acc: 98.22% | Label Acc: 98.22%\n",
      "Checking 8-0.1-10000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.011663074605166912, feature std is 0.9959745407104492.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3863 embeddings with positional data from imprinted layer.\n",
      "Assigned [483, 471, 478, 499, 480, 483, 488, 481] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6987 | S-BLEU: 0.40 | FMSE: 5.3990e-03 | \n",
      " G-BLEU: 0.37 | ROUGE1: 0.69| ROUGE2: 0.42 | ROUGE-L: 0.67| Token Acc: 75.85% | Label Acc: 75.85%\n",
      "Checking 8-0.1-10000.0-1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005376037675887346, feature std is 0.09341297298669815.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3861 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 388, 512, 512, 401, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4136 | S-BLEU: 0.30 | FMSE: 7.2419e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.50| ROUGE2: 0.24 | ROUGE-L: 0.40| Token Acc: 78.83% | Label Acc: 78.83%\n",
      "Checking 8-0.1-10000.0-1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00052449363283813, feature std is 0.009749405086040497.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3893 embeddings with positional data from imprinted layer.\n",
      "Assigned [502, 382, 512, 512, 512, 482, 512, 479] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6560 | S-BLEU: 0.36 | FMSE: 5.7579e-03 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.63| Token Acc: 75.32% | Label Acc: 75.32%\n",
      "Checking 8-0.1-10000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.4829663491109386e-05, feature std is 0.001009150524623692.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3866 embeddings with positional data from imprinted layer.\n",
      "Assigned [492, 469, 477, 482, 487, 490, 481, 488] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.7144 | S-BLEU: 0.42 | FMSE: 5.1370e-03 | \n",
      " G-BLEU: 0.40 | ROUGE1: 0.70| ROUGE2: 0.45 | ROUGE-L: 0.68| Token Acc: 77.78% | Label Acc: 77.78%\n",
      "Checking 8-0.1-10000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -67.84989166259766, feature std is 993.3914794921875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 49658, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1641 embeddings with positional data from imprinted layer.\n",
      "Assigned [243, 104, 174, 361, 204, 173, 165, 217] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10000.0-0.1-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.9612361192703247, feature std is 99.82087707519531.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3478 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [408, 512, 326, 392, 457, 512, 512, 359] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1140 | S-BLEU: 0.01 | FMSE: 1.9831e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.46| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 97.95% | Label Acc: 97.95%\n",
      "Checking 8-0.1-10000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.07354800403118134, feature std is 0.9541045427322388.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3767 embeddings with positional data from imprinted layer.\n",
      "Assigned [335, 512, 401, 512, 512, 512, 471, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3267 | S-BLEU: 0.18 | FMSE: 8.3859e-03 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.16 | ROUGE-L: 0.33| Token Acc: 69.58% | Label Acc: 69.58%\n",
      "Checking 8-0.1-10000.0-0.1-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0030600738245993853, feature std is 0.09785541146993637.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3730 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 451, 307, 473, 512, 483, 480, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5762 | S-BLEU: 0.25 | FMSE: 7.5097e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.29 | ROUGE-L: 0.55| Token Acc: 68.46% | Label Acc: 68.46%\n",
      "Checking 8-0.1-10000.0-0.1-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.7749085347750224e-05, feature std is 0.01003124937415123.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3767 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 512, 512, 183, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4763 | S-BLEU: 0.21 | FMSE: 8.5966e-03 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.52| ROUGE2: 0.23 | ROUGE-L: 0.46| Token Acc: 68.48% | Label Acc: 68.48%\n",
      "Checking 8-0.1-10000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.6622067050775513e-05, feature std is 0.0009684173273853958.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3761 embeddings with positional data from imprinted layer.\n",
      "Assigned [316, 512, 411, 512, 512, 512, 512, 474] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.3440 | S-BLEU: 0.15 | FMSE: 8.9609e-03 | \n",
      " G-BLEU: 0.16 | ROUGE1: 0.43| ROUGE2: 0.14 | ROUGE-L: 0.33| Token Acc: 68.19% | Label Acc: 68.19%\n",
      "Checking 8-0.1-10000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -15.57638168334961, feature std is 1007.933349609375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1661 embeddings with positional data from imprinted layer.\n",
      "Assigned [284, 220, 176, 123, 355, 237, 185, 81] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10000.0-0.01-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.518501281738281, feature std is 98.56505584716797.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3463 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 335, 512, 512, 253, 512, 315, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0820 | S-BLEU: 0.01 | FMSE: 2.5819e-03 | \n",
      " G-BLEU: 0.12 | ROUGE1: 0.45| ROUGE2: 0.03 | ROUGE-L: 0.18| Token Acc: 98.05% | Label Acc: 98.05%\n",
      "Checking 8-0.1-10000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.02101510763168335, feature std is 1.0153279304504395.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3700 embeddings with positional data from imprinted layer.\n",
      "Assigned [474, 467, 512, 512, 512, 447, 463, 313] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5803 | S-BLEU: 0.25 | FMSE: 6.4900e-03 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.58| ROUGE2: 0.29 | ROUGE-L: 0.55| Token Acc: 69.31% | Label Acc: 69.31%\n",
      "Checking 8-0.1-10000.0-0.01-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004828247707337141, feature std is 0.09813346713781357.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3734 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 473, 512, 512, 512, 355, 346, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.5664 | S-BLEU: 0.22 | FMSE: 7.3132e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.57| ROUGE2: 0.26 | ROUGE-L: 0.53| Token Acc: 68.21% | Label Acc: 68.21%\n",
      "Checking 8-0.1-10000.0-0.01-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0002516054955776781, feature std is 0.010121027007699013.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3712 embeddings with positional data from imprinted layer.\n",
      "Assigned [396, 387, 440, 512, 441, 512, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4746 | S-BLEU: 0.21 | FMSE: 7.6424e-03 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.51| ROUGE2: 0.23 | ROUGE-L: 0.45| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 8-0.1-10000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.622184133040719e-05, feature std is 0.0009890266228467226.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3754 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 213, 512, 512, 512, 469, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5386 | S-BLEU: 0.23 | FMSE: 7.2180e-03 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.55| ROUGE2: 0.26 | ROUGE-L: 0.51| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-0.1-10000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -101.9803466796875, feature std is 1001.667236328125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 1648 embeddings with positional data from imprinted layer.\n",
      "Assigned [211, 176, 75, 235, 207, 354, 217, 173] breached embeddings to each sentence.\n",
      "Checking 8-0.1-10000.0-0.001-100.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.7736408710479736, feature std is 101.084716796875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50203, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3415 embeddings with positional data from imprinted layer.\n",
      "Assigned [392, 400, 428, 361, 457, 424, 441, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.1487 | S-BLEU: 0.01 | FMSE: 1.3964e-03 | \n",
      " G-BLEU: 0.13 | ROUGE1: 0.49| ROUGE2: 0.04 | ROUGE-L: 0.20| Token Acc: 98.22% | Label Acc: 98.22%\n",
      "Checking 8-0.1-10000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.05769116431474686, feature std is 1.0210294723510742.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3733 embeddings with positional data from imprinted layer.\n",
      "Assigned [473, 512, 512, 512, 469, 475, 444, 336] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6023 | S-BLEU: 0.25 | FMSE: 6.6864e-03 | \n",
      " G-BLEU: 0.27 | ROUGE1: 0.61| ROUGE2: 0.30 | ROUGE-L: 0.58| Token Acc: 69.60% | Label Acc: 69.60%\n",
      "Checking 8-0.1-10000.0-0.001-0.1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0010260682320222259, feature std is 0.09701436758041382.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3728 embeddings with positional data from imprinted layer.\n",
      "Assigned [465, 446, 468, 512, 473, 472, 512, 380] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6077 | S-BLEU: 0.27 | FMSE: 7.6017e-03 | \n",
      " G-BLEU: 0.28 | ROUGE1: 0.61| ROUGE2: 0.31 | ROUGE-L: 0.58| Token Acc: 68.24% | Label Acc: 68.24%\n",
      "Checking 8-0.1-10000.0-0.001-0.01\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00011246249778196216, feature std is 0.009999671019613743.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([   11,    11,    11,  ..., 50210, 50210, 50210]) through strategy embedding-norm.\n",
      "Recovered 3723 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 463, 512, 284, 503, 425, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "Checking 8-0.1-10000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10254/2122966110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreaching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mattacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreaching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/__init__.py\u001b[0m in \u001b[0;36mconstruct_case\u001b[0;34m(cfg_case, setup, external_dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# User:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_case\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/users.py\u001b[0m in \u001b[0;36mconstruct_user\u001b[0;34m(model, loss_fn, cfg_case, setup)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"local_gradient\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# The user will deepcopy this model template to have their own\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/data/data_preparation.py\u001b[0m in \u001b[0;36mconstruct_dataloader\u001b[0;34m(cfg_data, cfg_impl, user_idx, return_full_dataset)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         dataset, collate_fn = _build_and_split_dataset_text(\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mcfg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples_from_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/data/datasets_text.py\u001b[0m in \u001b[0;36m_build_and_split_dataset_text\u001b[0;34m(cfg_data, split, user_idx, return_full_dataset)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mraw_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wikitext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wikitext-103-v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mraw_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_wikipedia_into_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"stackoverflow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/data/datasets_text.py\u001b[0m in \u001b[0;36m_split_wikipedia_into_articles\u001b[0;34m(dataset, user_idx, return_full_dataset, min_length)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0marticle_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\" = \"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\" ; \"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# exclude table headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   1916\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   1901\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pylist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_server = dict()\n",
    "for v_length in [8, 16, 32, 48, 64]:\n",
    "    for eps in [10, 1, 0.1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]:\n",
    "        for softmax_skew in [1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9, 1e10, 1e11, 1e12]:\n",
    "            for sequence_token_weight in [10, 1, 0.1, 0.01, 1e-3]:\n",
    "                for measurement_scale in [1e3, 1e2, 1, 0.1, 1e-2, 1e-3]:\n",
    "                    key = f\"{v_length}-{eps}-{softmax_skew}-{sequence_token_weight}-{measurement_scale}\"\n",
    "                    print(f\"Checking {key}\")\n",
    "                    cfg.attack.token_strategy=\"embedding-norm\"\n",
    "                    cfg.case.server.param_modification.v_length = v_length\n",
    "\n",
    "                    cfg.case.server.param_modification.eps = eps\n",
    "                    cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "                    cfg.case.server.param_modification.softmax_skew = softmax_skew\n",
    "                    cfg.case.server.param_modification.sequence_token_weight = sequence_token_weight\n",
    "\n",
    "                    cfg.case.server.param_modification.measurement_scale = measurement_scale\n",
    "\n",
    "                    cfg.case.server.pretrained = False\n",
    "\n",
    "                    user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "                    attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "\n",
    "                    server_payload = server.distribute_payload()\n",
    "                    shared_data, true_user_data = user.compute_local_updates(server_payload)\n",
    "                    try:\n",
    "                        reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "                        metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                                            server.model, cfg_case=cfg.case, setup=setup)\n",
    "\n",
    "                        results_server[key] = metrics[\"accuracy\"]\n",
    "                    except:\n",
    "                        results_server[key] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44a136be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735595703125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results_server.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c32e51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8-10-10.0-10-1000.0': 0.0,\n",
       " '8-10-10.0-10-100.0': 0.0,\n",
       " '8-10-10.0-10-1': 0.0224609375,\n",
       " '8-10-10.0-10-0.1': 0.068115234375,\n",
       " '8-10-10.0-10-0.01': 0.06396484375,\n",
       " '8-10-10.0-10-0.001': 0.052978515625,\n",
       " '8-10-10.0-1-1000.0': 0.0,\n",
       " '8-10-10.0-1-100.0': 0.0,\n",
       " '8-10-10.0-1-1': 0.022216796875,\n",
       " '8-10-10.0-1-0.1': 0.058837890625,\n",
       " '8-10-10.0-1-0.01': 0.077880859375,\n",
       " '8-10-10.0-1-0.001': 0.05419921875,\n",
       " '8-10-10.0-0.1-1000.0': 0.0,\n",
       " '8-10-10.0-0.1-100.0': 0.0,\n",
       " '8-10-10.0-0.1-1': 0.0205078125,\n",
       " '8-10-10.0-0.1-0.1': 0.1025390625,\n",
       " '8-10-10.0-0.1-0.01': 0.083251953125,\n",
       " '8-10-10.0-0.1-0.001': 0.052490234375,\n",
       " '8-10-10.0-0.01-1000.0': 0.0,\n",
       " '8-10-10.0-0.01-100.0': 0.0,\n",
       " '8-10-10.0-0.01-1': 0.020751953125,\n",
       " '8-10-10.0-0.01-0.1': 0.055419921875,\n",
       " '8-10-10.0-0.01-0.01': 0.08251953125,\n",
       " '8-10-10.0-0.01-0.001': 0.07763671875,\n",
       " '8-10-10.0-0.001-1000.0': 0.0,\n",
       " '8-10-10.0-0.001-100.0': 0.0,\n",
       " '8-10-10.0-0.001-1': 0.02197265625,\n",
       " '8-10-10.0-0.001-0.1': 0.09228515625,\n",
       " '8-10-10.0-0.001-0.01': 0.051513671875,\n",
       " '8-10-10.0-0.001-0.001': 0.097900390625,\n",
       " '8-10-100.0-10-1000.0': 0.0,\n",
       " '8-10-100.0-10-100.0': 0.0,\n",
       " '8-10-100.0-10-1': 0.02587890625,\n",
       " '8-10-100.0-10-0.1': 0.010009765625,\n",
       " '8-10-100.0-10-0.01': 0.049072265625,\n",
       " '8-10-100.0-10-0.001': 0.03515625,\n",
       " '8-10-100.0-1-1000.0': 0.0,\n",
       " '8-10-100.0-1-100.0': 0.0,\n",
       " '8-10-100.0-1-1': 0.0703125,\n",
       " '8-10-100.0-1-0.1': 0.563232421875,\n",
       " '8-10-100.0-1-0.01': 0.244873046875,\n",
       " '8-10-100.0-1-0.001': 0.6318359375,\n",
       " '8-10-100.0-0.1-1000.0': 0.0,\n",
       " '8-10-100.0-0.1-100.0': 0.0,\n",
       " '8-10-100.0-0.1-1': 0.03271484375,\n",
       " '8-10-100.0-0.1-0.1': 0.25244140625,\n",
       " '8-10-100.0-0.1-0.01': 0.243896484375,\n",
       " '8-10-100.0-0.1-0.001': 0.37060546875,\n",
       " '8-10-100.0-0.01-1000.0': 0.0,\n",
       " '8-10-100.0-0.01-100.0': 0.0,\n",
       " '8-10-100.0-0.01-1': 0.049560546875,\n",
       " '8-10-100.0-0.01-0.1': 0.40234375,\n",
       " '8-10-100.0-0.01-0.01': 0.184326171875,\n",
       " '8-10-100.0-0.01-0.001': 0.41943359375,\n",
       " '8-10-100.0-0.001-1000.0': 0.0,\n",
       " '8-10-100.0-0.001-100.0': 0.0,\n",
       " '8-10-100.0-0.001-1': 0.036865234375,\n",
       " '8-10-100.0-0.001-0.1': 0.363037109375,\n",
       " '8-10-100.0-0.001-0.01': 0.224609375,\n",
       " '8-10-100.0-0.001-0.001': 0.14208984375,\n",
       " '8-10-1000.0-10-1000.0': 0.0,\n",
       " '8-10-1000.0-10-100.0': 0.0,\n",
       " '8-10-1000.0-10-1': 0.017822265625,\n",
       " '8-10-1000.0-10-0.1': 0.035888671875,\n",
       " '8-10-1000.0-10-0.01': 0.05615234375,\n",
       " '8-10-1000.0-10-0.001': 0.02978515625,\n",
       " '8-10-1000.0-1-1000.0': 0.0,\n",
       " '8-10-1000.0-1-100.0': 0.0,\n",
       " '8-10-1000.0-1-1': 0.088623046875,\n",
       " '8-10-1000.0-1-0.1': 0.43701171875,\n",
       " '8-10-1000.0-1-0.01': 0.532958984375,\n",
       " '8-10-1000.0-1-0.001': 0.411376953125,\n",
       " '8-10-1000.0-0.1-1000.0': 0.0,\n",
       " '8-10-1000.0-0.1-100.0': 0.0,\n",
       " '8-10-1000.0-0.1-1': 0.037353515625,\n",
       " '8-10-1000.0-0.1-0.1': 0.694091796875,\n",
       " '8-10-1000.0-0.1-0.01': 0.472900390625,\n",
       " '8-10-1000.0-0.1-0.001': 0.18310546875,\n",
       " '8-10-1000.0-0.01-1000.0': 0.0,\n",
       " '8-10-1000.0-0.01-100.0': 0.0,\n",
       " '8-10-1000.0-0.01-1': 0.16259765625,\n",
       " '8-10-1000.0-0.01-0.1': 0.369384765625,\n",
       " '8-10-1000.0-0.01-0.01': 0.54638671875,\n",
       " '8-10-1000.0-0.01-0.001': 0.62353515625,\n",
       " '8-10-1000.0-0.001-1000.0': 0.0,\n",
       " '8-10-1000.0-0.001-100.0': 0.0,\n",
       " '8-10-1000.0-0.001-1': 0.08349609375,\n",
       " '8-10-1000.0-0.001-0.1': 0.282958984375,\n",
       " '8-10-1000.0-0.001-0.01': 0.246337890625,\n",
       " '8-10-1000.0-0.001-0.001': 0.247314453125,\n",
       " '8-10-10000.0-10-1000.0': 0.0,\n",
       " '8-10-10000.0-10-100.0': 0.0,\n",
       " '8-10-10000.0-10-1': 0.01953125,\n",
       " '8-10-10000.0-10-0.1': 0.01171875,\n",
       " '8-10-10000.0-10-0.01': 0.140869140625,\n",
       " '8-10-10000.0-10-0.001': 0.03515625,\n",
       " '8-10-10000.0-1-1000.0': 0.0,\n",
       " '8-10-10000.0-1-100.0': 0.0,\n",
       " '8-10-10000.0-1-1': 0.108642578125,\n",
       " '8-10-10000.0-1-0.1': 0.710205078125,\n",
       " '8-10-10000.0-1-0.01': 0.302490234375,\n",
       " '8-10-10000.0-1-0.001': 0.4599609375,\n",
       " '8-10-10000.0-0.1-1000.0': 0.0,\n",
       " '8-10-10000.0-0.1-100.0': 0.0,\n",
       " '8-10-10000.0-0.1-1': 0.0791015625,\n",
       " '8-10-10000.0-0.1-0.1': 0.13916015625,\n",
       " '8-10-10000.0-0.1-0.01': 0.359375,\n",
       " '8-10-10000.0-0.1-0.001': 0.184814453125,\n",
       " '8-10-10000.0-0.01-1000.0': 0.0,\n",
       " '8-10-10000.0-0.01-100.0': 0.0,\n",
       " '8-10-10000.0-0.01-1': 0.041748046875,\n",
       " '8-10-10000.0-0.01-0.1': 0.683837890625,\n",
       " '8-10-10000.0-0.01-0.01': 0.278076171875,\n",
       " '8-10-10000.0-0.01-0.001': 0.62255859375,\n",
       " '8-10-10000.0-0.001-1000.0': 0.0,\n",
       " '8-10-10000.0-0.001-100.0': 0.0,\n",
       " '8-10-10000.0-0.001-1': 0.0693359375,\n",
       " '8-10-10000.0-0.001-0.1': 0.307861328125,\n",
       " '8-10-10000.0-0.001-0.01': 0.57958984375,\n",
       " '8-10-10000.0-0.001-0.001': 0.5537109375,\n",
       " '8-10-100000.0-10-1000.0': 0.0,\n",
       " '8-10-100000.0-10-100.0': 0.0,\n",
       " '8-10-100000.0-10-1': 0.010498046875,\n",
       " '8-10-100000.0-10-0.1': 0.033203125,\n",
       " '8-10-100000.0-10-0.01': 0.0341796875,\n",
       " '8-10-100000.0-10-0.001': 0.024658203125,\n",
       " '8-10-100000.0-1-1000.0': 0.0,\n",
       " '8-10-100000.0-1-100.0': 0.0,\n",
       " '8-10-100000.0-1-1': 0.134765625,\n",
       " '8-10-100000.0-1-0.1': 0.3251953125,\n",
       " '8-10-100000.0-1-0.01': 0.697265625,\n",
       " '8-10-100000.0-1-0.001': 0.15234375,\n",
       " '8-10-100000.0-0.1-1000.0': 0.0,\n",
       " '8-10-100000.0-0.1-100.0': 0.0,\n",
       " '8-10-100000.0-0.1-1': 0.086181640625,\n",
       " '8-10-100000.0-0.1-0.1': 0.688232421875,\n",
       " '8-10-100000.0-0.1-0.01': 0.354248046875,\n",
       " '8-10-100000.0-0.1-0.001': 0.59375,\n",
       " '8-10-100000.0-0.01-1000.0': 0.0,\n",
       " '8-10-100000.0-0.01-100.0': 0.0,\n",
       " '8-10-100000.0-0.01-1': 0.135986328125,\n",
       " '8-10-100000.0-0.01-0.1': 0.671875,\n",
       " '8-10-100000.0-0.01-0.01': 0.309814453125,\n",
       " '8-10-100000.0-0.01-0.001': 0.192626953125,\n",
       " '8-10-100000.0-0.001-1000.0': 0.0,\n",
       " '8-10-100000.0-0.001-100.0': 0.0,\n",
       " '8-10-100000.0-0.001-1': 0.078369140625,\n",
       " '8-10-100000.0-0.001-0.1': 0.21435546875,\n",
       " '8-10-100000.0-0.001-0.01': 0.540283203125,\n",
       " '8-10-100000.0-0.001-0.001': 0.34423828125,\n",
       " '8-10-1000000.0-10-1000.0': 0.0,\n",
       " '8-10-1000000.0-10-100.0': 0.0,\n",
       " '8-10-1000000.0-10-1': 0.013671875,\n",
       " '8-10-1000000.0-10-0.1': 0.01611328125,\n",
       " '8-10-1000000.0-10-0.01': 0.051513671875,\n",
       " '8-10-1000000.0-10-0.001': 0.017578125,\n",
       " '8-10-1000000.0-1-1000.0': 0.0,\n",
       " '8-10-1000000.0-1-100.0': 0.0,\n",
       " '8-10-1000000.0-1-1': 0.170654296875,\n",
       " '8-10-1000000.0-1-0.1': 0.535888671875,\n",
       " '8-10-1000000.0-1-0.01': 0.694580078125,\n",
       " '8-10-1000000.0-1-0.001': 0.292724609375,\n",
       " '8-10-1000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-1000000.0-0.1-100.0': 0.0,\n",
       " '8-10-1000000.0-0.1-1': 0.104736328125,\n",
       " '8-10-1000000.0-0.1-0.1': 0.357421875,\n",
       " '8-10-1000000.0-0.1-0.01': 0.33740234375,\n",
       " '8-10-1000000.0-0.1-0.001': 0.2109375,\n",
       " '8-10-1000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-1000000.0-0.01-100.0': 0.0,\n",
       " '8-10-1000000.0-0.01-1': 0.1279296875,\n",
       " '8-10-1000000.0-0.01-0.1': 0.583984375,\n",
       " '8-10-1000000.0-0.01-0.01': 0.166259765625,\n",
       " '8-10-1000000.0-0.01-0.001': 0.15478515625,\n",
       " '8-10-1000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-1000000.0-0.001-100.0': 0.0,\n",
       " '8-10-1000000.0-0.001-1': 0.101806640625,\n",
       " '8-10-1000000.0-0.001-0.1': 0.43896484375,\n",
       " '8-10-1000000.0-0.001-0.01': 0.450439453125,\n",
       " '8-10-1000000.0-0.001-0.001': 0.30224609375,\n",
       " '8-10-10000000.0-10-1000.0': 0.0,\n",
       " '8-10-10000000.0-10-100.0': 0.0,\n",
       " '8-10-10000000.0-10-1': 0.012451171875,\n",
       " '8-10-10000000.0-10-0.1': 0.03759765625,\n",
       " '8-10-10000000.0-10-0.01': 0.014892578125,\n",
       " '8-10-10000000.0-10-0.001': 0.061279296875,\n",
       " '8-10-10000000.0-1-1000.0': 0.0,\n",
       " '8-10-10000000.0-1-100.0': 0.0,\n",
       " '8-10-10000000.0-1-1': 0.05322265625,\n",
       " '8-10-10000000.0-1-0.1': 0.654541015625,\n",
       " '8-10-10000000.0-1-0.01': 0.0947265625,\n",
       " '8-10-10000000.0-1-0.001': 0.70068359375,\n",
       " '8-10-10000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-10000000.0-0.1-100.0': 0.0,\n",
       " '8-10-10000000.0-0.1-1': 0.062744140625,\n",
       " '8-10-10000000.0-0.1-0.1': 0.310791015625,\n",
       " '8-10-10000000.0-0.1-0.01': 0.40283203125,\n",
       " '8-10-10000000.0-0.1-0.001': 0.487548828125,\n",
       " '8-10-10000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-10000000.0-0.01-100.0': 0.0,\n",
       " '8-10-10000000.0-0.01-1': 0.072021484375,\n",
       " '8-10-10000000.0-0.01-0.1': 0.171630859375,\n",
       " '8-10-10000000.0-0.01-0.01': 0.177001953125,\n",
       " '8-10-10000000.0-0.01-0.001': 0.171630859375,\n",
       " '8-10-10000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-10000000.0-0.001-100.0': 0.0,\n",
       " '8-10-10000000.0-0.001-1': 0.138427734375,\n",
       " '8-10-10000000.0-0.001-0.1': 0.189208984375,\n",
       " '8-10-10000000.0-0.001-0.01': 0.343994140625,\n",
       " '8-10-10000000.0-0.001-0.001': 0.583251953125,\n",
       " '8-10-100000000.0-10-1000.0': 0.0,\n",
       " '8-10-100000000.0-10-100.0': 0.0,\n",
       " '8-10-100000000.0-10-1': 0.012939453125,\n",
       " '8-10-100000000.0-10-0.1': 0.048583984375,\n",
       " '8-10-100000000.0-10-0.01': 0.022705078125,\n",
       " '8-10-100000000.0-10-0.001': 0.03271484375,\n",
       " '8-10-100000000.0-1-1000.0': 0.0,\n",
       " '8-10-100000000.0-1-100.0': 0.0,\n",
       " '8-10-100000000.0-1-1': 0.1484375,\n",
       " '8-10-100000000.0-1-0.1': 0.7177734375,\n",
       " '8-10-100000000.0-1-0.01': 0.42578125,\n",
       " '8-10-100000000.0-1-0.001': 0.684814453125,\n",
       " '8-10-100000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-100000000.0-0.1-100.0': 0.0,\n",
       " '8-10-100000000.0-0.1-1': 0.12255859375,\n",
       " '8-10-100000000.0-0.1-0.1': 0.288330078125,\n",
       " '8-10-100000000.0-0.1-0.01': 0.5166015625,\n",
       " '8-10-100000000.0-0.1-0.001': 0.593505859375,\n",
       " '8-10-100000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-100000000.0-0.01-100.0': 0.0,\n",
       " '8-10-100000000.0-0.01-1': 0.078857421875,\n",
       " '8-10-100000000.0-0.01-0.1': 0.65185546875,\n",
       " '8-10-100000000.0-0.01-0.01': 0.13525390625,\n",
       " '8-10-100000000.0-0.01-0.001': 0.28369140625,\n",
       " '8-10-100000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-100000000.0-0.001-100.0': 0.0,\n",
       " '8-10-100000000.0-0.001-1': 0.116943359375,\n",
       " '8-10-100000000.0-0.001-0.1': 0.185791015625,\n",
       " '8-10-100000000.0-0.001-0.01': 0.127197265625,\n",
       " '8-10-100000000.0-0.001-0.001': 0.173095703125,\n",
       " '8-10-1000000000.0-10-1000.0': 0.0,\n",
       " '8-10-1000000000.0-10-100.0': 0.0,\n",
       " '8-10-1000000000.0-10-1': 0.01171875,\n",
       " '8-10-1000000000.0-10-0.1': 0.029296875,\n",
       " '8-10-1000000000.0-10-0.01': 0.01611328125,\n",
       " '8-10-1000000000.0-10-0.001': 0.1533203125,\n",
       " '8-10-1000000000.0-1-1000.0': 0.0,\n",
       " '8-10-1000000000.0-1-100.0': 0.0,\n",
       " '8-10-1000000000.0-1-1': 0.151611328125,\n",
       " '8-10-1000000000.0-1-0.1': 0.70361328125,\n",
       " '8-10-1000000000.0-1-0.01': 0.43017578125,\n",
       " '8-10-1000000000.0-1-0.001': 0.6875,\n",
       " '8-10-1000000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-1000000000.0-0.1-100.0': 0.0,\n",
       " '8-10-1000000000.0-0.1-1': 0.03955078125,\n",
       " '8-10-1000000000.0-0.1-0.1': 0.64990234375,\n",
       " '8-10-1000000000.0-0.1-0.01': 0.615234375,\n",
       " '8-10-1000000000.0-0.1-0.001': 0.55908203125,\n",
       " '8-10-1000000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-1000000000.0-0.01-100.0': 0.0,\n",
       " '8-10-1000000000.0-0.01-1': 0.15771484375,\n",
       " '8-10-1000000000.0-0.01-0.1': 0.2373046875,\n",
       " '8-10-1000000000.0-0.01-0.01': 0.3388671875,\n",
       " '8-10-1000000000.0-0.01-0.001': 0.435546875,\n",
       " '8-10-1000000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-1000000000.0-0.001-100.0': 0.0,\n",
       " '8-10-1000000000.0-0.001-1': 0.141357421875,\n",
       " '8-10-1000000000.0-0.001-0.1': 0.242431640625,\n",
       " '8-10-1000000000.0-0.001-0.01': 0.46728515625,\n",
       " '8-10-1000000000.0-0.001-0.001': 0.446533203125,\n",
       " '8-10-10000000000.0-10-1000.0': 0.0,\n",
       " '8-10-10000000000.0-10-100.0': 0.0,\n",
       " '8-10-10000000000.0-10-1': 0.0205078125,\n",
       " '8-10-10000000000.0-10-0.1': 0.125732421875,\n",
       " '8-10-10000000000.0-10-0.01': 0.045654296875,\n",
       " '8-10-10000000000.0-10-0.001': 0.031005859375,\n",
       " '8-10-10000000000.0-1-1000.0': 0.0,\n",
       " '8-10-10000000000.0-1-100.0': 0.0,\n",
       " '8-10-10000000000.0-1-1': 0.08935546875,\n",
       " '8-10-10000000000.0-1-0.1': 0.663330078125,\n",
       " '8-10-10000000000.0-1-0.01': 0.236328125,\n",
       " '8-10-10000000000.0-1-0.001': 0.688720703125,\n",
       " '8-10-10000000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-10000000000.0-0.1-100.0': 0.0,\n",
       " '8-10-10000000000.0-0.1-1': 0.06494140625,\n",
       " '8-10-10000000000.0-0.1-0.1': 0.549560546875,\n",
       " '8-10-10000000000.0-0.1-0.01': 0.5869140625,\n",
       " '8-10-10000000000.0-0.1-0.001': 0.188720703125,\n",
       " '8-10-10000000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-10000000000.0-0.01-100.0': 0.0,\n",
       " '8-10-10000000000.0-0.01-1': 0.157958984375,\n",
       " '8-10-10000000000.0-0.01-0.1': 0.28369140625,\n",
       " '8-10-10000000000.0-0.01-0.01': 0.60400390625,\n",
       " '8-10-10000000000.0-0.01-0.001': 0.589111328125,\n",
       " '8-10-10000000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-10000000000.0-0.001-100.0': 0.0,\n",
       " '8-10-10000000000.0-0.001-1': 0.153076171875,\n",
       " '8-10-10000000000.0-0.001-0.1': 0.60986328125,\n",
       " '8-10-10000000000.0-0.001-0.01': 0.458740234375,\n",
       " '8-10-10000000000.0-0.001-0.001': 0.17138671875,\n",
       " '8-10-100000000000.0-10-1000.0': 0.0,\n",
       " '8-10-100000000000.0-10-100.0': 0.0,\n",
       " '8-10-100000000000.0-10-1': 0.014404296875,\n",
       " '8-10-100000000000.0-10-0.1': 0.01904296875,\n",
       " '8-10-100000000000.0-10-0.01': 0.0185546875,\n",
       " '8-10-100000000000.0-10-0.001': 0.09326171875,\n",
       " '8-10-100000000000.0-1-1000.0': 0.0,\n",
       " '8-10-100000000000.0-1-100.0': 0.0,\n",
       " '8-10-100000000000.0-1-1': 0.048583984375,\n",
       " '8-10-100000000000.0-1-0.1': 0.56494140625,\n",
       " '8-10-100000000000.0-1-0.01': 0.396484375,\n",
       " '8-10-100000000000.0-1-0.001': 0.17919921875,\n",
       " '8-10-100000000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-100000000000.0-0.1-100.0': 0.0,\n",
       " '8-10-100000000000.0-0.1-1': 0.138671875,\n",
       " '8-10-100000000000.0-0.1-0.1': 0.56689453125,\n",
       " '8-10-100000000000.0-0.1-0.01': 0.185546875,\n",
       " '8-10-100000000000.0-0.1-0.001': 0.218017578125,\n",
       " '8-10-100000000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-100000000000.0-0.01-100.0': 0.0,\n",
       " '8-10-100000000000.0-0.01-1': 0.05859375,\n",
       " '8-10-100000000000.0-0.01-0.1': 0.21875,\n",
       " '8-10-100000000000.0-0.01-0.01': 0.29443359375,\n",
       " '8-10-100000000000.0-0.01-0.001': 0.60693359375,\n",
       " '8-10-100000000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-100000000000.0-0.001-100.0': 0.0,\n",
       " '8-10-100000000000.0-0.001-1': 0.1328125,\n",
       " '8-10-100000000000.0-0.001-0.1': 0.25927734375,\n",
       " '8-10-100000000000.0-0.001-0.01': 0.32763671875,\n",
       " '8-10-100000000000.0-0.001-0.001': 0.43994140625,\n",
       " '8-10-1000000000000.0-10-1000.0': 0.0,\n",
       " '8-10-1000000000000.0-10-100.0': 0.0,\n",
       " '8-10-1000000000000.0-10-1': 0.012451171875,\n",
       " '8-10-1000000000000.0-10-0.1': 0.01123046875,\n",
       " '8-10-1000000000000.0-10-0.01': 0.016845703125,\n",
       " '8-10-1000000000000.0-10-0.001': 0.016357421875,\n",
       " '8-10-1000000000000.0-1-1000.0': 0.0,\n",
       " '8-10-1000000000000.0-1-100.0': 0.0,\n",
       " '8-10-1000000000000.0-1-1': 0.076416015625,\n",
       " '8-10-1000000000000.0-1-0.1': 0.294677734375,\n",
       " '8-10-1000000000000.0-1-0.01': 0.305908203125,\n",
       " '8-10-1000000000000.0-1-0.001': 0.61572265625,\n",
       " '8-10-1000000000000.0-0.1-1000.0': 0.0,\n",
       " '8-10-1000000000000.0-0.1-100.0': 0.0,\n",
       " '8-10-1000000000000.0-0.1-1': 0.140625,\n",
       " '8-10-1000000000000.0-0.1-0.1': 0.64990234375,\n",
       " '8-10-1000000000000.0-0.1-0.01': 0.58349609375,\n",
       " '8-10-1000000000000.0-0.1-0.001': 0.531982421875,\n",
       " '8-10-1000000000000.0-0.01-1000.0': 0.0,\n",
       " '8-10-1000000000000.0-0.01-100.0': 0.0,\n",
       " '8-10-1000000000000.0-0.01-1': 0.032470703125,\n",
       " '8-10-1000000000000.0-0.01-0.1': 0.24853515625,\n",
       " '8-10-1000000000000.0-0.01-0.01': 0.60595703125,\n",
       " '8-10-1000000000000.0-0.01-0.001': 0.394775390625,\n",
       " '8-10-1000000000000.0-0.001-1000.0': 0.0,\n",
       " '8-10-1000000000000.0-0.001-100.0': 0.0,\n",
       " '8-10-1000000000000.0-0.001-1': 0.0849609375,\n",
       " '8-10-1000000000000.0-0.001-0.1': 0.5341796875,\n",
       " '8-10-1000000000000.0-0.001-0.01': 0.0,\n",
       " '8-10-1000000000000.0-0.001-0.001': 0.25390625,\n",
       " '8-1-10.0-10-1000.0': 0.0,\n",
       " '8-1-10.0-10-100.0': 0.0,\n",
       " '8-1-10.0-10-1': 0.064697265625,\n",
       " '8-1-10.0-10-0.1': 0.0751953125,\n",
       " '8-1-10.0-10-0.01': 0.111572265625,\n",
       " '8-1-10.0-10-0.001': 0.08544921875,\n",
       " '8-1-10.0-1-1000.0': 0.0,\n",
       " '8-1-10.0-1-100.0': 0.0,\n",
       " '8-1-10.0-1-1': 0.075927734375,\n",
       " '8-1-10.0-1-0.1': 0.055908203125,\n",
       " '8-1-10.0-1-0.01': 0.070556640625,\n",
       " '8-1-10.0-1-0.001': 0.05322265625,\n",
       " '8-1-10.0-0.1-1000.0': 0.0,\n",
       " '8-1-10.0-0.1-100.0': 0.0,\n",
       " '8-1-10.0-0.1-1': 0.073486328125,\n",
       " '8-1-10.0-0.1-0.1': 0.0498046875,\n",
       " '8-1-10.0-0.1-0.01': 0.080810546875,\n",
       " '8-1-10.0-0.1-0.001': 0.113525390625,\n",
       " '8-1-10.0-0.01-1000.0': 0.0,\n",
       " '8-1-10.0-0.01-100.0': 0.0,\n",
       " '8-1-10.0-0.01-1': 0.047119140625,\n",
       " '8-1-10.0-0.01-0.1': 0.04833984375,\n",
       " '8-1-10.0-0.01-0.01': 0.064208984375,\n",
       " '8-1-10.0-0.01-0.001': 0.070068359375,\n",
       " '8-1-10.0-0.001-1000.0': 0.0,\n",
       " '8-1-10.0-0.001-100.0': 0.0,\n",
       " '8-1-10.0-0.001-1': 0.039306640625,\n",
       " '8-1-10.0-0.001-0.1': 0.05908203125,\n",
       " '8-1-10.0-0.001-0.01': 0.0,\n",
       " '8-1-10.0-0.001-0.001': 0.10400390625,\n",
       " '8-1-100.0-10-1000.0': 0.0,\n",
       " '8-1-100.0-10-100.0': 0.011962890625,\n",
       " '8-1-100.0-10-1': 0.0146484375,\n",
       " '8-1-100.0-10-0.1': 0.0146484375,\n",
       " '8-1-100.0-10-0.01': 0.021484375,\n",
       " '8-1-100.0-10-0.001': 0.011474609375,\n",
       " '8-1-100.0-1-1000.0': 0.0,\n",
       " '8-1-100.0-1-100.0': 0.0,\n",
       " '8-1-100.0-1-1': 0.1943359375,\n",
       " '8-1-100.0-1-0.1': 0.706298828125,\n",
       " '8-1-100.0-1-0.01': 0.247314453125,\n",
       " '8-1-100.0-1-0.001': 0.296630859375,\n",
       " '8-1-100.0-0.1-1000.0': 0.0,\n",
       " '8-1-100.0-0.1-100.0': 0.0,\n",
       " '8-1-100.0-0.1-1': 0.55712890625,\n",
       " '8-1-100.0-0.1-0.1': 0.16455078125,\n",
       " '8-1-100.0-0.1-0.01': 0.563720703125,\n",
       " '8-1-100.0-0.1-0.001': 0.3662109375,\n",
       " '8-1-100.0-0.01-1000.0': 0.0,\n",
       " '8-1-100.0-0.01-100.0': 0.0,\n",
       " '8-1-100.0-0.01-1': 0.59326171875,\n",
       " '8-1-100.0-0.01-0.1': 0.1513671875,\n",
       " '8-1-100.0-0.01-0.01': 0.268798828125,\n",
       " '8-1-100.0-0.01-0.001': 0.327392578125,\n",
       " '8-1-100.0-0.001-1000.0': 0.0,\n",
       " '8-1-100.0-0.001-100.0': 0.0,\n",
       " '8-1-100.0-0.001-1': 0.49853515625,\n",
       " '8-1-100.0-0.001-0.1': 0.25830078125,\n",
       " '8-1-100.0-0.001-0.01': 0.381103515625,\n",
       " '8-1-100.0-0.001-0.001': 0.62060546875,\n",
       " '8-1-1000.0-10-1000.0': 0.0,\n",
       " '8-1-1000.0-10-100.0': 0.01123046875,\n",
       " '8-1-1000.0-10-1': 0.017578125,\n",
       " '8-1-1000.0-10-0.1': 0.056884765625,\n",
       " '8-1-1000.0-10-0.01': 0.0234375,\n",
       " '8-1-1000.0-10-0.001': 0.026611328125,\n",
       " '8-1-1000.0-1-1000.0': 0.0,\n",
       " '8-1-1000.0-1-100.0': 0.0,\n",
       " '8-1-1000.0-1-1': 0.72607421875,\n",
       " '8-1-1000.0-1-0.1': 0.35302734375,\n",
       " '8-1-1000.0-1-0.01': 0.2021484375,\n",
       " '8-1-1000.0-1-0.001': 0.693603515625,\n",
       " '8-1-1000.0-0.1-1000.0': 0.0,\n",
       " '8-1-1000.0-0.1-100.0': 0.0,\n",
       " '8-1-1000.0-0.1-1': 0.148681640625,\n",
       " '8-1-1000.0-0.1-0.1': 0.5810546875,\n",
       " '8-1-1000.0-0.1-0.01': 0.57666015625,\n",
       " '8-1-1000.0-0.1-0.001': 0.35791015625,\n",
       " '8-1-1000.0-0.01-1000.0': 0.0,\n",
       " '8-1-1000.0-0.01-100.0': 0.0,\n",
       " '8-1-1000.0-0.01-1': 0.686767578125,\n",
       " '8-1-1000.0-0.01-0.1': 0.58642578125,\n",
       " '8-1-1000.0-0.01-0.01': 0.568603515625,\n",
       " '8-1-1000.0-0.01-0.001': 0.60400390625,\n",
       " '8-1-1000.0-0.001-1000.0': 0.0,\n",
       " '8-1-1000.0-0.001-100.0': 0.0,\n",
       " '8-1-1000.0-0.001-1': 0.503173828125,\n",
       " '8-1-1000.0-0.001-0.1': 0.54296875,\n",
       " '8-1-1000.0-0.001-0.01': 0.247314453125,\n",
       " '8-1-1000.0-0.001-0.001': 0.5234375,\n",
       " '8-1-10000.0-10-1000.0': 0.0,\n",
       " '8-1-10000.0-10-100.0': 0.0126953125,\n",
       " '8-1-10000.0-10-1': 0.0322265625,\n",
       " '8-1-10000.0-10-0.1': 0.062255859375,\n",
       " '8-1-10000.0-10-0.01': 0.05615234375,\n",
       " '8-1-10000.0-10-0.001': 0.01318359375,\n",
       " '8-1-10000.0-1-1000.0': 0.0,\n",
       " '8-1-10000.0-1-100.0': 0.0,\n",
       " '8-1-10000.0-1-1': 0.735595703125,\n",
       " '8-1-10000.0-1-0.1': 0.27880859375,\n",
       " '8-1-10000.0-1-0.01': 0.550048828125,\n",
       " '8-1-10000.0-1-0.001': 0.467529296875,\n",
       " '8-1-10000.0-0.1-1000.0': 0.0,\n",
       " '8-1-10000.0-0.1-100.0': 0.0,\n",
       " '8-1-10000.0-0.1-1': 0.35205078125,\n",
       " '8-1-10000.0-0.1-0.1': 0.2392578125,\n",
       " '8-1-10000.0-0.1-0.01': 0.20654296875,\n",
       " '8-1-10000.0-0.1-0.001': 0.20703125,\n",
       " '8-1-10000.0-0.01-1000.0': 0.0,\n",
       " '8-1-10000.0-0.01-100.0': 0.0,\n",
       " '8-1-10000.0-0.01-1': 0.42138671875,\n",
       " '8-1-10000.0-0.01-0.1': 0.41943359375,\n",
       " '8-1-10000.0-0.01-0.01': 0.28369140625,\n",
       " '8-1-10000.0-0.01-0.001': 0.508056640625,\n",
       " '8-1-10000.0-0.001-1000.0': 0.0,\n",
       " '8-1-10000.0-0.001-100.0': 0.0,\n",
       " '8-1-10000.0-0.001-1': 0.232666015625,\n",
       " '8-1-10000.0-0.001-0.1': 0.625732421875,\n",
       " '8-1-10000.0-0.001-0.01': 0.62353515625,\n",
       " '8-1-10000.0-0.001-0.001': 0.54248046875,\n",
       " '8-1-100000.0-10-1000.0': 0.0,\n",
       " '8-1-100000.0-10-100.0': 0.0126953125,\n",
       " '8-1-100000.0-10-1': 0.015869140625,\n",
       " '8-1-100000.0-10-0.1': 0.06005859375,\n",
       " '8-1-100000.0-10-0.01': 0.04296875,\n",
       " '8-1-100000.0-10-0.001': 0.02587890625,\n",
       " '8-1-100000.0-1-1000.0': 0.0,\n",
       " '8-1-100000.0-1-100.0': 0.0,\n",
       " '8-1-100000.0-1-1': 0.69970703125,\n",
       " '8-1-100000.0-1-0.1': 0.69677734375,\n",
       " '8-1-100000.0-1-0.01': 0.230224609375,\n",
       " '8-1-100000.0-1-0.001': 0.66259765625,\n",
       " '8-1-100000.0-0.1-1000.0': 0.0,\n",
       " '8-1-100000.0-0.1-100.0': 0.0,\n",
       " '8-1-100000.0-0.1-1': 0.70556640625,\n",
       " '8-1-100000.0-0.1-0.1': 0.52197265625,\n",
       " '8-1-100000.0-0.1-0.01': 0.572998046875,\n",
       " '8-1-100000.0-0.1-0.001': 0.2158203125,\n",
       " '8-1-100000.0-0.01-1000.0': 0.0,\n",
       " '8-1-100000.0-0.01-100.0': 0.0,\n",
       " '8-1-100000.0-0.01-1': 0.29248046875,\n",
       " '8-1-100000.0-0.01-0.1': 0.360107421875,\n",
       " '8-1-100000.0-0.01-0.01': 0.42724609375,\n",
       " '8-1-100000.0-0.01-0.001': 0.5087890625,\n",
       " '8-1-100000.0-0.001-1000.0': 0.0,\n",
       " '8-1-100000.0-0.001-100.0': 0.0,\n",
       " '8-1-100000.0-0.001-1': 0.6923828125,\n",
       " '8-1-100000.0-0.001-0.1': 0.431640625,\n",
       " '8-1-100000.0-0.001-0.01': 0.48193359375,\n",
       " '8-1-100000.0-0.001-0.001': 0.517822265625,\n",
       " '8-1-1000000.0-10-1000.0': 0.0,\n",
       " '8-1-1000000.0-10-100.0': 0.008056640625,\n",
       " '8-1-1000000.0-10-1': 0.025634765625,\n",
       " '8-1-1000000.0-10-0.1': 0.0634765625,\n",
       " '8-1-1000000.0-10-0.01': 0.07470703125,\n",
       " '8-1-1000000.0-10-0.001': 0.02197265625,\n",
       " '8-1-1000000.0-1-1000.0': 0.0,\n",
       " '8-1-1000000.0-1-100.0': 0.0,\n",
       " '8-1-1000000.0-1-1': 0.69091796875,\n",
       " '8-1-1000000.0-1-0.1': 0.4580078125,\n",
       " '8-1-1000000.0-1-0.01': 0.302001953125,\n",
       " '8-1-1000000.0-1-0.001': 0.672607421875,\n",
       " '8-1-1000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-1000000.0-0.1-100.0': 0.0,\n",
       " '8-1-1000000.0-0.1-1': 0.685302734375,\n",
       " '8-1-1000000.0-0.1-0.1': 0.2333984375,\n",
       " '8-1-1000000.0-0.1-0.01': 0.6171875,\n",
       " '8-1-1000000.0-0.1-0.001': 0.253662109375,\n",
       " '8-1-1000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-1000000.0-0.01-100.0': 0.0,\n",
       " '8-1-1000000.0-0.01-1': 0.650634765625,\n",
       " '8-1-1000000.0-0.01-0.1': 0.4970703125,\n",
       " '8-1-1000000.0-0.01-0.01': 0.513916015625,\n",
       " '8-1-1000000.0-0.01-0.001': 0.275146484375,\n",
       " '8-1-1000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-1000000.0-0.001-100.0': 0.0,\n",
       " '8-1-1000000.0-0.001-1': 0.532958984375,\n",
       " '8-1-1000000.0-0.001-0.1': 0.2607421875,\n",
       " '8-1-1000000.0-0.001-0.01': 0.233642578125,\n",
       " '8-1-1000000.0-0.001-0.001': 0.61572265625,\n",
       " '8-1-10000000.0-10-1000.0': 0.0,\n",
       " '8-1-10000000.0-10-100.0': 0.013427734375,\n",
       " '8-1-10000000.0-10-1': 0.100341796875,\n",
       " '8-1-10000000.0-10-0.1': 0.014892578125,\n",
       " '8-1-10000000.0-10-0.01': 0.03173828125,\n",
       " '8-1-10000000.0-10-0.001': 0.041259765625,\n",
       " '8-1-10000000.0-1-1000.0': 0.0,\n",
       " '8-1-10000000.0-1-100.0': 0.0,\n",
       " '8-1-10000000.0-1-1': 0.510498046875,\n",
       " '8-1-10000000.0-1-0.1': 0.20263671875,\n",
       " '8-1-10000000.0-1-0.01': 0.256103515625,\n",
       " '8-1-10000000.0-1-0.001': 0.239013671875,\n",
       " '8-1-10000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-10000000.0-0.1-100.0': 0.0,\n",
       " '8-1-10000000.0-0.1-1': 0.373046875,\n",
       " '8-1-10000000.0-0.1-0.1': 0.615234375,\n",
       " '8-1-10000000.0-0.1-0.01': 0.547607421875,\n",
       " '8-1-10000000.0-0.1-0.001': 0.611572265625,\n",
       " '8-1-10000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-10000000.0-0.01-100.0': 0.0,\n",
       " '8-1-10000000.0-0.01-1': 0.261474609375,\n",
       " '8-1-10000000.0-0.01-0.1': 0.510986328125,\n",
       " '8-1-10000000.0-0.01-0.01': 0.605712890625,\n",
       " '8-1-10000000.0-0.01-0.001': 0.510986328125,\n",
       " '8-1-10000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-10000000.0-0.001-100.0': 0.0,\n",
       " '8-1-10000000.0-0.001-1': 0.442138671875,\n",
       " '8-1-10000000.0-0.001-0.1': 0.60107421875,\n",
       " '8-1-10000000.0-0.001-0.01': 0.352294921875,\n",
       " '8-1-10000000.0-0.001-0.001': 0.510986328125,\n",
       " '8-1-100000000.0-10-1000.0': 0.0,\n",
       " '8-1-100000000.0-10-100.0': 0.0166015625,\n",
       " '8-1-100000000.0-10-1': 0.014404296875,\n",
       " '8-1-100000000.0-10-0.1': 0.021240234375,\n",
       " '8-1-100000000.0-10-0.01': 0.0126953125,\n",
       " '8-1-100000000.0-10-0.001': 0.013916015625,\n",
       " '8-1-100000000.0-1-1000.0': 0.0,\n",
       " '8-1-100000000.0-1-100.0': 0.0,\n",
       " '8-1-100000000.0-1-1': 0.611328125,\n",
       " '8-1-100000000.0-1-0.1': 0.65478515625,\n",
       " '8-1-100000000.0-1-0.01': 0.687744140625,\n",
       " '8-1-100000000.0-1-0.001': 0.7158203125,\n",
       " '8-1-100000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-100000000.0-0.1-100.0': 0.0,\n",
       " '8-1-100000000.0-0.1-1': 0.61181640625,\n",
       " '8-1-100000000.0-0.1-0.1': 0.642578125,\n",
       " '8-1-100000000.0-0.1-0.01': 0.531005859375,\n",
       " '8-1-100000000.0-0.1-0.001': 0.4501953125,\n",
       " '8-1-100000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-100000000.0-0.01-100.0': 0.0,\n",
       " '8-1-100000000.0-0.01-1': 0.256103515625,\n",
       " '8-1-100000000.0-0.01-0.1': 0.38330078125,\n",
       " '8-1-100000000.0-0.01-0.01': 0.563232421875,\n",
       " '8-1-100000000.0-0.01-0.001': 0.614013671875,\n",
       " '8-1-100000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-100000000.0-0.001-100.0': 0.0,\n",
       " '8-1-100000000.0-0.001-1': 0.301025390625,\n",
       " '8-1-100000000.0-0.001-0.1': 0.510009765625,\n",
       " '8-1-100000000.0-0.001-0.01': 0.177978515625,\n",
       " '8-1-100000000.0-0.001-0.001': 0.269775390625,\n",
       " '8-1-1000000000.0-10-1000.0': 0.0,\n",
       " '8-1-1000000000.0-10-100.0': 0.0146484375,\n",
       " '8-1-1000000000.0-10-1': 0.01806640625,\n",
       " '8-1-1000000000.0-10-0.1': 0.012939453125,\n",
       " '8-1-1000000000.0-10-0.01': 0.03857421875,\n",
       " '8-1-1000000000.0-10-0.001': 0.0185546875,\n",
       " '8-1-1000000000.0-1-1000.0': 0.0,\n",
       " '8-1-1000000000.0-1-100.0': 0.0,\n",
       " '8-1-1000000000.0-1-1': 0.691650390625,\n",
       " '8-1-1000000000.0-1-0.1': 0.53271484375,\n",
       " '8-1-1000000000.0-1-0.01': 0.47509765625,\n",
       " '8-1-1000000000.0-1-0.001': 0.224609375,\n",
       " '8-1-1000000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-1000000000.0-0.1-100.0': 0.0,\n",
       " '8-1-1000000000.0-0.1-1': 0.590576171875,\n",
       " '8-1-1000000000.0-0.1-0.1': 0.580322265625,\n",
       " '8-1-1000000000.0-0.1-0.01': 0.5751953125,\n",
       " '8-1-1000000000.0-0.1-0.001': 0.382568359375,\n",
       " '8-1-1000000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-1000000000.0-0.01-100.0': 0.0,\n",
       " '8-1-1000000000.0-0.01-1': 0.167724609375,\n",
       " '8-1-1000000000.0-0.01-0.1': 0.180419921875,\n",
       " '8-1-1000000000.0-0.01-0.01': 0.2939453125,\n",
       " '8-1-1000000000.0-0.01-0.001': 0.546630859375,\n",
       " '8-1-1000000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-1000000000.0-0.001-100.0': 0.0,\n",
       " '8-1-1000000000.0-0.001-1': 0.663818359375,\n",
       " '8-1-1000000000.0-0.001-0.1': 0.6123046875,\n",
       " '8-1-1000000000.0-0.001-0.01': 0.593994140625,\n",
       " '8-1-1000000000.0-0.001-0.001': 0.214111328125,\n",
       " '8-1-10000000000.0-10-1000.0': 0.0,\n",
       " '8-1-10000000000.0-10-100.0': 0.010986328125,\n",
       " '8-1-10000000000.0-10-1': 0.0146484375,\n",
       " '8-1-10000000000.0-10-0.1': 0.046630859375,\n",
       " '8-1-10000000000.0-10-0.01': 0.02197265625,\n",
       " '8-1-10000000000.0-10-0.001': 0.065185546875,\n",
       " '8-1-10000000000.0-1-1000.0': 0.0,\n",
       " '8-1-10000000000.0-1-100.0': 0.0,\n",
       " '8-1-10000000000.0-1-1': 0.184814453125,\n",
       " '8-1-10000000000.0-1-0.1': 0.26708984375,\n",
       " '8-1-10000000000.0-1-0.01': 0.48779296875,\n",
       " '8-1-10000000000.0-1-0.001': 0.6884765625,\n",
       " '8-1-10000000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-10000000000.0-0.1-100.0': 0.0,\n",
       " '8-1-10000000000.0-0.1-1': 0.63525390625,\n",
       " '8-1-10000000000.0-0.1-0.1': 0.206787109375,\n",
       " '8-1-10000000000.0-0.1-0.01': 0.1416015625,\n",
       " '8-1-10000000000.0-0.1-0.001': 0.4326171875,\n",
       " '8-1-10000000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-10000000000.0-0.01-100.0': 0.0,\n",
       " '8-1-10000000000.0-0.01-1': 0.1640625,\n",
       " '8-1-10000000000.0-0.01-0.1': 0.626953125,\n",
       " '8-1-10000000000.0-0.01-0.01': 0.555908203125,\n",
       " '8-1-10000000000.0-0.01-0.001': 0.53515625,\n",
       " '8-1-10000000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-10000000000.0-0.001-100.0': 0.0,\n",
       " '8-1-10000000000.0-0.001-1': 0.53271484375,\n",
       " '8-1-10000000000.0-0.001-0.1': 0.236328125,\n",
       " '8-1-10000000000.0-0.001-0.01': 0.3623046875,\n",
       " '8-1-10000000000.0-0.001-0.001': 0.57421875,\n",
       " '8-1-100000000000.0-10-1000.0': 0.0,\n",
       " '8-1-100000000000.0-10-100.0': 0.016357421875,\n",
       " '8-1-100000000000.0-10-1': 0.019287109375,\n",
       " '8-1-100000000000.0-10-0.1': 0.03173828125,\n",
       " '8-1-100000000000.0-10-0.01': 0.0341796875,\n",
       " '8-1-100000000000.0-10-0.001': 0.020751953125,\n",
       " '8-1-100000000000.0-1-1000.0': 0.0,\n",
       " '8-1-100000000000.0-1-100.0': 0.0,\n",
       " '8-1-100000000000.0-1-1': 0.638671875,\n",
       " '8-1-100000000000.0-1-0.1': 0.1748046875,\n",
       " '8-1-100000000000.0-1-0.01': 0.2666015625,\n",
       " '8-1-100000000000.0-1-0.001': 0.35888671875,\n",
       " '8-1-100000000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-100000000000.0-0.1-100.0': 0.0,\n",
       " '8-1-100000000000.0-0.1-1': 0.63134765625,\n",
       " '8-1-100000000000.0-0.1-0.1': 0.632080078125,\n",
       " '8-1-100000000000.0-0.1-0.01': 0.61181640625,\n",
       " '8-1-100000000000.0-0.1-0.001': 0.16796875,\n",
       " '8-1-100000000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-100000000000.0-0.01-100.0': 0.0,\n",
       " '8-1-100000000000.0-0.01-1': 0.680908203125,\n",
       " '8-1-100000000000.0-0.01-0.1': 0.329345703125,\n",
       " '8-1-100000000000.0-0.01-0.01': 0.386962890625,\n",
       " '8-1-100000000000.0-0.01-0.001': 0.441650390625,\n",
       " '8-1-100000000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-100000000000.0-0.001-100.0': 0.0,\n",
       " '8-1-100000000000.0-0.001-1': 0.652099609375,\n",
       " '8-1-100000000000.0-0.001-0.1': 0.2470703125,\n",
       " '8-1-100000000000.0-0.001-0.01': 0.571044921875,\n",
       " '8-1-100000000000.0-0.001-0.001': 0.56591796875,\n",
       " '8-1-1000000000000.0-10-1000.0': 0.0,\n",
       " '8-1-1000000000000.0-10-100.0': 0.01171875,\n",
       " '8-1-1000000000000.0-10-1': 0.0126953125,\n",
       " '8-1-1000000000000.0-10-0.1': 0.017333984375,\n",
       " '8-1-1000000000000.0-10-0.01': 0.027099609375,\n",
       " '8-1-1000000000000.0-10-0.001': 0.03173828125,\n",
       " '8-1-1000000000000.0-1-1000.0': 0.0,\n",
       " '8-1-1000000000000.0-1-100.0': 0.0,\n",
       " '8-1-1000000000000.0-1-1': 0.6279296875,\n",
       " '8-1-1000000000000.0-1-0.1': 0.26025390625,\n",
       " '8-1-1000000000000.0-1-0.01': 0.62060546875,\n",
       " '8-1-1000000000000.0-1-0.001': 0.316650390625,\n",
       " '8-1-1000000000000.0-0.1-1000.0': 0.0,\n",
       " '8-1-1000000000000.0-0.1-100.0': 0.0,\n",
       " '8-1-1000000000000.0-0.1-1': 0.539306640625,\n",
       " '8-1-1000000000000.0-0.1-0.1': 0.62890625,\n",
       " '8-1-1000000000000.0-0.1-0.01': 0.57373046875,\n",
       " '8-1-1000000000000.0-0.1-0.001': 0.54638671875,\n",
       " '8-1-1000000000000.0-0.01-1000.0': 0.0,\n",
       " '8-1-1000000000000.0-0.01-100.0': 0.0,\n",
       " '8-1-1000000000000.0-0.01-1': 0.400146484375,\n",
       " '8-1-1000000000000.0-0.01-0.1': 0.607177734375,\n",
       " '8-1-1000000000000.0-0.01-0.01': 0.373291015625,\n",
       " '8-1-1000000000000.0-0.01-0.001': 0.5703125,\n",
       " '8-1-1000000000000.0-0.001-1000.0': 0.0,\n",
       " '8-1-1000000000000.0-0.001-100.0': 0.0,\n",
       " '8-1-1000000000000.0-0.001-1': 0.702880859375,\n",
       " '8-1-1000000000000.0-0.001-0.1': 0.433837890625,\n",
       " '8-1-1000000000000.0-0.001-0.01': 0.408447265625,\n",
       " '8-1-1000000000000.0-0.001-0.001': 0.41845703125,\n",
       " '8-0.1-10.0-10-1000.0': 0.0,\n",
       " '8-0.1-10.0-10-100.0': 0.019287109375,\n",
       " '8-0.1-10.0-10-1': 0.078125,\n",
       " '8-0.1-10.0-10-0.1': 0.107177734375,\n",
       " '8-0.1-10.0-10-0.01': 0.0498046875,\n",
       " '8-0.1-10.0-10-0.001': 0.060791015625,\n",
       " '8-0.1-10.0-1-1000.0': 0.0,\n",
       " '8-0.1-10.0-1-100.0': 0.028076171875,\n",
       " '8-0.1-10.0-1-1': 0.05126953125,\n",
       " '8-0.1-10.0-1-0.1': 0.0458984375,\n",
       " '8-0.1-10.0-1-0.01': 0.07177734375,\n",
       " '8-0.1-10.0-1-0.001': 0.107421875,\n",
       " '8-0.1-10.0-0.1-1000.0': 0.0,\n",
       " '8-0.1-10.0-0.1-100.0': 0.025146484375,\n",
       " '8-0.1-10.0-0.1-1': 0.109619140625,\n",
       " '8-0.1-10.0-0.1-0.1': 0.1513671875,\n",
       " '8-0.1-10.0-0.1-0.01': 0.052978515625,\n",
       " '8-0.1-10.0-0.1-0.001': 0.044189453125,\n",
       " '8-0.1-10.0-0.01-1000.0': 0.0,\n",
       " '8-0.1-10.0-0.01-100.0': 0.021240234375,\n",
       " '8-0.1-10.0-0.01-1': 0.075927734375,\n",
       " '8-0.1-10.0-0.01-0.1': 0.061767578125,\n",
       " '8-0.1-10.0-0.01-0.01': 0.07568359375,\n",
       " '8-0.1-10.0-0.01-0.001': 0.062255859375,\n",
       " '8-0.1-10.0-0.001-1000.0': 0.0,\n",
       " '8-0.1-10.0-0.001-100.0': 0.016845703125,\n",
       " '8-0.1-10.0-0.001-1': 0.055419921875,\n",
       " '8-0.1-10.0-0.001-0.1': 0.08447265625,\n",
       " '8-0.1-10.0-0.001-0.01': 0.05810546875,\n",
       " '8-0.1-10.0-0.001-0.001': 0.13427734375,\n",
       " '8-0.1-100.0-10-1000.0': 0.0166015625,\n",
       " '8-0.1-100.0-10-100.0': 0.021484375,\n",
       " '8-0.1-100.0-10-1': 0.017822265625,\n",
       " '8-0.1-100.0-10-0.1': 0.028076171875,\n",
       " '8-0.1-100.0-10-0.01': 0.019287109375,\n",
       " '8-0.1-100.0-10-0.001': 0.02392578125,\n",
       " '8-0.1-100.0-1-1000.0': 0.0,\n",
       " '8-0.1-100.0-1-100.0': 0.04736328125,\n",
       " '8-0.1-100.0-1-1': 0.666259765625,\n",
       " '8-0.1-100.0-1-0.1': 0.2421875,\n",
       " '8-0.1-100.0-1-0.01': 0.362060546875,\n",
       " '8-0.1-100.0-1-0.001': 0.1337890625,\n",
       " '8-0.1-100.0-0.1-1000.0': 0.0,\n",
       " '8-0.1-100.0-0.1-100.0': 0.08203125,\n",
       " '8-0.1-100.0-0.1-1': 0.586669921875,\n",
       " '8-0.1-100.0-0.1-0.1': 0.414794921875,\n",
       " '8-0.1-100.0-0.1-0.01': 0.15869140625,\n",
       " '8-0.1-100.0-0.1-0.001': 0.309814453125,\n",
       " '8-0.1-100.0-0.01-1000.0': 0.0,\n",
       " '8-0.1-100.0-0.01-100.0': 0.08984375,\n",
       " '8-0.1-100.0-0.01-1': 0.39013671875,\n",
       " '8-0.1-100.0-0.01-0.1': 0.1630859375,\n",
       " '8-0.1-100.0-0.01-0.01': 0.18310546875,\n",
       " '8-0.1-100.0-0.01-0.001': 0.44580078125,\n",
       " '8-0.1-100.0-0.001-1000.0': 0.0,\n",
       " '8-0.1-100.0-0.001-100.0': 0.150634765625,\n",
       " '8-0.1-100.0-0.001-1': 0.63623046875,\n",
       " '8-0.1-100.0-0.001-0.1': 0.6103515625,\n",
       " '8-0.1-100.0-0.001-0.01': 0.1279296875,\n",
       " '8-0.1-100.0-0.001-0.001': 0.22216796875,\n",
       " '8-0.1-1000.0-10-1000.0': 0.01416015625,\n",
       " '8-0.1-1000.0-10-100.0': 0.02197265625,\n",
       " '8-0.1-1000.0-10-1': 0.03857421875,\n",
       " '8-0.1-1000.0-10-0.1': 0.01904296875,\n",
       " '8-0.1-1000.0-10-0.01': 0.037109375,\n",
       " '8-0.1-1000.0-10-0.001': 0.02587890625,\n",
       " '8-0.1-1000.0-1-1000.0': 0.0,\n",
       " '8-0.1-1000.0-1-100.0': 0.09814453125,\n",
       " '8-0.1-1000.0-1-1': 0.3564453125,\n",
       " '8-0.1-1000.0-1-0.1': 0.349365234375,\n",
       " '8-0.1-1000.0-1-0.01': 0.710693359375,\n",
       " '8-0.1-1000.0-1-0.001': 0.18994140625,\n",
       " '8-0.1-1000.0-0.1-1000.0': 0.0,\n",
       " '8-0.1-1000.0-0.1-100.0': 0.137939453125,\n",
       " '8-0.1-1000.0-0.1-1': 0.26708984375,\n",
       " '8-0.1-1000.0-0.1-0.1': 0.251953125,\n",
       " '8-0.1-1000.0-0.1-0.01': 0.36328125,\n",
       " '8-0.1-1000.0-0.1-0.001': 0.211669921875,\n",
       " '8-0.1-1000.0-0.01-1000.0': 0.0,\n",
       " '8-0.1-1000.0-0.01-100.0': 0.08642578125,\n",
       " '8-0.1-1000.0-0.01-1': 0.2802734375,\n",
       " '8-0.1-1000.0-0.01-0.1': 0.502685546875,\n",
       " '8-0.1-1000.0-0.01-0.01': 0.478271484375,\n",
       " '8-0.1-1000.0-0.01-0.001': 0.41162109375,\n",
       " '8-0.1-1000.0-0.001-1000.0': 0.0,\n",
       " '8-0.1-1000.0-0.001-100.0': 0.12060546875,\n",
       " '8-0.1-1000.0-0.001-1': 0.624755859375,\n",
       " '8-0.1-1000.0-0.001-0.1': 0.474853515625,\n",
       " '8-0.1-1000.0-0.001-0.01': 0.615478515625,\n",
       " '8-0.1-1000.0-0.001-0.001': 0.4443359375,\n",
       " '8-0.1-10000.0-10-1000.0': 0.011474609375,\n",
       " '8-0.1-10000.0-10-100.0': 0.015869140625,\n",
       " '8-0.1-10000.0-10-1': 0.02392578125,\n",
       " '8-0.1-10000.0-10-0.1': 0.020263671875,\n",
       " '8-0.1-10000.0-10-0.01': 0.016357421875,\n",
       " '8-0.1-10000.0-10-0.001': 0.01318359375,\n",
       " '8-0.1-10000.0-1-1000.0': 0.0,\n",
       " '8-0.1-10000.0-1-100.0': 0.04150390625,\n",
       " '8-0.1-10000.0-1-1': 0.69873046875,\n",
       " '8-0.1-10000.0-1-0.1': 0.41357421875,\n",
       " '8-0.1-10000.0-1-0.01': 0.656005859375,\n",
       " '8-0.1-10000.0-1-0.001': 0.71435546875,\n",
       " '8-0.1-10000.0-0.1-1000.0': 0.0,\n",
       " '8-0.1-10000.0-0.1-100.0': 0.114013671875,\n",
       " '8-0.1-10000.0-0.1-1': 0.32666015625,\n",
       " '8-0.1-10000.0-0.1-0.1': 0.576171875,\n",
       " '8-0.1-10000.0-0.1-0.01': 0.476318359375,\n",
       " '8-0.1-10000.0-0.1-0.001': 0.343994140625,\n",
       " '8-0.1-10000.0-0.01-1000.0': 0.0,\n",
       " '8-0.1-10000.0-0.01-100.0': 0.08203125,\n",
       " '8-0.1-10000.0-0.01-1': 0.580322265625,\n",
       " '8-0.1-10000.0-0.01-0.1': 0.56640625,\n",
       " '8-0.1-10000.0-0.01-0.01': 0.474609375,\n",
       " '8-0.1-10000.0-0.01-0.001': 0.53857421875,\n",
       " '8-0.1-10000.0-0.001-1000.0': 0.0,\n",
       " '8-0.1-10000.0-0.001-100.0': 0.148681640625,\n",
       " '8-0.1-10000.0-0.001-1': 0.602294921875,\n",
       " '8-0.1-10000.0-0.001-0.1': 0.607666015625,\n",
       " '8-0.1-10000.0-0.001-0.01': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a572b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Decepticon\n",
    "From Wikipedia, the free encyclopedia\n",
    "Jump to navigationJump to search\n",
    "For other uses, see Decepticon (disambiguation).\n",
    "\"Deceptacon\" redirects here. For other uses, see Deceptacon (disambiguation).\n",
    "Not to be confused with Deception (disambiguation).\n",
    "\n",
    "This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)\n",
    "This article needs additional citations for verification. (March 2015)\n",
    "This article may contain an excessive amount of intricate detail that may interest only a particular audience. (March 2018)\n",
    "Decepticon\n",
    "Decepticon small.jpg\n",
    "Decepticon Insignia\n",
    "Publication information\n",
    "Publisher\tMarvel Comics, IDW Publishing, Dreamwave Productions, Devil's Due Publishing, Fun Publications\n",
    "First appearance\tThe Transformers #1\n",
    "(September 1984)\n",
    "In-story information\n",
    "Base(s)\tHomeworld: Kaon, Cybertron\n",
    "Other: Chaar, the Victory (G1), the Megastar (RID), Decepticon City (G1), the Nemesis (G1, ROTF, Animated, SG, Prime).\n",
    "Leader(s)\tMegatron/Galvatron (stated in exodus and the cartoon), Starscream, Steeljaw, Liege Maximo, Unicron, The Fallen/Megatronus (in the movie series)\n",
    "The Decepticons are the main antagonists in the fictional universes of the Transformers multimedia franchise.[1] They are depicted as a faction of sentient robotic lifeforms led by Megatron, identified by a purple face-like insignia. Capable of transforming into alternate forms, these are often high-tech or powerful vehicles; including aircraft, military vehicles, construction vehicles, expensive luxury or sports cars and even smaller-than-human-sized objects.\n",
    "\n",
    "Decepticons are Cybertronian descendants of Terrakors, who are a fictional species of sentient self-configuring modular robotic lifeforms from Skalorr. They are a synergistic blend of biological evolution and technological engineering. The exotic materials that make up their composition is a living metal with a self-replicating cellular structure and genetic code.\n",
    "\n",
    "In the Japanese version of the franchise, the Decepticons are called Destron[2] or Deathtron (Japanese:  Desutoron). The only exception to this naming convention is Car Robots, where the sub-group referred to as \"Decepticons\" in the Robots in Disguise adaptation, is known in Japan as the Combatrons (the Japanese name of the G1 subgroup known as the Combaticons). The overall name of the Robots in Disguise villain faction is Destronger.[citation needed][clarification needed] However, the Japanese Version of Transformers Animated uses Decepticon ().\n",
    "\n",
    "As opposed to the Autobots' Supreme Commander, the Primes, the Decepticons' highest ranking leader is often given the title Emperor of Destruction. Beginning with the original Generation 1 cartoon, the Decepticon rallying cry has been \"Decepticons attack!\", as well as \"Transform and rise up!\" in Transformers: Animated as a play on the Autobots' \"Transform and roll out!\" rallying cry.\n",
    "\n",
    "\n",
    "Contents\n",
    "1\tTransformers: Generation 1\n",
    "1.1\tMembers\n",
    "1.2\tHasbro toyline\n",
    "1.3\tMarvel Comics\n",
    "1.4\tAnimated series\n",
    "1.5\tDreamwave Productions\n",
    "1.6\tIDW Publishing\n",
    "1.7\tBeast Era\n",
    "2\tTransformers: Robots in Disguise\n",
    "3\tUnicron Trilogy\n",
    "4\tLive-action films\n",
    "4.1\tTransformers (2007 film)\n",
    "4.2\tTransformers: Revenge of the Fallen (2009 film)\n",
    "4.3\tTransformers: Dark of the Moon (2011 film)\n",
    "4.4\tTransformers: Age of Extinction (2014 film)\n",
    "4.5\tTransformers: The Last Knight (2017 film)\n",
    "4.6\tBumblebee (2018 film)\n",
    "5\tTransformers Animated\n",
    "6\tTransformers: Timelines\n",
    "7\tAligned Continuity\n",
    "7.1\tTransformers: War for Cybertron\n",
    "7.2\tTransformers: Prime\n",
    "7.3\tTransformers: Robots in Disguise\n",
    "8\tSee also\n",
    "9\tReferences\n",
    "Transformers: Generation 1\n",
    "The Decepticons are from a race called Transformers - robots that can change into vehicles, mechanical devices and even animal forms. They waged war for eons on their home planet of Cybertron against the heroic Autobots. Both factions needed supplies, and select numbers from each side intended to get them. The Autobots did not wish to fight the Decepticons, but they fought in space anyway. When the Decepticons board the Autobots' ship it takes a beating and crashes onto Primitive Earth and knocks everyone unconscious. Millions of years later, in 1984 a volcano eruption causes a probe to give them all new forms which come from vehicles in the surrounding area. After the featured film The Transformers: The Movie, Megatron was reformed as Galvatron, and Optimus Prime was replaced for a time by Rodimus Prime, only to return later on.\n",
    "\n",
    "Members\n",
    "Unlike the Autobots, whose leader is a Prime bearing a Matrix, the Decepticons are led by the most powerful of their ranks (usually Megatron). This tends to cause some conflict, given how generally every Decepticon thinks that they're the most powerful. Also, the Decepticons are not exactly the most compassionate beings in the universe, but not all fight for greed. More than a few have a sense of honor, while others believe that Cybertron would be better protected by aggressive expansion. Ultimately, the Decepticons desire to protect their homeworld, even if it is at the expense of others. Other leaders include Galvatron, Shockwave, Soundwave, Scorponok, Devil Z, Deathsaurous, Starscream, Thunderwing, Jiaxus, Ratbat, and Bludgeaon. Some continuities also has Liege Maximo and The Fallen as the ancestor of the Decepticon faction.\n",
    "\n",
    "Hasbro toyline\n",
    "Hasbro launched the Transformers toy line with eighteen different Autobot characters, all of whom transformed into automobiles, while the ten distinct Decepticons, (seven packages as three came two to a box/pack) were weapons, aircraft and communications equipment. Many of the Transformers were based on Takara designs. Optimus Prime was among the first Transformers released from Hasbro in 1984. The character listing/mini-poster that came inside Transformer packaging identified him as \"Autobot Commander\", as contrasted with Megatron's title of \"Decepticon Leader\".\n",
    "\n",
    "Marvel Comics\n",
    "Main article: The Transformers (Marvel Comics)\n",
    "In the Marvel comic continuity, it was established that the Decepticons came in and out of the gladiator pits on Cybertron. Early on, the leadership of the Decepticons constantly changed due to their tendency to kill and replace their leaders. It would not be until a lowly Decepticon affiliated gladiator named Megatron assumed the throne that the Decepticons became a true threat to the rest of the population of Cybertron.\n",
    "\n",
    "While Megatron was the primary leader, other Decepticons had prominent roles as leaders of the group. Shockwave, Scorponok, Bludgeon, and Ratbat all led the Decepticons, often overthrowing Megatron in the process or taking over the group during the period when Megatron was believed dead.\n",
    "\n",
    "In the G2 Marvel series (which continues from the G1 Marvel series), it is stated that the Decepticon forces on Cybertron underwent a massive split in the wake of Megatron's disappearance when Megatron, Optimus Prime, and their respective troops crashed on Earth. The smartest, strongest, and most intelligent Decepticons left Cybertron to colonize nearby galaxies, leaving a token leadership of overly cruel and duplicitous Decepticons to control Cybertron. These Decepticons who left their homeworld became \"The Second Generation\" Decepticons, who were led by the villainous Liege Maximo. On the final page of the last issue, the Liege Maximo indicates that the Decepticons and all their descendants came from him, which indicates that he is the original founder of the Decepticons.\n",
    "\n",
    "Animated series\n",
    "The Decepticons are a malevolent race of robot warriors, brutal and merciless. The Decepticons are driven by a single undeviating goal: total domination of the universe. In the war that raged between the Decepticons and Autobots for millions of years, their home planet of Cybertron was drained of its once rich sources of energy. In hopes of finding new reserves for making Energon, their basic fuel, the Decepticons followed the Autobots to Earth. Under the leadership of the ruthless Megatron, they continued their efforts to destroy the remaining Autobot forces. They attacked throughout the Earth and in space, using their underwater Decepticon headquarters as their staging base and bunker. But, by the year 2000, the Decepticons had proven to be the losers of the last Great War. In an attempt to bolster the Decepticons' strength, the evil planet gobbling world, Unicron, reformed Megatron into a new robot named Galvatron to lead the Decepticons in a new era. Now, in 2006, the Decepticons have retreated to a burned out hulk of a planet called Chaar, a world of ash and ruin. Galvatron and his Decepticon lieutenants, the sleek and awesome Cyclonus, and the mighty Scourge, the master of the dreaded Sweeps, strike fear throughout the universe. Their ultimate goal: to reconquer Cybertron and destroy the Autobots.\n",
    "\n",
    "In the original animated series continuity, the Decepticons owe their warlike ways to their faction's origin as military hardware robots, created by the five-faced aliens, the Quintessons, while the Autobots were designed as consumer goods. Following the rebellion that forced the Quintessons off the planet, the Decepticons - as they named themselves - lusting for power, began a civil war. The Autobots could not hope to match the superior firepower and battlefield powers of the Decepticons, and instead turned to stealth, developing the art of transformation, modifying their bodies so that they could assume other forms. With this additional power, the Autobots were able to win the conflict, and a period of peace began, known as the Golden Age of Cybertron, when energy was plentiful and the planet shone with a golden hue.\n",
    "\n",
    "Working in secret, the Decepticons also developed transformation technology, along with new robot-mode flight powers, and, under the command of one of the first of this new breed, Megatron, they attacked one of the capital's outer cities, killing the current Autobot leader. As the knowledge of this act was not made public, younger robots continued to idolize these powerful new flying robots - until one such young robot, Orion Pax, was duped by Megatron into allowing him access to an energy storage facility. Megatron turned on Pax and fatally injured him, but the ancient Autobot, Alpha Trion, then rebuilt Pax into the first of a new, battle-hardy breed of Autobot - now, he was Optimus Prime, leader of the Autobots, who led them against Megatron and the Decepticons as the civil war erupted once more.\n",
    "\n",
    "After five million years, Cybertron was nearly depleted of all its energy when the Decepticons received word that the Autobots were planning to search for new energy resources. Following the Autobot ship, the Ark, in their ship, the Nemesis, the Decepticons boarded the Ark and engaged the Autobots on their ship. Unfortunately, the Ark drifted too close to Earth and crashed landed in a volcano. All the occupants of the Ark went into emergency stasis, while the Decepticons on the Nemesis ejected to South America. There, they scanned the forms of local insects, becoming the Insecticons. After 4 million years, the volcano the Ark was wedged in, erupted in Earth year 1984, restarting its computer, Teletraan I. Sending out Spy Satellites, Teletraan created alternative forms out of Earth vehicles for any transformers caught in its scanning beam (like F-15 Eagles for Skywarp and a Semi-trailer truck for Optimus Prime). The Decepticons awakened first but later the Autobots did too, thanks to Starscream's carelessness.\n",
    "\n",
    "By the Earth year 2005, however, the Decepticons had succeeded in completely conquering Cybertron. In a final attempt to destroy the remaining Autobots they attacked Autobot City on Earth but were defeated. On their way back to Cybertron Astrotrain encountered difficulty leaving Earth's gravity due to an over-large payload. Starscream convinced the others to jettison all the damaged and dying decepticons, including Megatron. Megatron was then found by Unicron who offered to rebuild him in return for destroying the Autobot Matrix of Leadership. Megatron was reformed into Galvatron who returned to Cybertron, destroyed Starscream for his treachery and reassumed command of the Decepticons. Galvatron then attempted to use the Matrix against Unicron, provoking him into attacking Cybertron. The attack coupled with the temporary loss of Galvatron shattered the decepticon forces, allowing the Autobots to reclaim their home planet. The Decepticons fled to the planet Chaar, a world of ash and ruin, where they struggled to survive until Galvatron returned to them and reorganized them into a fighting force, battling to take back Cybertron.\n",
    "\n",
    "Dreamwave Productions\n",
    "After Autobot leader Optimus Prime and Decepticon leader Megatron disappeared in a Space Bridge accident several million years ago, the Autobots and Decepticons split up into several factions. One of those who broke away was Ratbat, who quickly took the opportunity to form his own power base. Gathering loyalist followers and setting up their HQ in the Polyhex region of Cybertron the Ultracons quickly came into conflict with the Autobot splinter faction The Wreckers. However, Ratbat added a secret weapon to his ranks - the combiner team the Constructicons, in flagrant defiance of treaties banning their use in the civil war as both Autobots and Decepticons splintered.\n",
    "\n",
    "When the Ultracons attacked the Tagan Heights in order to seize its factories for themselves, they were opposed by the Wreckers. Ratbat quickly unleashed the Constructicons in their combined form of Devastator, routing the Wreckers. However, Ratbat was prevented from executing his rival Springer by the arrival of the Protectobots in their combined form of Defensor. The Autobot combiners were hoping to prevent an arms race between the various factions by stopping combiners signing up with the factions. After the battle devastated the very manufacturing facilities the two factions hoped to acquire, the Protectobots separated and defeated Devastator via sabotage. With their most potent weapon gone, the Ultracons retreated.\n",
    "\n",
    "Later, the Ultracons joined with the Decepticons under Shockwave to support a peace accord with the Autobots, fighting off Starscream's Predacon faction. However, Megatron's return with an army of Seeker clones would bring a halt to the peace proceedings, and the Ultracons would be reabsorbed into the Decepticons.\n",
    "\n",
    "IDW Publishing\n",
    "The origins of the Decepticons in the IDW continuity would be explored in The Transformers: Megatron Origin, which confirmed Megatron as their founder in this timeline. A lowly miner, Megatron penned a manifesto against Functionalism, the forcible assignment of cybertronians to jobs based on their vehicle modes, which was in force at the time on religious grounds. Megatron began to work against the practice through peaceful protest, but following imprisonment and a brutal beating by police, he determines that force is the only way to bring about equality. Ironically, on his way out the station after having been saved from a government ordered 'accidental-death-by-interrogation', he first meets the future Optimus Prime, who would go on to use his original writings as the basis for the Autobot movement.\n",
    "\n",
    "On the run after an unrelated attack on an Autobot Senator after a mining dispute, Megatron stumbled onto underground gladiator games in the state of Kaon and quickly became one of its rising stars. However, it only truly became more than this when Ratbat, then a senator seeing an opportunity for profit, dispatched Soundwave to arm the gladiators. Megatron's forces then began to commit acts of terrorism increasing in scale and daring, attracting the attention of Sentinel Prime. Kidnapping Senator Decimus as a symbol (with the help of new airborne recruit Starscream) Megatron issued a rallying call to the gladiators and their supporters, promising to unite them under one badge and make the whole planet their arena. Sentinel Prime's forces then found and arrested them en masse. This was all part of Megatron's plan: a supposedly informant Starscream massacred the Autobot Senate and freed the prisoners, signalling revolution and anarchy in Kaon. Megatron eventually seemed to have killed Sentinel Prime one-on-one, and the Decepticons were forged.\n",
    "\n",
    "In this continuity, there are a number of differences to the traditional norm. The Decepticons are no longer based on Cybertron due to its devastation by rogue scientist Thunderwing. Instead, they have spread out through the galaxy, using their transforming abilities to infiltrate target worlds (such as Earth or Nebulos) disguised as local vehicles and equipment. They then use their modes to create conflict, leading to complete anarchy as the world's political and social systems collapse. The Decepticons then move in and harvest the world's raw resources. How the world is pacified is unknown, although The Transformers: Spotlight issue on Sixshot revealed he is often sent in to complete the destruction of entire worlds. As in other continuities, Megatron is in command, and thus far has had to deal with the rebellion of Starscream's Earth infiltration unit and the reemergence of Thunderwing, as well as moving on to Earth in order to harvest the extremely powerful Energon variant Ore-13, something which promises to give the Decepticons a significant edge over the Autobots.\n",
    "\n",
    "The IDW continuity is unique in that it portrays the Decepticons as originally a force for good, standing up against oppression, who eventually themselves became oppressors. A large number of those who would become Autobots, including Optimus Prime himself, even support the Decepticon cause in the beginning, before it turns violent.\n",
    "\n",
    "Beast Era\n",
    "The Decepticons eventually evolve into the Predacons, a faction in the fictional Beast Wars universe created by Hasbro. Previously the name Predacon had been associated with the Transformer group which combined to form Predaking. The faction made their first appearance in the Beast Wars toyline and animated series, and have been represented in various Transformers animated series, comic books and toylines since.\n",
    "\n",
    "A Predacon is most commonly represented as a Decepticon descendant with a new smaller, more energy-efficient body. This body transforms into an animal instead of a vehicle. Though the Decepticons and Predacons share many similarities, several important differences exist, such as leadership and ideals (for example, choosing a pretense of peace with the Maximals, rather than maintaining a war at all costs). It is not completely known as to how the faction gained predominance over all the other various Decepticon factions, although the comic book miniseries Beast Wars: The Gathering has provided hints that their heritage may be found in the original combiner team Predacons, hints confirmed by the subsequent Timelines: Dawn of Futures Past, which confirmed that Razorclaw, Divebomb and the other Predacons had been working behind the scenes.\n",
    "\n",
    "Transformers: Robots in Disguise\n",
    "In Transformers: Robots in Disguise, the Decepticons were not the name of the evil faction, but rather a sub-faction created by Megatron. The main faction was instead the Predacons (carrying the name of the main villains over from Beast Wars), who transformed into mechanical animals. Realising that their ability to travel as Earth vehicles gave the Autobots an edge in stealth, Megatron decided to take drastic action.\n",
    "\n",
    "Megatron recovered the protoforms of six Autobots that had crashed to Earth some time before looking for Fortress Maximus. Scanning them with vehicle modes at a military base and infusing them with a fraction of his spark energy to ensure their new loyalty, the first five became the Commandos. But when Megatron tried to scan a tanker truck as an alternate mode for the leader Scourge, Optimus Prime was scanned as well, resulting in much of Prime's personality being scanned as well. With an infusion of Megatron's spark energy to complete the concoction, Scourge was born, emerging from his pod as a dark twin of Optimus Prime, who proved that Megatron's programming had over-ridden any Autobot goodness within him. Appointed leader of the new \"Decepticons\", they quickly established themselves as a force to be reckoned with.\n",
    "\n",
    "The newly created Decepticons would try many schemes over the course of the series, including attacking various dams and faking their defection to the Autobots. But their leader, Scourge, had grander ambitions in mind. The copy of Optimus' personality had been warped by Megatron's evil influence, but the individuality of Optimus remained and Scourge now wanted to control both Predacons and Decepticons. He would seize his chance when Fortress Maximus was awakened, directing him to destroy Galvatron (Megatron's new form). The attempt failed and Galvatron took a terrible revenge - he stripped the Decepticons of their individuality, turning them into little more than drones. After Galvatron's defeat by Omega Prime, the Decepticons were among those sent back to Cybertron for imprisonment, except for Sky-Byte.\n",
    "\n",
    "Unicron Trilogy\n",
    "The Decepticons appeared in Transformers: Armada, Transformers: Energon, and Transformers: Cybertron as mostly jets and military vehicles.\n",
    "\n",
    "In the Unicron Trilogy continuity, the early history of the war is not expounded upon. The Decepticons, however, remain the main antagonists, with whom the Autobots have been warring for quite some time. The enslavement of the small, power-enhancing Mini-Cons has long been a major goal of the Decepticons, and the Mini-Cons are seen as key to winning the war.\n",
    "\n",
    "Near the end of Armada, the Autobots and Decepticons join forces to defeat the planet-devouring Unicron, and the beginning of Energon sees them as uneasy allies. Many return to Megatron's side when he returns.\n",
    "\n",
    "Cybertron sees a much smaller Decepticon force than the previous two series, and what has become of most of the survivors of the earlier series remains unknown. As Megatron's true plans are discovered, most of the Decepticons, unwilling to be sacrificed as pawns as their leader seeks to remake the universe, again battle a common foe alongside the Autobots. The end of the series sees three of the comic-relief characters, with a reluctant Thundercracker, desiring to begin a new Decepticon force, and take off in a makeshift rocket. It makes it as far as Mars before it crashes, as the ending credits montage of the final episode shows. The foursome survives, however. The fates of the other surviving Decepticons remains unknown, though evidence of Starscream's survival is discovered.\n",
    "\n",
    "Live-action films\n",
    "The Movie Prequel comic by IDW Publishing would reveal their origins. Originally Optimus Prime and Megatron ruled Cybertron together, due to the power of the Allspark, a mysterious device that could give life to Transformers - and keep Cybertron itself alive. Eventually, Megatron began to desire its power for himself and assembled a like-minded army of separatists - the Decepticons. Megatron soon struck, and Cybertron became embroiled in civil war. However, this would later seem to be changed by the sequel films, where it is revealed that Sentinel Prime was the first leader of the Autobots and The Fallen the founder and supreme master of the Decepticons. Optimus would only take command after Sentinel was seemingly killed in action and Megatron served as leader of the second incarnation of the Decepticons with The Fallen as his master and mentor due to the latter's incapacitation. The subsequent prequel novel Transformers: Ghosts of Yesterday revealed that Starscream seized command of the Decepticons after Megatron's disappearance.\n",
    "\n",
    "Transformers (2007 film)\n",
    "The Decepticons make an appearance in the 2007 the Transformers live-action film. They include Megatron (Hugo Weaving), Starscream, Frenzy, Blackout, Barricade, Scorponok, Brawl and Bonecrusher. Like the Autobots, the Decepticons are designed to look more organic in the movie. While the Autobots have more human-like appearances, the Decepticons are more monstrous; they tend to resemble carnivorous insects, mammals and birds. In the film, the Autobots intend to use the AllSpark, the object that created their robotic race, in an attempt to rebuild Cybertron and end the war, while Megatron and the Decepticons desire to control it with the intention of building an army by giving life to the machines of Earth. Ultimately, nearly all the Decepticons who participated in the first battle (except Starscream, Scorponok and Barricade) are killed and the AllSpark is used by Sam to kill Megatron, thus making the Autobots accept Earth as their new home, while allying with humans to continue to hunt down remaining Decepticons.\n",
    "\n",
    "Transformers: Revenge of the Fallen (2009 film)\n",
    "In Transformers: Revenge of the Fallen it is revealed that The Fallen, a Prime who turned to evil, is the founder of the Decepticons, with Megatron being the leader of its second incarnation, accepting The Fallen as his master and mentor. This would seem to imply the Decepticons were originally Autobots who turned evil. In the final battle in the second movie, there are many Decepticon casualties including Devastator (destroyed by a rail gun), Mixmaster (cut in half and his head stomped off by Jetfire), Rampage (killed by Bumblebee), Ravage (stripped from his spine by Bumblebee), Scrapper and Long Haul (killed by an airstrike), Scorponok (head crushed by Jetfire) and the Fallen himself (spark ripped out by Optimus Prime). Also killed in the movie are Sideways (while still in his vehicle mode) by Sideswipe and Demolishor, killed at the beginning by Optimus and Ironhide. Following the Fallen's death, Megatron officially takes full command of the Decepticons at this point, swearing vengeance.\n",
    "\n",
    "Transformers: Dark of the Moon (2011 film)\n",
    "The Decepticons return in Transformers: Dark of the Moon with the plan to use a Space Bridge to bring an army to Earth and transport Cybertron into orbit to rebuild the planet with Earth's natural resources and human population as slaves. Megatron and Sentinel Prime planned this a long time ago, planning to meet on Earth before Megatron went after the Allspark and ended up frozen and the Ark was shot down by Decepticon fighters (few Decepticons knew of the plan) and crashed on Earth's Moon in 1961. This was detected by the Americans and the Russians and the space programs were created to reach the ship and study it. However, by 1963 the Decepticons had raided the Ark and removed all but five of the pillars and hid them on the Moon along with an army of hundreds of Decepticons, awaiting the time that the pillars would be used. After humans successfully reached the Moon and explored the ship, Soundwave and Laserbeak approached various humans including Dylan Gould's father to get them to shut down the American and Russian space programs.\n",
    "\n",
    "The Decepticons established a network of human collaborators who kept the humans from noticing the Decepticons actions on the Moon, later led by Dylan Gould. After a human collaborator named Alexi Voshkod leads NEST to Chernobyl where they retrieve an engine part from the Ark, the Decepticons reemerge for the first time since Egypt in the form of Shockwave and his Driller who attack, but retreat. This leads the Autobots to retrieve Sentinel and the remaining space bridge pillars and revive him and as this is going according to plan, Megatron orders Laserbeak to kill all the human collaborators but Dylan Gould which he does. Before he's killed, one of the collaborators named Jerry Wang alerts Sam Witwicky to this and he alerts NEST which ignores it. Sam and Seymour Simmons find out about the Decepticons plot from pictures a Russian probe got of the Decepticons hiding the pillars and the Dreads are sent to attack the convoy protecting Sentinel, but are killed by Bumblebee, Dino, Sideswipe and Ironhide.\n",
    "\n",
    "After Sentinel reveals his true colors and murders Ironhide, he sets up the pillars in the National Mall and brings the Decepticon army consisting of hundreds of Decepticon soldiers and Decepticon ships to Earth. With the army in hand, the Decepticons promise to bring no war against the human population in exchange that the Autobots must leave Earth. While taking off into the atmosphere, Starscream destroyed the ship, knowing that mankind will resist on their own. Some of the Decepticons scatter around the world to set up the pillars, but most of the army invades Chicago, devastating the human population and taking over. The Autobots, NEST and a team of mercenaries led by Sam Witwicky and Robert Epps invade Chicago and battle the Decepticon army, aided by the United States Army, and U.S. Air Force. The group manages to take out much of the army including Laserbeak (killed by Sam Witwicky and Bumblebee), the Driller (killed by Optimus), Starscream (killed by Sam Witwicky and Sergent Lennox), Soundwave (killed by Bumblebee), Barricade (killed by NEST) and Shockwave (killed by Optimus) and disrupt the Control Pillar, forcing Sentinel into battle. The combined human and Autobot forces overwhelm Sentinel and his remaining forces and Tomahawk missiles destroy most of the Decepticon fighters, forcing Sentinel to flee before engaging Optimus one-on-one. Dylan Gould reactivates the space bridge, but Sam Witwicky kills Gould, and Ratchet and Bumblebee destroy the Control Pillar, causing Cybertron to collapse and ruining the Decepticon plan. Also, the remaining Decepticon ships are sucked up into Cybertron by the space bridge and are destroyed with the planet.\n",
    "\n",
    "Sentinel nearly kills Optimus, but Megatron, convinced by Carly Spencer that he would end up working for Sentinel unless he could get rid of him, turns on Sentinel and severely injures him. Upon seeing Cybertron being destroyed with the space bridge, Megatron attempts to make a false truce with Optimus, but Optimus doesn't fall for it and kills Megatron and Sentinel. While the loss of human life in Chicago is massive, the battle is a major victory for the Autobots as they eliminated most of the Decepticon army on Earth (including Gould by traitor) despite there being some still scattered around the globe and the entire Decepticon command structure was destroyed with all of its members killed in the battle.\n",
    "\n",
    "Transformers: Age of Extinction (2014 film)\n",
    "While the regular Decepticons do not actually appear in Transformers: Age of Extinction (except Megatron who was reborn as Galvatron), they do play a role in the story as secondary antagonists. The \"Battle for Chicago\" (climactic battle of Dark of the Moon) has become a 9/11 like event to the public 5 years after the third film and a ruthless government organization named Cemetery Wind have begun hunting Decepticons who are still scattered around the globe and secretly hunted Autobots alike when the alliance between humans and Autobots ended (including alliance between humans and Decepticons as Dylan Gould is already dead). It was mentioned that there might still be less than a dozen Decepticons and Autobots hiding on the planet Earth by Harold Attinger (Kelsey Grammer). The film's antagonist is instead the neutral assassin and bounty hunter Lockdown, who may have been a Decepticon at one point, sent to Earth to hunt Optimus Prime by the Transformers' creator race (unseen in the movie). Lockdown and Attinger make a three-way deal along with a company named K.S.I., Kinetic Solutions Incorporated, by the boss, Joshua Joyce, who uses the original Decepticons' (and Autobots') remains to build new Transformer prototypes which can be controlled by humans and must eliminate those who cross their path such as the Yeager family who know this secret.\n",
    "\n",
    "Their crown jewel is Galvatron, who becomes possessed by Megatron's (Frank Welker) consciousness and then possesses the other prototypes and turns them into Decepticons controlled by him. Galvatron plans to use the Seed, a device that can create Transformium, the metal Transformers are made of, to rebuild his Decepticon army and conquer Earth, when Joyce was called by Cade Yeager, and, knowing that he was manipulated by Attinger and Galvatron, escapes with the Seed. After the final battle in Hong Kong, all the Decepticons are destroyed by Cade, the Autobots and Dinobots, except Galvatron, who escapes after Lockdown and Attinger are killed by Optimus Prime, vowing to return one day, for he is reborn, before Cemetery Wind dissolved by their crimes and branded as a terrorist organization.\n",
    "\n",
    "Barricade, Soundwave and a number of other Decepticon \"protoform drones\" appear in archival footage from Dark of the Moon presented by Attinger. Various deceased Autobots and Decepticons appear throughout the film in Chicago and in the KSI lab, including Megatron's head.\n",
    "\n",
    "Transformers: The Last Knight (2017 film)\n",
    "The Decepticons return in Transformers: The Last Knight with the revived leader, Megatron, when a war for survival has commenced between the human race and the Transformers and set up a military organization of TRF (Transformers Reaction Force). The Decepticons began to search for the staff when Barricade reports to Megatron that human has found the mysterious talisman they're seeking and suggests using TRF their purposes. Megatron contacting TRF abducting two CIA agents and offered an exchange to release his group of Decepticons. During the final battle, they assist the sorceress Quintessa in draining the life-energy from Earth to repair a damaged Cybertron and began to defend the from the Autobots and military. But the Autobots broke through and most of the Decepticons began to die and were defeated.\n",
    "\n",
    "Bumblebee (2018 film)\n",
    "The Decepticons return in Bumblebee, where they are first seen during the final battle for Cybertron against the Autobots. The Decepticons on Cybertron are co-led by Shockwave and Soundwave, who proceed to force the Autobots off of Cybertron.\n",
    "\n",
    "At some point prior to this battle, the Decepticon Seeker Blitzwing was sent to Earth by the Decepticons for unknown reasons. After the Autobot scout B-127 lands on Earth, Blitzwing intervenes in an ensuing skirmish between the Autobot and the human special operatives group known as Sector Seven. He proceeds to engage B-127 and interrogate him about Optimus Prime's whereabouts, even ripping out the scout's vocal processor and attempting to execute him. Before he could do this, however, B-127 attached one of Blitzwing's missiles onto Blitzwing's body, causing him to explode and die in the process.\n",
    "\n",
    "Decepticon Triple-Changer agents, Shatter and Dropkick are sent to intercept lieutenant Cliffjumper, one of the Autobots that escaped at the beginning of the film, in the hopes that they may find the Autobot leader, Optimus Prime. Cliffjumper refuses to reveal Optimus' whereabouts and thus subsequently fatally sliced in half by Dropkick.\n",
    "\n",
    "Transformers Animated\n",
    "In Transformers Animated, the Decepticons are usually bigger and stronger than the Autobots and usually turn into jets and military vehicles. It takes a group of Autobots to defeat one Decepticon and almost all Decepticons have red eyes and can fly[citation needed]. Most Decepticons in the series are similar to the original G1 series. In the Animated Series Blitzwing, for example, retains his triple changer modes of a tank and jet and also retains his G1 tan and purple color scheme.\n",
    "\n",
    "This series depicts a Decepticon force that is far from what it apparently once was, with Megatron having been chasing the Allspark for millions of years prior to the series' beginning. The Decepticons have been \"wandering the periphery\" for some time, but have been driven off of Cybertron long ago. These Decepticons see themselves as \"freedom fighters\", seeking to throw off \"Autobot tyranny\", and their plans tend to revolve around returning to Cybertron with the means to retake it. What started the great war in this series was some of the Cybertronians being kicked off of Cybertron for being freaks, eventually forming an alliance called the \"Decepticons\". Now the Decepticons fight for their rights and try to take back what was rightfully theirs.\n",
    "\n",
    "Transformers: Timelines\n",
    "A series of stories printed by Fun Publications, set in a variety of continuities, the Decepticons of alternate worlds can vary greatly from the classics Decepticon image. In the Transtech storyline, the Autobots and Decepticons are merely political factions on a Cybertron which never broke out into war. Lines between good and evil are more blurred.\n",
    "\n",
    "In the Shattered Glass storyline, a group of Decepticons, led by Megatron, are the mirror images of the personalities of most Decepticons. In this world the Decepticon logo is red, and worn by heroic Transformers who seek to protect the weak and oppressed from the evil Autobots.\n",
    "\n",
    "Aligned Continuity\n",
    "The main group of Decepticons, led by Megatron, in the 2010 computer animated series Transformers: Prime is much larger than in most continuities considering their ranks are bolstered by a clone army of drone named Vehicons (a possible homage to Beast Machines) who all look-alike though some have different vehicle modes and have personalities. The Vehicons are sometimes the center of a joke often shown unable to do their job and are very incompetent as well as constantly being killed off way too easily by the Autobots. However The Decepticons don't appear in the series Transformers: Rescue Bots, though it has been heavily implied that the two shows take place in the same continuity. The Decepticons are briefly mentioned by Heatwave in the episode \"Bot to the Future\", (who also mentioned Unicron in an earlier episode) when the Autobots arrive in an alternate timeline ruled by Morbots (who resemble Vehicons), Bumblebee believes the Morbots are Decepticons, only for Heatwave to correct him. In a later episode, the recruits retrieve what appears to be a cassette tape from a derelict spaceship and it transforms into an injured Laserbeak. The group disagree over whether to help him as he is a Decepticon (Hotshot in particular is against doing so) and it's ultimately revealed that Wedge was originally built as a Decepticon but was given the chance to instead be an Autobot (a fact he kept from the others due to the prejudices shown in this episode). In the end, they allow Laserbeak to stay at the academy while he recovers.\n",
    "\n",
    "Transformers: War for Cybertron\n",
    "In Transformers: War for Cybertron and Transformers: Fall of Cybertron, Megatron has come across a legendary element called \"Dark Energon\". He infiltrates Starscream's space station in order to corrupt himself with it. He then kills the Autobots' leader Zeta Prime and obtains the Omega Key, which then activates Omega Supreme. After Megatron defeats Omega Supreme, he goes to Cybertron's core and corrupts it with Dark Energon. Optimus Prime becomes the new Autobot leader, and heads into the planet to rescue Omega Supreme. He opens the Omega Lock into the core after Ratchet purges the Dark Energon corruption. Optimus discovers that he is too late to save Cybertron from the Dark Energon corruption, and the core must shut down for about one million years to survive. Optimus is giving a piece of Cybertron's spark for safe-keeping (The Matrix of Leadership). When Optimus evacuates the Autobot forces from Cybertron, Megatron tries to stop them from leaving. Silverbolt, Air Raid, and Jetfire try to stop it, but the space station transforms into Trypticon and crashes on Cybertron. Optimus and his Autobots then defeat Trypticon. Megatron has Trypticon rebuilt into the Nemesis. The Nemesis pursues the Ark, and then Megatron shoots Bumblebee. They go into a space bridge, and leave Cybertron to a lifeless wasteland.\n",
    "\n",
    "Transformers: Prime\n",
    "\n",
    "This article's plot summary may be too long or excessively detailed. Please help improve it by removing unnecessary details and making it more concise. (December 2019) (Learn how and when to remove this template message)\n",
    "By the time of Transformers: Prime, it has been three years since the Decepticons last attacked Earth and the Autobots still await their return. After the death of Cliffjumper, the Autobots fight to protect the Earth from the Decepticons and befriend three young humans while preparing for the return of Megatron, who has been missing for three Earth years. Megatron plans to use Dark Energon to raise an undead army of Cybertronians and defeat the Autobots. The Autobots destroy his space bridge and Megatron is believed killed in the process. Starscream becomes the new Decepticon leader. After Megatron's apparent death, new Decepticon leader Starscream does not stray from Megatron's path and recruits several new Decepticons. Starscream attempts many missions to destroy the Autobots and find their headquarters, while keeping a shard of the \"last\" remaining Dark Energon that he took out of Megatron's chest. In the episode \"Out of His Head\", Megatron returns after an incident where he takes control of Bumblebee's mind. Megatron then reclaims leadership of the Decepticons, keeping a strict eye on Starscream. After Starscream uses Megatron's share of Dark Energon, he tries to find more to once again bring back his \"un-dead army\". At the end of the episode \"Partners\", Starscream became an independent, striking out on his own, having become fed up with being disrespected. During the final four episodes of the season, the Autobots unwillingly team up with Megatron to battle a legendary threat to Earth's existence, Unicron.[3] To defeat Unicron, Optimus uses the Matrix of Leadership.\n",
    "\n",
    "With this sacrifice, he not only loses the Wisdom of the Primes but also his memories of the war and his comrades, and joins Megatron as a Decepticon under his old name, Orion Pax. Orion, under the false truths about the Autobots being evil and the Decepticons being good, Megatron, then sets about decoding the Iacon Database. The Autobots save him, journeying to Cybertron and back to recharge the Matrix of Leadership and help him regain his memories, but the Decepticons continued to search for the relics Orion did decode throughout Season 2, managing to decode all of them thanks to Soundwave's persistence and computer skills. Starscream meanwhile attempts several times to create personal armies and an alliance with MECH, only for the human terrorists to take his T-cog to construct Nemesis Prime as well as a failed attempt to assassinate Megatron. The Insecticons also join the crew of the Nemesis when Airachnid tries to eliminate Megatron for trying to terminate her previously. Airachnid is later imprisoned in a Stasis pod by Acree and held as a prisoner in the Autobot Base. Team Prime also is granted another Autobot when Smokescreen, the rookie warrior and bodyguard of Optimus Prime's mentor Alpha Trion, arrives on Earth in a Decpticon escape pod and Megatron gains MECH leader Silas, who has taken Breakdown's body for his own after nearly being killed by Optimus Prime, as an ally until he fails Megatron's expectations, causing Cylas (as he calls himself) to end up as Knockout's science experiment. When Optimus claims possession of the Star Saber and learns of the last four Iacon relics: the Omega keys (devices that can restore Cybertron), Megatron replaces his arm with an Ancient Prime's arm, so he can use the Forge of Solus Prime to turn a chunk of Dark Energon into the Dark Star Saber. In the battle that follows, Megatron destroys the Star Saber, robbing Optimus of Victory.\n",
    "\n",
    "Defeated, Optimus Prime retreats, gaining the first Omega Key in the process due to Smokescreen's clever thinking. Knock Out obtains the second however using the Resonance Blaster, and Starscream obtains the third using a dose of speed-enhancing Red Energon. The fourth and final one is revealed by Soundwave to have been inside Smokescreen, placed there to make sure it got to Optimus from Alpha Trion. After the Decepticons kidnap him, Knock Out uses the phase shifter to remove it. Megatron also finds out the purpose of the keys, by using the cortical psychic patch on Smokescreen. When Megatron leaves Knockout alone with him, Smokescreen and Knockout fight over the phase shifter, ending with the Autobot placing Knockout in a wall and leaving him there. He takes the one the Decepticons had and his and escaped the ship, starting a free fall battle, resulting in Smokescreen's escape. Starscream then goes on to steal the three keys the Autobots had. Starscream, now with all 4, uses them as a peace offering to rejoin the Decepticons.\n",
    "\n",
    "Dreadwing becomes angry that Megatron allowed Starscream to rejoin the Decepticons after seeing that Starscream turned Skyquake into a Terrorcon. He gives Optimus the Forge of Solus Prime, and attempts to kill Starscream but is killed in the process by Megatron. Knockout and Starscream use the keys and find out the location of the Omega Lock, with Optimus already knowing its location and turning the Goundbridge into a spacebridge, and reforging the Star saber. The Autobots head to Cybertron, fighting off the Decepticons with their Iacon relics, take back the keys and manage to kill all the Vehicons, managing to reach the Omega Lock. Sadly, the victory is short lived, as the Decepticons force them to give them back the keys, or they will expose Jack, Miko, and Raf to Cybertron's toxic atmosphere. The Autobots are forced to yield and give them the keys, which Megatron uses to rebuild the Hall of Records. He then opens a space bridge, and tries to terraform Earth into a new planet he considers calling New Kaon.\n",
    "\n",
    "Optimus, fearing for humanity and unwilling to let another world be destroyed, takes his Star Saber and cuts off Megatron's arm and destroys the Omega Lock, leaving Cybertron in its liveless state forever. The Autobots retreat back to Earth, only to find that Jasper, Nevada has now been changed into a giant fortress. The Nemesis lands there, and Optimus discovers the Decepticons have discovered the location of their base. Under Megatron's orders, Starscream leads an armada of Vehicons and Insecticons to start attacking the base. Wheeljack and Agent Fowler try and hold off the new Vehicons as long as they are able, trying to allow Team Prime to escape. Optimus has Team Prime split up to different parts of the country in the hope of making them more difficult to hunt down, with Optimus remaining behind to ensure the Decepticons could not follow. Outside, Wheeljack's ship, the Jack Hammer is shot down by Starscream. The Decepticons then blow up the base with Optimus inside as he destroys the Ground Bridge with Agent Fowler and June Darby watching in horror as the base explodes. Megatron and Starscream then fly down to the remains of the base to search for survivors. Celebrating their victory, they fail to notice Optimus's arm sticking out of the rubble.\n",
    "\n",
    "In Season 3, the Decepticons hold earth hostage with their fortress, christened as Darkmount, and search for the autobots across the United States, To track the autobots, the recently returned Shockwave brings with him a Predacon to hunt down the scattered Autobots. When the Predacon fails, the search continues under Starscream's command. This search is put on hold however when the Autobots unite under Ultra Magnus to assault Darkmount. However, as the assault continues, it is the Decepticons who emerge victorious even with the loss of the Predacon, capturing Team Prime. However, Optimus Prime, returned to health by Smokescreen's use of the Forge of Solus Prime, attacks Darkmount, defeating Megatron in one on one combat in the air and destroying the fortress' fusion cannons so that the military can destroy the fortress. Forced to use the Nemesis as their base once again, Megatron begins sending units to hunt down Predacon fossils in the hope of gaining an advantage over the Autobots through cloning an army. The return of the Predacon (Predaking himself) adds to this advantage. However, the Decepticon ranks are thinned when Starscream and Knock Out accidentally turn Cylas into a Terrorcon that can turn other Decepticons into Energon vampires through a mixture of Synthetic and Dark Energon. This plague also leads to Airachnid's escape and her retaking control of the Insecticons, forcing Soundwave to teleport her armada to one of Cybertron's moon's and leaving them to be eaten by her as she has become a Terrorcon hybrid. This accident forces the cloning process to be sped up on Project Predacon due to the loss of more than half of Megatron's forces. However, Project Predacon is terminated when Predaking reveals he is capable of higher thought as well as transformation, forcing Megatron to lure the Autobots into destroying the cloning laboratory for him. With the destruction of the lab, it is revealed that Predacon CNA combined with Synthetic Energon is capable of producing cybermatter. Attention is then focused on the restoration of the Omega Lock and the completion of the Synthetic Energon formula. To complete it, Ratchet is kidnapped and forced to aid in completing the formula, at which he succeeds. Megatron however does not count on Ratchet turning Predaking against him, nor the Autobots assaulting the Nemesis. With this, Megatron rallies his troops for a final stand. Though he kills Bumblebee and nearly kills Optimus, Megatron is killed by a resurrected Bumblebee who emerges from the Omega Lock and stabs him in the spark with the Star Saber, sending him tumbling to the earth far below. With Megatron's death, and Soundwave trapped in the Shadowzone by Jack and Miko, the remaining Decepticons are killed, imprisoned or retreat with Shockwave and Starscream to the ship's escape pods.\n",
    "\n",
    "In the film \"Predacons Rising\" - which serves as the series finale - it is further revealed that while many Decepticons were imprisoned, some defected to the Autobots to help rebuild Cybertron. Starscream and Shockwave, however, remain at large and having cloned two new Predacons they have named Skylynx and Darksteel, they continue to hunt Predacon bones to clone more soldiers. When Megatron returns, Starscream is at first overjoyed to have their leader back, but upon realization that Unicron is overshadowing and controlling him, Starscream retreats while Shockwave and the Predacons fight. Shockwave is also the one who suggests that the Predacons, now under Predaking's full leadership, help the Autobots defeat Unicron and his undead army. Starscream and the Decepticon prisoners aboard the Nemesis attempt to take control of the ship, only for Knock Out to change allegiance to the Autobots and imprison Starscream while the remaining mutineers are killed. Though Starscream escapes, Knock Out stays to help stop Unicron. When Unicron is defeated and imprisoned by Optimus Prime, Megatron is freed from his control and officially disbands the Decepticons and flies off to start a new life, as he is tired of conquest and no longer wishes to oppress anyone, having just experienced it himself. Starscream takes Megatron's throne but his rule is short-lived when the Predacons arrive to settle old scores, the outcome of which remains unknown.\n",
    "\n",
    "Transformers: Robots in Disguise\n",
    "Five years after the events of \"Predacons Rising\", Bumblebee is alerted to the existence of a new group of Decepticons on Earth. He eventually assembles a team-consisting of Autobots Strongarm, Sideswipe, Grimlock, and Fixit-to contend with these new Decepticons, which include the likes of Underbite and Bisk. Steeljaw, in particular, is the main antagonist, leading a group of Decepticons consisting of bounty hunter Fracture, crime boss Thunderhoof, the metal-consuming Underbite, and the crab-like Clampdown, in hopes of giving the Decepticons their own world. Towards the end of season one, Megatronus/The Fallen, the first Decepticon, contacts Steeljaw and convinces him to build him a space bridge so he can return to Earth. Steeljaw does so, but once on Earth, Megatronus attempts to destroy both Earth and Cybertron. Steeljaw tries to stop him, but Megatronus uses his telepathic powers to throw him into the distance. Ultimately, Megatronus is killed by Bumblebee's team and the rest of Steeljaw's pack is imprisoned.\n",
    "\n",
    "In season two, Steeljaw comes across a group of Decepticons who have turned the Alchemor into their own base, enslaving the Mini-Cons there as well. These Decepticons are led by the strict Glowstrike, ex-pirate Sabrehorn, and the gruff Scorponok. Steeljaw manages to reform his pack by using Scorponok as a distraction while he infiltrates the Autobots' scrapyard and frees Clampdown and Thunderhoof from stasis, along with the insane Springload, the revolutionary Quillfire, hyperactive Bisk, former gladiator Groundpounder, and spy/saboteur Overload. Scorponok is arrested by Bumblebee's team, with Steeljaw fabricating a story that Scorponok had betrayed them. At the end of the season, Steeljaw usurps Sabrehorn and Glowstrike and becomes leader of the escaped Decepticons (collectively known as \"Decepticon Island\"), but Bumblebee's team sets off a specialized bomb that places all Decepticons on board the Alchemor in stasis, including Steeljaw. Optimus Prime, Windblade, Ratchet, and the former Mini-Con prisoners then take the recaptured Decepticons back to Cybertron while Bumblebee decides to establish a permanent Autobot base on Earth.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29334643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11724"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_data = user.dataloader.dataset.tokenizer(text)\n",
    "len(additional_data[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb9d2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11264"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 * 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d86d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aaadc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "B = len(additional_data[\"input_ids\"]) // seq_length\n",
    "print(B)\n",
    "data = torch.as_tensor(additional_data[\"input_ids\"][:seq_length * B]).reshape(B, seq_length)\n",
    "input_data = dict(input_ids=data, labels=data)\n",
    "true_user_data = dict(data=input_data, labels=input_data)\n",
    "server_payload[\"metadata\"].shape = [seq_length]\n",
    "server.secrets[\"ImprintBlock\"][\"data_shape\"] = [seq_length]\n",
    "user.num_data_points = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f610e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update in model mode: eval.\n"
     ]
    }
   ],
   "source": [
    "shared_data, true_user_data = user.compute_local_updates(server_payload, custom_data=input_data)\n",
    "shared_data[\"metadata\"][\"num_data_points\"] = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9596886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker.cfg.sentence_algorithm = \"dynamic-threshold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88412947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9660 embeddings with positional data from imprinted layer.\n",
      "Assigned [369, 436, 441, 436, 448, 440, 448, 435, 432, 438, 438, 438, 443, 432, 493, 452, 446, 447, 427, 431, 444, 446] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6569 | S-BLEU: 0.35 | FMSE: 9.6357e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.59| Token Acc: 86.86% | Label Acc: 86.86%\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)\n",
    "\n",
    "#user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "083d0a3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9660 embeddings with positional data from imprinted layer.\n",
      "Assigned [369, 436, 441, 436, 448, 440, 448, 435, 432, 438, 438, 438, 443, 432, 493, 452, 446, 447, 427, 431, 444, 446] breached embeddings to each sentence.\n",
      "Replaced 70 tokens with avg. corr 0.07406255602836609 with new tokens with avg corr 0.33675870299339294\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6625 | S-BLEU: 0.36 | FMSE: 9.4901e-03 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.60| Token Acc: 87.40% | Label Acc: 87.40%\n"
     ]
    }
   ],
   "source": [
    "attacker.cfg.embedding_token_weight = 0.25\n",
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)\n",
    "\n",
    "#user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c6da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9660 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 512, 512, 1, 1, 1, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 441, 512, 512, 512, 512] breached embeddings to each sentence.\n",
      "Replaced 69 tokens with avg. corr 0.06986384093761444 with new tokens with avg corr 0.31250301003456116\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4726 | S-BLEU: 0.22 | FMSE: 1.5508e-02 | \n",
      " G-BLEU: 0.24 | ROUGE1: 0.54| ROUGE2: 0.23 | ROUGE-L: 0.44| Token Acc: 87.38% | Label Acc: 87.38%\n"
     ]
    }
   ],
   "source": [
    "attacker.cfg.embedding_token_weight = 0.25\n",
    "attacker.cfg.sentence_algorithm=\"k-means\"\n",
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "                                                      server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, cfg_case=cfg.case, setup=setup)\n",
    "\n",
    "#user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0c6a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attacker.cfg.embedding_token_weight = 0.0\n",
    "# attacker.cfg.sentence_algorithm=\"dynamic-threshold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f8dd841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 32-1e-05-1000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-50b83d69230e0003.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-bc2379d774fe375e.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-2646963aeb2db62a.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-f25c4eeab4499d7f.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 7.337190628051758, feature std is 137.18760681152344.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9654 embeddings with positional data from imprinted layer.\n",
      "Assigned [447, 385, 445, 430, 436, 454, 444, 439, 442, 429, 429, 438, 434, 451, 423, 443, 439, 440, 447, 442, 439, 478] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0181 | S-BLEU: 0.01 | FMSE: 1.1218e-03 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-c844f0c08e70b5b8.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-9db8f4b59c7e634a.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-01339f2983d5ccbf.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-f19e2be2d6a79922.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0042174761183559895, feature std is 0.10155291855335236.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9658 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 369, 199, 446, 301, 448, 438, 512, 512, 474, 438, 439, 512, 443, 448, 438, 459, 512, 444, 434, 435, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0128 | S-BLEU: 0.01 | FMSE: 6.4480e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-4ca0616f34218fbb.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-5272a8058f42c1f4.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-6bac458fa753dfab.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-8d6bd71cd26e7e62.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.900144290331809e-07, feature std is 0.00012547706137411296.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9590 embeddings with positional data from imprinted layer.\n",
      "Assigned [422, 437, 439, 447, 446, 437, 424, 452, 430, 436, 445, 435, 430, 433, 438, 439, 423, 433, 443, 429, 444, 428] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0145 | S-BLEU: 0.01 | FMSE: 9.5296e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-448cbbb71a6ded76.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-9c9ca007e2084c15.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-969885f6a51fa395.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-d746f7eff2c93614.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 88.32877349853516, feature std is 770.452392578125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9650 embeddings with positional data from imprinted layer.\n",
      "Assigned [408, 444, 423, 437, 433, 431, 444, 440, 429, 441, 447, 443, 436, 434, 438, 452, 466, 437, 459, 438, 448, 422] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6534 | S-BLEU: 0.35 | FMSE: 9.5915e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.37 | ROUGE-L: 0.59| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-1000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-db82a12fce6947ca.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-9972d7b825569ef9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-de2cbbcab2a94d0a.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-964297ce93a09a12.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.047953084111213684, feature std is 0.7348622679710388.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9658 embeddings with positional data from imprinted layer.\n",
      "Assigned [207, 444, 448, 441, 225, 512, 439, 439, 512, 453, 512, 438, 452, 512, 455, 454, 436, 445, 435, 512, 454, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6171 | S-BLEU: 0.32 | FMSE: 1.1875e-02 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.63| ROUGE2: 0.33 | ROUGE-L: 0.55| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-1000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-402ece7d9f83d106.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-2b57ceecf1a4cbf7.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-899f4d027850f497.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-732b18efdabd3a77.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.7307253882754594e-05, feature std is 0.0007698515546508133.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9679 embeddings with positional data from imprinted layer.\n",
      "Assigned [476, 440, 447, 445, 439, 444, 442, 429, 444, 435, 423, 440, 439, 411, 433, 437, 445, 448, 434, 445, 442, 441] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6579 | S-BLEU: 0.37 | FMSE: 9.4418e-03 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.59| Token Acc: 86.85% | Label Acc: 86.85%\n",
      "Checking 32-1e-05-1000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-16b52391e3beceeb.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-39fdc8d58846cc4f.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-1e1757bbcdf94273.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b7363800a13aaf66.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 34.42696762084961, feature std is 1048.4576416015625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9315 embeddings with positional data from imprinted layer.\n",
      "Assigned [356, 412, 423, 438, 423, 416, 494, 415, 434, 421, 430, 418, 429, 417, 443, 416, 412, 421, 424, 420, 428, 425] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5169 | S-BLEU: 0.17 | FMSE: 2.4653e-02 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.47| ROUGE2: 0.20 | ROUGE-L: 0.44| Token Acc: 66.97% | Label Acc: 66.97%\n",
      "Checking 32-1e-05-1000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-e464e2c1e9b17529.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-3ff05d8078cd1a20.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-48402d9ba6e611d0.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-6c25106fba67da85.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.07075333595275879, feature std is 0.9902721643447876.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9418 embeddings with positional data from imprinted layer.\n",
      "Assigned [265, 451, 463, 169, 437, 512, 433, 426, 433, 429, 444, 444, 421, 512, 425, 432, 438, 437, 412, 512, 512, 411] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5095 | S-BLEU: 0.17 | FMSE: 2.5081e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.47| ROUGE2: 0.20 | ROUGE-L: 0.43| Token Acc: 68.07% | Label Acc: 68.07%\n",
      "Checking 32-1e-05-1000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-18ff927017bc8aeb.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-f93044667be16605.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-d51bc92cc296c697.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b6b475004a1ccf48.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.484903805248905e-05, feature std is 0.0009906507330015302.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9482 embeddings with positional data from imprinted layer.\n",
      "Assigned [467, 434, 424, 444, 443, 422, 446, 431, 422, 433, 435, 432, 425, 414, 412, 424, 426, 422, 444, 413, 433, 436] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5376 | S-BLEU: 0.19 | FMSE: 2.2974e-02 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.49| ROUGE2: 0.22 | ROUGE-L: 0.46| Token Acc: 68.27% | Label Acc: 68.27%\n",
      "Checking 32-1e-05-1000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b5f1026dbda38335.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-6f17ea7ff15687c2.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b0f718db92a0fcc8.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-53f005fd5873cfad.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -54.211997985839844, feature std is 953.886474609375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8990 embeddings with positional data from imprinted layer.\n",
      "Assigned [452, 400, 384, 393, 424, 394, 415, 397, 419, 426, 412, 411, 416, 412, 407, 407, 387, 398, 417, 408, 413, 398] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4949 | S-BLEU: 0.15 | FMSE: 2.7163e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.73% | Label Acc: 63.73%\n",
      "Checking 32-1e-05-1000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-cda776524334c0e2.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-53d852f2b9f1aadb.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-42e4ef5e774eb185.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-151f8468b12e0189.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.007233045995235443, feature std is 1.0493074655532837.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered 8968 embeddings with positional data from imprinted layer.\n",
      "Assigned [247, 171, 409, 411, 512, 417, 421, 421, 415, 405, 512, 406, 421, 383, 427, 418, 401, 501, 422, 406, 427, 415] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4751 | S-BLEU: 0.14 | FMSE: 2.9051e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.66% | Label Acc: 63.66%\n",
      "Checking 32-1e-05-1000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-0a3437a8c6f1e2aa.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-a7644aca3b398184.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-4cbc815eacccda29.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-61c96caa5cd01ff7.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 6.299933829723159e-06, feature std is 0.001039755530655384.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8999 embeddings with positional data from imprinted layer.\n",
      "Assigned [230, 421, 512, 192, 414, 413, 400, 410, 416, 411, 409, 512, 418, 423, 432, 424, 415, 419, 411, 398, 407, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4779 | S-BLEU: 0.15 | FMSE: 2.7649e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.88% | Label Acc: 63.88%\n",
      "Checking 32-1e-05-1000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-5d4ac6219c35768d.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-28ebe3132367baee.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-0c04950ced16c643.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-42977b84e916e44e.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -37.56248092651367, feature std is 1026.8050537109375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9028 embeddings with positional data from imprinted layer.\n",
      "Assigned [415, 398, 416, 422, 234, 418, 512, 421, 403, 402, 402, 426, 472, 512, 430, 415, 401, 408, 430, 172, 512, 407] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4796 | S-BLEU: 0.15 | FMSE: 2.9466e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.73% | Label Acc: 63.73%\n",
      "Checking 32-1e-05-1000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-46a44e7eed5c3188.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-66c533a04b853056.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-6ce1eecc704acf7d.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-24f1fb90709a0238.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03818454220890999, feature std is 1.038419485092163.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9003 embeddings with positional data from imprinted layer.\n",
      "Assigned [310, 419, 424, 417, 409, 421, 512, 133, 417, 398, 408, 412, 417, 419, 415, 414, 512, 408, 414, 512, 404, 408] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4851 | S-BLEU: 0.14 | FMSE: 2.6137e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.45| ROUGE2: 0.17 | ROUGE-L: 0.42| Token Acc: 63.60% | Label Acc: 63.60%\n",
      "Checking 32-1e-05-1000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-1636b0a3d05b2bc2.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-a437dbcf58c99832.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-42965bf329466931.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-a0ec8cce0f2edf8f.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.196091711288318e-05, feature std is 0.0009838728001341224.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8969 embeddings with positional data from imprinted layer.\n",
      "Assigned [417, 433, 214, 419, 414, 512, 412, 207, 409, 413, 404, 409, 512, 409, 412, 422, 416, 407, 393, 512, 417, 406] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4745 | S-BLEU: 0.15 | FMSE: 2.7971e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.69% | Label Acc: 63.69%\n",
      "Checking 32-1e-05-10000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-5a09cb4aa5f50a71.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-c8d8f6c6c442e316.arrow\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-058620537fa471e4.arrow\n",
      "Loading cached processed dataset at /home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-e2152e557a56344c.arrow\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.8674380779266357, feature std is 94.07980346679688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9651 embeddings with positional data from imprinted layer.\n",
      "Assigned [397, 434, 438, 429, 435, 436, 442, 429, 436, 413, 449, 433, 449, 438, 443, 441, 433, 438, 452, 430, 444, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0139 | S-BLEU: 0.01 | FMSE: 4.7154e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-10000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0003700386150740087, feature std is 0.12759442627429962.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9629 embeddings with positional data from imprinted layer.\n",
      "Assigned [381, 442, 450, 430, 431, 442, 436, 442, 428, 455, 418, 437, 440, 434, 418, 434, 440, 492, 436, 452, 453, 438] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0161 | S-BLEU: 0.01 | FMSE: 1.0472e-03 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-10000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.2189567542009172e-06, feature std is 9.875197429209948e-05.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9630 embeddings with positional data from imprinted layer.\n",
      "Assigned [366, 439, 511, 444, 438, 441, 442, 425, 445, 449, 451, 429, 424, 434, 451, 451, 431, 438, 433, 424, 424, 440] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0125 | S-BLEU: 0.01 | FMSE: 6.0895e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-10000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 13.327655792236328, feature std is 682.8289184570312.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9703 embeddings with positional data from imprinted layer.\n",
      "Assigned [398, 448, 430, 492, 436, 444, 443, 443, 450, 452, 420, 423, 444, 458, 458, 435, 437, 445, 433, 435, 446, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6511 | S-BLEU: 0.35 | FMSE: 8.7165e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.65| ROUGE2: 0.37 | ROUGE-L: 0.58| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-10000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.0035454067401587963, feature std is 0.7598400115966797.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9675 embeddings with positional data from imprinted layer.\n",
      "Assigned [240, 512, 201, 448, 447, 446, 454, 512, 429, 441, 444, 449, 457, 443, 450, 512, 512, 458, 441, 426, 512, 441] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6183 | S-BLEU: 0.33 | FMSE: 1.1414e-02 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.64| ROUGE2: 0.34 | ROUGE-L: 0.56| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-10000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.174009857000783e-05, feature std is 0.000748530263081193.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9685 embeddings with positional data from imprinted layer.\n",
      "Assigned [416, 441, 440, 419, 431, 448, 432, 446, 445, 447, 428, 480, 443, 428, 460, 436, 447, 442, 444, 432, 435, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6556 | S-BLEU: 0.35 | FMSE: 9.9518e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.65| ROUGE2: 0.36 | ROUGE-L: 0.58| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-10000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -51.33457565307617, feature std is 1006.919677734375.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9505 embeddings with positional data from imprinted layer.\n",
      "Assigned [185, 512, 512, 424, 439, 422, 251, 441, 438, 445, 512, 442, 439, 457, 420, 437, 473, 512, 434, 436, 449, 425] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5249 | S-BLEU: 0.20 | FMSE: 2.4119e-02 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.48| ROUGE2: 0.22 | ROUGE-L: 0.45| Token Acc: 68.42% | Label Acc: 68.42%\n",
      "Checking 32-1e-05-10000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.02610151283442974, feature std is 0.9984118938446045.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9439 embeddings with positional data from imprinted layer.\n",
      "Assigned [429, 243, 512, 419, 186, 421, 426, 512, 512, 425, 458, 448, 492, 429, 440, 435, 418, 431, 437, 418, 436, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5129 | S-BLEU: 0.19 | FMSE: 2.4470e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.21 | ROUGE-L: 0.44| Token Acc: 66.89% | Label Acc: 66.89%\n",
      "Checking 32-1e-05-10000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.166178380022757e-05, feature std is 0.001050026505254209.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9516 embeddings with positional data from imprinted layer.\n",
      "Assigned [479, 431, 439, 444, 436, 433, 429, 436, 512, 444, 438, 420, 430, 416, 201, 432, 441, 433, 452, 432, 426, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5284 | S-BLEU: 0.19 | FMSE: 2.3768e-02 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.48| ROUGE2: 0.22 | ROUGE-L: 0.45| Token Acc: 68.49% | Label Acc: 68.49%\n",
      "Checking 32-1e-05-10000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -75.57132720947266, feature std is 1037.6324462890625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9017 embeddings with positional data from imprinted layer.\n",
      "Assigned [165, 512, 365, 412, 405, 423, 425, 412, 427, 413, 413, 512, 412, 397, 420, 431, 413, 422, 402, 408, 421, 407] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4833 | S-BLEU: 0.16 | FMSE: 2.6561e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.18 | ROUGE-L: 0.41| Token Acc: 63.69% | Label Acc: 63.69%\n",
      "Checking 32-1e-05-10000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.01692984625697136, feature std is 1.035488486289978.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9018 embeddings with positional data from imprinted layer.\n",
      "Assigned [409, 318, 393, 390, 398, 397, 414, 418, 498, 418, 407, 412, 411, 406, 419, 434, 429, 403, 406, 415, 409, 414] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4923 | S-BLEU: 0.15 | FMSE: 2.6758e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.65% | Label Acc: 63.65%\n",
      "Checking 32-1e-05-10000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 1.0042183475889033e-06, feature std is 0.0009741231333464384.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8960 embeddings with positional data from imprinted layer.\n",
      "Assigned [205, 426, 409, 417, 417, 414, 431, 421, 411, 418, 199, 411, 512, 401, 512, 512, 412, 395, 388, 428, 428, 393] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4672 | S-BLEU: 0.14 | FMSE: 2.7480e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.16 | ROUGE-L: 0.39| Token Acc: 63.57% | Label Acc: 63.57%\n",
      "Checking 32-1e-05-10000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 24.573665618896484, feature std is 1005.5177612304688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9005 embeddings with positional data from imprinted layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned [414, 407, 418, 206, 402, 512, 430, 441, 411, 418, 402, 512, 512, 410, 400, 416, 420, 406, 418, 219, 419, 412] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4816 | S-BLEU: 0.14 | FMSE: 2.6811e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.91% | Label Acc: 63.91%\n",
      "Checking 32-1e-05-10000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.06364689767360687, feature std is 1.0253955125808716.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8938 embeddings with positional data from imprinted layer.\n",
      "Assigned [421, 303, 403, 239, 409, 396, 512, 407, 404, 418, 410, 403, 418, 406, 400, 512, 404, 413, 405, 429, 407, 419] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4824 | S-BLEU: 0.15 | FMSE: 2.6594e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.77% | Label Acc: 63.77%\n",
      "Checking 32-1e-05-10000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.665000687964493e-06, feature std is 0.0010357388528063893.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8975 embeddings with positional data from imprinted layer.\n",
      "Assigned [254, 278, 406, 399, 415, 512, 420, 284, 512, 433, 512, 403, 407, 421, 426, 403, 422, 425, 404, 440, 403, 396] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4626 | S-BLEU: 0.15 | FMSE: 2.8964e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.42| ROUGE2: 0.17 | ROUGE-L: 0.39| Token Acc: 63.60% | Label Acc: 63.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 32-1e-05-100000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 3.6659605503082275, feature std is 108.03665924072266.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9633 embeddings with positional data from imprinted layer.\n",
      "Assigned [227, 363, 512, 441, 512, 290, 449, 433, 437, 512, 512, 454, 512, 465, 437, 447, 439, 433, 441, 446, 434, 437] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0167 | S-BLEU: 0.01 | FMSE: 7.0979e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-100000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.007322370074689388, feature std is 0.08953843265771866.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9626 embeddings with positional data from imprinted layer.\n",
      "Assigned [257, 348, 300, 512, 512, 452, 447, 512, 429, 428, 512, 440, 512, 437, 450, 440, 431, 448, 432, 442, 436, 449] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0130 | S-BLEU: 0.01 | FMSE: 5.2118e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-100000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.7556926549295895e-06, feature std is 0.00013091396249365062.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9644 embeddings with positional data from imprinted layer.\n",
      "Assigned [427, 436, 422, 452, 447, 466, 436, 435, 446, 433, 449, 406, 435, 431, 446, 429, 455, 433, 428, 442, 441, 449] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0153 | S-BLEU: 0.01 | FMSE: 1.0667e-03 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-100000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.706597328186035, feature std is 743.3299560546875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9660 embeddings with positional data from imprinted layer.\n",
      "Assigned [428, 438, 445, 454, 448, 421, 440, 437, 453, 431, 436, 448, 454, 442, 432, 424, 450, 425, 443, 450, 436, 425] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6555 | S-BLEU: 0.35 | FMSE: 9.1219e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.36 | ROUGE-L: 0.58| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-100000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.025208570063114166, feature std is 0.7117376923561096.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9645 embeddings with positional data from imprinted layer.\n",
      "Assigned [442, 512, 445, 512, 512, 438, 429, 445, 512, 267, 433, 445, 441, 494, 438, 512, 169, 451, 434, 440, 434, 440] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6242 | S-BLEU: 0.33 | FMSE: 9.8034e-03 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.63| ROUGE2: 0.34 | ROUGE-L: 0.56| Token Acc: 86.85% | Label Acc: 86.85%\n",
      "Checking 32-1e-05-100000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -5.905451689613983e-05, feature std is 0.0006845633615739644.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9700 embeddings with positional data from imprinted layer.\n",
      "Assigned [215, 445, 224, 452, 452, 439, 437, 450, 512, 439, 452, 447, 512, 512, 444, 469, 449, 443, 512, 512, 437, 446] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6271 | S-BLEU: 0.34 | FMSE: 1.0712e-02 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.64| ROUGE2: 0.35 | ROUGE-L: 0.56| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-100000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 92.08843231201172, feature std is 1005.04638671875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9349 embeddings with positional data from imprinted layer.\n",
      "Assigned [452, 426, 436, 414, 432, 418, 423, 420, 402, 414, 436, 419, 420, 416, 435, 422, 424, 407, 432, 426, 441, 434] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5287 | S-BLEU: 0.18 | FMSE: 2.4400e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.21 | ROUGE-L: 0.45| Token Acc: 67.58% | Label Acc: 67.58%\n",
      "Checking 32-1e-05-100000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.03964650630950928, feature std is 1.0589324235916138.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9407 embeddings with positional data from imprinted layer.\n",
      "Assigned [393, 436, 421, 430, 426, 426, 425, 428, 434, 419, 417, 421, 472, 431, 415, 420, 431, 425, 429, 438, 431, 439] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5204 | S-BLEU: 0.18 | FMSE: 2.4497e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.47| ROUGE2: 0.20 | ROUGE-L: 0.44| Token Acc: 66.23% | Label Acc: 66.23%\n",
      "Checking 32-1e-05-100000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.410118882944516e-07, feature std is 0.0010027928510680795.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9427 embeddings with positional data from imprinted layer.\n",
      "Assigned [266, 434, 512, 437, 163, 512, 435, 435, 425, 441, 432, 461, 425, 442, 421, 433, 512, 442, 424, 433, 512, 430] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5145 | S-BLEU: 0.18 | FMSE: 2.4693e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.47| ROUGE2: 0.21 | ROUGE-L: 0.44| Token Acc: 67.59% | Label Acc: 67.59%\n",
      "Checking 32-1e-05-100000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 53.10354995727539, feature std is 966.91064453125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8968 embeddings with positional data from imprinted layer.\n",
      "Assigned [192, 426, 396, 426, 419, 412, 418, 414, 512, 404, 427, 421, 410, 384, 512, 434, 416, 395, 228, 412, 398, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4731 | S-BLEU: 0.15 | FMSE: 2.6388e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.75% | Label Acc: 63.75%\n",
      "Checking 32-1e-05-100000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is 0.042414337396621704, feature std is 1.042128086090088.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8930 embeddings with positional data from imprinted layer.\n",
      "Assigned [392, 408, 276, 409, 418, 404, 410, 402, 408, 409, 391, 512, 390, 419, 407, 409, 420, 404, 393, 415, 416, 418] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4953 | S-BLEU: 0.14 | FMSE: 2.6504e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.46| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.79% | Label Acc: 63.79%\n",
      "Checking 32-1e-05-100000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.234052852960303e-05, feature std is 0.0010268307523801923.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8945 embeddings with positional data from imprinted layer.\n",
      "Assigned [412, 368, 414, 512, 410, 413, 512, 392, 227, 421, 404, 405, 407, 398, 417, 396, 415, 399, 412, 414, 396, 401] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4814 | S-BLEU: 0.15 | FMSE: 2.5846e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.56% | Label Acc: 63.56%\n",
      "Checking 32-1e-05-100000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -52.4931755065918, feature std is 1004.6544799804688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8995 embeddings with positional data from imprinted layer.\n",
      "Assigned [414, 409, 239, 512, 417, 408, 512, 397, 419, 182, 404, 423, 431, 404, 407, 438, 411, 406, 419, 512, 413, 418] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.4771 | S-BLEU: 0.15 | FMSE: 2.6941e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.71% | Label Acc: 63.71%\n",
      "Checking 32-1e-05-100000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.050762053579092026, feature std is 0.9848876595497131.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8924 embeddings with positional data from imprinted layer.\n",
      "Assigned [412, 394, 363, 404, 402, 406, 399, 422, 405, 399, 444, 396, 414, 403, 409, 403, 409, 419, 393, 422, 400, 406] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4871 | S-BLEU: 0.14 | FMSE: 2.7263e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.63% | Label Acc: 63.63%\n",
      "Checking 32-1e-05-100000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.1026597096351907e-05, feature std is 0.00102450221311301.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8955 embeddings with positional data from imprinted layer.\n",
      "Assigned [385, 435, 404, 420, 410, 410, 396, 399, 417, 402, 417, 397, 413, 410, 401, 405, 399, 416, 399, 418, 408, 394] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4893 | S-BLEU: 0.15 | FMSE: 2.7716e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.69% | Label Acc: 63.69%\n",
      "Checking 32-1e-05-1000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -4.767143249511719, feature std is 109.75137329101562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9640 embeddings with positional data from imprinted layer.\n",
      "Assigned [355, 449, 436, 430, 430, 445, 439, 434, 447, 443, 439, 437, 450, 435, 425, 439, 444, 444, 512, 436, 436, 435] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0117 | S-BLEU: 0.01 | FMSE: 8.6104e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.14| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.006500067189335823, feature std is 0.13126547634601593.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9696 embeddings with positional data from imprinted layer.\n",
      "Assigned [216, 512, 457, 439, 462, 245, 439, 431, 450, 453, 512, 444, 512, 438, 432, 445, 450, 443, 512, 450, 442, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0165 | S-BLEU: 0.01 | FMSE: 1.0750e-03 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.949843736947514e-06, feature std is 0.00014474896306637675.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9704 embeddings with positional data from imprinted layer.\n",
      "Assigned [422, 438, 450, 441, 435, 435, 438, 432, 444, 439, 439, 467, 436, 454, 436, 436, 433, 443, 439, 448, 446, 453] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0175 | S-BLEU: 0.01 | FMSE: 1.2785e-03 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -16.721118927001953, feature std is 900.3053588867188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9726 embeddings with positional data from imprinted layer.\n",
      "Assigned [450, 452, 444, 441, 447, 450, 447, 435, 439, 431, 436, 429, 438, 442, 433, 447, 457, 442, 443, 441, 441, 441] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6618 | S-BLEU: 0.36 | FMSE: 1.2060e-02 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.59| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-1000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.004889991134405136, feature std is 0.7075013518333435.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9615 embeddings with positional data from imprinted layer.\n",
      "Assigned [229, 436, 455, 438, 209, 446, 431, 512, 445, 439, 512, 444, 446, 505, 512, 440, 427, 450, 454, 512, 436, 437] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6147 | S-BLEU: 0.32 | FMSE: 1.0274e-02 | \n",
      " G-BLEU: 0.31 | ROUGE1: 0.63| ROUGE2: 0.33 | ROUGE-L: 0.55| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-1000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.490630115265958e-05, feature std is 0.0007656494271941483.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9655 embeddings with positional data from imprinted layer.\n",
      "Assigned [437, 446, 442, 175, 512, 445, 439, 512, 377, 440, 512, 447, 441, 438, 428, 428, 454, 441, 512, 438, 446, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6229 | S-BLEU: 0.33 | FMSE: 1.0240e-02 | \n",
      " G-BLEU: 0.33 | ROUGE1: 0.63| ROUGE2: 0.35 | ROUGE-L: 0.56| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-1000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 95.10264587402344, feature std is 1050.9434814453125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9449 embeddings with positional data from imprinted layer.\n",
      "Assigned [359, 424, 422, 501, 421, 428, 441, 428, 439, 436, 447, 410, 440, 436, 418, 428, 443, 434, 421, 403, 442, 428] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5392 | S-BLEU: 0.19 | FMSE: 2.5074e-02 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.50| ROUGE2: 0.23 | ROUGE-L: 0.46| Token Acc: 68.86% | Label Acc: 68.86%\n",
      "Checking 32-1e-05-1000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.028052741661667824, feature std is 1.0102280378341675.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9445 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 200, 233, 512, 432, 422, 435, 428, 430, 476, 409, 441, 435, 425, 512, 433, 440, 512, 431, 441, 436, 450] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5045 | S-BLEU: 0.17 | FMSE: 2.4657e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.46| ROUGE2: 0.20 | ROUGE-L: 0.43| Token Acc: 66.86% | Label Acc: 66.86%\n",
      "Checking 32-1e-05-1000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -4.14460118918214e-05, feature std is 0.0010124963009729981.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9500 embeddings with positional data from imprinted layer.\n",
      "Assigned [441, 224, 470, 421, 438, 220, 418, 420, 439, 512, 512, 446, 429, 443, 512, 434, 425, 446, 512, 443, 450, 445] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5342 | S-BLEU: 0.21 | FMSE: 2.4193e-02 | \n",
      " G-BLEU: 0.22 | ROUGE1: 0.49| ROUGE2: 0.23 | ROUGE-L: 0.45| Token Acc: 69.80% | Label Acc: 69.80%\n",
      "Checking 32-1e-05-1000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 33.65864562988281, feature std is 1095.984619140625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8951 embeddings with positional data from imprinted layer.\n",
      "Assigned [405, 415, 389, 240, 167, 512, 426, 415, 406, 412, 405, 413, 421, 512, 405, 390, 431, 415, 424, 415, 421, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4810 | S-BLEU: 0.15 | FMSE: 2.6726e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.88% | Label Acc: 63.88%\n",
      "Checking 32-1e-05-1000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.023753704503178596, feature std is 1.0467201471328735.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8995 embeddings with positional data from imprinted layer.\n",
      "Assigned [256, 407, 410, 512, 412, 159, 428, 443, 419, 421, 512, 419, 388, 409, 410, 400, 512, 409, 422, 416, 416, 415] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.4819 | S-BLEU: 0.15 | FMSE: 2.7743e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.18 | ROUGE-L: 0.41| Token Acc: 63.89% | Label Acc: 63.89%\n",
      "Checking 32-1e-05-1000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.087926572537981e-05, feature std is 0.0009931920794770122.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8953 embeddings with positional data from imprinted layer.\n",
      "Assigned [406, 425, 404, 420, 512, 238, 422, 395, 418, 387, 187, 394, 421, 512, 411, 512, 405, 426, 404, 419, 414, 421] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4739 | S-BLEU: 0.14 | FMSE: 2.7049e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.16 | ROUGE-L: 0.40| Token Acc: 63.72% | Label Acc: 63.72%\n",
      "Checking 32-1e-05-1000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -104.97863006591797, feature std is 990.4373779296875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8982 embeddings with positional data from imprinted layer.\n",
      "Assigned [401, 322, 406, 405, 391, 424, 393, 407, 419, 434, 401, 421, 393, 411, 397, 412, 403, 491, 412, 421, 400, 418] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4973 | S-BLEU: 0.16 | FMSE: 2.6180e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.71% | Label Acc: 63.71%\n",
      "Checking 32-1e-05-1000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.04717084765434265, feature std is 0.9997148513793945.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8941 embeddings with positional data from imprinted layer.\n",
      "Assigned [405, 166, 413, 512, 405, 401, 412, 512, 253, 401, 403, 430, 420, 408, 512, 412, 423, 402, 418, 413, 391, 429] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4722 | S-BLEU: 0.14 | FMSE: 2.6467e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.51% | Label Acc: 63.51%\n",
      "Checking 32-1e-05-1000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.558748358045705e-05, feature std is 0.0009859015699476004.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8956 embeddings with positional data from imprinted layer.\n",
      "Assigned [218, 188, 417, 409, 512, 407, 406, 512, 512, 403, 407, 416, 407, 441, 408, 428, 417, 402, 417, 394, 419, 416] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4784 | S-BLEU: 0.14 | FMSE: 2.7454e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.65% | Label Acc: 63.65%\n",
      "Checking 32-1e-05-10000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.0645270347595215, feature std is 112.08172607421875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9705 embeddings with positional data from imprinted layer.\n",
      "Assigned [378, 435, 446, 423, 448, 441, 511, 443, 440, 434, 447, 450, 434, 437, 448, 429, 453, 456, 434, 435, 437, 446] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0158 | S-BLEU: 0.01 | FMSE: 8.4537e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-10000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.00518452562391758, feature std is 0.09767995774745941.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9640 embeddings with positional data from imprinted layer.\n",
      "Assigned [405, 453, 436, 447, 437, 452, 445, 430, 427, 440, 442, 433, 437, 437, 481, 436, 433, 446, 437, 427, 445, 414] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0143 | S-BLEU: 0.01 | FMSE: 6.0815e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.39| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-10000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 5.373109956963162e-07, feature std is 0.00012213199806865305.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9656 embeddings with positional data from imprinted layer.\n",
      "Assigned [246, 340, 451, 450, 512, 439, 427, 304, 512, 437, 438, 432, 450, 450, 512, 458, 450, 445, 512, 442, 512, 437] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0182 | S-BLEU: 0.00 | FMSE: 9.3715e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-10000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 19.442407608032227, feature std is 882.8776245117188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9637 embeddings with positional data from imprinted layer.\n",
      "Assigned [512, 232, 512, 438, 205, 462, 447, 438, 451, 440, 512, 440, 427, 430, 451, 442, 429, 444, 512, 447, 454, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6199 | S-BLEU: 0.33 | FMSE: 1.4132e-02 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.63| ROUGE2: 0.34 | ROUGE-L: 0.55| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-10000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.010146435350179672, feature std is 0.757697343826294.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9712 embeddings with positional data from imprinted layer.\n",
      "Assigned [247, 442, 512, 443, 456, 453, 447, 442, 432, 196, 512, 512, 439, 512, 431, 445, 505, 444, 447, 440, 443, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6244 | S-BLEU: 0.33 | FMSE: 1.1434e-02 | \n",
      " G-BLEU: 0.32 | ROUGE1: 0.64| ROUGE2: 0.34 | ROUGE-L: 0.56| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-10000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 4.844007708015852e-05, feature std is 0.0007041340577416122.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9672 embeddings with positional data from imprinted layer.\n",
      "Assigned [426, 496, 427, 386, 457, 428, 438, 430, 428, 454, 450, 439, 439, 428, 455, 444, 441, 442, 439, 439, 443, 443] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6563 | S-BLEU: 0.36 | FMSE: 9.3380e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.65| ROUGE2: 0.37 | ROUGE-L: 0.58| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-10000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is -9.116655349731445, feature std is 997.0651245117188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9478 embeddings with positional data from imprinted layer.\n",
      "Assigned [431, 421, 227, 446, 438, 440, 206, 430, 413, 501, 512, 436, 446, 512, 435, 441, 512, 437, 422, 425, 512, 435] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5112 | S-BLEU: 0.19 | FMSE: 2.4647e-02 | \n",
      " G-BLEU: 0.21 | ROUGE1: 0.47| ROUGE2: 0.21 | ROUGE-L: 0.44| Token Acc: 67.76% | Label Acc: 67.76%\n",
      "Checking 32-1e-05-10000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.02030799724161625, feature std is 0.9923059940338135.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9457 embeddings with positional data from imprinted layer.\n",
      "Assigned [220, 446, 421, 417, 434, 426, 434, 433, 421, 442, 512, 512, 455, 427, 500, 429, 203, 428, 442, 431, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5156 | S-BLEU: 0.18 | FMSE: 2.3927e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.21 | ROUGE-L: 0.44| Token Acc: 68.51% | Label Acc: 68.51%\n",
      "Checking 32-1e-05-10000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -3.7463963963091373e-05, feature std is 0.0010071925353258848.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9451 embeddings with positional data from imprinted layer.\n",
      "Assigned [254, 301, 203, 127, 437, 512, 431, 428, 453, 424, 504, 512, 431, 512, 512, 512, 434, 484, 512, 444, 512, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.4830 | S-BLEU: 0.18 | FMSE: 2.5028e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.46| ROUGE2: 0.20 | ROUGE-L: 0.42| Token Acc: 69.89% | Label Acc: 69.89%\n",
      "Checking 32-1e-05-10000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 26.355207443237305, feature std is 1057.7969970703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9002 embeddings with positional data from imprinted layer.\n",
      "Assigned [480, 410, 389, 397, 411, 401, 331, 424, 400, 419, 417, 410, 412, 400, 433, 406, 392, 416, 422, 407, 410, 415] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4988 | S-BLEU: 0.15 | FMSE: 2.5772e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.46| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.93% | Label Acc: 63.93%\n",
      "Checking 32-1e-05-10000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.011387817561626434, feature std is 1.0189738273620605.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8970 embeddings with positional data from imprinted layer.\n",
      "Assigned [409, 512, 151, 409, 406, 403, 399, 272, 421, 422, 408, 428, 415, 512, 512, 392, 411, 418, 432, 417, 415, 406] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4760 | S-BLEU: 0.14 | FMSE: 2.6363e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.16 | ROUGE-L: 0.40| Token Acc: 63.78% | Label Acc: 63.78%\n",
      "Checking 32-1e-05-10000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 9.175853483611718e-05, feature std is 0.0009912544628605247.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8999 embeddings with positional data from imprinted layer.\n",
      "Assigned [424, 403, 399, 413, 293, 410, 117, 418, 512, 445, 512, 400, 512, 405, 415, 428, 420, 418, 412, 412, 412, 419] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4825 | S-BLEU: 0.16 | FMSE: 2.7264e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.18 | ROUGE-L: 0.41| Token Acc: 63.71% | Label Acc: 63.71%\n",
      "Checking 32-1e-05-10000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 32.0579948425293, feature std is 1024.4656982421875.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8981 embeddings with positional data from imprinted layer.\n",
      "Assigned [415, 177, 420, 412, 244, 390, 407, 394, 396, 416, 512, 412, 453, 396, 411, 512, 414, 425, 423, 512, 419, 421] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4762 | S-BLEU: 0.14 | FMSE: 2.7099e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.85% | Label Acc: 63.85%\n",
      "Checking 32-1e-05-10000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.005390901584178209, feature std is 0.9979456663131714.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9015 embeddings with positional data from imprinted layer.\n",
      "Assigned [394, 437, 175, 395, 241, 409, 473, 512, 403, 512, 406, 422, 410, 417, 421, 412, 407, 412, 512, 413, 415, 417] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4784 | S-BLEU: 0.14 | FMSE: 2.6793e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.43| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.64% | Label Acc: 63.64%\n",
      "Checking 32-1e-05-10000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 2.631662482599495e-06, feature std is 0.001034650718793273.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8916 embeddings with positional data from imprinted layer.\n",
      "Assigned [402, 401, 512, 167, 402, 393, 512, 397, 427, 423, 239, 412, 425, 411, 419, 407, 383, 413, 427, 418, 512, 414] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4771 | S-BLEU: 0.14 | FMSE: 2.6999e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.56% | Label Acc: 63.56%\n",
      "Checking 32-1e-05-100000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.4066507816314697, feature std is 107.10244750976562.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9654 embeddings with positional data from imprinted layer.\n",
      "Assigned [215, 419, 240, 512, 512, 438, 455, 448, 434, 512, 445, 427, 512, 461, 442, 440, 451, 452, 512, 441, 442, 444] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0116 | S-BLEU: 0.01 | FMSE: 7.3634e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-100000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0015452037332579494, feature std is 0.10532167553901672.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9593 embeddings with positional data from imprinted layer.\n",
      "Assigned [371, 422, 425, 424, 430, 441, 430, 424, 440, 508, 438, 438, 433, 433, 443, 447, 449, 455, 425, 432, 452, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0125 | S-BLEU: 0.01 | FMSE: 7.1293e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.02 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-100000000000.0-10-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -9.390226978212013e-07, feature std is 0.00010768164793262258.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9668 embeddings with positional data from imprinted layer.\n",
      "Assigned [404, 435, 433, 430, 437, 437, 435, 438, 428, 452, 437, 434, 461, 441, 440, 449, 447, 442, 444, 453, 450, 441] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0131 | S-BLEU: 0.01 | FMSE: 7.2166e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.14| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-100000000000.0-1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -15.81371784210205, feature std is 690.7560424804688.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9659 embeddings with positional data from imprinted layer.\n",
      "Assigned [443, 431, 436, 422, 433, 440, 436, 453, 443, 435, 433, 429, 448, 440, 452, 442, 441, 444, 441, 444, 441, 432] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6543 | S-BLEU: 0.35 | FMSE: 8.3041e-03 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.37 | ROUGE-L: 0.59| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-100000000000.0-1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature mean is 0.009296954609453678, feature std is 0.8311933875083923.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9688 embeddings with positional data from imprinted layer.\n",
      "Assigned [428, 433, 440, 446, 445, 431, 468, 438, 459, 427, 431, 442, 437, 446, 434, 442, 446, 430, 432, 446, 432, 455] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6567 | S-BLEU: 0.35 | FMSE: 1.2336e-02 | \n",
      " G-BLEU: 0.35 | ROUGE1: 0.66| ROUGE2: 0.38 | ROUGE-L: 0.60| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-100000000000.0-1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.8751532479654998e-05, feature std is 0.0009024784667417407.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9633 embeddings with positional data from imprinted layer.\n",
      "Assigned [435, 418, 448, 441, 441, 427, 420, 438, 434, 426, 430, 440, 442, 447, 444, 454, 435, 437, 454, 442, 433, 447] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.6530 | S-BLEU: 0.35 | FMSE: 1.2916e-02 | \n",
      " G-BLEU: 0.34 | ROUGE1: 0.66| ROUGE2: 0.36 | ROUGE-L: 0.58| Token Acc: 86.86% | Label Acc: 86.86%\n",
      "Checking 32-1e-05-100000000000.0-0.1-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -7.328407287597656, feature std is 944.7423095703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9364 embeddings with positional data from imprinted layer.\n",
      "Assigned [436, 420, 404, 425, 417, 346, 435, 434, 425, 425, 492, 423, 419, 417, 419, 433, 431, 435, 433, 440, 448, 407] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS: | Accuracy: 0.5191 | S-BLEU: 0.17 | FMSE: 2.4109e-02 | \n",
      " G-BLEU: 0.19 | ROUGE1: 0.47| ROUGE2: 0.20 | ROUGE-L: 0.44| Token Acc: 66.28% | Label Acc: 66.28%\n",
      "Checking 32-1e-05-100000000000.0-0.1-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.006055207923054695, feature std is 1.0059953927993774.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9460 embeddings with positional data from imprinted layer.\n",
      "Assigned [428, 390, 419, 434, 442, 436, 442, 440, 431, 422, 437, 417, 441, 427, 414, 424, 427, 429, 434, 475, 418, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5343 | S-BLEU: 0.18 | FMSE: 2.3566e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.21 | ROUGE-L: 0.45| Token Acc: 67.57% | Label Acc: 67.57%\n",
      "Checking 32-1e-05-100000000000.0-0.1-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -6.359649705700576e-05, feature std is 0.0009930538944900036.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9415 embeddings with positional data from imprinted layer.\n",
      "Assigned [373, 433, 409, 445, 432, 422, 436, 454, 464, 438, 427, 440, 421, 434, 439, 417, 415, 411, 420, 424, 428, 433] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.5202 | S-BLEU: 0.17 | FMSE: 2.4638e-02 | \n",
      " G-BLEU: 0.20 | ROUGE1: 0.48| ROUGE2: 0.20 | ROUGE-L: 0.44| Token Acc: 66.64% | Label Acc: 66.64%\n",
      "Checking 32-1e-05-100000000000.0-0.01-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -0.32418057322502136, feature std is 1058.9923095703125.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8996 embeddings with positional data from imprinted layer.\n",
      "Assigned [225, 408, 409, 402, 201, 435, 417, 408, 418, 404, 512, 407, 417, 411, 414, 421, 512, 419, 420, 421, 512, 403] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4772 | S-BLEU: 0.15 | FMSE: 2.7440e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.84% | Label Acc: 63.84%\n",
      "Checking 32-1e-05-100000000000.0-0.01-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.0009880176512524486, feature std is 0.998036801815033.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9017 embeddings with positional data from imprinted layer.\n",
      "Assigned [242, 421, 512, 411, 412, 408, 512, 422, 414, 412, 474, 406, 512, 404, 169, 423, 403, 414, 415, 396, 414, 421] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4782 | S-BLEU: 0.15 | FMSE: 2.7256e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.40| Token Acc: 63.68% | Label Acc: 63.68%\n",
      "Checking 32-1e-05-100000000000.0-0.01-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -2.4559503799537197e-05, feature std is 0.0010458030737936497.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8982 embeddings with positional data from imprinted layer.\n",
      "Assigned [234, 431, 418, 421, 423, 398, 512, 409, 181, 406, 425, 404, 423, 405, 411, 414, 409, 512, 422, 401, 411, 512] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4809 | S-BLEU: 0.14 | FMSE: 2.6721e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.64% | Label Acc: 63.64%\n",
      "Checking 32-1e-05-100000000000.0-0.001-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 21.731966018676758, feature std is 1057.179931640625.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8974 embeddings with positional data from imprinted layer.\n",
      "Assigned [419, 434, 404, 411, 404, 409, 417, 512, 512, 408, 426, 412, 233, 409, 414, 398, 283, 423, 414, 413, 402, 417] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4847 | S-BLEU: 0.15 | FMSE: 2.6805e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.81% | Label Acc: 63.81%\n",
      "Checking 32-1e-05-100000000000.0-0.001-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.041091881692409515, feature std is 0.9667670130729675.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8931 embeddings with positional data from imprinted layer.\n",
      "Assigned [442, 407, 419, 363, 417, 423, 391, 388, 399, 403, 403, 410, 394, 402, 407, 422, 403, 406, 402, 422, 408, 400] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4873 | S-BLEU: 0.14 | FMSE: 2.6928e-02 | \n",
      " G-BLEU: 0.17 | ROUGE1: 0.44| ROUGE2: 0.17 | ROUGE-L: 0.41| Token Acc: 63.64% | Label Acc: 63.64%\n",
      "Checking 32-1e-05-100000000000.0-0.001-0.001\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 9.48409979173448e-06, feature std is 0.0010145853739231825.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 8992 embeddings with positional data from imprinted layer.\n",
      "Assigned [352, 397, 411, 412, 388, 390, 405, 396, 408, 413, 412, 412, 420, 419, 447, 411, 413, 395, 398, 408, 421, 464] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.4935 | S-BLEU: 0.15 | FMSE: 2.6996e-02 | \n",
      " G-BLEU: 0.18 | ROUGE1: 0.45| ROUGE2: 0.18 | ROUGE-L: 0.42| Token Acc: 63.54% | Label Acc: 63.54%\n",
      "Checking 32-1e-05-1000000000000.0-10-1000.0\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is -1.0022677183151245, feature std is 103.35885620117188.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9691 embeddings with positional data from imprinted layer.\n",
      "Assigned [448, 464, 443, 442, 447, 415, 452, 436, 431, 454, 430, 446, 446, 445, 429, 449, 431, 426, 450, 442, 433, 432] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "METRICS: | Accuracy: 0.0139 | S-BLEU: 0.01 | FMSE: 6.8233e-04 | \n",
      " G-BLEU: 0.10 | ROUGE1: 0.38| ROUGE2: 0.01 | ROUGE-L: 0.15| Token Acc: 86.81% | Label Acc: 86.81%\n",
      "Checking 32-1e-05-1000000000000.0-10-1\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126 (last modified on Wed Jan 12 12:53:37 2022) since it couldn't be found locally at wikitext.\n",
      "Reusing dataset wikitext (/home/jonas/data/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Found attention of shape torch.Size([2304, 768]).\n",
      "Computing feature distribution before the probe layer Conv1D() from external data.\n",
      "Feature mean is 0.008995176292955875, feature std is 0.10370653867721558.\n",
      "Computing user update in model mode: eval.\n",
      "Recovered tokens tensor([    1,     1,     1,  ..., 50178, 50178, 50178]) through strategy embedding-norm.\n",
      "Recovered 9640 embeddings with positional data from imprinted layer.\n",
      "Assigned [433, 433, 450, 452, 445, 433, 441, 440, 437, 430, 427, 432, 438, 429, 428, 439, 434, 432, 437, 450, 449, 451] breached embeddings to each sentence.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/accuracy/3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Thu Jan  6 18:45:02 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/bleu/8bc44c0b5bba429a0a448e9968a8961bf9479d6ee30e00e93fed2c693040265a (last modified on Thu Jan  6 18:45:03 2022) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/google_bleu/bd7e6c5887f75974a6272946388ed86b5be85e95466b9f71edd4bd0ff5041640 (last modified on Thu Jan  6 18:45:22 2022) since it couldn't be found locally at google_bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jonas/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/015a527b2e180e7da27bda77c3fb309ebab15dba5d484fa6f3fec5e9f762c849 (last modified on Thu Jan  6 18:45:40 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "Checking 32-1e-05-1000000000000.0-10-0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25950/1987663728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreaching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mattacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreaching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/__init__.py\u001b[0m in \u001b[0;36mconstruct_case\u001b[0;34m(cfg_case, setup, external_dataloader)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_case\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"\"\"This is a helper function that summarizes the startup, but I find the full protocol to often be clearer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Server:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_case\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexternal_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/models/model_preparation.py\u001b[0m in \u001b[0;36mconstruct_model\u001b[0;34m(cfg_model, cfg_data, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_construct_vision_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_construct_text_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid data modality {cfg_data.modality}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/breaching/breaching/cases/models/model_preparation.py\u001b[0m in \u001b[0;36m_construct_text_model\u001b[0;34m(cfg_model, cfg_data, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mhf_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;31m# model.transformer.h[0].attn.scale_attn_weights = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcfg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_from_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# restore default dtype if it was modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_embd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;31m# Model parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_init_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# Initialize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;31m# Tie weights should be skipped when not initializing all weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_init_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Slightly different from the TF version which uses truncated_normal for initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# cf https://github.com/pytorch/pytorch/pull/5617\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# results_server = dict()\n",
    "# for v_length in [32, 48, 64]:\n",
    "#     for eps in [1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]:\n",
    "#         for softmax_skew in [1e6, 1e7, 1e8, 1e9, 1e10, 1e11, 1e12]:\n",
    "#             for sequence_token_weight in [10, 1, 0.1, 0.01, 1e-3]:\n",
    "#                 for measurement_scale in [1e3, 1, 1e-3]:\n",
    "#                     key = f\"{v_length}-{eps}-{softmax_skew}-{sequence_token_weight}-{measurement_scale}\"\n",
    "#                     print(f\"Checking {key}\")\n",
    "#                     cfg.attack.token_strategy=\"embedding-norm\"\n",
    "#                     cfg.case.server.param_modification.v_length = v_length\n",
    "\n",
    "#                     cfg.case.server.param_modification.eps = eps\n",
    "#                     cfg.case.server.param_modification.imprint_sentence_position = 0\n",
    "#                     cfg.case.server.param_modification.softmax_skew = softmax_skew\n",
    "#                     cfg.case.server.param_modification.sequence_token_weight = sequence_token_weight\n",
    "\n",
    "#                     cfg.case.server.param_modification.measurement_scale = measurement_scale\n",
    "\n",
    "#                     cfg.case.server.pretrained = False\n",
    "\n",
    "#                     user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "#                     attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "\n",
    "#                     server_payload = server.distribute_payload()\n",
    "\n",
    "#                     B = len(additional_data[\"input_ids\"]) // seq_length\n",
    "#                     user.data_key = \"input_ids\"\n",
    "#                     data = torch.as_tensor(additional_data[\"input_ids\"][:seq_length * B]).reshape(B, seq_length)\n",
    "#                     input_data = dict(input_ids=data, labels=data)\n",
    "#                     true_user_data = dict(data=input_data, labels=input_data)\n",
    "#                     server_payload[\"metadata\"].shape = [seq_length]\n",
    "#                     server.secrets[\"ImprintBlock\"][\"data_shape\"] = [seq_length]\n",
    "#                     user.num_data_points = B\n",
    "#                     shared_data, true_user_data = user.compute_local_updates(server_payload, custom_data=input_data)\n",
    "#                     shared_data[\"metadata\"][\"num_data_points\"] = B\n",
    "#                     try:\n",
    "#                         reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], \n",
    "#                                                                       server.secrets, dryrun=cfg.dryrun)\n",
    "\n",
    "#                         metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "#                                                             server.model, cfg_case=cfg.case, setup=setup)\n",
    "\n",
    "#                         results_server[key] = metrics[\"accuracy\"]\n",
    "#                     except:\n",
    "#                         results_server[key] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d53cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
